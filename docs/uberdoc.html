<!DOCTYPE html>
<html><head><meta charset="utf-8" content="text/html" http-equiv="Content-Type" /><meta content="An Integrated Suite of Rotational Analysis Tools." name="description" /><style type="text/css">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter a,
.syntaxhighlighter div,
.syntaxhighlighter code,
.syntaxhighlighter table,
.syntaxhighlighter table td,
.syntaxhighlighter table tr,
.syntaxhighlighter table tbody,
.syntaxhighlighter table thead,
.syntaxhighlighter table caption,
.syntaxhighlighter textarea {
  -moz-border-radius: 0 0 0 0 !important;
  -webkit-border-radius: 0 0 0 0 !important;
  background: none !important;
  border: 0 !important;
  bottom: auto !important;
  float: none !important;
  height: auto !important;
  left: auto !important;
  line-height: 1.1em !important;
/*  margin: 0 !important; */
  outline: 0 !important;
  overflow: visible !important;
  padding: 0 !important;
  position: static !important;
  right: auto !important;
  text-align: left !important;
  top: auto !important;
  vertical-align: baseline !important;
  width: auto !important;
  box-sizing: content-box !important;
  font-family: "Consolas", "Bitstream Vera Sans Mono", "Courier New", Courier, monospace !important;
  font-weight: normal !important;
  font-style: normal !important;
  min-height: inherit !important;
  min-height: auto !important;
}

.syntaxhighlighter {
/*  width: 100% !important; */
  margin: 1em 0 1em 0 !important;
  position: relative !important;
  overflow: auto !important;
}
.syntaxhighlighter.source {
  overflow: hidden !important;
}
.syntaxhighlighter .bold {
  font-weight: bold !important;
}
.syntaxhighlighter .italic {
  font-style: italic !important;
}
.syntaxhighlighter .line {
  white-space: pre !important;
}
.syntaxhighlighter table {
/*    width: 100% !important;*/
}
.syntaxhighlighter table caption {
  text-align: left !important;
  padding: .5em 0 0.5em 1em !important;
}
.syntaxhighlighter table td.code {
  width: 100% !important;
}
.syntaxhighlighter table td.code .container {
  position: relative !important;
}
.syntaxhighlighter table td.code .container textarea {
  box-sizing: border-box !important;
  position: absolute !important;
  left: 0 !important;
  top: 0 !important;
  width: 100% !important;
  height: 100% !important;
  border: none !important;
  background: white !important;
  padding-left: 1em !important;
  overflow: hidden !important;
  white-space: pre !important;
}
.syntaxhighlighter table td.gutter .line {
  text-align: right !important;
  padding: 0 0.5em 0 1em !important;
}
.syntaxhighlighter table td.code .line {
  padding: 0 1em !important;
}
.syntaxhighlighter.nogutter td.code .container textarea, .syntaxhighlighter.nogutter td.code .line {
  padding-left: 0em !important;
}
.syntaxhighlighter.show {
  display: block !important;
}
.syntaxhighlighter.collapsed table {
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar {
    display: none;
/*  padding: 0.1em 0.8em 0em 0.8em !important;
  font-size: 1em !important;
  position: static !important;
  width: auto !important;
  height: auto !important;*/
}
.syntaxhighlighter.collapsed .toolbar span {
  display: inline !important;
  margin-right: 1em !important;
}
.syntaxhighlighter.collapsed .toolbar span a {
  padding: 0 !important;
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar span a.expandSource {
  display: inline !important;
}
.syntaxhighlighter .toolbar {
    display: none;
/*  position: absolute !important;
  right: 1px !important;
  top: 1px !important;
  width: 11px !important;
  height: 11px !important;
  font-size: 10px !important;
  z-index: 10 !important;*/
}
.syntaxhighlighter .toolbar span.title {
  display: inline !important;
}
.syntaxhighlighter .toolbar a {
  display: block !important;
  text-align: center !important;
  text-decoration: none !important;
  padding-top: 1px !important;
}
.syntaxhighlighter .toolbar a.expandSource {
  display: none !important;
}
.syntaxhighlighter.ie {
  font-size: .9em !important;
  padding: 1px 0 1px 0 !important;
}
.syntaxhighlighter.ie .toolbar {
  line-height: 8px !important;
}
.syntaxhighlighter.ie .toolbar a {
  padding-top: 0px !important;
}
.syntaxhighlighter.printing .line.alt1 .content,
.syntaxhighlighter.printing .line.alt2 .content,
.syntaxhighlighter.printing .line.highlighted .number,
.syntaxhighlighter.printing .line.highlighted.alt1 .content,
.syntaxhighlighter.printing .line.highlighted.alt2 .content {
  background: none !important;
}
.syntaxhighlighter.printing .line .number {
  color: #bbbbbb !important;
}
.syntaxhighlighter.printing .line .content {
  color: black !important;
}
.syntaxhighlighter.printing .toolbar {
  display: none !important;
}
.syntaxhighlighter.printing a {
  text-decoration: none !important;
}
.syntaxhighlighter.printing .plain, .syntaxhighlighter.printing .plain a {
  color: black !important;
}
.syntaxhighlighter.printing .comments, .syntaxhighlighter.printing .comments a {
  color: #008200 !important;
}
.syntaxhighlighter.printing .string, .syntaxhighlighter.printing .string a {
  color: blue !important;
}
.syntaxhighlighter.printing .keyword {
  color: #006699 !important;
  font-weight: bold !important;
}
.syntaxhighlighter.printing .preprocessor {
  color: gray !important;
}
.syntaxhighlighter.printing .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter.printing .value {
  color: #009900 !important;
}
.syntaxhighlighter.printing .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .constants {
  color: #0066cc !important;
}
.syntaxhighlighter.printing .script {
  font-weight: bold !important;
}
.syntaxhighlighter.printing .color1, .syntaxhighlighter.printing .color1 a {
  color: gray !important;
}
.syntaxhighlighter.printing .color2, .syntaxhighlighter.printing .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .color3, .syntaxhighlighter.printing .color3 a {
  color: red !important;
}
.syntaxhighlighter.printing .break, .syntaxhighlighter.printing .break a {
  color: black !important;
}
</style><style type="text/css">.syntaxhighlighter{overflow:hidden !important;}</style><style type="text/css">/**
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt1 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt2 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.highlighted.alt1, .syntaxhighlighter .line.highlighted.alt2 {
  background-color: #c3defe !important;
}
.syntaxhighlighter .line.highlighted.number {
  color: white !important;
}
.syntaxhighlighter table caption {
  color: black !important;
}
.syntaxhighlighter .gutter {
  color: #787878 !important;
}
.syntaxhighlighter .gutter .line {
  border-right: 3px solid #d4d0c8 !important;
}
.syntaxhighlighter .gutter .line.highlighted {
  background-color: #d4d0c8 !important;
  color: white !important;
}
.syntaxhighlighter.printing .line .content {
  border: none !important;
}
.syntaxhighlighter.collapsed {
  overflow: visible !important;
}
.syntaxhighlighter.collapsed .toolbar {
  color: #3f5fbf !important;
  background: white !important;
  border: 1px solid #d4d0c8 !important;
}
.syntaxhighlighter.collapsed .toolbar a {
  color: #3f5fbf !important;
}
.syntaxhighlighter.collapsed .toolbar a:hover {
  color: #aa7700 !important;
}
.syntaxhighlighter .toolbar {
  color: #a0a0a0 !important;
  background: #d4d0c8 !important;
  border: none !important;
}
.syntaxhighlighter .toolbar a {
  color: #a0a0a0 !important;
}
.syntaxhighlighter .toolbar a:hover {
  color: red !important;
}
.syntaxhighlighter .plain, .syntaxhighlighter .plain a {
  color: black !important;
}
.syntaxhighlighter .comments, .syntaxhighlighter .comments a {
  color: #3f5fbf !important;
}
.syntaxhighlighter .string, .syntaxhighlighter .string a {
  color: #2a00ff !important;
}
.syntaxhighlighter .keyword {
  color: #7f0055 !important;
}
.syntaxhighlighter .preprocessor {
  color: #646464 !important;
}
.syntaxhighlighter .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter .value {
  color: #009900 !important;
}
.syntaxhighlighter .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter .constants {
  color: #0066cc !important;
}
.syntaxhighlighter .script {
  font-weight: bold !important;
  color: #7f0055 !important;
  background-color: none !important;
}
.syntaxhighlighter .color1, .syntaxhighlighter .color1 a {
  color: gray !important;
}
.syntaxhighlighter .color2, .syntaxhighlighter .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter .color3, .syntaxhighlighter .color3 a {
  color: red !important;
}

.syntaxhighlighter .xml .keyword {
  color: #3f7f7f !important;
  font-weight: normal !important;
}
.syntaxhighlighter .xml .color1, .syntaxhighlighter .xml .color1 a {
  color: #7f007f !important;
}
.syntaxhighlighter .xml .string {
  font-style: italic !important;
  color: #2a00ff !important;
}

.clojure.syntaxhighlighter .invalid { 
   background-color: #FAA !important;
}

.clojure.syntaxhighlighter .quoted {      
    font-style: italic !important;
}

.syntaxhighlighter .clojure.variable,
.syntaxhighlighter .clojure.symbol,
.syntaxhighlighter .clojure.value
{
    color: #006060 !important;
}

.syntaxhighlighter .clojure.string {
    color: #55B !important;
}

.syntaxhighlighter .clojure.functions {
    color: black !important;
}

.syntaxhighlighter .clojure.color1 {
    color: #666 !important;
}

.syntaxhighlighter .clojure.color3 {
    color: #900 !important;
}

.syntaxhighlighter .clojure.constants {
    color: #1A734D !important;
}

</style><style type="text/css">html{margin:0;padding:0;}h1{margin:0;padding:0;}h2{margin:0;padding:0;}h3{margin:0;padding:0;}h4{margin:0;padding:0;}a{color:#261A3B;}a:visited{color:#261A3B;}</style><style type="text/css">.header{margin-top:30px;}h1.project-name{font-size:34px;display:inline;}h2.project-version{font-size:18px;margin-top:0;display:inline;margin-left:10px;}.toc-link{font-size:12px;margin-left:10px;color:#252519;text-decoration:none;}.toc-link:hover{color:#5050A6;}.toc h1{font-size:34px;margin:0;}.docs-header{border-bottom:dotted #aaa 1px;padding-bottom:10px;margin-bottom:25px;}.toc h1{font-size:24px;}.toc{border-bottom:solid #bbb 1px;margin-bottom:40px;}.toc ul{margin-left:20px;padding-left:0px;padding-top:0;margin-top:0;}.toc li{list-style-type:none;padding-left:0;}.dependencies{}.dependencies table{font-size:16px;width:99.99%;border:none;margin-left:20px;}.dependencies td{padding-right:20px;;white-space:nowrap;}.dependencies .dotted{width:99%;}.dependencies .dotted hr{border-right:none;color:transparent;background-color:transparent;noshade:noshade;border-left:none;border-top:none;margin-bottom:-6px;height:0;border-bottom:dotted #bbb 1px;}.dependencies .dep-version{text-align:right;}.plugins ul{margin-left:20px;padding-left:0px;padding-top:0;margin-top:0;}.plugins li{list-style-type:none;padding-left:0;}.header p{margin-left:20px;}</style><style type="text/css">#floating-toc{position:fixed;top:10px;right:20px;height:20px;overflow:hidden;text-align:right;}#floating-toc li{list-style-type:none;margin:0;padding:0;}</style><style type="text/css">body{font-family:'Palatino Linotype', 'Book Antiqua', Palatino, FreeSerif, serif;;font-size:14px;color:#252519;}h1{font-size:20px;margin-top:0;}a.anchor{text-decoration:none;color:#252519;}a.anchor:hover{color:#5050A6;}table{border-spacing:0;border-bottom:solid #ddd 1px;;margin-bottom:10px;}code{display:inline;}p{margin-top:8px;}tr{margin:0px;padding:0px;}div.docs{vertical-align:top;margin:0px;padding-left:55px;padding-right:20px;border:none;background-color:white;}div.docs pre{font-size:12px;overflow:hidden;}.codes{border:none;margin:0px;margin-left:55px;padding-left:20px;border-left:solid #E5E5EE 6px;font-size:12pt;vertical-align:top;}td.spacer{padding-bottom:40px;}td.docs{width:410px;max-width:410px;vertical-align:top;margin:0px;padding-left:55px;padding-right:20px;border:none;background-color:#FFF;}td.docs pre{font-size:12px;overflow:hidden;}td.codes{vertical-align:top;font-size:10pt;overflow:hidden;background-color:#F5F5FF;width:55%;border-left:solid #E5E5EE 1px;padding-left:20px;border:none;margin:0px;}pre code{display:block;padding:4px;}code{border:solid #DEDEDE 1px;padding-left:3px;padding-right:3px;font-size:14px;}.syntaxhighlighter code{font-size:13px;}.footer{text-align:center;}</style><script type="text/javascript">/*! jQuery v1.7.1 jquery.com | jquery.org/license */
(function(a,b){function cy(a){return f.isWindow(a)?a:a.nodeType===9?a.defaultView||a.parentWindow:!1}function cv(a){if(!ck[a]){var b=c.body,d=f("<"+a+">").appendTo(b),e=d.css("display");d.remove();if(e==="none"||e===""){cl||(cl=c.createElement("iframe"),cl.frameBorder=cl.width=cl.height=0),b.appendChild(cl);if(!cm||!cl.createElement)cm=(cl.contentWindow||cl.contentDocument).document,cm.write((c.compatMode==="CSS1Compat"?"<!doctype html>":"")+"<html><body>"),cm.close();d=cm.createElement(a),cm.body.appendChild(d),e=f.css(d,"display"),b.removeChild(cl)}ck[a]=e}return ck[a]}function cu(a,b){var c={};f.each(cq.concat.apply([],cq.slice(0,b)),function(){c[this]=a});return c}function ct(){cr=b}function cs(){setTimeout(ct,0);return cr=f.now()}function cj(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}function ci(){try{return new a.XMLHttpRequest}catch(b){}}function cc(a,c){a.dataFilter&&(c=a.dataFilter(c,a.dataType));var d=a.dataTypes,e={},g,h,i=d.length,j,k=d[0],l,m,n,o,p;for(g=1;g<i;g++){if(g===1)for(h in a.converters)typeof h=="string"&&(e[h.toLowerCase()]=a.converters[h]);l=k,k=d[g];if(k==="*")k=l;else if(l!=="*"&&l!==k){m=l+" "+k,n=e[m]||e["* "+k];if(!n){p=b;for(o in e){j=o.split(" ");if(j[0]===l||j[0]==="*"){p=e[j[1]+" "+k];if(p){o=e[o],o===!0?n=p:p===!0&&(n=o);break}}}}!n&&!p&&f.error("No conversion from "+m.replace(" "," to ")),n!==!0&&(c=n?n(c):p(o(c)))}}return c}function cb(a,c,d){var e=a.contents,f=a.dataTypes,g=a.responseFields,h,i,j,k;for(i in g)i in d&&(c[g[i]]=d[i]);while(f[0]==="*")f.shift(),h===b&&(h=a.mimeType||c.getResponseHeader("content-type"));if(h)for(i in e)if(e[i]&&e[i].test(h)){f.unshift(i);break}if(f[0]in d)j=f[0];else{for(i in d){if(!f[0]||a.converters[i+" "+f[0]]){j=i;break}k||(k=i)}j=j||k}if(j){j!==f[0]&&f.unshift(j);return d[j]}}function ca(a,b,c,d){if(f.isArray(b))f.each(b,function(b,e){c||bE.test(a)?d(a,e):ca(a+"["+(typeof e=="object"||f.isArray(e)?b:"")+"]",e,c,d)});else if(!c&&b!=null&&typeof b=="object")for(var e in b)ca(a+"["+e+"]",b[e],c,d);else d(a,b)}function b_(a,c){var d,e,g=f.ajaxSettings.flatOptions||{};for(d in c)c[d]!==b&&((g[d]?a:e||(e={}))[d]=c[d]);e&&f.extend(!0,a,e)}function b$(a,c,d,e,f,g){f=f||c.dataTypes[0],g=g||{},g[f]=!0;var h=a[f],i=0,j=h?h.length:0,k=a===bT,l;for(;i<j&&(k||!l);i++)l=h[i](c,d,e),typeof l=="string"&&(!k||g[l]?l=b:(c.dataTypes.unshift(l),l=b$(a,c,d,e,l,g)));(k||!l)&&!g["*"]&&(l=b$(a,c,d,e,"*",g));return l}function bZ(a){return function(b,c){typeof b!="string"&&(c=b,b="*");if(f.isFunction(c)){var d=b.toLowerCase().split(bP),e=0,g=d.length,h,i,j;for(;e<g;e++)h=d[e],j=/^\+/.test(h),j&&(h=h.substr(1)||"*"),i=a[h]=a[h]||[],i[j?"unshift":"push"](c)}}}function bC(a,b,c){var d=b==="width"?a.offsetWidth:a.offsetHeight,e=b==="width"?bx:by,g=0,h=e.length;if(d>0){if(c!=="border")for(;g<h;g++)c||(d-=parseFloat(f.css(a,"padding"+e[g]))||0),c==="margin"?d+=parseFloat(f.css(a,c+e[g]))||0:d-=parseFloat(f.css(a,"border"+e[g]+"Width"))||0;return d+"px"}d=bz(a,b,b);if(d<0||d==null)d=a.style[b]||0;d=parseFloat(d)||0;if(c)for(;g<h;g++)d+=parseFloat(f.css(a,"padding"+e[g]))||0,c!=="padding"&&(d+=parseFloat(f.css(a,"border"+e[g]+"Width"))||0),c==="margin"&&(d+=parseFloat(f.css(a,c+e[g]))||0);return d+"px"}function bp(a,b){b.src?f.ajax({url:b.src,async:!1,dataType:"script"}):f.globalEval((b.text||b.textContent||b.innerHTML||"").replace(bf,"/*$0*/")),b.parentNode&&b.parentNode.removeChild(b)}function bo(a){var b=c.createElement("div");bh.appendChild(b),b.innerHTML=a.outerHTML;return b.firstChild}function bn(a){var b=(a.nodeName||"").toLowerCase();b==="input"?bm(a):b!=="script"&&typeof a.getElementsByTagName!="undefined"&&f.grep(a.getElementsByTagName("input"),bm)}function bm(a){if(a.type==="checkbox"||a.type==="radio")a.defaultChecked=a.checked}function bl(a){return typeof a.getElementsByTagName!="undefined"?a.getElementsByTagName("*"):typeof a.querySelectorAll!="undefined"?a.querySelectorAll("*"):[]}function bk(a,b){var c;if(b.nodeType===1){b.clearAttributes&&b.clearAttributes(),b.mergeAttributes&&b.mergeAttributes(a),c=b.nodeName.toLowerCase();if(c==="object")b.outerHTML=a.outerHTML;else if(c!=="input"||a.type!=="checkbox"&&a.type!=="radio"){if(c==="option")b.selected=a.defaultSelected;else if(c==="input"||c==="textarea")b.defaultValue=a.defaultValue}else a.checked&&(b.defaultChecked=b.checked=a.checked),b.value!==a.value&&(b.value=a.value);b.removeAttribute(f.expando)}}function bj(a,b){if(b.nodeType===1&&!!f.hasData(a)){var c,d,e,g=f._data(a),h=f._data(b,g),i=g.events;if(i){delete h.handle,h.events={};for(c in i)for(d=0,e=i[c].length;d<e;d++)f.event.add(b,c+(i[c][d].namespace?".":"")+i[c][d].namespace,i[c][d],i[c][d].data)}h.data&&(h.data=f.extend({},h.data))}}function bi(a,b){return f.nodeName(a,"table")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function U(a){var b=V.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}function T(a,b,c){b=b||0;if(f.isFunction(b))return f.grep(a,function(a,d){var e=!!b.call(a,d,a);return e===c});if(b.nodeType)return f.grep(a,function(a,d){return a===b===c});if(typeof b=="string"){var d=f.grep(a,function(a){return a.nodeType===1});if(O.test(b))return f.filter(b,d,!c);b=f.filter(b,d)}return f.grep(a,function(a,d){return f.inArray(a,b)>=0===c})}function S(a){return!a||!a.parentNode||a.parentNode.nodeType===11}function K(){return!0}function J(){return!1}function n(a,b,c){var d=b+"defer",e=b+"queue",g=b+"mark",h=f._data(a,d);h&&(c==="queue"||!f._data(a,e))&&(c==="mark"||!f._data(a,g))&&setTimeout(function(){!f._data(a,e)&&!f._data(a,g)&&(f.removeData(a,d,!0),h.fire())},0)}function m(a){for(var b in a){if(b==="data"&&f.isEmptyObject(a[b]))continue;if(b!=="toJSON")return!1}return!0}function l(a,c,d){if(d===b&&a.nodeType===1){var e="data-"+c.replace(k,"-$1").toLowerCase();d=a.getAttribute(e);if(typeof d=="string"){try{d=d==="true"?!0:d==="false"?!1:d==="null"?null:f.isNumeric(d)?parseFloat(d):j.test(d)?f.parseJSON(d):d}catch(g){}f.data(a,c,d)}else d=b}return d}function h(a){var b=g[a]={},c,d;a=a.split(/\s+/);for(c=0,d=a.length;c<d;c++)b[a[c]]=!0;return b}var c=a.document,d=a.navigator,e=a.location,f=function(){function J(){if(!e.isReady){try{c.documentElement.doScroll("left")}catch(a){setTimeout(J,1);return}e.ready()}}var e=function(a,b){return new e.fn.init(a,b,h)},f=a.jQuery,g=a.$,h,i=/^(?:[^#<]*(<[\w\W]+>)[^>]*$|#([\w\-]*)$)/,j=/\S/,k=/^\s+/,l=/\s+$/,m=/^<(\w+)\s*\/?>(?:<\/\1>)?$/,n=/^[\],:{}\s]*$/,o=/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,p=/"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,q=/(?:^|:|,)(?:\s*\[)+/g,r=/(webkit)[ \/]([\w.]+)/,s=/(opera)(?:.*version)?[ \/]([\w.]+)/,t=/(msie) ([\w.]+)/,u=/(mozilla)(?:.*? rv:([\w.]+))?/,v=/-([a-z]|[0-9])/ig,w=/^-ms-/,x=function(a,b){return(b+"").toUpperCase()},y=d.userAgent,z,A,B,C=Object.prototype.toString,D=Object.prototype.hasOwnProperty,E=Array.prototype.push,F=Array.prototype.slice,G=String.prototype.trim,H=Array.prototype.indexOf,I={};e.fn=e.prototype={constructor:e,init:function(a,d,f){var g,h,j,k;if(!a)return this;if(a.nodeType){this.context=this[0]=a,this.length=1;return this}if(a==="body"&&!d&&c.body){this.context=c,this[0]=c.body,this.selector=a,this.length=1;return this}if(typeof a=="string"){a.charAt(0)!=="<"||a.charAt(a.length-1)!==">"||a.length<3?g=i.exec(a):g=[null,a,null];if(g&&(g[1]||!d)){if(g[1]){d=d instanceof e?d[0]:d,k=d?d.ownerDocument||d:c,j=m.exec(a),j?e.isPlainObject(d)?(a=[c.createElement(j[1])],e.fn.attr.call(a,d,!0)):a=[k.createElement(j[1])]:(j=e.buildFragment([g[1]],[k]),a=(j.cacheable?e.clone(j.fragment):j.fragment).childNodes);return e.merge(this,a)}h=c.getElementById(g[2]);if(h&&h.parentNode){if(h.id!==g[2])return f.find(a);this.length=1,this[0]=h}this.context=c,this.selector=a;return this}return!d||d.jquery?(d||f).find(a):this.constructor(d).find(a)}if(e.isFunction(a))return f.ready(a);a.selector!==b&&(this.selector=a.selector,this.context=a.context);return e.makeArray(a,this)},selector:"",jquery:"1.7.1",length:0,size:function(){return this.length},toArray:function(){return F.call(this,0)},get:function(a){return a==null?this.toArray():a<0?this[this.length+a]:this[a]},pushStack:function(a,b,c){var d=this.constructor();e.isArray(a)?E.apply(d,a):e.merge(d,a),d.prevObject=this,d.context=this.context,b==="find"?d.selector=this.selector+(this.selector?" ":"")+c:b&&(d.selector=this.selector+"."+b+"("+c+")");return d},each:function(a,b){return e.each(this,a,b)},ready:function(a){e.bindReady(),A.add(a);return this},eq:function(a){a=+a;return a===-1?this.slice(a):this.slice(a,a+1)},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},slice:function(){return this.pushStack(F.apply(this,arguments),"slice",F.call(arguments).join(","))},map:function(a){return this.pushStack(e.map(this,function(b,c){return a.call(b,c,b)}))},end:function(){return this.prevObject||this.constructor(null)},push:E,sort:[].sort,splice:[].splice},e.fn.init.prototype=e.fn,e.extend=e.fn.extend=function(){var a,c,d,f,g,h,i=arguments[0]||{},j=1,k=arguments.length,l=!1;typeof i=="boolean"&&(l=i,i=arguments[1]||{},j=2),typeof i!="object"&&!e.isFunction(i)&&(i={}),k===j&&(i=this,--j);for(;j<k;j++)if((a=arguments[j])!=null)for(c in a){d=i[c],f=a[c];if(i===f)continue;l&&f&&(e.isPlainObject(f)||(g=e.isArray(f)))?(g?(g=!1,h=d&&e.isArray(d)?d:[]):h=d&&e.isPlainObject(d)?d:{},i[c]=e.extend(l,h,f)):f!==b&&(i[c]=f)}return i},e.extend({noConflict:function(b){a.$===e&&(a.$=g),b&&a.jQuery===e&&(a.jQuery=f);return e},isReady:!1,readyWait:1,holdReady:function(a){a?e.readyWait++:e.ready(!0)},ready:function(a){if(a===!0&&!--e.readyWait||a!==!0&&!e.isReady){if(!c.body)return setTimeout(e.ready,1);e.isReady=!0;if(a!==!0&&--e.readyWait>0)return;A.fireWith(c,[e]),e.fn.trigger&&e(c).trigger("ready").off("ready")}},bindReady:function(){if(!A){A=e.Callbacks("once memory");if(c.readyState==="complete")return setTimeout(e.ready,1);if(c.addEventListener)c.addEventListener("DOMContentLoaded",B,!1),a.addEventListener("load",e.ready,!1);else if(c.attachEvent){c.attachEvent("onreadystatechange",B),a.attachEvent("onload",e.ready);var b=!1;try{b=a.frameElement==null}catch(d){}c.documentElement.doScroll&&b&&J()}}},isFunction:function(a){return e.type(a)==="function"},isArray:Array.isArray||function(a){return e.type(a)==="array"},isWindow:function(a){return a&&typeof a=="object"&&"setInterval"in a},isNumeric:function(a){return!isNaN(parseFloat(a))&&isFinite(a)},type:function(a){return a==null?String(a):I[C.call(a)]||"object"},isPlainObject:function(a){if(!a||e.type(a)!=="object"||a.nodeType||e.isWindow(a))return!1;try{if(a.constructor&&!D.call(a,"constructor")&&!D.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}var d;for(d in a);return d===b||D.call(a,d)},isEmptyObject:function(a){for(var b in a)return!1;return!0},error:function(a){throw new Error(a)},parseJSON:function(b){if(typeof b!="string"||!b)return null;b=e.trim(b);if(a.JSON&&a.JSON.parse)return a.JSON.parse(b);if(n.test(b.replace(o,"@").replace(p,"]").replace(q,"")))return(new Function("return "+b))();e.error("Invalid JSON: "+b)},parseXML:function(c){var d,f;try{a.DOMParser?(f=new DOMParser,d=f.parseFromString(c,"text/xml")):(d=new ActiveXObject("Microsoft.XMLDOM"),d.async="false",d.loadXML(c))}catch(g){d=b}(!d||!d.documentElement||d.getElementsByTagName("parsererror").length)&&e.error("Invalid XML: "+c);return d},noop:function(){},globalEval:function(b){b&&j.test(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(w,"ms-").replace(v,x)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toUpperCase()===b.toUpperCase()},each:function(a,c,d){var f,g=0,h=a.length,i=h===b||e.isFunction(a);if(d){if(i){for(f in a)if(c.apply(a[f],d)===!1)break}else for(;g<h;)if(c.apply(a[g++],d)===!1)break}else if(i){for(f in a)if(c.call(a[f],f,a[f])===!1)break}else for(;g<h;)if(c.call(a[g],g,a[g++])===!1)break;return a},trim:G?function(a){return a==null?"":G.call(a)}:function(a){return a==null?"":(a+"").replace(k,"").replace(l,"")},makeArray:function(a,b){var c=b||[];if(a!=null){var d=e.type(a);a.length==null||d==="string"||d==="function"||d==="regexp"||e.isWindow(a)?E.call(c,a):e.merge(c,a)}return c},inArray:function(a,b,c){var d;if(b){if(H)return H.call(b,a,c);d=b.length,c=c?c<0?Math.max(0,d+c):c:0;for(;c<d;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,c){var d=a.length,e=0;if(typeof c.length=="number")for(var f=c.length;e<f;e++)a[d++]=c[e];else while(c[e]!==b)a[d++]=c[e++];a.length=d;return a},grep:function(a,b,c){var d=[],e;c=!!c;for(var f=0,g=a.length;f<g;f++)e=!!b(a[f],f),c!==e&&d.push(a[f]);return d},map:function(a,c,d){var f,g,h=[],i=0,j=a.length,k=a instanceof e||j!==b&&typeof j=="number"&&(j>0&&a[0]&&a[j-1]||j===0||e.isArray(a));if(k)for(;i<j;i++)f=c(a[i],i,d),f!=null&&(h[h.length]=f);else for(g in a)f=c(a[g],g,d),f!=null&&(h[h.length]=f);return h.concat.apply([],h)},guid:1,proxy:function(a,c){if(typeof c=="string"){var d=a[c];c=a,a=d}if(!e.isFunction(a))return b;var f=F.call(arguments,2),g=function(){return a.apply(c,f.concat(F.call(arguments)))};g.guid=a.guid=a.guid||g.guid||e.guid++;return g},access:function(a,c,d,f,g,h){var i=a.length;if(typeof c=="object"){for(var j in c)e.access(a,j,c[j],f,g,d);return a}if(d!==b){f=!h&&f&&e.isFunction(d);for(var k=0;k<i;k++)g(a[k],c,f?d.call(a[k],k,g(a[k],c)):d,h);return a}return i?g(a[0],c):b},now:function(){return(new Date).getTime()},uaMatch:function(a){a=a.toLowerCase();var b=r.exec(a)||s.exec(a)||t.exec(a)||a.indexOf("compatible")<0&&u.exec(a)||[];return{browser:b[1]||"",version:b[2]||"0"}},sub:function(){function a(b,c){return new a.fn.init(b,c)}e.extend(!0,a,this),a.superclass=this,a.fn=a.prototype=this(),a.fn.constructor=a,a.sub=this.sub,a.fn.init=function(d,f){f&&f instanceof e&&!(f instanceof a)&&(f=a(f));return e.fn.init.call(this,d,f,b)},a.fn.init.prototype=a.fn;var b=a(c);return a},browser:{}}),e.each("Boolean Number String Function Array Date RegExp Object".split(" "),function(a,b){I["[object "+b+"]"]=b.toLowerCase()}),z=e.uaMatch(y),z.browser&&(e.browser[z.browser]=!0,e.browser.version=z.version),e.browser.webkit&&(e.browser.safari=!0),j.test(" ")&&(k=/^[\s\xA0]+/,l=/[\s\xA0]+$/),h=e(c),c.addEventListener?B=function(){c.removeEventListener("DOMContentLoaded",B,!1),e.ready()}:c.attachEvent&&(B=function(){c.readyState==="complete"&&(c.detachEvent("onreadystatechange",B),e.ready())});return e}(),g={};f.Callbacks=function(a){a=a?g[a]||h(a):{};var c=[],d=[],e,i,j,k,l,m=function(b){var d,e,g,h,i;for(d=0,e=b.length;d<e;d++)g=b[d],h=f.type(g),h==="array"?m(g):h==="function"&&(!a.unique||!o.has(g))&&c.push(g)},n=function(b,f){f=f||[],e=!a.memory||[b,f],i=!0,l=j||0,j=0,k=c.length;for(;c&&l<k;l++)if(c[l].apply(b,f)===!1&&a.stopOnFalse){e=!0;break}i=!1,c&&(a.once?e===!0?o.disable():c=[]:d&&d.length&&(e=d.shift(),o.fireWith(e[0],e[1])))},o={add:function(){if(c){var a=c.length;m(arguments),i?k=c.length:e&&e!==!0&&(j=a,n(e[0],e[1]))}return this},remove:function(){if(c){var b=arguments,d=0,e=b.length;for(;d<e;d++)for(var f=0;f<c.length;f++)if(b[d]===c[f]){i&&f<=k&&(k--,f<=l&&l--),c.splice(f--,1);if(a.unique)break}}return this},has:function(a){if(c){var b=0,d=c.length;for(;b<d;b++)if(a===c[b])return!0}return!1},empty:function(){c=[];return this},disable:function(){c=d=e=b;return this},disabled:function(){return!c},lock:function(){d=b,(!e||e===!0)&&o.disable();return this},locked:function(){return!d},fireWith:function(b,c){d&&(i?a.once||d.push([b,c]):(!a.once||!e)&&n(b,c));return this},fire:function(){o.fireWith(this,arguments);return this},fired:function(){return!!e}};return o};var i=[].slice;f.extend({Deferred:function(a){var b=f.Callbacks("once memory"),c=f.Callbacks("once memory"),d=f.Callbacks("memory"),e="pending",g={resolve:b,reject:c,notify:d},h={done:b.add,fail:c.add,progress:d.add,state:function(){return e},isResolved:b.fired,isRejected:c.fired,then:function(a,b,c){i.done(a).fail(b).progress(c);return this},always:function(){i.done.apply(i,arguments).fail.apply(i,arguments);return this},pipe:function(a,b,c){return f.Deferred(function(d){f.each({done:[a,"resolve"],fail:[b,"reject"],progress:[c,"notify"]},function(a,b){var c=b[0],e=b[1],g;f.isFunction(c)?i[a](function(){g=c.apply(this,arguments),g&&f.isFunction(g.promise)?g.promise().then(d.resolve,d.reject,d.notify):d[e+"With"](this===i?d:this,[g])}):i[a](d[e])})}).promise()},promise:function(a){if(a==null)a=h;else for(var b in h)a[b]=h[b];return a}},i=h.promise({}),j;for(j in g)i[j]=g[j].fire,i[j+"With"]=g[j].fireWith;i.done(function(){e="resolved"},c.disable,d.lock).fail(function(){e="rejected"},b.disable,d.lock),a&&a.call(i,i);return i},when:function(a){function m(a){return function(b){e[a]=arguments.length>1?i.call(arguments,0):b,j.notifyWith(k,e)}}function l(a){return function(c){b[a]=arguments.length>1?i.call(arguments,0):c,--g||j.resolveWith(j,b)}}var b=i.call(arguments,0),c=0,d=b.length,e=Array(d),g=d,h=d,j=d<=1&&a&&f.isFunction(a.promise)?a:f.Deferred(),k=j.promise();if(d>1){for(;c<d;c++)b[c]&&b[c].promise&&f.isFunction(b[c].promise)?b[c].promise().then(l(c),j.reject,m(c)):--g;g||j.resolveWith(j,b)}else j!==a&&j.resolveWith(j,d?[a]:[]);return k}}),f.support=function(){var b,d,e,g,h,i,j,k,l,m,n,o,p,q=c.createElement("div"),r=c.documentElement;q.setAttribute("className","t"),q.innerHTML="   <link/><table></table><a href='/a' style='top:1px;float:left;opacity:.55;'>a</a><input type='checkbox'/>",d=q.getElementsByTagName("*"),e=q.getElementsByTagName("a")[0];if(!d||!d.length||!e)return{};g=c.createElement("select"),h=g.appendChild(c.createElement("option")),i=q.getElementsByTagName("input")[0],b={leadingWhitespace:q.firstChild.nodeType===3,tbody:!q.getElementsByTagName("tbody").length,htmlSerialize:!!q.getElementsByTagName("link").length,style:/top/.test(e.getAttribute("style")),hrefNormalized:e.getAttribute("href")==="/a",opacity:/^0.55/.test(e.style.opacity),cssFloat:!!e.style.cssFloat,checkOn:i.value==="on",optSelected:h.selected,getSetAttribute:q.className!=="t",enctype:!!c.createElement("form").enctype,html5Clone:c.createElement("nav").cloneNode(!0).outerHTML!=="<:nav></:nav>",submitBubbles:!0,changeBubbles:!0,focusinBubbles:!1,deleteExpando:!0,noCloneEvent:!0,inlineBlockNeedsLayout:!1,shrinkWrapBlocks:!1,reliableMarginRight:!0},i.checked=!0,b.noCloneChecked=i.cloneNode(!0).checked,g.disabled=!0,b.optDisabled=!h.disabled;try{delete q.test}catch(s){b.deleteExpando=!1}!q.addEventListener&&q.attachEvent&&q.fireEvent&&(q.attachEvent("onclick",function(){b.noCloneEvent=!1}),q.cloneNode(!0).fireEvent("onclick")),i=c.createElement("input"),i.value="t",i.setAttribute("type","radio"),b.radioValue=i.value==="t",i.setAttribute("checked","checked"),q.appendChild(i),k=c.createDocumentFragment(),k.appendChild(q.lastChild),b.checkClone=k.cloneNode(!0).cloneNode(!0).lastChild.checked,b.appendChecked=i.checked,k.removeChild(i),k.appendChild(q),q.innerHTML="",a.getComputedStyle&&(j=c.createElement("div"),j.style.width="0",j.style.marginRight="0",q.style.width="2px",q.appendChild(j),b.reliableMarginRight=(parseInt((a.getComputedStyle(j,null)||{marginRight:0}).marginRight,10)||0)===0);if(q.attachEvent)for(o in{submit:1,change:1,focusin:1})n="on"+o,p=n in q,p||(q.setAttribute(n,"return;"),p=typeof q[n]=="function"),b[o+"Bubbles"]=p;k.removeChild(q),k=g=h=j=q=i=null,f(function(){var a,d,e,g,h,i,j,k,m,n,o,r=c.getElementsByTagName("body")[0];!r||(j=1,k="position:absolute;top:0;left:0;width:1px;height:1px;margin:0;",m="visibility:hidden;border:0;",n="style='"+k+"border:5px solid #000;padding:0;'",o="<div "+n+"><div></div></div>"+"<table "+n+" cellpadding='0' cellspacing='0'>"+"<tr><td></td></tr></table>",a=c.createElement("div"),a.style.cssText=m+"width:0;height:0;position:static;top:0;margin-top:"+j+"px",r.insertBefore(a,r.firstChild),q=c.createElement("div"),a.appendChild(q),q.innerHTML="<table><tr><td style='padding:0;border:0;display:none'></td><td>t</td></tr></table>",l=q.getElementsByTagName("td"),p=l[0].offsetHeight===0,l[0].style.display="",l[1].style.display="none",b.reliableHiddenOffsets=p&&l[0].offsetHeight===0,q.innerHTML="",q.style.width=q.style.paddingLeft="1px",f.boxModel=b.boxModel=q.offsetWidth===2,typeof q.style.zoom!="undefined"&&(q.style.display="inline",q.style.zoom=1,b.inlineBlockNeedsLayout=q.offsetWidth===2,q.style.display="",q.innerHTML="<div style='width:4px;'></div>",b.shrinkWrapBlocks=q.offsetWidth!==2),q.style.cssText=k+m,q.innerHTML=o,d=q.firstChild,e=d.firstChild,h=d.nextSibling.firstChild.firstChild,i={doesNotAddBorder:e.offsetTop!==5,doesAddBorderForTableAndCells:h.offsetTop===5},e.style.position="fixed",e.style.top="20px",i.fixedPosition=e.offsetTop===20||e.offsetTop===15,e.style.position=e.style.top="",d.style.overflow="hidden",d.style.position="relative",i.subtractsBorderForOverflowNotVisible=e.offsetTop===-5,i.doesNotIncludeMarginInBodyOffset=r.offsetTop!==j,r.removeChild(a),q=a=null,f.extend(b,i))});return b}();var j=/^(?:\{.*\}|\[.*\])$/,k=/([A-Z])/g;f.extend({cache:{},uuid:0,expando:"jQuery"+(f.fn.jquery+Math.random()).replace(/\D/g,""),noData:{embed:!0,object:"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000",applet:!0},hasData:function(a){a=a.nodeType?f.cache[a[f.expando]]:a[f.expando];return!!a&&!m(a)},data:function(a,c,d,e){if(!!f.acceptData(a)){var g,h,i,j=f.expando,k=typeof c=="string",l=a.nodeType,m=l?f.cache:a,n=l?a[j]:a[j]&&j,o=c==="events";if((!n||!m[n]||!o&&!e&&!m[n].data)&&k&&d===b)return;n||(l?a[j]=n=++f.uuid:n=j),m[n]||(m[n]={},l||(m[n].toJSON=f.noop));if(typeof c=="object"||typeof c=="function")e?m[n]=f.extend(m[n],c):m[n].data=f.extend(m[n].data,c);g=h=m[n],e||(h.data||(h.data={}),h=h.data),d!==b&&(h[f.camelCase(c)]=d);if(o&&!h[c])return g.events;k?(i=h[c],i==null&&(i=h[f.camelCase(c)])):i=h;return i}},removeData:function(a,b,c){if(!!f.acceptData(a)){var d,e,g,h=f.expando,i=a.nodeType,j=i?f.cache:a,k=i?a[h]:h;if(!j[k])return;if(b){d=c?j[k]:j[k].data;if(d){f.isArray(b)||(b in d?b=[b]:(b=f.camelCase(b),b in d?b=[b]:b=b.split(" ")));for(e=0,g=b.length;e<g;e++)delete d[b[e]];if(!(c?m:f.isEmptyObject)(d))return}}if(!c){delete j[k].data;if(!m(j[k]))return}f.support.deleteExpando||!j.setInterval?delete j[k]:j[k]=null,i&&(f.support.deleteExpando?delete a[h]:a.removeAttribute?a.removeAttribute(h):a[h]=null)}},_data:function(a,b,c){return f.data(a,b,c,!0)},acceptData:function(a){if(a.nodeName){var b=f.noData[a.nodeName.toLowerCase()];if(b)return b!==!0&&a.getAttribute("classid")===b}return!0}}),f.fn.extend({data:function(a,c){var d,e,g,h=null;if(typeof a=="undefined"){if(this.length){h=f.data(this[0]);if(this[0].nodeType===1&&!f._data(this[0],"parsedAttrs")){e=this[0].attributes;for(var i=0,j=e.length;i<j;i++)g=e[i].name,g.indexOf("data-")===0&&(g=f.camelCase(g.substring(5)),l(this[0],g,h[g]));f._data(this[0],"parsedAttrs",!0)}}return h}if(typeof a=="object")return this.each(function(){f.data(this,a)});d=a.split("."),d[1]=d[1]?"."+d[1]:"";if(c===b){h=this.triggerHandler("getData"+d[1]+"!",[d[0]]),h===b&&this.length&&(h=f.data(this[0],a),h=l(this[0],a,h));return h===b&&d[1]?this.data(d[0]):h}return this.each(function(){var b=f(this),e=[d[0],c];b.triggerHandler("setData"+d[1]+"!",e),f.data(this,a,c),b.triggerHandler("changeData"+d[1]+"!",e)})},removeData:function(a){return this.each(function(){f.removeData(this,a)})}}),f.extend({_mark:function(a,b){a&&(b=(b||"fx")+"mark",f._data(a,b,(f._data(a,b)||0)+1))},_unmark:function(a,b,c){a!==!0&&(c=b,b=a,a=!1);if(b){c=c||"fx";var d=c+"mark",e=a?0:(f._data(b,d)||1)-1;e?f._data(b,d,e):(f.removeData(b,d,!0),n(b,c,"mark"))}},queue:function(a,b,c){var d;if(a){b=(b||"fx")+"queue",d=f._data(a,b),c&&(!d||f.isArray(c)?d=f._data(a,b,f.makeArray(c)):d.push(c));return d||[]}},dequeue:function(a,b){b=b||"fx";var c=f.queue(a,b),d=c.shift(),e={};d==="inprogress"&&(d=c.shift()),d&&(b==="fx"&&c.unshift("inprogress"),f._data(a,b+".run",e),d.call(a,function(){f.dequeue(a,b)},e)),c.length||(f.removeData(a,b+"queue "+b+".run",!0),n(a,b,"queue"))}}),f.fn.extend({queue:function(a,c){typeof a!="string"&&(c=a,a="fx");if(c===b)return f.queue(this[0],a);return this.each(function(){var b=f.queue(this,a,c);a==="fx"&&b[0]!=="inprogress"&&f.dequeue(this,a)})},dequeue:function(a){return this.each(function(){f.dequeue(this,a)})},delay:function(a,b){a=f.fx?f.fx.speeds[a]||a:a,b=b||"fx";return this.queue(b,function(b,c){var d=setTimeout(b,a);c.stop=function(){clearTimeout(d)}})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,c){function m(){--h||d.resolveWith(e,[e])}typeof a!="string"&&(c=a,a=b),a=a||"fx";var d=f.Deferred(),e=this,g=e.length,h=1,i=a+"defer",j=a+"queue",k=a+"mark",l;while(g--)if(l=f.data(e[g],i,b,!0)||(f.data(e[g],j,b,!0)||f.data(e[g],k,b,!0))&&f.data(e[g],i,f.Callbacks("once memory"),!0))h++,l.add(m);m();return d.promise()}});var o=/[\n\t\r]/g,p=/\s+/,q=/\r/g,r=/^(?:button|input)$/i,s=/^(?:button|input|object|select|textarea)$/i,t=/^a(?:rea)?$/i,u=/^(?:autofocus|autoplay|async|checked|controls|defer|disabled|hidden|loop|multiple|open|readonly|required|scoped|selected)$/i,v=f.support.getSetAttribute,w,x,y;f.fn.extend({attr:function(a,b){return f.access(this,a,b,!0,f.attr)},removeAttr:function(a){return this.each(function(){f.removeAttr(this,a)})},prop:function(a,b){return f.access(this,a,b,!0,f.prop)},removeProp:function(a){a=f.propFix[a]||a;return this.each(function(){try{this[a]=b,delete this[a]}catch(c){}})},addClass:function(a){var b,c,d,e,g,h,i;if(f.isFunction(a))return this.each(function(b){f(this).addClass(a.call(this,b,this.className))});if(a&&typeof a=="string"){b=a.split(p);for(c=0,d=this.length;c<d;c++){e=this[c];if(e.nodeType===1)if(!e.className&&b.length===1)e.className=a;else{g=" "+e.className+" ";for(h=0,i=b.length;h<i;h++)~g.indexOf(" "+b[h]+" ")||(g+=b[h]+" ");e.className=f.trim(g)}}}return this},removeClass:function(a){var c,d,e,g,h,i,j;if(f.isFunction(a))return this.each(function(b){f(this).removeClass(a.call(this,b,this.className))});if(a&&typeof a=="string"||a===b){c=(a||"").split(p);for(d=0,e=this.length;d<e;d++){g=this[d];if(g.nodeType===1&&g.className)if(a){h=(" "+g.className+" ").replace(o," ");for(i=0,j=c.length;i<j;i++)h=h.replace(" "+c[i]+" "," ");g.className=f.trim(h)}else g.className=""}}return this},toggleClass:function(a,b){var c=typeof a,d=typeof b=="boolean";if(f.isFunction(a))return this.each(function(c){f(this).toggleClass(a.call(this,c,this.className,b),b)});return this.each(function(){if(c==="string"){var e,g=0,h=f(this),i=b,j=a.split(p);while(e=j[g++])i=d?i:!h.hasClass(e),h[i?"addClass":"removeClass"](e)}else if(c==="undefined"||c==="boolean")this.className&&f._data(this,"__className__",this.className),this.className=this.className||a===!1?"":f._data(this,"__className__")||""})},hasClass:function(a){var b=" "+a+" ",c=0,d=this.length;for(;c<d;c++)if(this[c].nodeType===1&&(" "+this[c].className+" ").replace(o," ").indexOf(b)>-1)return!0;return!1},val:function(a){var c,d,e,g=this[0];{if(!!arguments.length){e=f.isFunction(a);return this.each(function(d){var g=f(this),h;if(this.nodeType===1){e?h=a.call(this,d,g.val()):h=a,h==null?h="":typeof h=="number"?h+="":f.isArray(h)&&(h=f.map(h,function(a){return a==null?"":a+""})),c=f.valHooks[this.nodeName.toLowerCase()]||f.valHooks[this.type];if(!c||!("set"in c)||c.set(this,h,"value")===b)this.value=h}})}if(g){c=f.valHooks[g.nodeName.toLowerCase()]||f.valHooks[g.type];if(c&&"get"in c&&(d=c.get(g,"value"))!==b)return d;d=g.value;return typeof d=="string"?d.replace(q,""):d==null?"":d}}}}),f.extend({valHooks:{option:{get:function(a){var b=a.attributes.value;return!b||b.specified?a.value:a.text}},select:{get:function(a){var b,c,d,e,g=a.selectedIndex,h=[],i=a.options,j=a.type==="select-one";if(g<0)return null;c=j?g:0,d=j?g+1:i.length;for(;c<d;c++){e=i[c];if(e.selected&&(f.support.optDisabled?!e.disabled:e.getAttribute("disabled")===null)&&(!e.parentNode.disabled||!f.nodeName(e.parentNode,"optgroup"))){b=f(e).val();if(j)return b;h.push(b)}}if(j&&!h.length&&i.length)return f(i[g]).val();return h},set:function(a,b){var c=f.makeArray(b);f(a).find("option").each(function(){this.selected=f.inArray(f(this).val(),c)>=0}),c.length||(a.selectedIndex=-1);return c}}},attrFn:{val:!0,css:!0,html:!0,text:!0,data:!0,width:!0,height:!0,offset:!0},attr:function(a,c,d,e){var g,h,i,j=a.nodeType;if(!!a&&j!==3&&j!==8&&j!==2){if(e&&c in f.attrFn)return f(a)[c](d);if(typeof a.getAttribute=="undefined")return f.prop(a,c,d);i=j!==1||!f.isXMLDoc(a),i&&(c=c.toLowerCase(),h=f.attrHooks[c]||(u.test(c)?x:w));if(d!==b){if(d===null){f.removeAttr(a,c);return}if(h&&"set"in h&&i&&(g=h.set(a,d,c))!==b)return g;a.setAttribute(c,""+d);return d}if(h&&"get"in h&&i&&(g=h.get(a,c))!==null)return g;g=a.getAttribute(c);return g===null?b:g}},removeAttr:function(a,b){var c,d,e,g,h=0;if(b&&a.nodeType===1){d=b.toLowerCase().split(p),g=d.length;for(;h<g;h++)e=d[h],e&&(c=f.propFix[e]||e,f.attr(a,e,""),a.removeAttribute(v?e:c),u.test(e)&&c in a&&(a[c]=!1))}},attrHooks:{type:{set:function(a,b){if(r.test(a.nodeName)&&a.parentNode)f.error("type property can't be changed");else if(!f.support.radioValue&&b==="radio"&&f.nodeName(a,"input")){var c=a.value;a.setAttribute("type",b),c&&(a.value=c);return b}}},value:{get:function(a,b){if(w&&f.nodeName(a,"button"))return w.get(a,b);return b in a?a.value:null},set:function(a,b,c){if(w&&f.nodeName(a,"button"))return w.set(a,b,c);a.value=b}}},propFix:{tabindex:"tabIndex",readonly:"readOnly","for":"htmlFor","class":"className",maxlength:"maxLength",cellspacing:"cellSpacing",cellpadding:"cellPadding",rowspan:"rowSpan",colspan:"colSpan",usemap:"useMap",frameborder:"frameBorder",contenteditable:"contentEditable"},prop:function(a,c,d){var e,g,h,i=a.nodeType;if(!!a&&i!==3&&i!==8&&i!==2){h=i!==1||!f.isXMLDoc(a),h&&(c=f.propFix[c]||c,g=f.propHooks[c]);return d!==b?g&&"set"in g&&(e=g.set(a,d,c))!==b?e:a[c]=d:g&&"get"in g&&(e=g.get(a,c))!==null?e:a[c]}},propHooks:{tabIndex:{get:function(a){var c=a.getAttributeNode("tabindex");return c&&c.specified?parseInt(c.value,10):s.test(a.nodeName)||t.test(a.nodeName)&&a.href?0:b}}}}),f.attrHooks.tabindex=f.propHooks.tabIndex,x={get:function(a,c){var d,e=f.prop(a,c);return e===!0||typeof e!="boolean"&&(d=a.getAttributeNode(c))&&d.nodeValue!==!1?c.toLowerCase():b},set:function(a,b,c){var d;b===!1?f.removeAttr(a,c):(d=f.propFix[c]||c,d in a&&(a[d]=!0),a.setAttribute(c,c.toLowerCase()));return c}},v||(y={name:!0,id:!0},w=f.valHooks.button={get:function(a,c){var d;d=a.getAttributeNode(c);return d&&(y[c]?d.nodeValue!=="":d.specified)?d.nodeValue:b},set:function(a,b,d){var e=a.getAttributeNode(d);e||(e=c.createAttribute(d),a.setAttributeNode(e));return e.nodeValue=b+""}},f.attrHooks.tabindex.set=w.set,f.each(["width","height"],function(a,b){f.attrHooks[b]=f.extend(f.attrHooks[b],{set:function(a,c){if(c===""){a.setAttribute(b,"auto");return c}}})}),f.attrHooks.contenteditable={get:w.get,set:function(a,b,c){b===""&&(b="false"),w.set(a,b,c)}}),f.support.hrefNormalized||f.each(["href","src","width","height"],function(a,c){f.attrHooks[c]=f.extend(f.attrHooks[c],{get:function(a){var d=a.getAttribute(c,2);return d===null?b:d}})}),f.support.style||(f.attrHooks.style={get:function(a){return a.style.cssText.toLowerCase()||b},set:function(a,b){return a.style.cssText=""+b}}),f.support.optSelected||(f.propHooks.selected=f.extend(f.propHooks.selected,{get:function(a){var b=a.parentNode;b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex);return null}})),f.support.enctype||(f.propFix.enctype="encoding"),f.support.checkOn||f.each(["radio","checkbox"],function(){f.valHooks[this]={get:function(a){return a.getAttribute("value")===null?"on":a.value}}}),f.each(["radio","checkbox"],function(){f.valHooks[this]=f.extend(f.valHooks[this],{set:function(a,b){if(f.isArray(b))return a.checked=f.inArray(f(a).val(),b)>=0}})});var z=/^(?:textarea|input|select)$/i,A=/^([^\.]*)?(?:\.(.+))?$/,B=/\bhover(\.\S+)?\b/,C=/^key/,D=/^(?:mouse|contextmenu)|click/,E=/^(?:focusinfocus|focusoutblur)$/,F=/^(\w*)(?:#([\w\-]+))?(?:\.([\w\-]+))?$/,G=function(a){var b=F.exec(a);b&&(b[1]=(b[1]||"").toLowerCase(),b[3]=b[3]&&new RegExp("(?:^|\\s)"+b[3]+"(?:\\s|$)"));return b},H=function(a,b){var c=a.attributes||{};return(!b[1]||a.nodeName.toLowerCase()===b[1])&&(!b[2]||(c.id||{}).value===b[2])&&(!b[3]||b[3].test((c["class"]||{}).value))},I=function(a){return f.event.special.hover?a:a.replace(B,"mouseenter$1 mouseleave$1")};
f.event={add:function(a,c,d,e,g){var h,i,j,k,l,m,n,o,p,q,r,s;if(!(a.nodeType===3||a.nodeType===8||!c||!d||!(h=f._data(a)))){d.handler&&(p=d,d=p.handler),d.guid||(d.guid=f.guid++),j=h.events,j||(h.events=j={}),i=h.handle,i||(h.handle=i=function(a){return typeof f!="undefined"&&(!a||f.event.triggered!==a.type)?f.event.dispatch.apply(i.elem,arguments):b},i.elem=a),c=f.trim(I(c)).split(" ");for(k=0;k<c.length;k++){l=A.exec(c[k])||[],m=l[1],n=(l[2]||"").split(".").sort(),s=f.event.special[m]||{},m=(g?s.delegateType:s.bindType)||m,s=f.event.special[m]||{},o=f.extend({type:m,origType:l[1],data:e,handler:d,guid:d.guid,selector:g,quick:G(g),namespace:n.join(".")},p),r=j[m];if(!r){r=j[m]=[],r.delegateCount=0;if(!s.setup||s.setup.call(a,e,n,i)===!1)a.addEventListener?a.addEventListener(m,i,!1):a.attachEvent&&a.attachEvent("on"+m,i)}s.add&&(s.add.call(a,o),o.handler.guid||(o.handler.guid=d.guid)),g?r.splice(r.delegateCount++,0,o):r.push(o),f.event.global[m]=!0}a=null}},global:{},remove:function(a,b,c,d,e){var g=f.hasData(a)&&f._data(a),h,i,j,k,l,m,n,o,p,q,r,s;if(!!g&&!!(o=g.events)){b=f.trim(I(b||"")).split(" ");for(h=0;h<b.length;h++){i=A.exec(b[h])||[],j=k=i[1],l=i[2];if(!j){for(j in o)f.event.remove(a,j+b[h],c,d,!0);continue}p=f.event.special[j]||{},j=(d?p.delegateType:p.bindType)||j,r=o[j]||[],m=r.length,l=l?new RegExp("(^|\\.)"+l.split(".").sort().join("\\.(?:.*\\.)?")+"(\\.|$)"):null;for(n=0;n<r.length;n++)s=r[n],(e||k===s.origType)&&(!c||c.guid===s.guid)&&(!l||l.test(s.namespace))&&(!d||d===s.selector||d==="**"&&s.selector)&&(r.splice(n--,1),s.selector&&r.delegateCount--,p.remove&&p.remove.call(a,s));r.length===0&&m!==r.length&&((!p.teardown||p.teardown.call(a,l)===!1)&&f.removeEvent(a,j,g.handle),delete o[j])}f.isEmptyObject(o)&&(q=g.handle,q&&(q.elem=null),f.removeData(a,["events","handle"],!0))}},customEvent:{getData:!0,setData:!0,changeData:!0},trigger:function(c,d,e,g){if(!e||e.nodeType!==3&&e.nodeType!==8){var h=c.type||c,i=[],j,k,l,m,n,o,p,q,r,s;if(E.test(h+f.event.triggered))return;h.indexOf("!")>=0&&(h=h.slice(0,-1),k=!0),h.indexOf(".")>=0&&(i=h.split("."),h=i.shift(),i.sort());if((!e||f.event.customEvent[h])&&!f.event.global[h])return;c=typeof c=="object"?c[f.expando]?c:new f.Event(h,c):new f.Event(h),c.type=h,c.isTrigger=!0,c.exclusive=k,c.namespace=i.join("."),c.namespace_re=c.namespace?new RegExp("(^|\\.)"+i.join("\\.(?:.*\\.)?")+"(\\.|$)"):null,o=h.indexOf(":")<0?"on"+h:"";if(!e){j=f.cache;for(l in j)j[l].events&&j[l].events[h]&&f.event.trigger(c,d,j[l].handle.elem,!0);return}c.result=b,c.target||(c.target=e),d=d!=null?f.makeArray(d):[],d.unshift(c),p=f.event.special[h]||{};if(p.trigger&&p.trigger.apply(e,d)===!1)return;r=[[e,p.bindType||h]];if(!g&&!p.noBubble&&!f.isWindow(e)){s=p.delegateType||h,m=E.test(s+h)?e:e.parentNode,n=null;for(;m;m=m.parentNode)r.push([m,s]),n=m;n&&n===e.ownerDocument&&r.push([n.defaultView||n.parentWindow||a,s])}for(l=0;l<r.length&&!c.isPropagationStopped();l++)m=r[l][0],c.type=r[l][1],q=(f._data(m,"events")||{})[c.type]&&f._data(m,"handle"),q&&q.apply(m,d),q=o&&m[o],q&&f.acceptData(m)&&q.apply(m,d)===!1&&c.preventDefault();c.type=h,!g&&!c.isDefaultPrevented()&&(!p._default||p._default.apply(e.ownerDocument,d)===!1)&&(h!=="click"||!f.nodeName(e,"a"))&&f.acceptData(e)&&o&&e[h]&&(h!=="focus"&&h!=="blur"||c.target.offsetWidth!==0)&&!f.isWindow(e)&&(n=e[o],n&&(e[o]=null),f.event.triggered=h,e[h](),f.event.triggered=b,n&&(e[o]=n));return c.result}},dispatch:function(c){c=f.event.fix(c||a.event);var d=(f._data(this,"events")||{})[c.type]||[],e=d.delegateCount,g=[].slice.call(arguments,0),h=!c.exclusive&&!c.namespace,i=[],j,k,l,m,n,o,p,q,r,s,t;g[0]=c,c.delegateTarget=this;if(e&&!c.target.disabled&&(!c.button||c.type!=="click")){m=f(this),m.context=this.ownerDocument||this;for(l=c.target;l!=this;l=l.parentNode||this){o={},q=[],m[0]=l;for(j=0;j<e;j++)r=d[j],s=r.selector,o[s]===b&&(o[s]=r.quick?H(l,r.quick):m.is(s)),o[s]&&q.push(r);q.length&&i.push({elem:l,matches:q})}}d.length>e&&i.push({elem:this,matches:d.slice(e)});for(j=0;j<i.length&&!c.isPropagationStopped();j++){p=i[j],c.currentTarget=p.elem;for(k=0;k<p.matches.length&&!c.isImmediatePropagationStopped();k++){r=p.matches[k];if(h||!c.namespace&&!r.namespace||c.namespace_re&&c.namespace_re.test(r.namespace))c.data=r.data,c.handleObj=r,n=((f.event.special[r.origType]||{}).handle||r.handler).apply(p.elem,g),n!==b&&(c.result=n,n===!1&&(c.preventDefault(),c.stopPropagation()))}}return c.result},props:"attrChange attrName relatedNode srcElement altKey bubbles cancelable ctrlKey currentTarget eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){a.which==null&&(a.which=b.charCode!=null?b.charCode:b.keyCode);return a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,d){var e,f,g,h=d.button,i=d.fromElement;a.pageX==null&&d.clientX!=null&&(e=a.target.ownerDocument||c,f=e.documentElement,g=e.body,a.pageX=d.clientX+(f&&f.scrollLeft||g&&g.scrollLeft||0)-(f&&f.clientLeft||g&&g.clientLeft||0),a.pageY=d.clientY+(f&&f.scrollTop||g&&g.scrollTop||0)-(f&&f.clientTop||g&&g.clientTop||0)),!a.relatedTarget&&i&&(a.relatedTarget=i===a.target?d.toElement:i),!a.which&&h!==b&&(a.which=h&1?1:h&2?3:h&4?2:0);return a}},fix:function(a){if(a[f.expando])return a;var d,e,g=a,h=f.event.fixHooks[a.type]||{},i=h.props?this.props.concat(h.props):this.props;a=f.Event(g);for(d=i.length;d;)e=i[--d],a[e]=g[e];a.target||(a.target=g.srcElement||c),a.target.nodeType===3&&(a.target=a.target.parentNode),a.metaKey===b&&(a.metaKey=a.ctrlKey);return h.filter?h.filter(a,g):a},special:{ready:{setup:f.bindReady},load:{noBubble:!0},focus:{delegateType:"focusin"},blur:{delegateType:"focusout"},beforeunload:{setup:function(a,b,c){f.isWindow(this)&&(this.onbeforeunload=c)},teardown:function(a,b){this.onbeforeunload===b&&(this.onbeforeunload=null)}}},simulate:function(a,b,c,d){var e=f.extend(new f.Event,c,{type:a,isSimulated:!0,originalEvent:{}});d?f.event.trigger(e,null,b):f.event.dispatch.call(b,e),e.isDefaultPrevented()&&c.preventDefault()}},f.event.handle=f.event.dispatch,f.removeEvent=c.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c,!1)}:function(a,b,c){a.detachEvent&&a.detachEvent("on"+b,c)},f.Event=function(a,b){if(!(this instanceof f.Event))return new f.Event(a,b);a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||a.returnValue===!1||a.getPreventDefault&&a.getPreventDefault()?K:J):this.type=a,b&&f.extend(this,b),this.timeStamp=a&&a.timeStamp||f.now(),this[f.expando]=!0},f.Event.prototype={preventDefault:function(){this.isDefaultPrevented=K;var a=this.originalEvent;!a||(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){this.isPropagationStopped=K;var a=this.originalEvent;!a||(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){this.isImmediatePropagationStopped=K,this.stopPropagation()},isDefaultPrevented:J,isPropagationStopped:J,isImmediatePropagationStopped:J},f.each({mouseenter:"mouseover",mouseleave:"mouseout"},function(a,b){f.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c=this,d=a.relatedTarget,e=a.handleObj,g=e.selector,h;if(!d||d!==c&&!f.contains(c,d))a.type=e.origType,h=e.handler.apply(this,arguments),a.type=b;return h}}}),f.support.submitBubbles||(f.event.special.submit={setup:function(){if(f.nodeName(this,"form"))return!1;f.event.add(this,"click._submit keypress._submit",function(a){var c=a.target,d=f.nodeName(c,"input")||f.nodeName(c,"button")?c.form:b;d&&!d._submit_attached&&(f.event.add(d,"submit._submit",function(a){this.parentNode&&!a.isTrigger&&f.event.simulate("submit",this.parentNode,a,!0)}),d._submit_attached=!0)})},teardown:function(){if(f.nodeName(this,"form"))return!1;f.event.remove(this,"._submit")}}),f.support.changeBubbles||(f.event.special.change={setup:function(){if(z.test(this.nodeName)){if(this.type==="checkbox"||this.type==="radio")f.event.add(this,"propertychange._change",function(a){a.originalEvent.propertyName==="checked"&&(this._just_changed=!0)}),f.event.add(this,"click._change",function(a){this._just_changed&&!a.isTrigger&&(this._just_changed=!1,f.event.simulate("change",this,a,!0))});return!1}f.event.add(this,"beforeactivate._change",function(a){var b=a.target;z.test(b.nodeName)&&!b._change_attached&&(f.event.add(b,"change._change",function(a){this.parentNode&&!a.isSimulated&&!a.isTrigger&&f.event.simulate("change",this.parentNode,a,!0)}),b._change_attached=!0)})},handle:function(a){var b=a.target;if(this!==b||a.isSimulated||a.isTrigger||b.type!=="radio"&&b.type!=="checkbox")return a.handleObj.handler.apply(this,arguments)},teardown:function(){f.event.remove(this,"._change");return z.test(this.nodeName)}}),f.support.focusinBubbles||f.each({focus:"focusin",blur:"focusout"},function(a,b){var d=0,e=function(a){f.event.simulate(b,a.target,f.event.fix(a),!0)};f.event.special[b]={setup:function(){d++===0&&c.addEventListener(a,e,!0)},teardown:function(){--d===0&&c.removeEventListener(a,e,!0)}}}),f.fn.extend({on:function(a,c,d,e,g){var h,i;if(typeof a=="object"){typeof c!="string"&&(d=c,c=b);for(i in a)this.on(i,c,d,a[i],g);return this}d==null&&e==null?(e=c,d=c=b):e==null&&(typeof c=="string"?(e=d,d=b):(e=d,d=c,c=b));if(e===!1)e=J;else if(!e)return this;g===1&&(h=e,e=function(a){f().off(a);return h.apply(this,arguments)},e.guid=h.guid||(h.guid=f.guid++));return this.each(function(){f.event.add(this,a,e,d,c)})},one:function(a,b,c,d){return this.on.call(this,a,b,c,d,1)},off:function(a,c,d){if(a&&a.preventDefault&&a.handleObj){var e=a.handleObj;f(a.delegateTarget).off(e.namespace?e.type+"."+e.namespace:e.type,e.selector,e.handler);return this}if(typeof a=="object"){for(var g in a)this.off(g,c,a[g]);return this}if(c===!1||typeof c=="function")d=c,c=b;d===!1&&(d=J);return this.each(function(){f.event.remove(this,a,d,c)})},bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},live:function(a,b,c){f(this.context).on(a,this.selector,b,c);return this},die:function(a,b){f(this.context).off(a,this.selector||"**",b);return this},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return arguments.length==1?this.off(a,"**"):this.off(b,a,c)},trigger:function(a,b){return this.each(function(){f.event.trigger(a,b,this)})},triggerHandler:function(a,b){if(this[0])return f.event.trigger(a,b,this[0],!0)},toggle:function(a){var b=arguments,c=a.guid||f.guid++,d=0,e=function(c){var e=(f._data(this,"lastToggle"+a.guid)||0)%d;f._data(this,"lastToggle"+a.guid,e+1),c.preventDefault();return b[e].apply(this,arguments)||!1};e.guid=c;while(d<b.length)b[d++].guid=c;return this.click(e)},hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}}),f.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){f.fn[b]=function(a,c){c==null&&(c=a,a=null);return arguments.length>0?this.on(b,null,a,c):this.trigger(b)},f.attrFn&&(f.attrFn[b]=!0),C.test(b)&&(f.event.fixHooks[b]=f.event.keyHooks),D.test(b)&&(f.event.fixHooks[b]=f.event.mouseHooks)}),function(){function x(a,b,c,e,f,g){for(var h=0,i=e.length;h<i;h++){var j=e[h];if(j){var k=!1;j=j[a];while(j){if(j[d]===c){k=e[j.sizset];break}if(j.nodeType===1){g||(j[d]=c,j.sizset=h);if(typeof b!="string"){if(j===b){k=!0;break}}else if(m.filter(b,[j]).length>0){k=j;break}}j=j[a]}e[h]=k}}}function w(a,b,c,e,f,g){for(var h=0,i=e.length;h<i;h++){var j=e[h];if(j){var k=!1;j=j[a];while(j){if(j[d]===c){k=e[j.sizset];break}j.nodeType===1&&!g&&(j[d]=c,j.sizset=h);if(j.nodeName.toLowerCase()===b){k=j;break}j=j[a]}e[h]=k}}}var a=/((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^\[\]]*\]|['"][^'"]*['"]|[^\[\]'"]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g,d="sizcache"+(Math.random()+"").replace(".",""),e=0,g=Object.prototype.toString,h=!1,i=!0,j=/\\/g,k=/\r\n/g,l=/\W/;[0,0].sort(function(){i=!1;return 0});var m=function(b,d,e,f){e=e||[],d=d||c;var h=d;if(d.nodeType!==1&&d.nodeType!==9)return[];if(!b||typeof b!="string")return e;var i,j,k,l,n,q,r,t,u=!0,v=m.isXML(d),w=[],x=b;do{a.exec(""),i=a.exec(x);if(i){x=i[3],w.push(i[1]);if(i[2]){l=i[3];break}}}while(i);if(w.length>1&&p.exec(b))if(w.length===2&&o.relative[w[0]])j=y(w[0]+w[1],d,f);else{j=o.relative[w[0]]?[d]:m(w.shift(),d);while(w.length)b=w.shift(),o.relative[b]&&(b+=w.shift()),j=y(b,j,f)}else{!f&&w.length>1&&d.nodeType===9&&!v&&o.match.ID.test(w[0])&&!o.match.ID.test(w[w.length-1])&&(n=m.find(w.shift(),d,v),d=n.expr?m.filter(n.expr,n.set)[0]:n.set[0]);if(d){n=f?{expr:w.pop(),set:s(f)}:m.find(w.pop(),w.length===1&&(w[0]==="~"||w[0]==="+")&&d.parentNode?d.parentNode:d,v),j=n.expr?m.filter(n.expr,n.set):n.set,w.length>0?k=s(j):u=!1;while(w.length)q=w.pop(),r=q,o.relative[q]?r=w.pop():q="",r==null&&(r=d),o.relative[q](k,r,v)}else k=w=[]}k||(k=j),k||m.error(q||b);if(g.call(k)==="[object Array]")if(!u)e.push.apply(e,k);else if(d&&d.nodeType===1)for(t=0;k[t]!=null;t++)k[t]&&(k[t]===!0||k[t].nodeType===1&&m.contains(d,k[t]))&&e.push(j[t]);else for(t=0;k[t]!=null;t++)k[t]&&k[t].nodeType===1&&e.push(j[t]);else s(k,e);l&&(m(l,h,e,f),m.uniqueSort(e));return e};m.uniqueSort=function(a){if(u){h=i,a.sort(u);if(h)for(var b=1;b<a.length;b++)a[b]===a[b-1]&&a.splice(b--,1)}return a},m.matches=function(a,b){return m(a,null,null,b)},m.matchesSelector=function(a,b){return m(b,null,null,[a]).length>0},m.find=function(a,b,c){var d,e,f,g,h,i;if(!a)return[];for(e=0,f=o.order.length;e<f;e++){h=o.order[e];if(g=o.leftMatch[h].exec(a)){i=g[1],g.splice(1,1);if(i.substr(i.length-1)!=="\\"){g[1]=(g[1]||"").replace(j,""),d=o.find[h](g,b,c);if(d!=null){a=a.replace(o.match[h],"");break}}}}d||(d=typeof b.getElementsByTagName!="undefined"?b.getElementsByTagName("*"):[]);return{set:d,expr:a}},m.filter=function(a,c,d,e){var f,g,h,i,j,k,l,n,p,q=a,r=[],s=c,t=c&&c[0]&&m.isXML(c[0]);while(a&&c.length){for(h in o.filter)if((f=o.leftMatch[h].exec(a))!=null&&f[2]){k=o.filter[h],l=f[1],g=!1,f.splice(1,1);if(l.substr(l.length-1)==="\\")continue;s===r&&(r=[]);if(o.preFilter[h]){f=o.preFilter[h](f,s,d,r,e,t);if(!f)g=i=!0;else if(f===!0)continue}if(f)for(n=0;(j=s[n])!=null;n++)j&&(i=k(j,f,n,s),p=e^i,d&&i!=null?p?g=!0:s[n]=!1:p&&(r.push(j),g=!0));if(i!==b){d||(s=r),a=a.replace(o.match[h],"");if(!g)return[];break}}if(a===q)if(g==null)m.error(a);else break;q=a}return s},m.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)};var n=m.getText=function(a){var b,c,d=a.nodeType,e="";if(d){if(d===1||d===9){if(typeof a.textContent=="string")return a.textContent;if(typeof a.innerText=="string")return a.innerText.replace(k,"");for(a=a.firstChild;a;a=a.nextSibling)e+=n(a)}else if(d===3||d===4)return a.nodeValue}else for(b=0;c=a[b];b++)c.nodeType!==8&&(e+=n(c));return e},o=m.selectors={order:["ID","NAME","TAG"],match:{ID:/#((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,CLASS:/\.((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,NAME:/\[name=['"]*((?:[\w\u00c0-\uFFFF\-]|\\.)+)['"]*\]/,ATTR:/\[\s*((?:[\w\u00c0-\uFFFF\-]|\\.)+)\s*(?:(\S?=)\s*(?:(['"])(.*?)\3|(#?(?:[\w\u00c0-\uFFFF\-]|\\.)*)|)|)\s*\]/,TAG:/^((?:[\w\u00c0-\uFFFF\*\-]|\\.)+)/,CHILD:/:(only|nth|last|first)-child(?:\(\s*(even|odd|(?:[+\-]?\d+|(?:[+\-]?\d*)?n\s*(?:[+\-]\s*\d+)?))\s*\))?/,POS:/:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^\-]|$)/,PSEUDO:/:((?:[\w\u00c0-\uFFFF\-]|\\.)+)(?:\((['"]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/},leftMatch:{},attrMap:{"class":"className","for":"htmlFor"},attrHandle:{href:function(a){return a.getAttribute("href")},type:function(a){return a.getAttribute("type")}},relative:{"+":function(a,b){var c=typeof b=="string",d=c&&!l.test(b),e=c&&!d;d&&(b=b.toLowerCase());for(var f=0,g=a.length,h;f<g;f++)if(h=a[f]){while((h=h.previousSibling)&&h.nodeType!==1);a[f]=e||h&&h.nodeName.toLowerCase()===b?h||!1:h===b}e&&m.filter(b,a,!0)},">":function(a,b){var c,d=typeof b=="string",e=0,f=a.length;if(d&&!l.test(b)){b=b.toLowerCase();for(;e<f;e++){c=a[e];if(c){var g=c.parentNode;a[e]=g.nodeName.toLowerCase()===b?g:!1}}}else{for(;e<f;e++)c=a[e],c&&(a[e]=d?c.parentNode:c.parentNode===b);d&&m.filter(b,a,!0)}},"":function(a,b,c){var d,f=e++,g=x;typeof b=="string"&&!l.test(b)&&(b=b.toLowerCase(),d=b,g=w),g("parentNode",b,f,a,d,c)},"~":function(a,b,c){var d,f=e++,g=x;typeof b=="string"&&!l.test(b)&&(b=b.toLowerCase(),d=b,g=w),g("previousSibling",b,f,a,d,c)}},find:{ID:function(a,b,c){if(typeof b.getElementById!="undefined"&&!c){var d=b.getElementById(a[1]);return d&&d.parentNode?[d]:[]}},NAME:function(a,b){if(typeof b.getElementsByName!="undefined"){var c=[],d=b.getElementsByName(a[1]);for(var e=0,f=d.length;e<f;e++)d[e].getAttribute("name")===a[1]&&c.push(d[e]);return c.length===0?null:c}},TAG:function(a,b){if(typeof b.getElementsByTagName!="undefined")return b.getElementsByTagName(a[1])}},preFilter:{CLASS:function(a,b,c,d,e,f){a=" "+a[1].replace(j,"")+" ";if(f)return a;for(var g=0,h;(h=b[g])!=null;g++)h&&(e^(h.className&&(" "+h.className+" ").replace(/[\t\n\r]/g," ").indexOf(a)>=0)?c||d.push(h):c&&(b[g]=!1));return!1},ID:function(a){return a[1].replace(j,"")},TAG:function(a,b){return a[1].replace(j,"").toLowerCase()},CHILD:function(a){if(a[1]==="nth"){a[2]||m.error(a[0]),a[2]=a[2].replace(/^\+|\s*/g,"");var b=/(-?)(\d*)(?:n([+\-]?\d*))?/.exec(a[2]==="even"&&"2n"||a[2]==="odd"&&"2n+1"||!/\D/.test(a[2])&&"0n+"+a[2]||a[2]);a[2]=b[1]+(b[2]||1)-0,a[3]=b[3]-0}else a[2]&&m.error(a[0]);a[0]=e++;return a},ATTR:function(a,b,c,d,e,f){var g=a[1]=a[1].replace(j,"");!f&&o.attrMap[g]&&(a[1]=o.attrMap[g]),a[4]=(a[4]||a[5]||"").replace(j,""),a[2]==="~="&&(a[4]=" "+a[4]+" ");return a},PSEUDO:function(b,c,d,e,f){if(b[1]==="not")if((a.exec(b[3])||"").length>1||/^\w/.test(b[3]))b[3]=m(b[3],null,null,c);else{var g=m.filter(b[3],c,d,!0^f);d||e.push.apply(e,g);return!1}else if(o.match.POS.test(b[0])||o.match.CHILD.test(b[0]))return!0;return b},POS:function(a){a.unshift(!0);return a}},filters:{enabled:function(a){return a.disabled===!1&&a.type!=="hidden"},disabled:function(a){return a.disabled===!0},checked:function(a){return a.checked===!0},selected:function(a){a.parentNode&&a.parentNode.selectedIndex;return a.selected===!0},parent:function(a){return!!a.firstChild},empty:function(a){return!a.firstChild},has:function(a,b,c){return!!m(c[3],a).length},header:function(a){return/h\d/i.test(a.nodeName)},text:function(a){var b=a.getAttribute("type"),c=a.type;return a.nodeName.toLowerCase()==="input"&&"text"===c&&(b===c||b===null)},radio:function(a){return a.nodeName.toLowerCase()==="input"&&"radio"===a.type},checkbox:function(a){return a.nodeName.toLowerCase()==="input"&&"checkbox"===a.type},file:function(a){return a.nodeName.toLowerCase()==="input"&&"file"===a.type},password:function(a){return a.nodeName.toLowerCase()==="input"&&"password"===a.type},submit:function(a){var b=a.nodeName.toLowerCase();return(b==="input"||b==="button")&&"submit"===a.type},image:function(a){return a.nodeName.toLowerCase()==="input"&&"image"===a.type},reset:function(a){var b=a.nodeName.toLowerCase();return(b==="input"||b==="button")&&"reset"===a.type},button:function(a){var b=a.nodeName.toLowerCase();return b==="input"&&"button"===a.type||b==="button"},input:function(a){return/input|select|textarea|button/i.test(a.nodeName)},focus:function(a){return a===a.ownerDocument.activeElement}},setFilters:{first:function(a,b){return b===0},last:function(a,b,c,d){return b===d.length-1},even:function(a,b){return b%2===0},odd:function(a,b){return b%2===1},lt:function(a,b,c){return b<c[3]-0},gt:function(a,b,c){return b>c[3]-0},nth:function(a,b,c){return c[3]-0===b},eq:function(a,b,c){return c[3]-0===b}},filter:{PSEUDO:function(a,b,c,d){var e=b[1],f=o.filters[e];if(f)return f(a,c,b,d);if(e==="contains")return(a.textContent||a.innerText||n([a])||"").indexOf(b[3])>=0;if(e==="not"){var g=b[3];for(var h=0,i=g.length;h<i;h++)if(g[h]===a)return!1;return!0}m.error(e)},CHILD:function(a,b){var c,e,f,g,h,i,j,k=b[1],l=a;switch(k){case"only":case"first":while(l=l.previousSibling)if(l.nodeType===1)return!1;if(k==="first")return!0;l=a;case"last":while(l=l.nextSibling)if(l.nodeType===1)return!1;return!0;case"nth":c=b[2],e=b[3];if(c===1&&e===0)return!0;f=b[0],g=a.parentNode;if(g&&(g[d]!==f||!a.nodeIndex)){i=0;for(l=g.firstChild;l;l=l.nextSibling)l.nodeType===1&&(l.nodeIndex=++i);g[d]=f}j=a.nodeIndex-e;return c===0?j===0:j%c===0&&j/c>=0}},ID:function(a,b){return a.nodeType===1&&a.getAttribute("id")===b},TAG:function(a,b){return b==="*"&&a.nodeType===1||!!a.nodeName&&a.nodeName.toLowerCase()===b},CLASS:function(a,b){return(" "+(a.className||a.getAttribute("class"))+" ").indexOf(b)>-1},ATTR:function(a,b){var c=b[1],d=m.attr?m.attr(a,c):o.attrHandle[c]?o.attrHandle[c](a):a[c]!=null?a[c]:a.getAttribute(c),e=d+"",f=b[2],g=b[4];return d==null?f==="!=":!f&&m.attr?d!=null:f==="="?e===g:f==="*="?e.indexOf(g)>=0:f==="~="?(" "+e+" ").indexOf(g)>=0:g?f==="!="?e!==g:f==="^="?e.indexOf(g)===0:f==="$="?e.substr(e.length-g.length)===g:f==="|="?e===g||e.substr(0,g.length+1)===g+"-":!1:e&&d!==!1},POS:function(a,b,c,d){var e=b[2],f=o.setFilters[e];if(f)return f(a,c,b,d)}}},p=o.match.POS,q=function(a,b){return"\\"+(b-0+1)};for(var r in o.match)o.match[r]=new RegExp(o.match[r].source+/(?![^\[]*\])(?![^\(]*\))/.source),o.leftMatch[r]=new RegExp(/(^(?:.|\r|\n)*?)/.source+o.match[r].source.replace(/\\(\d+)/g,q));var s=function(a,b){a=Array.prototype.slice.call(a,0);if(b){b.push.apply(b,a);return b}return a};try{Array.prototype.slice.call(c.documentElement.childNodes,0)[0].nodeType}catch(t){s=function(a,b){var c=0,d=b||[];if(g.call(a)==="[object Array]")Array.prototype.push.apply(d,a);else if(typeof a.length=="number")for(var e=a.length;c<e;c++)d.push(a[c]);else for(;a[c];c++)d.push(a[c]);return d}}var u,v;c.documentElement.compareDocumentPosition?u=function(a,b){if(a===b){h=!0;return 0}if(!a.compareDocumentPosition||!b.compareDocumentPosition)return a.compareDocumentPosition?-1:1;return a.compareDocumentPosition(b)&4?-1:1}:(u=function(a,b){if(a===b){h=!0;return 0}if(a.sourceIndex&&b.sourceIndex)return a.sourceIndex-b.sourceIndex;var c,d,e=[],f=[],g=a.parentNode,i=b.parentNode,j=g;if(g===i)return v(a,b);if(!g)return-1;if(!i)return 1;while(j)e.unshift(j),j=j.parentNode;j=i;while(j)f.unshift(j),j=j.parentNode;c=e.length,d=f.length;for(var k=0;k<c&&k<d;k++)if(e[k]!==f[k])return v(e[k],f[k]);return k===c?v(a,f[k],-1):v(e[k],b,1)},v=function(a,b,c){if(a===b)return c;var d=a.nextSibling;while(d){if(d===b)return-1;d=d.nextSibling}return 1}),function(){var a=c.createElement("div"),d="script"+(new Date).getTime(),e=c.documentElement;a.innerHTML="<a name='"+d+"'/>",e.insertBefore(a,e.firstChild),c.getElementById(d)&&(o.find.ID=function(a,c,d){if(typeof c.getElementById!="undefined"&&!d){var e=c.getElementById(a[1]);return e?e.id===a[1]||typeof e.getAttributeNode!="undefined"&&e.getAttributeNode("id").nodeValue===a[1]?[e]:b:[]}},o.filter.ID=function(a,b){var c=typeof a.getAttributeNode!="undefined"&&a.getAttributeNode("id");return a.nodeType===1&&c&&c.nodeValue===b}),e.removeChild(a),e=a=null}(),function(){var a=c.createElement("div");a.appendChild(c.createComment("")),a.getElementsByTagName("*").length>0&&(o.find.TAG=function(a,b){var c=b.getElementsByTagName(a[1]);if(a[1]==="*"){var d=[];for(var e=0;c[e];e++)c[e].nodeType===1&&d.push(c[e]);c=d}return c}),a.innerHTML="<a href='#'></a>",a.firstChild&&typeof a.firstChild.getAttribute!="undefined"&&a.firstChild.getAttribute("href")!=="#"&&(o.attrHandle.href=function(a){return a.getAttribute("href",2)}),a=null}(),c.querySelectorAll&&function(){var a=m,b=c.createElement("div"),d="__sizzle__";b.innerHTML="<p class='TEST'></p>";if(!b.querySelectorAll||b.querySelectorAll(".TEST").length!==0){m=function(b,e,f,g){e=e||c;if(!g&&!m.isXML(e)){var h=/^(\w+$)|^\.([\w\-]+$)|^#([\w\-]+$)/.exec(b);if(h&&(e.nodeType===1||e.nodeType===9)){if(h[1])return s(e.getElementsByTagName(b),f);if(h[2]&&o.find.CLASS&&e.getElementsByClassName)return s(e.getElementsByClassName(h[2]),f)}if(e.nodeType===9){if(b==="body"&&e.body)return s([e.body],f);if(h&&h[3]){var i=e.getElementById(h[3]);if(!i||!i.parentNode)return s([],f);if(i.id===h[3])return s([i],f)}try{return s(e.querySelectorAll(b),f)}catch(j){}}else if(e.nodeType===1&&e.nodeName.toLowerCase()!=="object"){var k=e,l=e.getAttribute("id"),n=l||d,p=e.parentNode,q=/^\s*[+~]/.test(b);l?n=n.replace(/'/g,"\\$&"):e.setAttribute("id",n),q&&p&&(e=e.parentNode);try{if(!q||p)return s(e.querySelectorAll("[id='"+n+"'] "+b),f)}catch(r){}finally{l||k.removeAttribute("id")}}}return a(b,e,f,g)};for(var e in a)m[e]=a[e];b=null}}(),function(){var a=c.documentElement,b=a.matchesSelector||a.mozMatchesSelector||a.webkitMatchesSelector||a.msMatchesSelector;if(b){var d=!b.call(c.createElement("div"),"div"),e=!1;try{b.call(c.documentElement,"[test!='']:sizzle")}catch(f){e=!0}m.matchesSelector=function(a,c){c=c.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!m.isXML(a))try{if(e||!o.match.PSEUDO.test(c)&&!/!=/.test(c)){var f=b.call(a,c);if(f||!d||a.document&&a.document.nodeType!==11)return f}}catch(g){}return m(c,null,null,[a]).length>0}}}(),function(){var a=c.createElement("div");a.innerHTML="<div class='test e'></div><div class='test'></div>";if(!!a.getElementsByClassName&&a.getElementsByClassName("e").length!==0){a.lastChild.className="e";if(a.getElementsByClassName("e").length===1)return;o.order.splice(1,0,"CLASS"),o.find.CLASS=function(a,b,c){if(typeof b.getElementsByClassName!="undefined"&&!c)return b.getElementsByClassName(a[1])},a=null}}(),c.documentElement.contains?m.contains=function(a,b){return a!==b&&(a.contains?a.contains(b):!0)}:c.documentElement.compareDocumentPosition?m.contains=function(a,b){return!!(a.compareDocumentPosition(b)&16)}:m.contains=function(){return!1},m.isXML=function(a){var b=(a?a.ownerDocument||a:0).documentElement;return b?b.nodeName!=="HTML":!1};var y=function(a,b,c){var d,e=[],f="",g=b.nodeType?[b]:b;while(d=o.match.PSEUDO.exec(a))f+=d[0],a=a.replace(o.match.PSEUDO,"");a=o.relative[a]?a+"*":a;for(var h=0,i=g.length;h<i;h++)m(a,g[h],e,c);return m.filter(f,e)};m.attr=f.attr,m.selectors.attrMap={},f.find=m,f.expr=m.selectors,f.expr[":"]=f.expr.filters,f.unique=m.uniqueSort,f.text=m.getText,f.isXMLDoc=m.isXML,f.contains=m.contains}();var L=/Until$/,M=/^(?:parents|prevUntil|prevAll)/,N=/,/,O=/^.[^:#\[\.,]*$/,P=Array.prototype.slice,Q=f.expr.match.POS,R={children:!0,contents:!0,next:!0,prev:!0};f.fn.extend({find:function(a){var b=this,c,d;if(typeof a!="string")return f(a).filter(function(){for(c=0,d=b.length;c<d;c++)if(f.contains(b[c],this))return!0});var e=this.pushStack("","find",a),g,h,i;for(c=0,d=this.length;c<d;c++){g=e.length,f.find(a,this[c],e);if(c>0)for(h=g;h<e.length;h++)for(i=0;i<g;i++)if(e[i]===e[h]){e.splice(h--,1);break}}return e},has:function(a){var b=f(a);return this.filter(function(){for(var a=0,c=b.length;a<c;a++)if(f.contains(this,b[a]))return!0})},not:function(a){return this.pushStack(T(this,a,!1),"not",a)},filter:function(a){return this.pushStack(T(this,a,!0),"filter",a)},is:function(a){return!!a&&(typeof a=="string"?Q.test(a)?f(a,this.context).index(this[0])>=0:f.filter(a,this).length>0:this.filter(a).length>0)},closest:function(a,b){var c=[],d,e,g=this[0];if(f.isArray(a)){var h=1;while(g&&g.ownerDocument&&g!==b){for(d=0;d<a.length;d++)f(g).is(a[d])&&c.push({selector:a[d],elem:g,level:h});g=g.parentNode,h++}return c}var i=Q.test(a)||typeof a!="string"?f(a,b||this.context):0;for(d=0,e=this.length;d<e;d++){g=this[d];while(g){if(i?i.index(g)>-1:f.find.matchesSelector(g,a)){c.push(g);break}g=g.parentNode;if(!g||!g.ownerDocument||g===b||g.nodeType===11)break}}c=c.length>1?f.unique(c):c;return this.pushStack(c,"closest",a)},index:function(a){if(!a)return this[0]&&this[0].parentNode?this.prevAll().length:-1;if(typeof a=="string")return f.inArray(this[0],f(a));return f.inArray(a.jquery?a[0]:a,this)},add:function(a,b){var c=typeof a=="string"?f(a,b):f.makeArray(a&&a.nodeType?[a]:a),d=f.merge(this.get(),c);return this.pushStack(S(c[0])||S(d[0])?d:f.unique(d))},andSelf:function(){return this.add(this.prevObject)}}),f.each({parent:function(a){var b=a.parentNode;return b&&b.nodeType!==11?b:null},parents:function(a){return f.dir(a,"parentNode")},parentsUntil:function(a,b,c){return f.dir(a,"parentNode",c)},next:function(a){return f.nth(a,2,"nextSibling")},prev:function(a){return f.nth(a,2,"previousSibling")},nextAll:function(a){return f.dir(a,"nextSibling")},prevAll:function(a){return f.dir(a,"previousSibling")},nextUntil:function(a,b,c){return f.dir(a,"nextSibling",c)},prevUntil:function(a,b,c){return f.dir(a,"previousSibling",c)},siblings:function(a){return f.sibling(a.parentNode.firstChild,a)},children:function(a){return f.sibling(a.firstChild)},contents:function(a){return f.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:f.makeArray(a.childNodes)}},function(a,b){f.fn[a]=function(c,d){var e=f.map(this,b,c);L.test(a)||(d=c),d&&typeof d=="string"&&(e=f.filter(d,e)),e=this.length>1&&!R[a]?f.unique(e):e,(this.length>1||N.test(d))&&M.test(a)&&(e=e.reverse());return this.pushStack(e,a,P.call(arguments).join(","))}}),f.extend({filter:function(a,b,c){c&&(a=":not("+a+")");return b.length===1?f.find.matchesSelector(b[0],a)?[b[0]]:[]:f.find.matches(a,b)},dir:function(a,c,d){var e=[],g=a[c];while(g&&g.nodeType!==9&&(d===b||g.nodeType!==1||!f(g).is(d)))g.nodeType===1&&e.push(g),g=g[c];return e},nth:function(a,b,c,d){b=b||1;var e=0;for(;a;a=a[c])if(a.nodeType===1&&++e===b)break;return a},sibling:function(a,b){var c=[];for(;a;a=a.nextSibling)a.nodeType===1&&a!==b&&c.push(a);return c}});var V="abbr|article|aside|audio|canvas|datalist|details|figcaption|figure|footer|header|hgroup|mark|meter|nav|output|progress|section|summary|time|video",W=/ jQuery\d+="(?:\d+|null)"/g,X=/^\s+/,Y=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/ig,Z=/<([\w:]+)/,$=/<tbody/i,_=/<|&#?\w+;/,ba=/<(?:script|style)/i,bb=/<(?:script|object|embed|option|style)/i,bc=new RegExp("<(?:"+V+")","i"),bd=/checked\s*(?:[^=]|=\s*.checked.)/i,be=/\/(java|ecma)script/i,bf=/^\s*<!(?:\[CDATA\[|\-\-)/,bg={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],area:[1,"<map>","</map>"],_default:[0,"",""]},bh=U(c);bg.optgroup=bg.option,bg.tbody=bg.tfoot=bg.colgroup=bg.caption=bg.thead,bg.th=bg.td,f.support.htmlSerialize||(bg._default=[1,"div<div>","</div>"]),f.fn.extend({text:function(a){if(f.isFunction(a))return this.each(function(b){var c=f(this);c.text(a.call(this,b,c.text()))});if(typeof a!="object"&&a!==b)return this.empty().append((this[0]&&this[0].ownerDocument||c).createTextNode(a));return f.text(this)},wrapAll:function(a){if(f.isFunction(a))return this.each(function(b){f(this).wrapAll(a.call(this,b))});if(this[0]){var b=f(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&a.firstChild.nodeType===1)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){if(f.isFunction(a))return this.each(function(b){f(this).wrapInner(a.call(this,b))});return this.each(function(){var b=f(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=f.isFunction(a);return this.each(function(c){f(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){f.nodeName(this,"body")||f(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,!0,function(a){this.nodeType===1&&this.appendChild(a)})},prepend:function(){return this.domManip(arguments,!0,function(a){this.nodeType===1&&this.insertBefore(a,this.firstChild)})},before:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,!1,function(a){this.parentNode.insertBefore(a,this)});if(arguments.length){var a=f.clean(arguments);a.push.apply(a,this.toArray());return this.pushStack(a,"before",arguments)}},after:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,!1,function(a){this.parentNode.insertBefore(a,this.nextSibling)});if(arguments.length){var a=this.pushStack(this,"after",arguments);a.push.apply(a,f.clean(arguments));return a}},remove:function(a,b){for(var c=0,d;(d=this[c])!=null;c++)if(!a||f.filter(a,[d]).length)!b&&d.nodeType===1&&(f.cleanData(d.getElementsByTagName("*")),f.cleanData([d])),d.parentNode&&d.parentNode.removeChild(d);return this},empty:function()
{for(var a=0,b;(b=this[a])!=null;a++){b.nodeType===1&&f.cleanData(b.getElementsByTagName("*"));while(b.firstChild)b.removeChild(b.firstChild)}return this},clone:function(a,b){a=a==null?!1:a,b=b==null?a:b;return this.map(function(){return f.clone(this,a,b)})},html:function(a){if(a===b)return this[0]&&this[0].nodeType===1?this[0].innerHTML.replace(W,""):null;if(typeof a=="string"&&!ba.test(a)&&(f.support.leadingWhitespace||!X.test(a))&&!bg[(Z.exec(a)||["",""])[1].toLowerCase()]){a=a.replace(Y,"<$1></$2>");try{for(var c=0,d=this.length;c<d;c++)this[c].nodeType===1&&(f.cleanData(this[c].getElementsByTagName("*")),this[c].innerHTML=a)}catch(e){this.empty().append(a)}}else f.isFunction(a)?this.each(function(b){var c=f(this);c.html(a.call(this,b,c.html()))}):this.empty().append(a);return this},replaceWith:function(a){if(this[0]&&this[0].parentNode){if(f.isFunction(a))return this.each(function(b){var c=f(this),d=c.html();c.replaceWith(a.call(this,b,d))});typeof a!="string"&&(a=f(a).detach());return this.each(function(){var b=this.nextSibling,c=this.parentNode;f(this).remove(),b?f(b).before(a):f(c).append(a)})}return this.length?this.pushStack(f(f.isFunction(a)?a():a),"replaceWith",a):this},detach:function(a){return this.remove(a,!0)},domManip:function(a,c,d){var e,g,h,i,j=a[0],k=[];if(!f.support.checkClone&&arguments.length===3&&typeof j=="string"&&bd.test(j))return this.each(function(){f(this).domManip(a,c,d,!0)});if(f.isFunction(j))return this.each(function(e){var g=f(this);a[0]=j.call(this,e,c?g.html():b),g.domManip(a,c,d)});if(this[0]){i=j&&j.parentNode,f.support.parentNode&&i&&i.nodeType===11&&i.childNodes.length===this.length?e={fragment:i}:e=f.buildFragment(a,this,k),h=e.fragment,h.childNodes.length===1?g=h=h.firstChild:g=h.firstChild;if(g){c=c&&f.nodeName(g,"tr");for(var l=0,m=this.length,n=m-1;l<m;l++)d.call(c?bi(this[l],g):this[l],e.cacheable||m>1&&l<n?f.clone(h,!0,!0):h)}k.length&&f.each(k,bp)}return this}}),f.buildFragment=function(a,b,d){var e,g,h,i,j=a[0];b&&b[0]&&(i=b[0].ownerDocument||b[0]),i.createDocumentFragment||(i=c),a.length===1&&typeof j=="string"&&j.length<512&&i===c&&j.charAt(0)==="<"&&!bb.test(j)&&(f.support.checkClone||!bd.test(j))&&(f.support.html5Clone||!bc.test(j))&&(g=!0,h=f.fragments[j],h&&h!==1&&(e=h)),e||(e=i.createDocumentFragment(),f.clean(a,i,e,d)),g&&(f.fragments[j]=h?e:1);return{fragment:e,cacheable:g}},f.fragments={},f.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){f.fn[a]=function(c){var d=[],e=f(c),g=this.length===1&&this[0].parentNode;if(g&&g.nodeType===11&&g.childNodes.length===1&&e.length===1){e[b](this[0]);return this}for(var h=0,i=e.length;h<i;h++){var j=(h>0?this.clone(!0):this).get();f(e[h])[b](j),d=d.concat(j)}return this.pushStack(d,a,e.selector)}}),f.extend({clone:function(a,b,c){var d,e,g,h=f.support.html5Clone||!bc.test("<"+a.nodeName)?a.cloneNode(!0):bo(a);if((!f.support.noCloneEvent||!f.support.noCloneChecked)&&(a.nodeType===1||a.nodeType===11)&&!f.isXMLDoc(a)){bk(a,h),d=bl(a),e=bl(h);for(g=0;d[g];++g)e[g]&&bk(d[g],e[g])}if(b){bj(a,h);if(c){d=bl(a),e=bl(h);for(g=0;d[g];++g)bj(d[g],e[g])}}d=e=null;return h},clean:function(a,b,d,e){var g;b=b||c,typeof b.createElement=="undefined"&&(b=b.ownerDocument||b[0]&&b[0].ownerDocument||c);var h=[],i;for(var j=0,k;(k=a[j])!=null;j++){typeof k=="number"&&(k+="");if(!k)continue;if(typeof k=="string")if(!_.test(k))k=b.createTextNode(k);else{k=k.replace(Y,"<$1></$2>");var l=(Z.exec(k)||["",""])[1].toLowerCase(),m=bg[l]||bg._default,n=m[0],o=b.createElement("div");b===c?bh.appendChild(o):U(b).appendChild(o),o.innerHTML=m[1]+k+m[2];while(n--)o=o.lastChild;if(!f.support.tbody){var p=$.test(k),q=l==="table"&&!p?o.firstChild&&o.firstChild.childNodes:m[1]==="<table>"&&!p?o.childNodes:[];for(i=q.length-1;i>=0;--i)f.nodeName(q[i],"tbody")&&!q[i].childNodes.length&&q[i].parentNode.removeChild(q[i])}!f.support.leadingWhitespace&&X.test(k)&&o.insertBefore(b.createTextNode(X.exec(k)[0]),o.firstChild),k=o.childNodes}var r;if(!f.support.appendChecked)if(k[0]&&typeof (r=k.length)=="number")for(i=0;i<r;i++)bn(k[i]);else bn(k);k.nodeType?h.push(k):h=f.merge(h,k)}if(d){g=function(a){return!a.type||be.test(a.type)};for(j=0;h[j];j++)if(e&&f.nodeName(h[j],"script")&&(!h[j].type||h[j].type.toLowerCase()==="text/javascript"))e.push(h[j].parentNode?h[j].parentNode.removeChild(h[j]):h[j]);else{if(h[j].nodeType===1){var s=f.grep(h[j].getElementsByTagName("script"),g);h.splice.apply(h,[j+1,0].concat(s))}d.appendChild(h[j])}}return h},cleanData:function(a){var b,c,d=f.cache,e=f.event.special,g=f.support.deleteExpando;for(var h=0,i;(i=a[h])!=null;h++){if(i.nodeName&&f.noData[i.nodeName.toLowerCase()])continue;c=i[f.expando];if(c){b=d[c];if(b&&b.events){for(var j in b.events)e[j]?f.event.remove(i,j):f.removeEvent(i,j,b.handle);b.handle&&(b.handle.elem=null)}g?delete i[f.expando]:i.removeAttribute&&i.removeAttribute(f.expando),delete d[c]}}}});var bq=/alpha\([^)]*\)/i,br=/opacity=([^)]*)/,bs=/([A-Z]|^ms)/g,bt=/^-?\d+(?:px)?$/i,bu=/^-?\d/,bv=/^([\-+])=([\-+.\de]+)/,bw={position:"absolute",visibility:"hidden",display:"block"},bx=["Left","Right"],by=["Top","Bottom"],bz,bA,bB;f.fn.css=function(a,c){if(arguments.length===2&&c===b)return this;return f.access(this,a,c,!0,function(a,c,d){return d!==b?f.style(a,c,d):f.css(a,c)})},f.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=bz(a,"opacity","opacity");return c===""?"1":c}return a.style.opacity}}},cssNumber:{fillOpacity:!0,fontWeight:!0,lineHeight:!0,opacity:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":f.support.cssFloat?"cssFloat":"styleFloat"},style:function(a,c,d,e){if(!!a&&a.nodeType!==3&&a.nodeType!==8&&!!a.style){var g,h,i=f.camelCase(c),j=a.style,k=f.cssHooks[i];c=f.cssProps[i]||i;if(d===b){if(k&&"get"in k&&(g=k.get(a,!1,e))!==b)return g;return j[c]}h=typeof d,h==="string"&&(g=bv.exec(d))&&(d=+(g[1]+1)*+g[2]+parseFloat(f.css(a,c)),h="number");if(d==null||h==="number"&&isNaN(d))return;h==="number"&&!f.cssNumber[i]&&(d+="px");if(!k||!("set"in k)||(d=k.set(a,d))!==b)try{j[c]=d}catch(l){}}},css:function(a,c,d){var e,g;c=f.camelCase(c),g=f.cssHooks[c],c=f.cssProps[c]||c,c==="cssFloat"&&(c="float");if(g&&"get"in g&&(e=g.get(a,!0,d))!==b)return e;if(bz)return bz(a,c)},swap:function(a,b,c){var d={};for(var e in b)d[e]=a.style[e],a.style[e]=b[e];c.call(a);for(e in b)a.style[e]=d[e]}}),f.curCSS=f.css,f.each(["height","width"],function(a,b){f.cssHooks[b]={get:function(a,c,d){var e;if(c){if(a.offsetWidth!==0)return bC(a,b,d);f.swap(a,bw,function(){e=bC(a,b,d)});return e}},set:function(a,b){if(!bt.test(b))return b;b=parseFloat(b);if(b>=0)return b+"px"}}}),f.support.opacity||(f.cssHooks.opacity={get:function(a,b){return br.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?parseFloat(RegExp.$1)/100+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=f.isNumeric(b)?"alpha(opacity="+b*100+")":"",g=d&&d.filter||c.filter||"";c.zoom=1;if(b>=1&&f.trim(g.replace(bq,""))===""){c.removeAttribute("filter");if(d&&!d.filter)return}c.filter=bq.test(g)?g.replace(bq,e):g+" "+e}}),f(function(){f.support.reliableMarginRight||(f.cssHooks.marginRight={get:function(a,b){var c;f.swap(a,{display:"inline-block"},function(){b?c=bz(a,"margin-right","marginRight"):c=a.style.marginRight});return c}})}),c.defaultView&&c.defaultView.getComputedStyle&&(bA=function(a,b){var c,d,e;b=b.replace(bs,"-$1").toLowerCase(),(d=a.ownerDocument.defaultView)&&(e=d.getComputedStyle(a,null))&&(c=e.getPropertyValue(b),c===""&&!f.contains(a.ownerDocument.documentElement,a)&&(c=f.style(a,b)));return c}),c.documentElement.currentStyle&&(bB=function(a,b){var c,d,e,f=a.currentStyle&&a.currentStyle[b],g=a.style;f===null&&g&&(e=g[b])&&(f=e),!bt.test(f)&&bu.test(f)&&(c=g.left,d=a.runtimeStyle&&a.runtimeStyle.left,d&&(a.runtimeStyle.left=a.currentStyle.left),g.left=b==="fontSize"?"1em":f||0,f=g.pixelLeft+"px",g.left=c,d&&(a.runtimeStyle.left=d));return f===""?"auto":f}),bz=bA||bB,f.expr&&f.expr.filters&&(f.expr.filters.hidden=function(a){var b=a.offsetWidth,c=a.offsetHeight;return b===0&&c===0||!f.support.reliableHiddenOffsets&&(a.style&&a.style.display||f.css(a,"display"))==="none"},f.expr.filters.visible=function(a){return!f.expr.filters.hidden(a)});var bD=/%20/g,bE=/\[\]$/,bF=/\r?\n/g,bG=/#.*$/,bH=/^(.*?):[ \t]*([^\r\n]*)\r?$/mg,bI=/^(?:color|date|datetime|datetime-local|email|hidden|month|number|password|range|search|tel|text|time|url|week)$/i,bJ=/^(?:about|app|app\-storage|.+\-extension|file|res|widget):$/,bK=/^(?:GET|HEAD)$/,bL=/^\/\//,bM=/\?/,bN=/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,bO=/^(?:select|textarea)/i,bP=/\s+/,bQ=/([?&])_=[^&]*/,bR=/^([\w\+\.\-]+:)(?:\/\/([^\/?#:]*)(?::(\d+))?)?/,bS=f.fn.load,bT={},bU={},bV,bW,bX=["*/"]+["*"];try{bV=e.href}catch(bY){bV=c.createElement("a"),bV.href="",bV=bV.href}bW=bR.exec(bV.toLowerCase())||[],f.fn.extend({load:function(a,c,d){if(typeof a!="string"&&bS)return bS.apply(this,arguments);if(!this.length)return this;var e=a.indexOf(" ");if(e>=0){var g=a.slice(e,a.length);a=a.slice(0,e)}var h="GET";c&&(f.isFunction(c)?(d=c,c=b):typeof c=="object"&&(c=f.param(c,f.ajaxSettings.traditional),h="POST"));var i=this;f.ajax({url:a,type:h,dataType:"html",data:c,complete:function(a,b,c){c=a.responseText,a.isResolved()&&(a.done(function(a){c=a}),i.html(g?f("<div>").append(c.replace(bN,"")).find(g):c)),d&&i.each(d,[c,b,a])}});return this},serialize:function(){return f.param(this.serializeArray())},serializeArray:function(){return this.map(function(){return this.elements?f.makeArray(this.elements):this}).filter(function(){return this.name&&!this.disabled&&(this.checked||bO.test(this.nodeName)||bI.test(this.type))}).map(function(a,b){var c=f(this).val();return c==null?null:f.isArray(c)?f.map(c,function(a,c){return{name:b.name,value:a.replace(bF,"\r\n")}}):{name:b.name,value:c.replace(bF,"\r\n")}}).get()}}),f.each("ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend".split(" "),function(a,b){f.fn[b]=function(a){return this.on(b,a)}}),f.each(["get","post"],function(a,c){f[c]=function(a,d,e,g){f.isFunction(d)&&(g=g||e,e=d,d=b);return f.ajax({type:c,url:a,data:d,success:e,dataType:g})}}),f.extend({getScript:function(a,c){return f.get(a,b,c,"script")},getJSON:function(a,b,c){return f.get(a,b,c,"json")},ajaxSetup:function(a,b){b?b_(a,f.ajaxSettings):(b=a,a=f.ajaxSettings),b_(a,b);return a},ajaxSettings:{url:bV,isLocal:bJ.test(bW[1]),global:!0,type:"GET",contentType:"application/x-www-form-urlencoded",processData:!0,async:!0,accepts:{xml:"application/xml, text/xml",html:"text/html",text:"text/plain",json:"application/json, text/javascript","*":bX},contents:{xml:/xml/,html:/html/,json:/json/},responseFields:{xml:"responseXML",text:"responseText"},converters:{"* text":a.String,"text html":!0,"text json":f.parseJSON,"text xml":f.parseXML},flatOptions:{context:!0,url:!0}},ajaxPrefilter:bZ(bT),ajaxTransport:bZ(bU),ajax:function(a,c){function w(a,c,l,m){if(s!==2){s=2,q&&clearTimeout(q),p=b,n=m||"",v.readyState=a>0?4:0;var o,r,u,w=c,x=l?cb(d,v,l):b,y,z;if(a>=200&&a<300||a===304){if(d.ifModified){if(y=v.getResponseHeader("Last-Modified"))f.lastModified[k]=y;if(z=v.getResponseHeader("Etag"))f.etag[k]=z}if(a===304)w="notmodified",o=!0;else try{r=cc(d,x),w="success",o=!0}catch(A){w="parsererror",u=A}}else{u=w;if(!w||a)w="error",a<0&&(a=0)}v.status=a,v.statusText=""+(c||w),o?h.resolveWith(e,[r,w,v]):h.rejectWith(e,[v,w,u]),v.statusCode(j),j=b,t&&g.trigger("ajax"+(o?"Success":"Error"),[v,d,o?r:u]),i.fireWith(e,[v,w]),t&&(g.trigger("ajaxComplete",[v,d]),--f.active||f.event.trigger("ajaxStop"))}}typeof a=="object"&&(c=a,a=b),c=c||{};var d=f.ajaxSetup({},c),e=d.context||d,g=e!==d&&(e.nodeType||e instanceof f)?f(e):f.event,h=f.Deferred(),i=f.Callbacks("once memory"),j=d.statusCode||{},k,l={},m={},n,o,p,q,r,s=0,t,u,v={readyState:0,setRequestHeader:function(a,b){if(!s){var c=a.toLowerCase();a=m[c]=m[c]||a,l[a]=b}return this},getAllResponseHeaders:function(){return s===2?n:null},getResponseHeader:function(a){var c;if(s===2){if(!o){o={};while(c=bH.exec(n))o[c[1].toLowerCase()]=c[2]}c=o[a.toLowerCase()]}return c===b?null:c},overrideMimeType:function(a){s||(d.mimeType=a);return this},abort:function(a){a=a||"abort",p&&p.abort(a),w(0,a);return this}};h.promise(v),v.success=v.done,v.error=v.fail,v.complete=i.add,v.statusCode=function(a){if(a){var b;if(s<2)for(b in a)j[b]=[j[b],a[b]];else b=a[v.status],v.then(b,b)}return this},d.url=((a||d.url)+"").replace(bG,"").replace(bL,bW[1]+"//"),d.dataTypes=f.trim(d.dataType||"*").toLowerCase().split(bP),d.crossDomain==null&&(r=bR.exec(d.url.toLowerCase()),d.crossDomain=!(!r||r[1]==bW[1]&&r[2]==bW[2]&&(r[3]||(r[1]==="http:"?80:443))==(bW[3]||(bW[1]==="http:"?80:443)))),d.data&&d.processData&&typeof d.data!="string"&&(d.data=f.param(d.data,d.traditional)),b$(bT,d,c,v);if(s===2)return!1;t=d.global,d.type=d.type.toUpperCase(),d.hasContent=!bK.test(d.type),t&&f.active++===0&&f.event.trigger("ajaxStart");if(!d.hasContent){d.data&&(d.url+=(bM.test(d.url)?"&":"?")+d.data,delete d.data),k=d.url;if(d.cache===!1){var x=f.now(),y=d.url.replace(bQ,"$1_="+x);d.url=y+(y===d.url?(bM.test(d.url)?"&":"?")+"_="+x:"")}}(d.data&&d.hasContent&&d.contentType!==!1||c.contentType)&&v.setRequestHeader("Content-Type",d.contentType),d.ifModified&&(k=k||d.url,f.lastModified[k]&&v.setRequestHeader("If-Modified-Since",f.lastModified[k]),f.etag[k]&&v.setRequestHeader("If-None-Match",f.etag[k])),v.setRequestHeader("Accept",d.dataTypes[0]&&d.accepts[d.dataTypes[0]]?d.accepts[d.dataTypes[0]]+(d.dataTypes[0]!=="*"?", "+bX+"; q=0.01":""):d.accepts["*"]);for(u in d.headers)v.setRequestHeader(u,d.headers[u]);if(d.beforeSend&&(d.beforeSend.call(e,v,d)===!1||s===2)){v.abort();return!1}for(u in{success:1,error:1,complete:1})v[u](d[u]);p=b$(bU,d,c,v);if(!p)w(-1,"No Transport");else{v.readyState=1,t&&g.trigger("ajaxSend",[v,d]),d.async&&d.timeout>0&&(q=setTimeout(function(){v.abort("timeout")},d.timeout));try{s=1,p.send(l,w)}catch(z){if(s<2)w(-1,z);else throw z}}return v},param:function(a,c){var d=[],e=function(a,b){b=f.isFunction(b)?b():b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};c===b&&(c=f.ajaxSettings.traditional);if(f.isArray(a)||a.jquery&&!f.isPlainObject(a))f.each(a,function(){e(this.name,this.value)});else for(var g in a)ca(g,a[g],c,e);return d.join("&").replace(bD,"+")}}),f.extend({active:0,lastModified:{},etag:{}});var cd=f.now(),ce=/(\=)\?(&|$)|\?\?/i;f.ajaxSetup({jsonp:"callback",jsonpCallback:function(){return f.expando+"_"+cd++}}),f.ajaxPrefilter("json jsonp",function(b,c,d){var e=b.contentType==="application/x-www-form-urlencoded"&&typeof b.data=="string";if(b.dataTypes[0]==="jsonp"||b.jsonp!==!1&&(ce.test(b.url)||e&&ce.test(b.data))){var g,h=b.jsonpCallback=f.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,i=a[h],j=b.url,k=b.data,l="$1"+h+"$2";b.jsonp!==!1&&(j=j.replace(ce,l),b.url===j&&(e&&(k=k.replace(ce,l)),b.data===k&&(j+=(/\?/.test(j)?"&":"?")+b.jsonp+"="+h))),b.url=j,b.data=k,a[h]=function(a){g=[a]},d.always(function(){a[h]=i,g&&f.isFunction(i)&&a[h](g[0])}),b.converters["script json"]=function(){g||f.error(h+" was not called");return g[0]},b.dataTypes[0]="json";return"script"}}),f.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/javascript|ecmascript/},converters:{"text script":function(a){f.globalEval(a);return a}}}),f.ajaxPrefilter("script",function(a){a.cache===b&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),f.ajaxTransport("script",function(a){if(a.crossDomain){var d,e=c.head||c.getElementsByTagName("head")[0]||c.documentElement;return{send:function(f,g){d=c.createElement("script"),d.async="async",a.scriptCharset&&(d.charset=a.scriptCharset),d.src=a.url,d.onload=d.onreadystatechange=function(a,c){if(c||!d.readyState||/loaded|complete/.test(d.readyState))d.onload=d.onreadystatechange=null,e&&d.parentNode&&e.removeChild(d),d=b,c||g(200,"success")},e.insertBefore(d,e.firstChild)},abort:function(){d&&d.onload(0,1)}}}});var cf=a.ActiveXObject?function(){for(var a in ch)ch[a](0,1)}:!1,cg=0,ch;f.ajaxSettings.xhr=a.ActiveXObject?function(){return!this.isLocal&&ci()||cj()}:ci,function(a){f.extend(f.support,{ajax:!!a,cors:!!a&&"withCredentials"in a})}(f.ajaxSettings.xhr()),f.support.ajax&&f.ajaxTransport(function(c){if(!c.crossDomain||f.support.cors){var d;return{send:function(e,g){var h=c.xhr(),i,j;c.username?h.open(c.type,c.url,c.async,c.username,c.password):h.open(c.type,c.url,c.async);if(c.xhrFields)for(j in c.xhrFields)h[j]=c.xhrFields[j];c.mimeType&&h.overrideMimeType&&h.overrideMimeType(c.mimeType),!c.crossDomain&&!e["X-Requested-With"]&&(e["X-Requested-With"]="XMLHttpRequest");try{for(j in e)h.setRequestHeader(j,e[j])}catch(k){}h.send(c.hasContent&&c.data||null),d=function(a,e){var j,k,l,m,n;try{if(d&&(e||h.readyState===4)){d=b,i&&(h.onreadystatechange=f.noop,cf&&delete ch[i]);if(e)h.readyState!==4&&h.abort();else{j=h.status,l=h.getAllResponseHeaders(),m={},n=h.responseXML,n&&n.documentElement&&(m.xml=n),m.text=h.responseText;try{k=h.statusText}catch(o){k=""}!j&&c.isLocal&&!c.crossDomain?j=m.text?200:404:j===1223&&(j=204)}}}catch(p){e||g(-1,p)}m&&g(j,k,m,l)},!c.async||h.readyState===4?d():(i=++cg,cf&&(ch||(ch={},f(a).unload(cf)),ch[i]=d),h.onreadystatechange=d)},abort:function(){d&&d(0,1)}}}});var ck={},cl,cm,cn=/^(?:toggle|show|hide)$/,co=/^([+\-]=)?([\d+.\-]+)([a-z%]*)$/i,cp,cq=[["height","marginTop","marginBottom","paddingTop","paddingBottom"],["width","marginLeft","marginRight","paddingLeft","paddingRight"],["opacity"]],cr;f.fn.extend({show:function(a,b,c){var d,e;if(a||a===0)return this.animate(cu("show",3),a,b,c);for(var g=0,h=this.length;g<h;g++)d=this[g],d.style&&(e=d.style.display,!f._data(d,"olddisplay")&&e==="none"&&(e=d.style.display=""),e===""&&f.css(d,"display")==="none"&&f._data(d,"olddisplay",cv(d.nodeName)));for(g=0;g<h;g++){d=this[g];if(d.style){e=d.style.display;if(e===""||e==="none")d.style.display=f._data(d,"olddisplay")||""}}return this},hide:function(a,b,c){if(a||a===0)return this.animate(cu("hide",3),a,b,c);var d,e,g=0,h=this.length;for(;g<h;g++)d=this[g],d.style&&(e=f.css(d,"display"),e!=="none"&&!f._data(d,"olddisplay")&&f._data(d,"olddisplay",e));for(g=0;g<h;g++)this[g].style&&(this[g].style.display="none");return this},_toggle:f.fn.toggle,toggle:function(a,b,c){var d=typeof a=="boolean";f.isFunction(a)&&f.isFunction(b)?this._toggle.apply(this,arguments):a==null||d?this.each(function(){var b=d?a:f(this).is(":hidden");f(this)[b?"show":"hide"]()}):this.animate(cu("toggle",3),a,b,c);return this},fadeTo:function(a,b,c,d){return this.filter(":hidden").css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){function g(){e.queue===!1&&f._mark(this);var b=f.extend({},e),c=this.nodeType===1,d=c&&f(this).is(":hidden"),g,h,i,j,k,l,m,n,o;b.animatedProperties={};for(i in a){g=f.camelCase(i),i!==g&&(a[g]=a[i],delete a[i]),h=a[g],f.isArray(h)?(b.animatedProperties[g]=h[1],h=a[g]=h[0]):b.animatedProperties[g]=b.specialEasing&&b.specialEasing[g]||b.easing||"swing";if(h==="hide"&&d||h==="show"&&!d)return b.complete.call(this);c&&(g==="height"||g==="width")&&(b.overflow=[this.style.overflow,this.style.overflowX,this.style.overflowY],f.css(this,"display")==="inline"&&f.css(this,"float")==="none"&&(!f.support.inlineBlockNeedsLayout||cv(this.nodeName)==="inline"?this.style.display="inline-block":this.style.zoom=1))}b.overflow!=null&&(this.style.overflow="hidden");for(i in a)j=new f.fx(this,b,i),h=a[i],cn.test(h)?(o=f._data(this,"toggle"+i)||(h==="toggle"?d?"show":"hide":0),o?(f._data(this,"toggle"+i,o==="show"?"hide":"show"),j[o]()):j[h]()):(k=co.exec(h),l=j.cur(),k?(m=parseFloat(k[2]),n=k[3]||(f.cssNumber[i]?"":"px"),n!=="px"&&(f.style(this,i,(m||1)+n),l=(m||1)/j.cur()*l,f.style(this,i,l+n)),k[1]&&(m=(k[1]==="-="?-1:1)*m+l),j.custom(l,m,n)):j.custom(l,h,""));return!0}var e=f.speed(b,c,d);if(f.isEmptyObject(a))return this.each(e.complete,[!1]);a=f.extend({},a);return e.queue===!1?this.each(g):this.queue(e.queue,g)},stop:function(a,c,d){typeof a!="string"&&(d=c,c=a,a=b),c&&a!==!1&&this.queue(a||"fx",[]);return this.each(function(){function h(a,b,c){var e=b[c];f.removeData(a,c,!0),e.stop(d)}var b,c=!1,e=f.timers,g=f._data(this);d||f._unmark(!0,this);if(a==null)for(b in g)g[b]&&g[b].stop&&b.indexOf(".run")===b.length-4&&h(this,g,b);else g[b=a+".run"]&&g[b].stop&&h(this,g,b);for(b=e.length;b--;)e[b].elem===this&&(a==null||e[b].queue===a)&&(d?e[b](!0):e[b].saveState(),c=!0,e.splice(b,1));(!d||!c)&&f.dequeue(this,a)})}}),f.each({slideDown:cu("show",1),slideUp:cu("hide",1),slideToggle:cu("toggle",1),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){f.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),f.extend({speed:function(a,b,c){var d=a&&typeof a=="object"?f.extend({},a):{complete:c||!c&&b||f.isFunction(a)&&a,duration:a,easing:c&&b||b&&!f.isFunction(b)&&b};d.duration=f.fx.off?0:typeof d.duration=="number"?d.duration:d.duration in f.fx.speeds?f.fx.speeds[d.duration]:f.fx.speeds._default;if(d.queue==null||d.queue===!0)d.queue="fx";d.old=d.complete,d.complete=function(a){f.isFunction(d.old)&&d.old.call(this),d.queue?f.dequeue(this,d.queue):a!==!1&&f._unmark(this)};return d},easing:{linear:function(a,b,c,d){return c+d*a},swing:function(a,b,c,d){return(-Math.cos(a*Math.PI)/2+.5)*d+c}},timers:[],fx:function(a,b,c){this.options=b,this.elem=a,this.prop=c,b.orig=b.orig||{}}}),f.fx.prototype={update:function(){this.options.step&&this.options.step.call(this.elem,this.now,this),(f.fx.step[this.prop]||f.fx.step._default)(this)},cur:function(){if(this.elem[this.prop]!=null&&(!this.elem.style||this.elem.style[this.prop]==null))return this.elem[this.prop];var a,b=f.css(this.elem,this.prop);return isNaN(a=parseFloat(b))?!b||b==="auto"?0:b:a},custom:function(a,c,d){function h(a){return e.step(a)}var e=this,g=f.fx;this.startTime=cr||cs(),this.end=c,this.now=this.start=a,this.pos=this.state=0,this.unit=d||this.unit||(f.cssNumber[this.prop]?"":"px"),h.queue=this.options.queue,h.elem=this.elem,h.saveState=function(){e.options.hide&&f._data(e.elem,"fxshow"+e.prop)===b&&f._data(e.elem,"fxshow"+e.prop,e.start)},h()&&f.timers.push(h)&&!cp&&(cp=setInterval(g.tick,g.interval))},show:function(){var a=f._data(this.elem,"fxshow"+this.prop);this.options.orig[this.prop]=a||f.style(this.elem,this.prop),this.options.show=!0,a!==b?this.custom(this.cur(),a):this.custom(this.prop==="width"||this.prop==="height"?1:0,this.cur()),f(this.elem).show()},hide:function(){this.options.orig[this.prop]=f._data(this.elem,"fxshow"+this.prop)||f.style(this.elem,this.prop),this.options.hide=!0,this.custom(this.cur(),0)},step:function(a){var b,c,d,e=cr||cs(),g=!0,h=this.elem,i=this.options;if(a||e>=i.duration+this.startTime){this.now=this.end,this.pos=this.state=1,this.update(),i.animatedProperties[this.prop]=!0;for(b in i.animatedProperties)i.animatedProperties[b]!==!0&&(g=!1);if(g){i.overflow!=null&&!f.support.shrinkWrapBlocks&&f.each(["","X","Y"],function(a,b){h.style["overflow"+b]=i.overflow[a]}),i.hide&&f(h).hide();if(i.hide||i.show)for(b in i.animatedProperties)f.style(h,b,i.orig[b]),f.removeData(h,"fxshow"+b,!0),f.removeData(h,"toggle"+b,!0);d=i.complete,d&&(i.complete=!1,d.call(h))}return!1}i.duration==Infinity?this.now=e:(c=e-this.startTime,this.state=c/i.duration,this.pos=f.easing[i.animatedProperties[this.prop]](this.state,c,0,1,i.duration),this.now=this.start+(this.end-this.start)*this.pos),this.update();return!0}},f.extend(f.fx,{tick:function(){var a,b=f.timers,c=0;for(;c<b.length;c++)a=b[c],!a()&&b[c]===a&&b.splice(c--,1);b.length||f.fx.stop()},interval:13,stop:function(){clearInterval(cp),cp=null},speeds:{slow:600,fast:200,_default:400},step:{opacity:function(a){f.style(a.elem,"opacity",a.now)},_default:function(a){a.elem.style&&a.elem.style[a.prop]!=null?a.elem.style[a.prop]=a.now+a.unit:a.elem[a.prop]=a.now}}}),f.each(["width","height"],function(a,b){f.fx.step[b]=function(a){f.style(a.elem,b,Math.max(0,a.now)+a.unit)}}),f.expr&&f.expr.filters&&(f.expr.filters.animated=function(a){return f.grep(f.timers,function(b){return a===b.elem}).length});var cw=/^t(?:able|d|h)$/i,cx=/^(?:body|html)$/i;"getBoundingClientRect"in c.documentElement?f.fn.offset=function(a){var b=this[0],c;if(a)return this.each(function(b){f.offset.setOffset(this,a,b)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return f.offset.bodyOffset(b);try{c=b.getBoundingClientRect()}catch(d){}var e=b.ownerDocument,g=e.documentElement;if(!c||!f.contains(g,b))return c?{top:c.top,left:c.left}:{top:0,left:0};var h=e.body,i=cy(e),j=g.clientTop||h.clientTop||0,k=g.clientLeft||h.clientLeft||0,l=i.pageYOffset||f.support.boxModel&&g.scrollTop||h.scrollTop,m=i.pageXOffset||f.support.boxModel&&g.scrollLeft||h.scrollLeft,n=c.top+l-j,o=c.left+m-k;return{top:n,left:o}}:f.fn.offset=function(a){var b=this[0];if(a)return this.each(function(b){f.offset.setOffset(this,a,b)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return f.offset.bodyOffset(b);var c,d=b.offsetParent,e=b,g=b.ownerDocument,h=g.documentElement,i=g.body,j=g.defaultView,k=j?j.getComputedStyle(b,null):b.currentStyle,l=b.offsetTop,m=b.offsetLeft;while((b=b.parentNode)&&b!==i&&b!==h){if(f.support.fixedPosition&&k.position==="fixed")break;c=j?j.getComputedStyle(b,null):b.currentStyle,l-=b.scrollTop,m-=b.scrollLeft,b===d&&(l+=b.offsetTop,m+=b.offsetLeft,f.support.doesNotAddBorder&&(!f.support.doesAddBorderForTableAndCells||!cw.test(b.nodeName))&&(l+=parseFloat(c.borderTopWidth)||0,m+=parseFloat(c.borderLeftWidth)||0),e=d,d=b.offsetParent),f.support.subtractsBorderForOverflowNotVisible&&c.overflow!=="visible"&&(l+=parseFloat(c.borderTopWidth)||0,m+=parseFloat(c.borderLeftWidth)||0),k=c}if(k.position==="relative"||k.position==="static")l+=i.offsetTop,m+=i.offsetLeft;f.support.fixedPosition&&k.position==="fixed"&&(l+=Math.max(h.scrollTop,i.scrollTop),m+=Math.max(h.scrollLeft,i.scrollLeft));return{top:l,left:m}},f.offset={bodyOffset:function(a){var b=a.offsetTop,c=a.offsetLeft;f.support.doesNotIncludeMarginInBodyOffset&&(b+=parseFloat(f.css(a,"marginTop"))||0,c+=parseFloat(f.css(a,"marginLeft"))||0);return{top:b,left:c}},setOffset:function(a,b,c){var d=f.css(a,"position");d==="static"&&(a.style.position="relative");var e=f(a),g=e.offset(),h=f.css(a,"top"),i=f.css(a,"left"),j=(d==="absolute"||d==="fixed")&&f.inArray("auto",[h,i])>-1,k={},l={},m,n;j?(l=e.position(),m=l.top,n=l.left):(m=parseFloat(h)||0,n=parseFloat(i)||0),f.isFunction(b)&&(b=b.call(a,c,g)),b.top!=null&&(k.top=b.top-g.top+m),b.left!=null&&(k.left=b.left-g.left+n),"using"in b?b.using.call(a,k):e.css(k)}},f.fn.extend({position:function(){if(!this[0])return null;var a=this[0],b=this.offsetParent(),c=this.offset(),d=cx.test(b[0].nodeName)?{top:0,left:0}:b.offset();c.top-=parseFloat(f.css(a,"marginTop"))||0,c.left-=parseFloat(f.css(a,"marginLeft"))||0,d.top+=parseFloat(f.css(b[0],"borderTopWidth"))||0,d.left+=parseFloat(f.css(b[0],"borderLeftWidth"))||0;return{top:c.top-d.top,left:c.left-d.left}},offsetParent:function(){return this.map(function(){var a=this.offsetParent||c.body;while(a&&!cx.test(a.nodeName)&&f.css(a,"position")==="static")a=a.offsetParent;return a})}}),f.each(["Left","Top"],function(a,c){var d="scroll"+c;f.fn[d]=function(c){var e,g;if(c===b){e=this[0];if(!e)return null;g=cy(e);return g?"pageXOffset"in g?g[a?"pageYOffset":"pageXOffset"]:f.support.boxModel&&g.document.documentElement[d]||g.document.body[d]:e[d]}return this.each(function(){g=cy(this),g?g.scrollTo(a?f(g).scrollLeft():c,a?c:f(g).scrollTop()):this[d]=c})}}),f.each(["Height","Width"],function(a,c){var d=c.toLowerCase();f.fn["inner"+c]=function(){var a=this[0];return a?a.style?parseFloat(f.css(a,d,"padding")):this[d]():null},f.fn["outer"+c]=function(a){var b=this[0];return b?b.style?parseFloat(f.css(b,d,a?"margin":"border")):this[d]():null},f.fn[d]=function(a){var e=this[0];if(!e)return a==null?null:this;if(f.isFunction(a))return this.each(function(b){var c=f(this);c[d](a.call(this,b,c[d]()))});if(f.isWindow(e)){var g=e.document.documentElement["client"+c],h=e.document.body;return e.document.compatMode==="CSS1Compat"&&g||h&&h["client"+c]||g}if(e.nodeType===9)return Math.max(e.documentElement["client"+c],e.body["scroll"+c],e.documentElement["scroll"+c],e.body["offset"+c],e.documentElement["offset"+c]);if(a===b){var i=f.css(e,d),j=parseFloat(i);return f.isNumeric(j)?j:i}return this.css(d,typeof a=="string"?a:a+"px")}}),a.jQuery=a.$=f,typeof define=="function"&&define.amd&&define.amd.jQuery&&define("jquery",[],function(){return f})})(window);
</script><script type="text/javascript">//XRegExp 1.5.0 <xregexp.com> MIT License
var XRegExp;if(XRegExp){throw Error("can't load XRegExp twice in the same frame")}(function(){XRegExp=function(w,r){var q=[],u=XRegExp.OUTSIDE_CLASS,x=0,p,s,v,t,y;if(XRegExp.isRegExp(w)){if(r!==undefined){throw TypeError("can't supply flags when constructing one RegExp from another")}return j(w)}if(g){throw Error("can't call the XRegExp constructor within token definition functions")}r=r||"";p={hasNamedCapture:false,captureNames:[],hasFlag:function(z){return r.indexOf(z)>-1},setFlag:function(z){r+=z}};while(x<w.length){s=o(w,x,u,p);if(s){q.push(s.output);x+=(s.match[0].length||1)}else{if(v=m.exec.call(i[u],w.slice(x))){q.push(v[0]);x+=v[0].length}else{t=w.charAt(x);if(t==="["){u=XRegExp.INSIDE_CLASS}else{if(t==="]"){u=XRegExp.OUTSIDE_CLASS}}q.push(t);x++}}}y=RegExp(q.join(""),m.replace.call(r,h,""));y._xregexp={source:w,captureNames:p.hasNamedCapture?p.captureNames:null};return y};XRegExp.version="1.5.0";XRegExp.INSIDE_CLASS=1;XRegExp.OUTSIDE_CLASS=2;var c=/\$(?:(\d\d?|[$&`'])|{([$\w]+)})/g,h=/[^gimy]+|([\s\S])(?=[\s\S]*\1)/g,n=/^(?:[?*+]|{\d+(?:,\d*)?})\??/,g=false,k=[],m={exec:RegExp.prototype.exec,test:RegExp.prototype.test,match:String.prototype.match,replace:String.prototype.replace,split:String.prototype.split},a=m.exec.call(/()??/,"")[1]===undefined,e=function(){var p=/^/g;m.test.call(p,"");return !p.lastIndex}(),f=function(){var p=/x/g;m.replace.call("x",p,"");return !p.lastIndex}(),b=RegExp.prototype.sticky!==undefined,i={};i[XRegExp.INSIDE_CLASS]=/^(?:\\(?:[0-3][0-7]{0,2}|[4-7][0-7]?|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S]))/;i[XRegExp.OUTSIDE_CLASS]=/^(?:\\(?:0(?:[0-3][0-7]{0,2}|[4-7][0-7]?)?|[1-9]\d*|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S])|\(\?[:=!]|[?*+]\?|{\d+(?:,\d*)?}\??)/;XRegExp.addToken=function(s,r,q,p){k.push({pattern:j(s,"g"+(b?"y":"")),handler:r,scope:q||XRegExp.OUTSIDE_CLASS,trigger:p||null})};XRegExp.cache=function(r,p){var q=r+"/"+(p||"");return XRegExp.cache[q]||(XRegExp.cache[q]=XRegExp(r,p))};XRegExp.copyAsGlobal=function(p){return j(p,"g")};XRegExp.escape=function(p){return p.replace(/[-[\]{}()*+?.,\\^$|#\s]/g,"\\$&")};XRegExp.execAt=function(s,r,t,q){r=j(r,"g"+((q&&b)?"y":""));r.lastIndex=t=t||0;var p=r.exec(s);if(q){return(p&&p.index===t)?p:null}else{return p}};XRegExp.freezeTokens=function(){XRegExp.addToken=function(){throw Error("can't run addToken after freezeTokens")}};XRegExp.isRegExp=function(p){return Object.prototype.toString.call(p)==="[object RegExp]"};XRegExp.iterate=function(u,p,v,s){var t=j(p,"g"),r=-1,q;while(q=t.exec(u)){v.call(s,q,++r,u,t);if(t.lastIndex===q.index){t.lastIndex++}}if(p.global){p.lastIndex=0}};XRegExp.matchChain=function(q,p){return function r(s,x){var v=p[x].regex?p[x]:{regex:p[x]},u=j(v.regex,"g"),w=[],t;for(t=0;t<s.length;t++){XRegExp.iterate(s[t],u,function(y){w.push(v.backref?(y[v.backref]||""):y[0])})}return((x===p.length-1)||!w.length)?w:r(w,x+1)}([q],0)};RegExp.prototype.apply=function(q,p){return this.exec(p[0])};RegExp.prototype.call=function(p,q){return this.exec(q)};RegExp.prototype.exec=function(t){var r=m.exec.apply(this,arguments),q,p;if(r){if(!a&&r.length>1&&l(r,"")>-1){p=RegExp(this.source,m.replace.call(d(this),"g",""));m.replace.call(t.slice(r.index),p,function(){for(var u=1;u<arguments.length-2;u++){if(arguments[u]===undefined){r[u]=undefined}}})}if(this._xregexp&&this._xregexp.captureNames){for(var s=1;s<r.length;s++){q=this._xregexp.captureNames[s-1];if(q){r[q]=r[s]}}}if(!e&&this.global&&!r[0].length&&(this.lastIndex>r.index)){this.lastIndex--}}return r};if(!e){RegExp.prototype.test=function(q){var p=m.exec.call(this,q);if(p&&this.global&&!p[0].length&&(this.lastIndex>p.index)){this.lastIndex--}return !!p}}String.prototype.match=function(q){if(!XRegExp.isRegExp(q)){q=RegExp(q)}if(q.global){var p=m.match.apply(this,arguments);q.lastIndex=0;return p}return q.exec(this)};String.prototype.replace=function(r,s){var t=XRegExp.isRegExp(r),q,p,u;if(t&&typeof s.valueOf()==="string"&&s.indexOf("${")===-1&&f){return m.replace.apply(this,arguments)}if(!t){r=r+""}else{if(r._xregexp){q=r._xregexp.captureNames}}if(typeof s==="function"){p=m.replace.call(this,r,function(){if(q){arguments[0]=new String(arguments[0]);for(var v=0;v<q.length;v++){if(q[v]){arguments[0][q[v]]=arguments[v+1]}}}if(t&&r.global){r.lastIndex=arguments[arguments.length-2]+arguments[0].length}return s.apply(null,arguments)})}else{u=this+"";p=m.replace.call(u,r,function(){var v=arguments;return m.replace.call(s,c,function(x,w,A){if(w){switch(w){case"$":return"$";case"&":return v[0];case"`":return v[v.length-1].slice(0,v[v.length-2]);case"'":return v[v.length-1].slice(v[v.length-2]+v[0].length);default:var y="";w=+w;if(!w){return x}while(w>v.length-3){y=String.prototype.slice.call(w,-1)+y;w=Math.floor(w/10)}return(w?v[w]||"":"$")+y}}else{var z=+A;if(z<=v.length-3){return v[z]}z=q?l(q,A):-1;return z>-1?v[z+1]:x}})})}if(t&&r.global){r.lastIndex=0}return p};String.prototype.split=function(u,p){if(!XRegExp.isRegExp(u)){return m.split.apply(this,arguments)}var w=this+"",r=[],v=0,t,q;if(p===undefined||+p<0){p=Infinity}else{p=Math.floor(+p);if(!p){return[]}}u=XRegExp.copyAsGlobal(u);while(t=u.exec(w)){if(u.lastIndex>v){r.push(w.slice(v,t.index));if(t.length>1&&t.index<w.length){Array.prototype.push.apply(r,t.slice(1))}q=t[0].length;v=u.lastIndex;if(r.length>=p){break}}if(u.lastIndex===t.index){u.lastIndex++}}if(v===w.length){if(!m.test.call(u,"")||q){r.push("")}}else{r.push(w.slice(v))}return r.length>p?r.slice(0,p):r};function j(r,q){if(!XRegExp.isRegExp(r)){throw TypeError("type RegExp expected")}var p=r._xregexp;r=XRegExp(r.source,d(r)+(q||""));if(p){r._xregexp={source:p.source,captureNames:p.captureNames?p.captureNames.slice(0):null}}return r}function d(p){return(p.global?"g":"")+(p.ignoreCase?"i":"")+(p.multiline?"m":"")+(p.extended?"x":"")+(p.sticky?"y":"")}function o(v,u,w,p){var r=k.length,y,s,x;g=true;try{while(r--){x=k[r];if((w&x.scope)&&(!x.trigger||x.trigger.call(p))){x.pattern.lastIndex=u;s=x.pattern.exec(v);if(s&&s.index===u){y={output:x.handler.call(p,s,w),match:s};break}}}}catch(q){throw q}finally{g=false}return y}function l(s,q,r){if(Array.prototype.indexOf){return s.indexOf(q,r)}for(var p=r||0;p<s.length;p++){if(s[p]===q){return p}}return -1}XRegExp.addToken(/\(\?#[^)]*\)/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"});XRegExp.addToken(/\((?!\?)/,function(){this.captureNames.push(null);return"("});XRegExp.addToken(/\(\?<([$\w]+)>/,function(p){this.captureNames.push(p[1]);this.hasNamedCapture=true;return"("});XRegExp.addToken(/\\k<([\w$]+)>/,function(q){var p=l(this.captureNames,q[1]);return p>-1?"\\"+(p+1)+(isNaN(q.input.charAt(q.index+q[0].length))?"":"(?:)"):q[0]});XRegExp.addToken(/\[\^?]/,function(p){return p[0]==="[]"?"\\b\\B":"[\\s\\S]"});XRegExp.addToken(/^\(\?([imsx]+)\)/,function(p){this.setFlag(p[1]);return""});XRegExp.addToken(/(?:\s+|#.*)+/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("x")});XRegExp.addToken(/\./,function(){return"[\\s\\S]"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("s")})})();
</script><script type="text/javascript">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
//
// Begin anonymous function. This is used to contain local scope variables without polutting global scope.
//
var SyntaxHighlighter = function() { 

// CommonJS
if (typeof(require) != 'undefined' && typeof(XRegExp) == 'undefined')
{
	XRegExp = require('XRegExp').XRegExp;
}

// Shortcut object which will be assigned to the SyntaxHighlighter variable.
// This is a shorthand for local reference in order to avoid long namespace 
// references to SyntaxHighlighter.whatever...
var sh = {
	defaults : {
		/** Additional CSS class names to be added to highlighter elements. */
		'class-name' : '',
		
		/** First line number. */
		'first-line' : 1,
		
		/**
		 * Pads line numbers. Possible values are:
		 *
		 *   false - don't pad line numbers.
		 *   true  - automaticaly pad numbers with minimum required number of leading zeroes.
		 *   [int] - length up to which pad line numbers.
		 */
		'pad-line-numbers' : false,
		
		/** Lines to highlight. */
		'highlight' : null,
		
		/** Title to be displayed above the code block. */
		'title' : null,
		
		/** Enables or disables smart tabs. */
		'smart-tabs' : true,
		
		/** Gets or sets tab size. */
		'tab-size' : 4,
		
		/** Enables or disables gutter. */
		'gutter' : true,
		
		/** Enables or disables toolbar. */
		'toolbar' : true,
		
		/** Enables quick code copy and paste from double click. */
		'quick-code' : true,
		
		/** Forces code view to be collapsed. */
		'collapse' : false,
		
		/** Enables or disables automatic links. */
		'auto-links' : true,
		
		/** Gets or sets light mode. Equavalent to turning off gutter and toolbar. */
		'light' : false,
		
		'html-script' : false
	},
	
	config : {
		space : '&nbsp;',
		
		/** Enables use of <SCRIPT type="syntaxhighlighter" /> tags. */
		useScriptTags : true,
		
		/** Blogger mode flag. */
		bloggerMode : false,
		
		stripBrs : false,
		
		/** Name of the tag that SyntaxHighlighter will automatically look for. */
		tagName : 'pre',
		
		strings : {
			expandSource : 'expand source',
			help : '?',
			alert: 'SyntaxHighlighter\n\n',
			noBrush : 'Can\'t find brush for: ',
			brushNotHtmlScript : 'Brush wasn\'t configured for html-script option: ',
			
			// this is populated by the build script
			aboutDialog : '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><title>About SyntaxHighlighter</title></head><body style="font-family:Geneva,Arial,Helvetica,sans-serif;background-color:#fff;color:#000;font-size:1em;text-align:center;"><div style="text-align:center;margin-top:1.5em;"><div style="font-size:xx-large;">SyntaxHighlighter</div><div style="font-size:.75em;margin-bottom:3em;"><div>version 3.0.83 (July 02 2010)</div><div><a href="http://alexgorbatchev.com/SyntaxHighlighter" target="_blank" style="color:#005896">http://alexgorbatchev.com/SyntaxHighlighter</a></div><div>JavaScript code syntax highlighter.</div><div>Copyright 2004-2010 Alex Gorbatchev.</div></div><div>If you like this script, please <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=2930402" style="color:#005896">donate</a> to <br/>keep development active!</div></div></body></html>'
		}
	},
	
	/** Internal 'global' variables. */
	vars : {
		discoveredBrushes : null,
		highlighters : {}
	},
	
	/** This object is populated by user included external brush files. */
	brushes : {},

	/** Common regular expressions. */
	regexLib : {
		multiLineCComments			: /\/\*[\s\S]*?\*\//gm,
		singleLineCComments			: /\/\/.*$/gm,
		singleLinePerlComments		: /#.*$/gm,
		doubleQuotedString			: /"([^\\"\n]|\\.)*"/g,
		singleQuotedString			: /'([^\\'\n]|\\.)*'/g,
		multiLineDoubleQuotedString	: new XRegExp('"([^\\\\"]|\\\\.)*"', 'gs'),
		multiLineSingleQuotedString	: new XRegExp("'([^\\\\']|\\\\.)*'", 'gs'),
		xmlComments					: /(&lt;|<)!--[\s\S]*?--(&gt;|>)/gm,
		url							: /\w+:\/\/[\w-.\/?%&=:@;]*/g,
		
		/** <?= ?> tags. */
		phpScriptTags 				: { left: /(&lt;|<)\?=?/g, right: /\?(&gt;|>)/g },
		
		/** <%= %> tags. */
		aspScriptTags				: { left: /(&lt;|<)%=?/g, right: /%(&gt;|>)/g },
		
		scriptScriptTags			: { left: /(&lt;|<)\s*script.*?(&gt;|>)/gi, right: /(&lt;|<)\/\s*script\s*(&gt;|>)/gi }
	},

	toolbar: {
		/**
		 * Generates HTML markup for the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @return {String} Returns HTML markup.
		 */
		getHtml: function(highlighter)
		{
			var html = '<div class="toolbar">',
				items = sh.toolbar.items,
				list = items.list
				;
			
			function defaultGetHtml(highlighter, name)
			{
				return sh.toolbar.getButtonHtml(highlighter, name, sh.config.strings[name]);
			};
			
			for (var i = 0; i < list.length; i++)
				html += (items[list[i]].getHtml || defaultGetHtml)(highlighter, list[i]);
			
			html += '</div>';
			
			return html;
		},
		
		/**
		 * Generates HTML markup for a regular button in the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @param {String} commandName		Command name that would be executed.
		 * @param {String} label			Label text to display.
		 * @return {String}					Returns HTML markup.
		 */
		getButtonHtml: function(highlighter, commandName, label)
		{
			return '<span><a href="#" class="toolbar_item'
				+ ' command_' + commandName
				+ ' ' + commandName
				+ '">' + label + '</a></span>'
				;
		},
		
		/**
		 * Event handler for a toolbar anchor.
		 */
		handler: function(e)
		{
			var target = e.target,
				className = target.className || ''
				;

			function getValue(name)
			{
				var r = new RegExp(name + '_(\\w+)'),
					match = r.exec(className)
					;

				return match ? match[1] : null;
			};
			
			var highlighter = getHighlighterById(findParentElement(target, '.syntaxhighlighter').id),
				commandName = getValue('command')
				;
			
			// execute the toolbar command
			if (highlighter && commandName)
				sh.toolbar.items[commandName].execute(highlighter);

			// disable default A click behaviour
			e.preventDefault();
		},
		
		/** Collection of toolbar items. */
		items : {
			// Ordered lis of items in the toolbar. Can't expect `for (var n in items)` to be consistent.
			list: ['expandSource', 'help'],

			expandSource: {
				getHtml: function(highlighter)
				{
					if (highlighter.getParam('collapse') != true)
						return '';
						
					var title = highlighter.getParam('title');
					return sh.toolbar.getButtonHtml(highlighter, 'expandSource', title ? title : sh.config.strings.expandSource);
				},
			
				execute: function(highlighter)
				{
					var div = getHighlighterDivById(highlighter.id);
					removeClass(div, 'collapsed');
				}
			},

			/** Command to display the about dialog window. */
			help: {
				execute: function(highlighter)
				{	
					var wnd = popup('', '_blank', 500, 250, 'scrollbars=0'),
						doc = wnd.document
						;
					
					doc.write(sh.config.strings.aboutDialog);
					doc.close();
					wnd.focus();
				}
			}
		}
	},

	/**
	 * Finds all elements on the page which should be processes by SyntaxHighlighter.
	 *
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are returned which qualify.
	 *
	 * @return {Array}	Returns list of <code>{ target: DOMElement, params: Object }</code> objects.
	 */
	findElements: function(globalParams, element)
	{
		var elements = element ? [element] : toArray(document.getElementsByTagName(sh.config.tagName)), 
			conf = sh.config,
			result = []
			;

		// support for <SCRIPT TYPE="syntaxhighlighter" /> feature
		if (conf.useScriptTags)
			elements = elements.concat(getSyntaxHighlighterScriptTags());

		if (elements.length === 0) 
			return result;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var item = {
				target: elements[i], 
				// local params take precedence over globals
				params: merge(globalParams, parseParams(elements[i].className))
			};

			if (item.params['brush'] == null)
				continue;
				
			result.push(item);
		}
		
		return result;
	},

	/**
	 * Shorthand to highlight all elements on the page that are marked as 
	 * SyntaxHighlighter source code.
	 * 
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are highlighted.
	 */ 
	highlight: function(globalParams, element)
	{
		var elements = this.findElements(globalParams, element),
			propertyName = 'innerHTML', 
			highlighter = null,
			conf = sh.config
			;

		if (elements.length === 0) 
			return;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var element = elements[i],
				target = element.target,
				params = element.params,
				brushName = params.brush,
				code
				;

			if (brushName == null)
				continue;

			// Instantiate a brush
			if (params['html-script'] == 'true' || sh.defaults['html-script'] == true) 
			{
				highlighter = new sh.HtmlScript(brushName);
				brushName = 'htmlscript';
			}
			else
			{
				var brush = findBrush(brushName);
				
				if (brush)
					highlighter = new brush();
				else
					continue;
			}
			
			code = target[propertyName];
			
			// remove CDATA from <SCRIPT/> tags if it's present
			if (conf.useScriptTags)
				code = stripCData(code);
				
			// Inject title if the attribute is present
			if ((target.title || '') != '')
				params.title = target.title;
				
			params['brush'] = brushName;
			highlighter.init(params);
			element = highlighter.getDiv(code);
			
			// carry over ID
			if ((target.id || '') != '')
				element.id = target.id;
			
			target.parentNode.replaceChild(element, target);
		}
	},

	/**
	 * Main entry point for the SyntaxHighlighter.
	 * @param {Object} params Optional params to apply to all highlighted elements.
	 */
	all: function(params)
	{
		attachEvent(
			window,
			'load',
			function() { sh.highlight(params); }
		);
	}
}; // end of sh

sh['all']			= sh.all;
sh['highlight']		= sh.highlight;

/**
 * Checks if target DOM elements has specified CSS class.
 * @param {DOMElement} target Target DOM element to check.
 * @param {String} className Name of the CSS class to check for.
 * @return {Boolean} Returns true if class name is present, false otherwise.
 */
function hasClass(target, className)
{
	return target.className.indexOf(className) != -1;
};

/**
 * Adds CSS class name to the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className New CSS class to add.
 */
function addClass(target, className)
{
	if (!hasClass(target, className))
		target.className += ' ' + className;
};

/**
 * Removes CSS class name from the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className CSS class to remove.
 */
function removeClass(target, className)
{
	target.className = target.className.replace(className, '');
};

/**
 * Converts the source to array object. Mostly used for function arguments and 
 * lists returned by getElementsByTagName() which aren't Array objects.
 * @param {List} source Source list.
 * @return {Array} Returns array.
 */
function toArray(source)
{
	var result = [];
	
	for (var i = 0; i < source.length; i++) 
		result.push(source[i]);
		
	return result;
};

/**
 * Splits block of text into lines.
 * @param {String} block Block of text.
 * @return {Array} Returns array of lines.
 */
function splitLines(block)
{
	return block.split('\n');
}

/**
 * Generates HTML ID for the highlighter.
 * @param {String} highlighterId Highlighter ID.
 * @return {String} Returns HTML ID.
 */
function getHighlighterId(id)
{
	var prefix = 'highlighter_';
	return id.indexOf(prefix) == 0 ? id : prefix + id;
};

/**
 * Finds Highlighter instance by ID.
 * @param {String} highlighterId Highlighter ID.
 * @return {Highlighter} Returns instance of the highlighter.
 */
function getHighlighterById(id)
{
	return sh.vars.highlighters[getHighlighterId(id)];
};

/**
 * Finds highlighter's DIV container.
 * @param {String} highlighterId Highlighter ID.
 * @return {Element} Returns highlighter's DIV element.
 */
function getHighlighterDivById(id)
{
	return document.getElementById(getHighlighterId(id));
};

/**
 * Stores highlighter so that getHighlighterById() can do its thing. Each
 * highlighter must call this method to preserve itself.
 * @param {Highilghter} highlighter Highlighter instance.
 */
function storeHighlighter(highlighter)
{
	sh.vars.highlighters[getHighlighterId(highlighter.id)] = highlighter;
};

/**
 * Looks for a child or parent node which has specified classname.
 * Equivalent to jQuery's $(container).find(".className")
 * @param {Element} target Target element.
 * @param {String} search Class name or node name to look for.
 * @param {Boolean} reverse If set to true, will go up the node tree instead of down.
 * @return {Element} Returns found child or parent element on null.
 */
function findElement(target, search, reverse /* optional */)
{
	if (target == null)
		return null;
		
	var nodes			= reverse != true ? target.childNodes : [ target.parentNode ],
		propertyToFind	= { '#' : 'id', '.' : 'className' }[search.substr(0, 1)] || 'nodeName',
		expectedValue,
		found
		;

	expectedValue = propertyToFind != 'nodeName'
		? search.substr(1)
		: search.toUpperCase()
		;
		
	// main return of the found node
	if ((target[propertyToFind] || '').indexOf(expectedValue) != -1)
		return target;
	
	for (var i = 0; nodes && i < nodes.length && found == null; i++)
		found = findElement(nodes[i], search, reverse);
	
	return found;
};

/**
 * Looks for a parent node which has specified classname.
 * This is an alias to <code>findElement(container, className, true)</code>.
 * @param {Element} target Target element.
 * @param {String} className Class name to look for.
 * @return {Element} Returns found parent element on null.
 */
function findParentElement(target, className)
{
	return findElement(target, className, true);
};

/**
 * Finds an index of element in the array.
 * @ignore
 * @param {Object} searchElement
 * @param {Number} fromIndex
 * @return {Number} Returns index of element if found; -1 otherwise.
 */
function indexOf(array, searchElement, fromIndex)
{
	fromIndex = Math.max(fromIndex || 0, 0);

	for (var i = fromIndex; i < array.length; i++)
		if(array[i] == searchElement)
			return i;
	
	return -1;
};

/**
 * Generates a unique element ID.
 */
function guid(prefix)
{
	return (prefix || '') + Math.round(Math.random() * 1000000).toString();
};

/**
 * Merges two objects. Values from obj2 override values in obj1.
 * Function is NOT recursive and works only for one dimensional objects.
 * @param {Object} obj1 First object.
 * @param {Object} obj2 Second object.
 * @return {Object} Returns combination of both objects.
 */
function merge(obj1, obj2)
{
	var result = {}, name;

	for (name in obj1) 
		result[name] = obj1[name];
	
	for (name in obj2) 
		result[name] = obj2[name];
		
	return result;
};

/**
 * Attempts to convert string to boolean.
 * @param {String} value Input string.
 * @return {Boolean} Returns true if input was "true", false if input was "false" and value otherwise.
 */
function toBoolean(value)
{
	var result = { "true" : true, "false" : false }[value];
	return result == null ? value : result;
};

/**
 * Opens up a centered popup window.
 * @param {String} url		URL to open in the window.
 * @param {String} name		Popup name.
 * @param {int} width		Popup width.
 * @param {int} height		Popup height.
 * @param {String} options	window.open() options.
 * @return {Window}			Returns window instance.
 */
function popup(url, name, width, height, options)
{
	var x = (screen.width - width) / 2,
		y = (screen.height - height) / 2
		;
		
	options +=	', left=' + x + 
				', top=' + y +
				', width=' + width +
				', height=' + height
		;
	options = options.replace(/^,/, '');

	var win = window.open(url, name, options);
	win.focus();
	return win;
};

/**
 * Adds event handler to the target object.
 * @param {Object} obj		Target object.
 * @param {String} type		Name of the event.
 * @param {Function} func	Handling function.
 */
function attachEvent(obj, type, func, scope)
{
	function handler(e)
	{
		e = e || window.event;
		
		if (!e.target)
		{
			e.target = e.srcElement;
			e.preventDefault = function()
			{
				this.returnValue = false;
			};
		}
			
		func.call(scope || window, e);
	};
	
	if (obj.attachEvent) 
	{
		obj.attachEvent('on' + type, handler);
	}
	else 
	{
		obj.addEventListener(type, handler, false);
	}
};

/**
 * Displays an alert.
 * @param {String} str String to display.
 */
function alert(str)
{
	window.alert(sh.config.strings.alert + str);
};

/**
 * Finds a brush by its alias.
 *
 * @param {String} alias		Brush alias.
 * @param {Boolean} showAlert	Suppresses the alert if false.
 * @return {Brush}				Returns bursh constructor if found, null otherwise.
 */
function findBrush(alias, showAlert)
{
	var brushes = sh.vars.discoveredBrushes,
		result = null
		;
	
	if (brushes == null) 
	{
		brushes = {};
		
		// Find all brushes
		for (var brush in sh.brushes) 
		{
			var info = sh.brushes[brush],
				aliases = info.aliases
				;
			
			if (aliases == null) 
				continue;
			
			// keep the brush name
			info.brushName = brush.toLowerCase();
			
			for (var i = 0; i < aliases.length; i++) 
				brushes[aliases[i]] = brush;
		}
		
		sh.vars.discoveredBrushes = brushes;
	}
	
	result = sh.brushes[brushes[alias]];

	if (result == null && showAlert != false)
		alert(sh.config.strings.noBrush + alias);
	
	return result;
};

/**
 * Executes a callback on each line and replaces each line with result from the callback.
 * @param {Object} str			Input string.
 * @param {Object} callback		Callback function taking one string argument and returning a string.
 */
function eachLine(str, callback)
{
	var lines = splitLines(str);
	
	for (var i = 0; i < lines.length; i++)
		lines[i] = callback(lines[i], i);
		
	return lines.join('\n');
};

/**
 * This is a special trim which only removes first and last empty lines
 * and doesn't affect valid leading space on the first line.
 * 
 * @param {String} str   Input string
 * @return {String}      Returns string without empty first and last lines.
 */
function trimFirstAndLastLines(str)
{
	return str.replace(/^[ ]*[\n]+|[\n]*[ ]*$/g, '');
};

/**
 * Parses key/value pairs into hash object.
 * 
 * Understands the following formats:
 * - name: word;
 * - name: [word, word];
 * - name: "string";
 * - name: 'string';
 * 
 * For example:
 *   name1: value; name2: [value, value]; name3: 'value'
 *   
 * @param {String} str    Input string.
 * @return {Object}       Returns deserialized object.
 */
function parseParams(str)
{
	var match, 
		result = {},
		arrayRegex = new XRegExp("^\\[(?<values>(.*?))\\]$"),
		regex = new XRegExp(
			"(?<name>[\\w-]+)" +
			"\\s*:\\s*" +
			"(?<value>" +
				"[\\w-%#]+|" +		// word
				"\\[.*?\\]|" +		// [] array
				'".*?"|' +			// "" string
				"'.*?'" +			// '' string
			")\\s*;?",
			"g"
		)
		;

	while ((match = regex.exec(str)) != null) 
	{
		var value = match.value
			.replace(/^['"]|['"]$/g, '') // strip quotes from end of strings
			;
		
		// try to parse array value
		if (value != null && arrayRegex.test(value))
		{
			var m = arrayRegex.exec(value);
			value = m.values.length > 0 ? m.values.split(/\s*,\s*/) : [];
		}
		
		result[match.name] = value;
	}
	
	return result;
};

/**
 * Wraps each line of the string into <code/> tag with given style applied to it.
 * 
 * @param {String} str   Input string.
 * @param {String} css   Style name to apply to the string.
 * @return {String}      Returns input string with each line surrounded by <span/> tag.
 */
function wrapLinesWithCode(str, css)
{
	if (str == null || str.length == 0 || str == '\n') 
		return str;

	str = str.replace(/</g, '&lt;');

	// Replace two or more sequential spaces with &nbsp; leaving last space untouched.
	str = str.replace(/ {2,}/g, function(m)
	{
		var spaces = '';
		
		for (var i = 0; i < m.length - 1; i++)
			spaces += sh.config.space;
		
		return spaces + ' ';
	});

	// Split each line and apply <span class="...">...</span> to them so that
	// leading spaces aren't included.
	if (css != null) 
		str = eachLine(str, function(line)
		{
			if (line.length == 0) 
				return '';
			
			var spaces = '';
			
			line = line.replace(/^(&nbsp;| )+/, function(s)
			{
				spaces = s;
				return '';
			});
			
			if (line.length == 0) 
				return spaces;
			
			return spaces + '<code class="' + css + '">' + line + '</code>';
		});

	return str;
};

/**
 * Pads number with zeros until it's length is the same as given length.
 * 
 * @param {Number} number	Number to pad.
 * @param {Number} length	Max string length with.
 * @return {String}			Returns a string padded with proper amount of '0'.
 */
function padNumber(number, length)
{
	var result = number.toString();
	
	while (result.length < length)
		result = '0' + result;
	
	return result;
};

/**
 * Replaces tabs with spaces.
 * 
 * @param {String} code		Source code.
 * @param {Number} tabSize	Size of the tab.
 * @return {String}			Returns code with all tabs replaces by spaces.
 */
function processTabs(code, tabSize)
{
	var tab = '';
	
	for (var i = 0; i < tabSize; i++)
		tab += ' ';

	return code.replace(/\t/g, tab);
};

/**
 * Replaces tabs with smart spaces.
 * 
 * @param {String} code    Code to fix the tabs in.
 * @param {Number} tabSize Number of spaces in a column.
 * @return {String}        Returns code with all tabs replaces with roper amount of spaces.
 */
function processSmartTabs(code, tabSize)
{
	var lines = splitLines(code),
		tab = '\t',
		spaces = ''
		;
	
	// Create a string with 1000 spaces to copy spaces from... 
	// It's assumed that there would be no indentation longer than that.
	for (var i = 0; i < 50; i++) 
		spaces += '                    '; // 20 spaces * 50
			
	// This function inserts specified amount of spaces in the string
	// where a tab is while removing that given tab.
	function insertSpaces(line, pos, count)
	{
		return line.substr(0, pos)
			+ spaces.substr(0, count)
			+ line.substr(pos + 1, line.length) // pos + 1 will get rid of the tab
			;
	};

	// Go through all the lines and do the 'smart tabs' magic.
	code = eachLine(code, function(line)
	{
		if (line.indexOf(tab) == -1) 
			return line;
		
		var pos = 0;
		
		while ((pos = line.indexOf(tab)) != -1) 
		{
			// This is pretty much all there is to the 'smart tabs' logic.
			// Based on the position within the line and size of a tab,
			// calculate the amount of spaces we need to insert.
			var spaces = tabSize - pos % tabSize;
			line = insertSpaces(line, pos, spaces);
		}
		
		return line;
	});
	
	return code;
};

/**
 * Performs various string fixes based on configuration.
 */
function fixInputString(str)
{
	var br = /<br\s*\/?>|&lt;br\s*\/?&gt;/gi;
	
	if (sh.config.bloggerMode == true)
		str = str.replace(br, '\n');

	if (sh.config.stripBrs == true)
		str = str.replace(br, '');
		
	return str;
};

/**
 * Removes all white space at the begining and end of a string.
 * 
 * @param {String} str   String to trim.
 * @return {String}      Returns string without leading and following white space characters.
 */
function trim(str)
{
	return str.replace(/^\s+|\s+$/g, '');
};

/**
 * Unindents a block of text by the lowest common indent amount.
 * @param {String} str   Text to unindent.
 * @return {String}      Returns unindented text block.
 */
function unindent(str)
{
	var lines = splitLines(fixInputString(str)),
		indents = new Array(),
		regex = /^\s*/,
		min = 1000
		;
	
	// go through every line and check for common number of indents
	for (var i = 0; i < lines.length && min > 0; i++) 
	{
		var line = lines[i];
		
		if (trim(line).length == 0) 
			continue;
		
		var matches = regex.exec(line);
		
		// In the event that just one line doesn't have leading white space
		// we can't unindent anything, so bail completely.
		if (matches == null) 
			return str;
			
		min = Math.min(matches[0].length, min);
	}
	
	// trim minimum common number of white space from the begining of every line
	if (min > 0) 
		for (var i = 0; i < lines.length; i++) 
			lines[i] = lines[i].substr(min);
	
	return lines.join('\n');
};

/**
 * Callback method for Array.sort() which sorts matches by
 * index position and then by length.
 * 
 * @param {Match} m1	Left object.
 * @param {Match} m2    Right object.
 * @return {Number}     Returns -1, 0 or -1 as a comparison result.
 */
function matchesSortCallback(m1, m2)
{
	// sort matches by index first
	if(m1.index < m2.index)
		return -1;
	else if(m1.index > m2.index)
		return 1;
	else
	{
		// if index is the same, sort by length
		if(m1.length < m2.length)
			return -1;
		else if(m1.length > m2.length)
			return 1;
	}
	
	return 0;
};

/**
 * Executes given regular expression on provided code and returns all
 * matches that are found.
 * 
 * @param {String} code    Code to execute regular expression on.
 * @param {Object} regex   Regular expression item info from <code>regexList</code> collection.
 * @return {Array}         Returns a list of Match objects.
 */ 
function getMatches(code, regexInfo)
{
	function defaultAdd(match, regexInfo)
	{
		return match[0];
	};
	
	var index = 0,
		match = null,
		matches = [],
		func = regexInfo.func ? regexInfo.func : defaultAdd
		;
	
	while((match = regexInfo.regex.exec(code)) != null)
	{
		var resultMatch = func(match, regexInfo);
		
		if (typeof(resultMatch) == 'string')
			resultMatch = [new sh.Match(resultMatch, match.index, regexInfo.css)];

		matches = matches.concat(resultMatch);
	}
	
	return matches;
};

/**
 * Turns all URLs in the code into <a/> tags.
 * @param {String} code Input code.
 * @return {String} Returns code with </a> tags.
 */
function processUrls(code)
{
	var gt = /(.*)((&gt;|&lt;).*)/;
	
	return code.replace(sh.regexLib.url, function(m)
	{
		var suffix = '',
			match = null
			;
		
		// We include &lt; and &gt; in the URL for the common cases like <http://google.com>
		// The problem is that they get transformed into &lt;http://google.com&gt;
		// Where as &gt; easily looks like part of the URL string.
	
		if (match = gt.exec(m))
		{
			m = match[1];
			suffix = match[2];
		}
		
		return '<a href="' + m + '">' + m + '</a>' + suffix;
	});
};

/**
 * Finds all <SCRIPT TYPE="syntaxhighlighter" /> elementss.
 * @return {Array} Returns array of all found SyntaxHighlighter tags.
 */
function getSyntaxHighlighterScriptTags()
{
	var tags = document.getElementsByTagName('script'),
		result = []
		;
	
	for (var i = 0; i < tags.length; i++)
		if (tags[i].type == 'syntaxhighlighter')
			result.push(tags[i]);
			
	return result;
};

/**
 * Strips <![CDATA[]]> from <SCRIPT /> content because it should be used
 * there in most cases for XHTML compliance.
 * @param {String} original	Input code.
 * @return {String} Returns code without leading <![CDATA[]]> tags.
 */
function stripCData(original)
{
	var left = '<![CDATA[',
		right = ']]>',
		// for some reason IE inserts some leading blanks here
		copy = trim(original),
		changed = false,
		leftLength = left.length,
		rightLength = right.length
		;
	
	if (copy.indexOf(left) == 0)
	{
		copy = copy.substring(leftLength);
		changed = true;
	}
	
	var copyLength = copy.length;
	
	if (copy.indexOf(right) == copyLength - rightLength)
	{
		copy = copy.substring(0, copyLength - rightLength);
		changed = true;
	}
	
	return changed ? copy : original;
};


/**
 * Quick code mouse double click handler.
 */
function quickCodeHandler(e)
{
	var target = e.target,
		highlighterDiv = findParentElement(target, '.syntaxhighlighter'),
		container = findParentElement(target, '.container'),
		textarea = document.createElement('textarea'),
		highlighter
		;

	if (!container || !highlighterDiv || findElement(container, 'textarea'))
		return;

	highlighter = getHighlighterById(highlighterDiv.id);
	
	// add source class name
	addClass(highlighterDiv, 'source');

	// Have to go over each line and grab it's text, can't just do it on the
	// container because Firefox loses all \n where as Webkit doesn't.
	var lines = container.childNodes,
		code = []
		;
	
	for (var i = 0; i < lines.length; i++)
		code.push(lines[i].innerText || lines[i].textContent);
	
	// using \r instead of \r or \r\n makes this work equally well on IE, FF and Webkit
	code = code.join('\r');
	
	// inject <textarea/> tag
	textarea.appendChild(document.createTextNode(code));
	container.appendChild(textarea);
	
	// preselect all text
	textarea.focus();
	textarea.select();
	
	// set up handler for lost focus
	attachEvent(textarea, 'blur', function(e)
	{
		textarea.parentNode.removeChild(textarea);
		removeClass(highlighterDiv, 'source');
	});
};

/**
 * Match object.
 */
sh.Match = function(value, index, css)
{
	this.value = value;
	this.index = index;
	this.length = value.length;
	this.css = css;
	this.brushName = null;
};

sh.Match.prototype.toString = function()
{
	return this.value;
};

/**
 * Simulates HTML code with a scripting language embedded.
 * 
 * @param {String} scriptBrushName Brush name of the scripting language.
 */
sh.HtmlScript = function(scriptBrushName)
{
	var brushClass = findBrush(scriptBrushName),
		scriptBrush,
		xmlBrush = new sh.brushes.Xml(),
		bracketsRegex = null,
		ref = this,
		methodsToExpose = 'getDiv getHtml init'.split(' ')
		;

	if (brushClass == null)
		return;
	
	scriptBrush = new brushClass();
	
	for(var i = 0; i < methodsToExpose.length; i++)
		// make a closure so we don't lose the name after i changes
		(function() {
			var name = methodsToExpose[i];
			
			ref[name] = function()
			{
				return xmlBrush[name].apply(xmlBrush, arguments);
			};
		})();
	
	if (scriptBrush.htmlScript == null)
	{
		alert(sh.config.strings.brushNotHtmlScript + scriptBrushName);
		return;
	}
	
	xmlBrush.regexList.push(
		{ regex: scriptBrush.htmlScript.code, func: process }
	);
	
	function offsetMatches(matches, offset)
	{
		for (var j = 0; j < matches.length; j++) 
			matches[j].index += offset;
	}
	
	function process(match, info)
	{
		var code = match.code,
			matches = [],
			regexList = scriptBrush.regexList,
			offset = match.index + match.left.length,
			htmlScript = scriptBrush.htmlScript,
			result
			;

		// add all matches from the code
		for (var i = 0; i < regexList.length; i++)
		{
			result = getMatches(code, regexList[i]);
			offsetMatches(result, offset);
			matches = matches.concat(result);
		}
		
		// add left script bracket
		if (htmlScript.left != null && match.left != null)
		{
			result = getMatches(match.left, htmlScript.left);
			offsetMatches(result, match.index);
			matches = matches.concat(result);
		}
		
		// add right script bracket
		if (htmlScript.right != null && match.right != null)
		{
			result = getMatches(match.right, htmlScript.right);
			offsetMatches(result, match.index + match[0].lastIndexOf(match.right));
			matches = matches.concat(result);
		}
		
		for (var j = 0; j < matches.length; j++)
			matches[j].brushName = brushClass.brushName;
			
		return matches;
	}
};

/**
 * Main Highlither class.
 * @constructor
 */
sh.Highlighter = function()
{
	// not putting any code in here because of the prototype inheritance
};

sh.Highlighter.prototype = {
	/**
	 * Returns value of the parameter passed to the highlighter.
	 * @param {String} name				Name of the parameter.
	 * @param {Object} defaultValue		Default value.
	 * @return {Object}					Returns found value or default value otherwise.
	 */
	getParam: function(name, defaultValue)
	{
		var result = this.params[name];
		return toBoolean(result == null ? defaultValue : result);
	},
	
	/**
	 * Shortcut to document.createElement().
	 * @param {String} name		Name of the element to create (DIV, A, etc).
	 * @return {HTMLElement}	Returns new HTML element.
	 */
	create: function(name)
	{
		return document.createElement(name);
	},
	
	/**
	 * Applies all regular expression to the code and stores all found
	 * matches in the `this.matches` array.
	 * @param {Array} regexList		List of regular expressions.
	 * @param {String} code			Source code.
	 * @return {Array}				Returns list of matches.
	 */
	findMatches: function(regexList, code)
	{
		var result = [];
		
		if (regexList != null)
			for (var i = 0; i < regexList.length; i++) 
				// BUG: length returns len+1 for array if methods added to prototype chain (oising@gmail.com)
				if (typeof (regexList[i]) == "object")
					result = result.concat(getMatches(code, regexList[i]));
		
		// sort and remove nested the matches
		return this.removeNestedMatches(result.sort(matchesSortCallback));
	},
	
	/**
	 * Checks to see if any of the matches are inside of other matches. 
	 * This process would get rid of highligted strings inside comments, 
	 * keywords inside strings and so on.
	 */
	removeNestedMatches: function(matches)
	{
		// Optimized by Jose Prado (http://joseprado.com)
		for (var i = 0; i < matches.length; i++) 
		{ 
			if (matches[i] === null)
				continue;
			
			var itemI = matches[i],
				itemIEndPos = itemI.index + itemI.length
				;
			
			for (var j = i + 1; j < matches.length && matches[i] !== null; j++) 
			{
				var itemJ = matches[j];
				
				if (itemJ === null) 
					continue;
				else if (itemJ.index > itemIEndPos) 
					break;
				else if (itemJ.index == itemI.index && itemJ.length > itemI.length)
					matches[i] = null;
				else if (itemJ.index >= itemI.index && itemJ.index < itemIEndPos) 
					matches[j] = null;
			}
		}
		
		return matches;
	},
	
	/**
	 * Creates an array containing integer line numbers starting from the 'first-line' param.
	 * @return {Array} Returns array of integers.
	 */
	figureOutLineNumbers: function(code)
	{
		var lines = [],
			firstLine = parseInt(this.getParam('first-line'))
			;
		
		eachLine(code, function(line, index)
		{
			lines.push(index + firstLine);
		});
		
		return lines;
	},
	
	/**
	 * Determines if specified line number is in the highlighted list.
	 */
	isLineHighlighted: function(lineNumber)
	{
		var list = this.getParam('highlight', []);
		
		if (typeof(list) != 'object' && list.push == null) 
			list = [ list ];
		
		return indexOf(list, lineNumber.toString()) != -1;
	},
	
	/**
	 * Generates HTML markup for a single line of code while determining alternating line style.
	 * @param {Integer} lineNumber	Line number.
	 * @param {String} code Line	HTML markup.
	 * @return {String}				Returns HTML markup.
	 */
	getLineHtml: function(lineIndex, lineNumber, code)
	{
		var classes = [
			'line',
			'number' + lineNumber,
			'index' + lineIndex,
			'alt' + (lineNumber % 2 == 0 ? 1 : 2).toString()
		];
		
		if (this.isLineHighlighted(lineNumber))
		 	classes.push('highlighted');
		
		if (lineNumber == 0)
			classes.push('break');
			
		return '<div class="' + classes.join(' ') + '">' + code + '</div>';
	},
	
	/**
	 * Generates HTML markup for line number column.
	 * @param {String} code			Complete code HTML markup.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns HTML markup.
	 */
	getLineNumbersHtml: function(code, lineNumbers)
	{
		var html = '',
			count = splitLines(code).length,
			firstLine = parseInt(this.getParam('first-line')),
			pad = this.getParam('pad-line-numbers')
			;
		
		if (pad == true)
			pad = (firstLine + count - 1).toString().length;
		else if (isNaN(pad) == true)
			pad = 0;
			
		for (var i = 0; i < count; i++)
		{
			var lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i,
				code = lineNumber == 0 ? sh.config.space : padNumber(lineNumber, pad)
				;
				
			html += this.getLineHtml(i, lineNumber, code);
		}
		
		return html;
	},
	
	/**
	 * Splits block of text into individual DIV lines.
	 * @param {String} code			Code to highlight.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns highlighted code in HTML form.
	 */
	getCodeLinesHtml: function(html, lineNumbers)
	{
		html = trim(html);
		
		var lines = splitLines(html),
			padLength = this.getParam('pad-line-numbers'),
			firstLine = parseInt(this.getParam('first-line')),
			html = '',
			brushName = this.getParam('brush')
			;

		for (var i = 0; i < lines.length; i++)
		{
			var line = lines[i],
				indent = /^(&nbsp;|\s)+/.exec(line),
				spaces = null,
				lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i;
				;

			if (indent != null)
			{
				spaces = indent[0].toString();
				line = line.substr(spaces.length);
				spaces = spaces.replace(' ', sh.config.space);
			}

			line = trim(line);
			
			if (line.length == 0)
				line = sh.config.space;
			
			html += this.getLineHtml(
				i,
				lineNumber, 
				(spaces != null ? '<code class="' + brushName + ' spaces">' + spaces + '</code>' : '') + line
			);
		}
		
		return html;
	},
	
	/**
	 * Returns HTML for the table title or empty string if title is null.
	 */
	getTitleHtml: function(title)
	{
		return title ? '<caption>' + title + '</caption>' : '';
	},
	
	/**
	 * Finds all matches in the source code.
	 * @param {String} code		Source code to process matches in.
	 * @param {Array} matches	Discovered regex matches.
	 * @return {String} Returns formatted HTML with processed mathes.
	 */
	getMatchesHtml: function(code, matches)
	{
		var pos = 0, 
			result = '',
			brushName = this.getParam('brush', '')
			;
		
		function getBrushNameCss(match)
		{
			var result = match ? (match.brushName || brushName) : brushName;
			return result ? result + ' ' : '';
		};
		
		// Finally, go through the final list of matches and pull the all
		// together adding everything in between that isn't a match.
		for (var i = 0; i < matches.length; i++) 
		{
			var match = matches[i],
				matchBrushName
				;
			
			if (match === null || match.length === 0) 
				continue;
			
			matchBrushName = getBrushNameCss(match);
			
			result += wrapLinesWithCode(code.substr(pos, match.index - pos), matchBrushName + 'plain')
					+ wrapLinesWithCode(match.value, matchBrushName + match.css)
					;

			pos = match.index + match.length + (match.offset || 0);
		}

		// don't forget to add whatever's remaining in the string
		result += wrapLinesWithCode(code.substr(pos), getBrushNameCss() + 'plain');

		return result;
	},
	
	/**
	 * Generates HTML markup for the whole syntax highlighter.
	 * @param {String} code Source code.
	 * @return {String} Returns HTML markup.
	 */
	getHtml: function(code)
	{
		var html = '',
			classes = [ 'syntaxhighlighter' ],
			tabSize,
			matches,
			lineNumbers
			;
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;

		className = 'syntaxhighlighter';

		if (this.getParam('collapse') == true)
			classes.push('collapsed');
		
		if ((gutter = this.getParam('gutter')) == false)
			classes.push('nogutter');

		// add custom user style name
		classes.push(this.getParam('class-name'));

		// add brush alias to the class name for custom CSS
		classes.push(this.getParam('brush'));

		code = trimFirstAndLastLines(code)
			.replace(/\r/g, ' ') // IE lets these buggers through
			;

		tabSize = this.getParam('tab-size');

		// replace tabs with spaces
		code = this.getParam('smart-tabs') == true
			? processSmartTabs(code, tabSize)
			: processTabs(code, tabSize)
			;

		// unindent code by the common indentation
		code = unindent(code);

		if (gutter)
			lineNumbers = this.figureOutLineNumbers(code);
		
		// find matches in the code using brushes regex list
		matches = this.findMatches(this.regexList, code);
		// processes found matches into the html
		html = this.getMatchesHtml(code, matches);
		// finally, split all lines so that they wrap well
		html = this.getCodeLinesHtml(html, lineNumbers);

		// finally, process the links
		if (this.getParam('auto-links'))
			html = processUrls(html);
		
		if (typeof(navigator) != 'undefined' && navigator.userAgent && navigator.userAgent.match(/MSIE/))
			classes.push('ie');
		
		html = 
			'<div id="' + getHighlighterId(this.id) + '" class="' + classes.join(' ') + '">'
				+ (this.getParam('toolbar') ? sh.toolbar.getHtml(this) : '')
				+ '<table border="0" cellpadding="0" cellspacing="0">'
					+ this.getTitleHtml(this.getParam('title'))
					+ '<tbody>'
						+ '<tr>'
							+ (gutter ? '<td class="gutter">' + this.getLineNumbersHtml(code) + '</td>' : '')
							+ '<td class="code">'
								+ '<div class="container">'
									+ html
								+ '</div>'
							+ '</td>'
						+ '</tr>'
					+ '</tbody>'
				+ '</table>'
			+ '</div>'
			;
			
		return html;
	},
	
	/**
	 * Highlights the code and returns complete HTML.
	 * @param {String} code     Code to highlight.
	 * @return {Element}        Returns container DIV element with all markup.
	 */
	getDiv: function(code)
	{
		if (code === null) 
			code = '';
		
		this.code = code;

		var div = this.create('div');

		// create main HTML
		div.innerHTML = this.getHtml(code);
		
		// set up click handlers
		if (this.getParam('toolbar'))
			attachEvent(findElement(div, '.toolbar'), 'click', sh.toolbar.handler);
		
		if (this.getParam('quick-code'))
			attachEvent(findElement(div, '.code'), 'dblclick', quickCodeHandler);
		
		return div;
	},
	
	/**
	 * Initializes the highlighter/brush.
	 *
	 * Constructor isn't used for initialization so that nothing executes during necessary
	 * `new SyntaxHighlighter.Highlighter()` call when setting up brush inheritence.
	 *
	 * @param {Hash} params Highlighter parameters.
	 */
	init: function(params)
	{
		this.id = guid();
		
		// register this instance in the highlighters list
		storeHighlighter(this);
		
		// local params take precedence over defaults
		this.params = merge(sh.defaults, params || {})
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;
	},
	
	/**
	 * Converts space separated list of keywords into a regular expression string.
	 * @param {String} str    Space separated keywords.
	 * @return {String}       Returns regular expression string.
	 */
	getKeywords: function(str)
	{
		str = str
			.replace(/^\s+|\s+$/g, '')
			.replace(/\s+/g, '|')
			;
		
		return '\\b(?:' + str + ')\\b';
	},
	
	/**
	 * Makes a brush compatible with the `html-script` functionality.
	 * @param {Object} regexGroup Object containing `left` and `right` regular expressions.
	 */
	forHtmlScript: function(regexGroup)
	{
		this.htmlScript = {
			left : { regex: regexGroup.left, css: 'script' },
			right : { regex: regexGroup.right, css: 'script' },
			code : new XRegExp(
				"(?<left>" + regexGroup.left.source + ")" +
				"(?<code>.*?)" +
				"(?<right>" + regexGroup.right.source + ")",
				"sgi"
				)
		};
	}
}; // end of Highlighter

return sh;
}(); // end of anonymous function

// CommonJS
typeof(exports) != 'undefined' ? exports['SyntaxHighlighter'] = SyntaxHighlighter : null;
</script><script type="text/javascript">// (inc clojure-brush) ;; an improved SyntaxHighlighter brush for clojure
//
// Copyright (C) 2011 Andrew Brehaut
//
// Distributed under the Eclipse Public License, the same as Clojure.
//
// https://github.com/brehaut/inc-clojure-brush
//
// Written by Andrew Brehaut
// V0.9.1, November 2011

if (typeof net == "undefined") net = {};
if (!(net.brehaut)) net.brehaut = {};

net.brehaut.ClojureTools = (function (SH) {
  "use strict";
  // utiliies
  if (!Object.create) Object.create = function object(o) {
    function F() {};
    F.prototype = o;  
    return new F();
  };
        
  // data
  
  function Token(value, index, tag, length) {
    this.value = value;
    this.index = index;
    this.length = length || value.length;
    this.tag = tag;
    this.secondary_tags = {};
  }
  
  // null_token exists so that LispNodes that have not had a closing tag attached
  // can have a dummy token to simplify annotation
  var null_token = new Token("", -1, "null", -1);
  
  /* LispNodes are aggregate nodes for sexpressions. 
   *
   */
  function LispNode(tag, children, opening) {
    this.tag = tag;            // current metadata for syntax inference
    this.parent = null;        // the parent expression
    this.list = children;      // all the child forms in order
    this.opening = opening;    // the token that opens this form.
    this.closing = null_token; // the token that closes this form.
    this.meta = null;          // metadata nodes will be attached here if they are found
  }

  var null_lispnode = new LispNode("null", [], null_token);

  
  function PrefixNode(tag, token, attached_node) {
    this.tag = tag;
    this.token = token;
    this.attached_node = attached_node;
    this.parent = null;
  }

  
  
  // tokenize

  function tokenize(code) {
    var tokens = [];
    var tn = 0;
    
    var zero = "0".charCodeAt(0);
    var nine = "9".charCodeAt(0); 
    var lower_a = "a".charCodeAt(0);
    var lower_f = "f".charCodeAt(0);    
    var upper_a = "A".charCodeAt(0);
    var upper_f = "F".charCodeAt(0);
    
    var dispatch = false; // have we just seen a # character?
    
    // i tracks the start of the current window
    // extent is the window for slicing
    
    for (var i = 0, 
             extent = i, 
             j = code.length; 
             i < j && extent <= j;) {          
                
      var c = code[i];
      
      // we care about capturing the whole token when dispatch is used, so back up the
      // starting index by 1
      if (dispatch) i--; 
      
      switch (c) {
        // dispatch alters the value of the next thing read
        case "#":
          dispatch = true;
          i++;
          extent++;
          continue;
          
        case " ":    // ignore whitespace
        case "\t":
        case "\n":
        case "\r":
        case ",":   
          extent++
          break; 
          
        // simple terms
        case "^":
        case "`":
        case ")":
        case "[":
        case "]":
        case "}":
        case "@":
          tokens[tn++] = new Token(c, i, c, ++extent - i);
          break;
        
        case "'":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#'" : "'", extent - i);
          break
        
        case "(":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "(", extent - i);
          break;          
          
        case "{":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#{" : "{", extent - i);
          break;  
        
        case "\\":
          if (code.slice(i + 1, i + 8) === "newline") {
            tokens[tn++] = new Token("\\newline", i, "value", 8);
            extent = i + 9; 
          }
          else if (code.slice(i + 1, i + 6) === "space") {
            tokens[tn++] = new Token("\\space", i, "value", 6);
            extent = i + 6;
          }
          else if (code.slice(i + 1, i + 4) === "tab") {
            tokens[tn++] = new Token("\\tab", i, "value", 4);
            extent = i + 5;
          } // work around fun bug with &,>,< in character literals
          else if (code.slice(i + 1, i + 6) === "&amp;") {
            tokens[tn++] = new Token("\\&amp;", i, "value", 6);
            extent = i + 6; 
          }
          else if (code.slice(i + 1, i + 5) === "&lt;") {
            tokens[tn++] = new Token("\\&lt;", i, "value", 5);
            extent = i + 5;
          }
          else if (code.slice(i + 1, i + 5) === "&gt;") {
            tokens[tn++] = new Token("\\&gt;", i, "value", 5);
            extent = i + 5;
          }
          
          else {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "value", 2);
          }
          break;
        
        case "~": // slice
          if (code[i + 1] === "@") {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "splice", 2);
          }
          else {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "unquote", 2);
          }
          break;
        
        // complicated terms
        case "\"": // strings and regexps
          for (extent++; extent <= j; extent++) {
            if (code[extent] === "\\") extent++;
            else if (code[extent] === "\"") break;
          }
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "regexp" : "string", extent - i);       
          break;
          
        case ";":
          for (; extent <= j && code[extent] !== "\n" && code[extent] !== "\r"; extent++);
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "comments", extent - i);   
          break;
        
        case "+": // numbers; fall through to symbol for + and - not prefixing a number
        case "-":
        case "0":
        case "1":
        case "2":
        case "3":
        case "4":
        case "5":
        case "6":
        case "7":
        case "8":
        case "9":
        // todo: exponents, hex
        // http://my.safaribooksonline.com/9781449310387/14?reader=pf&readerfullscreen=&readerleftmenu=1
          var c2 = code.charCodeAt(i + 1);
          if (((c === "+" || c === "-") && (c2 >= zero && c2 <= nine)) // prefixes
              || (c !== "+" && c !== "-")) {
            if (c === "+" || c === "-") extent++; 
            for (; extent <= j; extent++) {
              var charCode = code.charCodeAt(extent);
              if (charCode < zero || charCode > nine) break;
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "r" || c === "R" || c === "/" || c === ".") // interstitial characters
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "x" || c === "X") && 
                ((c2 >= zero && c2 <= nine) 
                 || (c2 >= lower_a && c2 <= lower_f)
                 || (c2 >= upper_a && c2 <= upper_f))) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (((charCode >= zero && charCode <= nine) 
                    || (charCode >= lower_a && charCode <= lower_f)
                    || (charCode >= upper_a && charCode <= upper_f))) continue;
                break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "e" || c === "E") 
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            if (c === "N" || c === "M") extent++;

            tokens[tn++] = new Token(code.slice(i, extent), i, "value", extent - i);
            break;
          }

        case "_":
          if (dispatch && c === "_") {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "skip", extent - i);
            break;
          } // if not a skip, fall through to symbols
        
        // Allow just about any other symbol as a symbol. This is far more permissive than 
        // clojure actually allows, but should catch any weirdo crap that accidentally gets
        // into the code.
        default: 
          for (extent++; extent <= j; extent++) {
            switch (code[extent]) {
              case " ":
              case "\t":
              case "\n":
              case "\r":
              case "\\":
              case ",":
              case "{":
              case "}":
              case "(":
              case ")":
              case "[":
              case "]":
              case "^":
              case "`":
              case "@":   
                break;
              case ";":   
                // theres a weird bug via syntax highligher that gives us escaped entities.
                // need to watch out for these
                if (code.slice(extent-3, extent+1) === "&lt;"
                    ||code.slice(extent-3, extent+1) === "&gt;"
                    ||code.slice(extent-4, extent+1) === "&amp;") {
                  continue;
                }
                break;
              default:
                continue;
            }
            break;
          }
          
          var value = code.slice(i, extent);
          var tag = "symbol";
          if (value[0] == ":") {
            tag = "keyword";
          }
          else if (value === "true" || value === "false" || value === "nil") {
            tag = "value";
          }
          tokens[tn++] = new Token(value, i, tag, extent - i);
      }
      
      dispatch = false;
      i = extent;
    } 

    return tokens;
  }


  function build_tree(tokens) {
    var toplevel = {
      list: [], 
      tag: "toplevel", 
      parent: null, 
      opening: null,
      closing: null,
      depth: -1
    };
    
    // loop variables hoisted out as semi globals to track position in token stream
    var i = -1;
    var j = tokens.length;
    
    function parse_one(t) {
      // ignore special tokens and forms that dont belong in the tree
      for (; t && (t.tag === "comments" || t.tag === "invalid" || t.tag == "skip") && i < j; ) {
        if (t.tag === "skip") {
          t.tag = "preprocessor";
          annotate_comment(parse_one(tokens[++i]));
        }
        t = tokens[++i];
      }
      
      if (!t) return {}; // hackity hack
      
      switch (t.tag) {
        case "{":
          return build_aggregate(new LispNode("map", [], t), "}");
        case "(":
          return build_aggregate(new LispNode("list", [], t), ")");
        case "#{":
          return build_aggregate(new LispNode("set", [], t), "}");
        case "[":
          return build_aggregate(new LispNode("vector", [], t), "]");
        case "'":
          return new PrefixNode("quote", t, parse_one(tokens[++i]));
        case "#'":
          return new PrefixNode("varquote", t, parse_one(tokens[++i]));  
        case "@":
          return new PrefixNode("deref", t, parse_one(tokens[++i]));  
        case "`":
          return new PrefixNode("quasiquote", t, parse_one(tokens[++i]));  
        case "unquote":
          return new PrefixNode("unquote", t, parse_one(tokens[++i]));
        case "splice":
          return new PrefixNode("splice", t, parse_one(tokens[++i]));  
        case "^":
          t.tag = "meta";
          var meta = parse_one(tokens[++i]);
          var next = parse_one(tokens[++i]);
          next.meta = meta;
          return next;
      }
      
      return t;
    }
    
    // build_aggregate collects to ether sub forms for one aggregate for. 
    function build_aggregate(current, expected_closing) {
      for (i++; i < j; i++) {
        var t = tokens[i];

        if (t.tag === "}" || t.tag === ")" || t.tag === "]") {
          if (t.tag !== expected_closing) t.tag = "invalid";
          current.closing = t;
          if (expected_closing) return current;
        }
        var node = parse_one(t);

        node.parent = current;
        current.list[current.list.length] = node;
      }
      
      return current;
    }
    
    build_aggregate(toplevel, null);
    
    return toplevel;
  }

  // annotation rules to apply to a form based on its head

  var show_locals = true;  // HACK. would rather not use a (semi)-global.

  /* annotate_comment is a special case annotation. 
   * in addition to its role in styling specific forms, it is called by parse_one to
   * ignore any forms skipped with #_
   */ 
  function annotate_comment(exp) {
    exp.tag = "comments";

    if (exp.list) {
      exp.opening.tag = "comments";
      exp.closing.tag = "comments";
    
      for (var i = 0; i < exp.list.length; i++) {
        var child = exp.list[i];
        if (child.list) {
          annotate_comment(child);
        }
        if (child.attached_node) {
          annotate_comment(child.attached_node);
        }
        else {
          child.tag = "comments";
        }
      }
    }
  }

  /* custom annotation rules are stored here */
  var annotation_rules = {};
  
  // this function is exposed to allow ad hoc extension of the customisation rules
  function register_annotation_rule(names, rule) {
    for (var i = 0; i < names.length; i++) {
      annotation_rules[names[i]] = rule;
    }
  }


  function annotate_destructuring (exp, scope) {
    if (exp.list) {
      if (exp.tag === "vector") {
        for (var i = 0; i < exp.list.length; i++) {
          annotate_destructuring(exp.list[i], scope);
        }
      } 
      else if (exp.tag === "map") {
        for (var i = 0; i < exp.list.length; i += 2) {
          var key = exp.list[i];
          var val = exp.list[i + 1];
          
          if (key.tag === "keyword" && val.tag === "vector") {
            for (var ii = 0, jj = val.list.length; ii < jj; ii++) {
              if (val.list[ii].tag !== "symbol") continue;
              val.list[ii].tag = "variable";
              scope[val.list[ii].value] = true;
            }
          }
          else {
            annotate_destructuring(key, scope);
            annotate_expressions(val, scope);
          }
        } 
      }
    } 
    else if (exp.tag === "symbol" && (exp.value !== "&" && exp.value !== "&amp;")){
      exp.tag = "variable";
      scope[exp.value] = true;
    }
  }

  function _annotate_binding_vector (exp, scope) {
    if (exp.tag !== "vector") return;
  
    var bindings = exp.list;

    if (bindings.length % 2 === 1) return;
    
    for (var i = 0; i < bindings.length; i += 2) {
      annotate_destructuring(bindings[i], scope);
      annotate_expressions(bindings[i + 1], scope);
    }    
  }

  function annotate_binding (exp, scope) {
    var bindings = exp.list[1];
    if (!show_locals) return; // HACK

    if (bindings) {
      scope = Object.create(scope);
      _annotate_binding_vector(bindings, scope);
    }
    for (var i = 2; i < exp.list.length; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function _annotate_function_body (exp, scope, start_idx) {
    var argvec = exp.list[start_idx];
    if (argvec.tag !== "vector") return;

    scope = Object.create(scope);

    for (var i = 0, j = argvec.list.length; i < j; i++) {
      annotate_destructuring(argvec.list[i], scope);
    }
    
    for (var i = start_idx, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function annotate_function (exp, scope) {
    for (var i = 1, j = exp.list.length; i < j; i++) {
      var child = exp.list[i];
      
      if (child.tag === "vector") {
        _annotate_function_body (exp, scope, i);
        return;
      }
      else if (child.tag === "list") {
        _annotate_function_body(child, scope, 0)
      }
    }
  }
  
  function annotate_letfn (exp, scope) {
    scope = Object.create(scope);
    var bindings = exp.list[1];
    
    var fn;
    for (var i = 0, j = bindings.list.length; i < j; i++) {
      fn = bindings.list[i];
      if (!fn.list[0]) continue;
      fn.list[0].tag = "variable";
      scope[fn.list[0].value] = true;
    }
    
    for (i = 0, j = bindings.list.length; i < j; i++) {
      var fn = bindings.list[i];
      annotate_function(fn, scope);
    }
    
    for (i = 2, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }

  register_annotation_rule(
    ["comment"],
    annotate_comment
  );
  
  register_annotation_rule(
    ["let", "when-let", "if-let", "binding", "doseq", "for", "dotimes", "let*"],
    annotate_binding
  );
  
  register_annotation_rule(
    ["defn", "defn-", "fn", "bound-fn", "defmacro", "fn*", "defmethod"],
    annotate_function
  );
  
  register_annotation_rule(
    ["letfn"],
    annotate_letfn
  );

  // standard annotations

  function _annotate_metadata_recursive(meta, scope) {
    if (!meta) return;

    if (meta.list !== undefined && meta.list !== null) {
      for (var i = 0, j = meta.list.length; i < j; i++) {
        meta.opening.secondary_tags.meta = true
        meta.closing.secondary_tags.meta = true
        _annotate_metadata_recursive(meta.list[i], scope);
      }
    }
    else if (meta.attached_node) {
      meta.token.secondary_tags.meta = true;
      _annotate_metadata_recursive(meta.attached_node, scope);
    }
    else {
      meta.secondary_tags.meta = true;
    }
  }
  
  function annotate_metadata(exp) {
    if (!(exp && exp.meta)) return;
    var meta = exp.meta;
    
     annotate_expressions(meta, {});    
    _annotate_metadata_recursive(meta, {});
  }


  function annotate_quoted(exp, scope) {
    if (!exp) return;

    if (exp.list !== undefined && exp.list !== null) {
      for (var i = 0, j = exp.list.length; i < j; i++) {
        exp.opening.secondary_tags.quoted = true
        exp.closing.secondary_tags.quoted = true
        annotate_quoted(exp.list[i], scope);
      }
    }
    else if (exp.attached_node) {
      if (exp.tag === "unquote" || exp.tag === "splice") return;
      exp.token.secondary_tags.quoted = true;
      annotate_quoted(exp.attached_node, scope);
    }
    else {
      exp.secondary_tags.quoted = true;
    }
  }


  function annotate_expressions(exp, scope) {
    annotate_metadata(exp);
    
    switch (exp.tag) {
      case "toplevel": 
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "list": // functions, macros, special forms, comments
        var head = exp.list[0];
      
        if (head) {
          if (head.tag === "list" || head.tag === "vector" 
           || head.tag === "map" || head.tag === "set") {
            annotate_expressions(head, scope);
          }
          else if (head.attached_node) {
            annotate_expressions(head.attached_node, scope);
          }
          else {
            head.tag = (head.value.match(/(^\.)|(\.$)|[A-Z].*\//)
                        ? "method"
                        : "function");
          }

          // apply specific rules
          if (annotation_rules.hasOwnProperty(head.value)) {
            annotation_rules[head.value](exp, scope);
          } 
          else {
            for (var i = 1; i < exp.list.length; i++) {
              annotate_expressions(exp.list[i], scope);
            }
          } 
        }
        else { // empty list
          exp.opening.tag = "value";
          exp.closing.tag = "value";
        }
      
        break;
      
      case "vector": // data
      case "map":
      case "set":
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "symbol":
        if (exp.value.match(/[A-Z].*\/[A-Z_]+/)) {
          exp.tag = "constant";
        }
        else if (show_locals && scope[exp.value]) {
          exp.tag = "variable";
        }
        else if (exp.tag === "symbol" && exp.value.match(/([A-Z].*\/)?[A-Z_]+/)) {
          exp.tag = "type";
        }
        break;
      
      case "quote":
      case "quasiquote":
        annotate_quoted(exp.attached_node, scope);
        
      default:
        if (exp.attached_node) annotate_expressions(exp.attached_node, scope);
    }
  }

  // translation of tag to css:
  var css_translation = {
    "constant":     "constants",
    "keyword":      "constants",
    "method":       "color1",
    "type":         "color3", 
    "function":     "functions",
    "string":       "string",
    "regexp":       "string",
    "value":        "value",
    "comments":     "comments",
    "symbol":       "symbol",
    "variable":     "variable",
    "splice":       "preprocessor", 
    "unquote":      "preprocessor",     
    "preprocessor": "preprocessor",
    "meta":         "preprocessor", 
    "'":            "preprocessor", 
    "#'":           "preprocessor",    
    "(":            "plain",
    ")":            "plain",
    "{":            "keyword",
    "}":            "keyword",
    "#{":           "keyword",   
    "[":            "keyword",
    "]":            "keyword",
    "invalid":      "invalid",
    "@":            "plain" 
  };
  
  function translate_tags_to_css(tokens) {
    for (var i = 0, j = tokens.length; i < j; i++) {
      var token = tokens[i];
      token.css = css_translation[token.tag];
      for (var k in token.secondary_tags) if (token.secondary_tags.hasOwnProperty(k))
        token.css += " " + k ;
    };
  }
  
  
  // create the new brush

  SH.brushes.Clojure = function () {};
  SH.brushes.Clojure.prototype = new SyntaxHighlighter.Highlighter();
  
  SH.brushes.Clojure.prototype.findMatches = function find_matches (regexpList, code) {
    // this is a nasty global hack. need to resolve this
    if (this.params && this.params.locals) {
      show_locals = this.params.locals === true || this.params.locals === "true"; 
    }
    else {
      show_locals = true;
    }
    
    var tokens = tokenize(code);
    annotate_expressions(build_tree(tokens), {});
    translate_tags_to_css(tokens);

    return tokens;
  };
  
  SH.brushes.Clojure.aliases = ['clojure', 'Clojure', 'clj'];
  SH.brushes.Clojure.register_annotation_rule = register_annotation_rule;

  return {
    tokenize: tokenize,
    build_tree: build_tree
  };
})(SyntaxHighlighter);
</script><title>marathon -- Marginalia</title></head><body><div class="docs"><div class="header"><h1 class="project-name">marathon</h1><h2 class="project-version">4.0.9-SNAPSHOT</h2><br /><p>An Integrated Suite of Rotational Analysis Tools.</p>
</div>
<div class="dependencies"><h3>dependencies</h3><table><tr><td class="dep-name">org.clojure/clojure</td><td class="dotted"><hr /></td><td class="dep-version">1.8.0</td></tr><tr><td class="dep-name">spork</td><td class="dotted"><hr /></td><td class="dep-version">0.1.9.8-SNAPSHOT</td></tr><tr><td class="dep-name">proc</td><td class="dotted"><hr /></td><td class="dep-version">0.2.0-SNAPSHOT</td></tr><tr><td class="dep-name">com.taoensso/nippy</td><td class="dotted"><hr /></td><td class="dep-version">2.11.0-RC1</td></tr><tr><td class="dep-name">datascript</td><td class="dotted"><hr /></td><td class="dep-version">0.15.0</td></tr><tr><td class="dep-name">org.clojure/core.logic</td><td class="dotted"><hr /></td><td class="dep-version">0.8.10</td></tr><tr><td class="dep-name">joinr/swingrepl</td><td class="dotted"><hr /></td><td class="dep-version">1.4.2-SNAPSHOT</td></tr></table></div>
</div><div class="docs"><div class="toc"><a name="toc"><h3>namespaces</h3></a><ul><li><a href="#marathon.documentation">marathon.documentation</a></li><li><a href="#marathon.prelude">marathon.prelude</a></li><li><a href="#marathon.core">marathon.core</a></li><li><a href="#marathon.project">marathon.project</a></li><li><a href="#marathon.project.excel">marathon.project.excel</a></li><li><a href="#marathon.ces.core">marathon.ces.core</a></li><li><a href="#marathon.ces.engine">marathon.ces.engine</a></li><li><a href="#marathon.ces.fill">marathon.ces.fill</a></li><li><a href="#marathon.ces.deployment">marathon.ces.deployment</a></li><li><a href="#marathon.ces.demand">marathon.ces.demand</a></li><li><a href="#marathon.ces.supply">marathon.ces.supply</a></li><li><a href="#marathon.ces.policy">marathon.ces.policy</a></li><li><a href="#marathon.ces.policyio">marathon.ces.policyio</a></li><li><a href="#marathon.analysis">marathon.analysis</a></li><li><a href="#marathon.analysis.requirements">marathon.analysis.requirements</a></li><li><a href="#marathon.data.store">marathon.data.store</a></li><li><a href="#marathon.data.protocols">marathon.data.protocols</a></li><li><a href="#marathon.fill.filldata">marathon.fill.filldata</a></li><li><a href="#marathon.demand.demanddata">marathon.demand.demanddata</a></li><li><a href="#marathon.supply.unitdata">marathon.supply.unitdata</a></li><li><a href="#marathon.policy.policydata">marathon.policy.policydata</a></li><li><a href="#marathon.data.cycle">marathon.data.cycle</a></li><li><a href="#marathon.data.period">marathon.data.period</a></li><li><a href="#marathon.processing.highwater">marathon.processing.highwater</a></li><li><a href="#marathon.processing.forgereader">marathon.processing.forgereader</a></li><li><a href="#marathon.processing.helmet.core">marathon.processing.helmet.core</a></li><li><a href="#marathon.processing.helmet.collision">marathon.processing.helmet.collision</a></li><li><a href="#marathon.processing.helmet.split">marathon.processing.helmet.split</a></li></ul></div></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.documentation" name="marathon.documentation"><h1 class="project-name">marathon.documentation</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><h2>Note for Folks Viewing From a Browser</h2>

<p>If you're reading this, and you want to enable the syntax highlighting for
the source code, you need to make sure javascript, or for Internet Explorer,
ActiveX content is enabled.  The syntax highlighter is a small script that
runs in the browser and colorizes the text.  The PDF version does not suffer
this problem.</p>
</div><div class="codes"></div><div class="docs"><h1>Documentation Overview</h1>

<p>Marathon documentation serves dual purposes: it's a build script that we can 
run from the REPL to generate various pieces of documentation, and it 
provides a topical overview of the different namespaces the support Marathon.  </p>
</div><div class="codes"></div><div class="docs"><p>It assumes we have marginalia installed, and the lein-marginalia plugin.
This makes it easy to cook off a couple of different documentation builds, 
from a full-on bible that describes every system in the package, to more 
targeted builds.  </p>
</div><div class="codes"></div><div class="docs"><p>The documentation tool, marginalia, produces one or more formatted html files
that aim for a simple form of literate programming.  The idea is that author
commentary appears on the left margin, while the actual source code appears 
on the right, so that the commentary is taken in context with the code.  </p>
</div><div class="codes"></div><div class="docs"><p>By default, every build of the documentation will include this file, to serve
as a topical roadmap, and a prelude for Marathon.  The prelude is intended 
to provide a brief, high-level overview of the "what" and "why" of Marathon.</p>
</div><div class="codes"></div><div class="docs"><p>Deeper discourse will appear in later chapters.  The general aim is to provide
the highest level concepts early in any documentation, and then descend 
to the more granular implementation details.  </p>
</div><div class="codes"></div><div class="docs"><p>I apologize up-front for the current elegance, or lack thereof, of much of 
the prose.  The current versions of the source code and the comments were 
very recently lifted from a large legacy code-base.  Apparently, the demons 
from Marathon's previous environment, the padded walls of VBA, echoed through
the 40K lines of code, hundreds of classes, and 30K lines of comments gathered
over 2 to 3 years.  One reader of an earlier, somewhat "raw" draft likened 
the document to "a man's journal of his own descent into madness."    </p>
</div><div class="codes"></div><div class="docs"><p>Such criticism is welcome, and I have since struggled to avoid offending
readers' sensibilities. I am still porting both the source code, and 
refining the prose.  My hope is to asymptotically approach the quality and 
clarity of Don Knuth's writings, but that particular mountain top is quite 
distant.  </p>
</div><div class="codes"></div><div class="docs"><p>As the documentation matures, I will try to take advantage of the 
formatting options available, to help distinguish between my interspersed 
commentary, and commentary attached to specific source code.  I have only 
just begun to modify the default Cascading Style Sheet, and hope to find 
a more pleasing form in the future.  </p>
</div><div class="codes"></div><div class="docs"><p>The code you will see throughout is from a Lisp dialect called Clojure: 
http://clojure.org/        </p>
</div><div class="codes"></div><div class="docs"><p>The position of commentary directly preceding code implies a direct relation 
to the code block. Code is called out via block formatting, with a simple 
delimited line on the left margin.</p>
</div><div class="codes"></div><div class="docs"><p>Feel free to contact me at <strong>thomas.spoon@us.army.mil</strong> <br />
<strong>-Tom Spoon</strong>  </p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.documentation
  (:require [clojure.java [shell :as shell]]))</pre></div><div class="docs"><h1>Documentation v0.1 - i.e. this file</h1>
</div><div class="codes"><pre class="brush: clojure">(def documentation &quot;marathon.documentation&quot;)</pre></div><div class="docs"><h1>The standard prelude for all marathon docs.</h1>

<p>Basically a bumper sticker namespace with summary info.</p>
</div><div class="codes"><pre class="brush: clojure">(def prelude [&quot;marathon.prelude&quot;])</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn expand-paths [root xs] (map #(str root \. %) xs))
(defn path-&gt;file [p]
  (str &quot;src/&quot; (clojure.string/replace p \. \/) &quot;.clj&quot;))</pre></div><div class="docs"><h1>Stochastic Demand PreProcessing Libraries</h1>
</div><div class="codes"><pre class="brush: clojure">(def stochastic-demand
  (expand-paths 
   &quot;marathon.processing.helmet&quot; 
   [&quot;core&quot; &quot;collision&quot; &quot;split&quot;]))</pre></div><div class="docs"><h1>Aggregate and primitive data used by Marathon</h1>
</div><div class="codes"><pre class="brush: clojure">(def marathon-data 
  [&quot;marathon.data.store&quot;
   &quot;marathon.data.protocols&quot; ;sketchy.
   &quot;marathon.fill.filldata&quot;
   &quot;marathon.demand.demanddata&quot;
   &quot;marathon.supply.unitdata&quot;
   &quot;marathon.policy.policydata&quot;
   &quot;marathon.data.cycle&quot;
   &quot;marathon.data.period&quot;   ;Note, this is duplicated in marathon.sim.policy
   ])</pre></div><div class="docs"><h1>High Level Simulation Functions in Marathon</h1>
</div><div class="codes"><pre class="brush: clojure">(def marathon-sim
  (expand-paths &quot;marathon.ces&quot; 
    [&quot;core&quot; 
     &quot;engine&quot;
     &quot;fill&quot;
     &quot;deployment&quot;
     &quot;demand&quot;
     &quot;supply&quot;
     &quot;policy&quot;
     &quot;policyio&quot;]))</pre></div><div class="docs"><h1>Analysis API and scripting functions</h1>
</div><div class="codes"><pre class="brush: clojure">(def marathon-analysis
  (into [&quot;marathon.analysis&quot;]
        (expand-paths &quot;marathon.analysis&quot;
                      [&quot;requirements&quot;])))</pre></div><div class="docs"><h1>Processing Tasks</h1>
</div><div class="codes"><pre class="brush: clojure">(def processing 
  (expand-paths &quot;marathon.processing&quot; 
    [
     &quot;highwater&quot;
     &quot;forgereader&quot;
     ]))</pre></div><div class="docs"><h1>The Main User-Facing Entry Point</h1>
</div><div class="codes"><pre class="brush: clojure">(def user-interface 
  [&quot;marathon.core&quot;])</pre></div><div class="docs"><h1>Marathon Project Definition and Management</h1>
</div><div class="codes"><pre class="brush: clojure">(def marathon-project 
  [&quot;marathon.project&quot;
   &quot;marathon.project.excel&quot;])</pre></div><div class="docs"><p>The rest are internal functions that build topical subsets of the Marathon 
documentation, or push out an entire compendium.</p>
</div><div class="codes"></div><div class="docs"><p>Specify different build configurations for various levels of documentation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn build-config
  [xs]
   (flatten (into [documentation prelude] xs)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def build-everything 
  (build-config [user-interface 
                 marathon-project
                 marathon-sim
                 marathon-analysis
                 marathon-data
                 processing
                 stochastic-demand]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def simulation-only 
  (build-config [marathon-sim marathon-data]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn marge-command [xs]
  (into [&quot;lein&quot; &quot;marg&quot;]  
        (map path-&gt;file xs)))</pre></div><div class="docs"><p>Spits a set of file paths to marginalia for documentation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn build-docs
  [files]
  (apply clojure.java.shell/sh 
    (marge-command files))) </pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.prelude" name="marathon.prelude"><h1 class="project-name">marathon.prelude</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>A short description of Marathon, and its supporting infrastructure.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.prelude)</pre></div><div class="docs"><h1>What is Marathon?</h1>

<p>Marathon is a mechanism for analyzing the effects of Army supply, demand, and 
policy variations, where supply is a set of potentially deployable units, 
demand is a set of activities requiring a unit, and policy is a collection of
rules or constraints that determine a units ability to fill a demand.  </p>
</div><div class="codes"></div><div class="docs"><p>As a design goal, Marathon seeks to validly simulate the physics of Army 
supply and demand, governed by policy, to analyze both the general behavior of
such systems and the specific effects relative to changes in supply, demand, 
or policy. Ultimately, Marathon is an analytic sandbox for evaluating courses 
of action relative to the Army Force Generation domain.  </p>
</div><div class="codes"></div><div class="docs"><h1>Army Force Generation</h1>

<p>Army Force Generation is a system for managing readiness, the ability for 
units to deploy to meet contingencies.  In general, force generation is the 
structured progression of increased unit readiness over time, resulting in the
periodic availability of trained, ready and cohesive units prepared for 
operational deployment in support of civil authorities and combatant commander
requirements.  The domain of Army Force Generation is enormous,   encompassing
the range of processes and resources necessary to man, equip, train, deploy, 
and sustain the Armys supply of units.  </p>
</div><div class="codes"></div><div class="docs"><p>Out of necessity, Marathon focuses on a subset of the Force Generation
process, and generally holds many gross assumptions about the behavior of 
quite complex subsystems (such as training processes, manning, equipment, 
mobilization, etc.)  Even with the Force Generation domain scoped to the unit 
level of detail , and with complex subsystems like equipping and manning 
abstracted away, the variety of supply, demand, and policy options is still
staggering.  </p>
</div><div class="codes"></div><div class="docs"><h1>How Does Marathon Work?</h1>

<p>Marathon typically simulates the force generation process through a 
coordinated set of supply, demand, and policy simulations.</p>
</div><div class="codes"></div><div class="docs"><h1>Supply</h1>

<p>The supply system acts as a coordination point for polling unit availability, 
a dissemination channel for simulation supply events, and a general container 
of units. <br />
Thousands  of unique unit entities follow rotational policies that are either
global (shared)  or local (unique to the unit), and are directed by one or 
more supply systems to execute the supply physics dictated by the 
corresponding  policy.  Each units simulated history can be traced, recorded,
and reacted to within the simulation ecosystem.  </p>
</div><div class="codes"></div><div class="docs"><p>Unit rotational policy generally consists of a directed sequence of states and
durations.   Units also have a behavior, which interprets policy to implement 
the desired supply-side and deployed actions.  Policies are entirely modular 
and variable, as are individual unit behaviors.  The decoupling of behavior 
and policy allows for both homogenous sets of units that appear to behave 
identically, as well as a diaspora of independent singletons that can apply 
similar behavior to different policies or interpret the same policies 
(via different behavior) to simulate radically different populations.  </p>
</div><div class="codes"></div><div class="docs"><p>The potential for unique entities allows Marathon to flexibly and modularly 
account for the legion of subtleties and corner-cases in the force generation 
problem domain.  </p>
</div><div class="codes"></div><div class="docs"><h1>Demand</h1>

<p>Demands are activated, and slated for filling, based on a - potentially 
sophisticated - user-defined priority function.  A fill system matches the 
highest priority demand to the most suitable supply as needed, and directs the
transition of units from the supply system to deployments or other states. <br />
The fill system also accounts for potentially complex unit substitution rules,
demand preferences, and almost any value function associated with the 
selection of units to fill demands.  </p>
</div><div class="codes"></div><div class="docs"><h1>Policy</h1>

<p>Finally, a policy system accounts for changes to policy (such as ARFORGEN 
suspension, variation in lifecycle length, and changes in deployment time) by 
enacting system-wide policy changes in response to either time or event. <br />
Policy changes automatically filter down to subscribing units, enabling a rich
and diverse simulation of the supply-policy-demand dynamics.</p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.core" name="marathon.core"><h1 class="project-name">marathon.core</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.core
  (:require [spork.util [table :as tbl]
                        [io :as io]]
            [marathon.processing.helmet [core :as helm]]
            [marathon.processing.stoke [core :as stoke]
                                       [io :as stokeio]
                                        ;[scraper :as scraper]
             ]
            [marathon.run :as run]
            [marathon.analysis [requirements :as requirements]]
            [clojure       [pprint :as pprint]
                           [set :as set]]
            [spork.cljgui.components [swing :as gui]]
            [spork         [mvc :as mvc]]
            [spork.events  [observe :as obs]
                           [native :as swing-events]]
            ;[piccolotest.repl :as repl]
            [org.dipert.swingrepl.main])
  (:use [spork.util.mailbox] ;;should be able to deprecate this.
        [marathon.processing.post]
        [marathon.project]
        [clojure.repl])
  (:import [javax.swing JFrame]) ;Bah!
  ;(:gen-class :main true))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def noisy (atom true))
(defn toggle-noisy [] (swap! noisy (fn [n] (not n))))</pre></div><div class="docs"><p>From Stuart Sierra's blog post, for catching otherwise "slient" exceptions
Since we're using multithreading and the like, and we don't want
exceptions to get silently swallowed</p>
</div><div class="codes"><pre class="brush: clojure">(let [out *out*]
  (Thread/setDefaultUncaughtExceptionHandler
   (reify Thread$UncaughtExceptionHandler
     (uncaughtException [_ thread ex]
       (when @noisy 
         (binding [*out* out]
           (println [&quot;Uncaught Exception on&quot; (.getName thread) ex])))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def  path-history   (atom [(System/getProperty &quot;user.dir&quot;)]))
(defn add-path! [p]  (swap! path-history conj p))
(defn active-path [] (last @path-history))  </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn select-file []
  (let [p (gui/select-file (active-path))]
    (do (add-path! p)
      p)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn select-folder []
  (let [p (gui/select-folder (active-path))]
    (do (add-path! p)
      p)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn notify [msg]
  (fn [] (gui/alert msg)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn not-implemented 
  ([msg] (fn [] (gui/alert (str msg &quot; Not Implemented&quot;))))
  ([] (not-implemented )))</pre></div><div class="docs"><p>project-manager is a simple agent that maintains internal state. 
we design the event handling functions as simple events that the user enters,
can communicate them to project-manager. </p>
</div><div class="codes"></div><div class="docs"><p>Project-manager then routes tasks, using the currently-loaded project as its 
environment. </p>
</div><div class="codes"><pre class="brush: clojure">(defn project-mvc [routes init-state]
  {:model (agent {:state init-state
                  :routes routes})
   :view nil 
   :control route-message})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def sample-path 
  &quot;C:\\Users\\thomas.spoon\\Documents\\Marathon_NIPR\\OngoingDevelopment\\smallsampling&quot;)
(def sample 
  &quot;C:\\Users\\thomas.spoon\\Documents\\Marathon_NIPR\\OngoingDevelopment\\smallsampling\\MPI_3.760298326.xlsm&quot;)</pre></div><div class="docs"><p>This is a hack, need a more elegant solution.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tbl-&gt;view [t &amp; {:keys [sorted] :or 
                       {sorted true}}]    
    (gui/-&gt;swing-table (tbl/table-fields t)
                       (tbl/table-rows t) 
                       :sorted sorted))</pre></div><div class="docs"><p>Creates a swing-repl that we can send code to for remote 
   evaluation, or allow the user to interactively eval 
   expressions.</p>
</div><div class="codes"><pre class="brush: clojure">(defn repl-panel
  ([opts]
   (org.dipert.swingrepl.main/make-repl-jconsole
    (merge org.dipert.swingrepl.main/default-opts opts)))
  ([w h]
   (doto (repl-panel {})
     (.setPreferredSize (java.awt.Dimension. w h))))
  ([w h opts]
   (doto (repl-panel opts)
         (.setPreferredSize (java.awt.Dimension. w h)))))</pre></div><div class="docs"><p>Probably need to modify this....</p>
</div><div class="codes"><pre class="brush: clojure">(def project-routes 
  {:clear-project (message-handler 
                    (assoc-in env 
                        [:state :current-project] {})) ;state-&gt;msg-&gt;state   
   :load-project (message-handler
                   (assoc-in env 
                      [:state :current-project]
                        (load-project msg-data))) ;state-&gt;msg-&gt;state   
   :save-project (message-handler  
                   (pass-through #(save-project % msg-data))) ;state-&gt;msg-&gt;state
   :view-project (effect (not-implemented :view-project)) ;state-&gt;msg-&gt;state
   :view-table   (pass-through 
                     #(gui/view (tbl-&gt;view (get-table (:current-project state)
                                           msg-data)
                                :sorted true)
                                :title (str msg-data))) ;state-&gt;msg-&gt;state   
   :add-table    (message-handler
                   (let [[name table] msg-data]
                     (assoc-in env [:state :current-project] 
                       (add-table (:current-project state)
                          msg-data))))}) ;state-&gt;msg-&gt;state</pre></div><div class="docs"><p>state->msg->state</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment 
  (def project-manager
    (project-mvc (merge default-routes project-routes)   {}))
  (def sample-table {:First [&quot;Tom&quot;]
                     :Last  [&quot;Spoon&quot;]}))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def project-menu-spec  
  {&quot;Examine-Project&quot;    &quot;Provides a visual presentation of a project.&quot;   
  ;  &quot;Save-Project&quot;    &quot;Saves a project into the project path.&quot;
  ;  &quot;Save-Project-As&quot; &quot;Saves a currently-loaded project into path.&quot;
 ;   &quot;Convert-Project&quot; &quot;Convert a project from one format to another.&quot;
 ;   &quot;Derive-Project&quot;  &quot;Allows one to derive multiple projects from the current.&quot;
 ;   &quot;Migrate-Project&quot; &quot;Port data from a legacy version of marathon to a new one.&quot;
   ; &quot;Audit-Project&quot;   &quot;Audits the current project.&quot;
   ; &quot;Audit-Projects&quot;  &quot;Audits multiple projects&quot;
    })</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def processing-menu-spec
  {;&quot;Clean&quot;              &quot;Cleans a run&quot;
   ;&quot;High-Water&quot;         &quot;Computes HighWater trails&quot;
   ;&quot;Deployment-Vectors&quot; &quot;Analyzes deployments&quot;
   ;;&quot;Charts&quot;             &quot;Generate plots.&quot;   
   &quot;Capacity-Analysis&quot;     &quot;Performs a capacity run (default)&quot;
   &quot;Requirements-Analysis&quot; &quot;Performs a Requirements Run&quot;
   &quot;Stochastic-Demand&quot;     &quot;Generate stochastic demand files from a casebook.&quot;
   &quot;Compute-Peaks&quot;         &quot;Extract the peak concurrent demands from a folder.&quot;
   &quot;Debug-Run&quot;             &quot;Runs the capacity analysis with output directed toward a file&quot;
;;   &quot;Custom&quot;             &quot;Run a custom script on the project&quot;
;;   &quot;Eval&quot;               &quot;Evaluate an expression in the context&quot;
   })</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def debug-menu-spec  
  {&quot;Debug-Run&quot;
      &quot;Performs a capacity analysis with copious amounts of debug info.&quot;
    &quot;Debug-Run-Heavy&quot;
       &quot;Capacity Analysis With ai-behavior level output.&quot;
  ;  &quot;Save-Project&quot;    &quot;Saves a project into the project path.&quot;
  ;  &quot;Save-Project-As&quot; &quot;Saves a currently-loaded project into path.&quot;
 ;   &quot;Convert-Project&quot; &quot;Convert a project from one format to another.&quot;
 ;   &quot;Derive-Project&quot;  &quot;Allows one to derive multiple projects from the current.&quot;
 ;   &quot;Migrate-Project&quot; &quot;Port data from a legacy version of marathon to a new one.&quot;
   ; &quot;Audit-Project&quot;   &quot;Audits the current project.&quot;
   ; &quot;Audit-Projects&quot;  &quot;Audits multiple projects&quot;
    })</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def scripting-menu-spec
  {&quot;Load-Script&quot; &quot;Load a clojure script into the environment.&quot;})
(def help-menu-spec
  {&quot;Search-For&quot; &quot;Interactive Help&quot;})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def preferences-menu-spec
  {&quot;Update&quot; &quot;Check for updates to Marathon.&quot;
   &quot;Eval&quot;   &quot;Evaluate an expression in the context&quot;})</pre></div><div class="docs"><p>Given a map of menu specs, builds a menu-system model with an integrated
   event stream that has a unique event for each menu item selected.  Returns 
   an event stream that is a union or merge of all the menu events.</p>
</div><div class="codes"><pre class="brush: clojure">(defn reactive-menu-system
  [specs]
  (let [menus (reduce (fn [acc [name spec]]
                        (assoc acc name 
                               (gui/map-&gt;reactive-menu name spec))))]
    (mvc/make-modelview nil menus 
      {:menu-events (obs/multimerge-obs (vals menus))})))       </pre></div><div class="docs"><p>This is helmet specific.</p>
</div><div class="codes"><pre class="brush: clojure">(defn casekey-&gt;filename [[case-name future]]
  (str case-name \_ future &quot;.txt&quot;))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn spit-tables [futures path]
  (let [root-dir (io/as-directory path)]        
    (doseq [[case-key tbl] futures]
      (let [file-name (casekey-&gt;filename case-key)]
        (io/hock  (io/relative-path root-dir [file-name]) 
                  (tbl/table-&gt;tabdelimited tbl))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro with-alert [alert body]
  `(do (~'gui/alert ~alert)
       ~body))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro request-path [[bind alert] body]
  `(when-let [~bind (with-alert ~alert (~'select-file))]
     ~body))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn compute-peaks-dialogue []
  (request-path [the-path &quot;Please select a file co-located in a folder with demand case files.&quot;]
    (let [dump-folder (apply str (interleave (butlast (io/list-path the-path))
                                               (repeat &quot;\\&quot;)))
          target (str dump-folder &quot;peaks\\&quot;)          
          _ (gui/alert (str &quot;dumping peaks files to &quot; target))]            
      (stokeio/compute-peaks dump-folder target))))</pre></div><div class="docs"><p>a quick hack to compute the deciles from a set of peaks, in case we 
don't need to compute the peaks and the deciles again.  We may 
separate this from the compute-peaks entirely.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compute-deciles-dialogue []
  (request-path [the-path &quot;Please select a file co-located in a folder with demand peak files.&quot;]
    (let [dump-folder (apply str (interleave (butlast (io/list-path the-path))
                                               (repeat &quot;\\&quot;)))
          target dump-folder          
          _ (gui/alert (str &quot;dumping peaks stats to &quot; target))]            
      (stokeio/compute-peak-stats dump-folder target))))</pre></div><div class="docs"><p>a quick plugin for stochastic demand generation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn stoch-demand-dialogue []
  (request-path [wbpath &quot;Please select the location of valid case-book.&quot;]
    (let [dump-folder (apply str (interleave (butlast (io/list-path wbpath))
                                               (repeat &quot;\\&quot;)))
          _ (gui/alert (str &quot;dumping to &quot; dump-folder))]            
      (spit-tables 
       (helm/futures-&gt;tables 
        (helm/xlsx-&gt;futures wbpath :ignore-dates? true :log? false)) dump-folder))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn clean-demand-dialogue []
  (request-path [wbpath &quot;Please select the location of valid case-files.&quot;]
    (let [fl          (clojure.java.io/file wbpath)
          cases       {(str (io/fname fl) \_ &quot;split.txt&quot;) (tbl/read-table fl)}
          ;dump-same?  @(future (gui/yes-no-box &quot;Dump cases in same location?&quot;))
          dump-folder ;(if dump-same?
          (apply str (interleave (butlast (io/list-path wbpath))
                                 (repeat &quot;\\&quot;)))
          ;(select-folder))
          _ (print (str &quot;dumping to &quot; dump-folder))]      
      (spit-tables cases dump-folder))))</pre></div><div class="docs"><p>legacy auditing of marathon workbooks.....needs verification.</p>
</div><div class="codes"><pre class="brush: clojure">(defn audit-project-dialogue []
  (request-path [wbpath &quot;Please select the location of valid case-files.&quot;]  
    (let [fl           (clojure.java.io/file wbpath)
          cases       {(str (io/fname fl) \_ &quot;split.txt&quot;) (tbl/read-table fl)}
          ;dump-same?  @(future (gui/yes-no-box &quot;Dump cases in same location?&quot;))
          dump-folder ;(if dump-same?
          (apply str (interleave (butlast (io/list-path wbpath))
                                   (repeat &quot;\\&quot;)))
            ;(select-folder))
            _ (print (str &quot;dumping to &quot; dump-folder))]      
      (spit-tables cases dump-folder))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn capacity-analysis [wbpath]
  (let [pieces       (clojure.string/split wbpath #&quot;\\&quot;)
        root         (io/as-directory (clojure.string/join &quot;\\&quot; (butlast pieces)))
        target       (last    pieces)
        _            (println [:running :capacity-analysis :at wbpath])]
    (run/run-cases root [target])))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn capacity-analysis-dialogue []
    (request-path [wbpath &quot;Please select the location of a valid MARATHON project file.&quot;]  
                  (capacity-analysis wbpath)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn requirements-analysis-dialogue []
    (request-path [wbpath &quot;Please select the location of a valid MARATHON requirements project file.&quot;]  
                  (requirements/requirements-run wbpath)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn debug-run-dialogue []
  (request-path [wbpath &quot;Please select the location of a valid MARATHON project file.&quot;]
    (let [pieces       (clojure.string/split wbpath #&quot;\\&quot;)
          root         (io/as-directory (clojure.string/join &quot;\\&quot; (butlast pieces)))
          target       (last    pieces)
          dbgtgt       (str root &quot;debug.txt&quot;)
          _ (println [:performing-debug-run :to dbgtgt])]
      (with-open [wrtr (clojure.java.io/writer dbgtgt)]
        (binding [*out* wrtr]
          (marathon.ces.core/debugging                
           (capacity-analysis wbpath)))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn debug-run-dialogue! []
  (request-path [wbpath &quot;Please select the location of a valid MARATHON project file.&quot;] 
     (marathon.ces.core/debugging!                
      (capacity-analysis wbpath))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn examine-project-dialogue []
  (request-path [wbpath &quot;Please select the location of a valid MARATHON project file.&quot;] 
     (run/examine-project wbpath)))</pre></div><div class="docs"><p>Default menu-handling function.  Handles events coming from the 
   swing menu, which are typically just keywords, and dispatches them 
   to the appropriate command.</p>

<p>holy wow this is terrible.  must be a better way...</p>
</div><div class="codes"><pre class="brush: clojure">(defn menu-handler
  [rpl]
  (fn [e]
    (let [expr 
          (case e
            :stochastic-demand  '(stoch-demand-dialogue)
            :compute-peaks      '(compute-peaks-dialogue) 
            :say-hello          '(println &quot;hello!&quot;)
            :capacity-analysis  '(capacity-analysis-dialogue)
            :requirements-analysis  '(requirements-analysis-dialogue)
            :debug-run          '(debug-run-dialogue)
            :examine-project    '(examine-project-dialogue)
            :search-for         '(pprint/pprint
                                  (apropos
                                   (gui/input-box
                                    :prompt &quot;Enter A Topic&quot;)))
            :load-script        '(load-file
                                  (gui/input-box
                                   :prompt &quot;Select a Clojure script&quot;))
            `(~'println ~e))]
      (org.dipert.swingrepl.main/send-repl rpl (str expr)))))</pre></div><div class="docs"><p>work on separating out from the jframe.
(defn hub-panel []
  (let [rpl             (repl/repl-panel 800 600)
        project-menu    (gui/map->reactive-menu "Project-Management" <br />
                                               project-menu-spec)
        processing-menu (gui/map->reactive-menu "Processing"
                                                processing-menu-spec)
        debug-menu      (gui/map->reactive-menu "Debug"
                                                debug-menu-spec)
        main-menu       (gui/menu-bar (:view project-menu)
                                      (:view processing-menu)
                                      (:view debug-menu))
        menu-events     (obs/multimerge-obs [(-> project-menu :control :event-stream)
                                             (-> processing-menu :control :event-stream)
                                             (-> debug-menu   :control :event-stream)])
        textlog         (gui/label "Idle")
        audit           (gui/button "Clear" (fn [_] 
                                              (obs/notify! menu-events :clear)))
        handle-menu       (atom  (menu-handler rpl))
        reflect-selection (->> menu-events 
                               (obs/subscribe  #(gui/change-label textlog %)))
        _                 (->> menu-events 
                               (obs/subscribe  #(@handle-menu %))) <br />
        ]
    (mvc/make-modelview 
      (agent {:state (if project {:current-project project} {})
              :routes (merge default-routes project-routes)}) <br />
      (gui/display (->> (close-beh 
                          (gui/empty-frame "Marathon Project Management")) 
                        (gui/add-menu main-menu)
                        )
                   (gui/stack textlog <br />
                              rpl
                              audit))
      {:menu-events menu-events
       :repl rpl
       :handle-menu handle-menu
       :set-handler (fn [f] (reset! handle-menu (menu-handler rpl)))})))</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn hub [&amp; {:keys [project exit? repl-options]}]
  (let [close-beh (if exit?
                    (fn [^JFrame fr] 
                      (doto fr
                        (.setDefaultCloseOperation JFrame/EXIT_ON_CLOSE)))
                      identity)
        rpl             (repl-panel 800 600)
        project-menu    (gui/map-&gt;reactive-menu &quot;Project-Management&quot;  
                                               project-menu-spec)
        processing-menu (gui/map-&gt;reactive-menu &quot;Processing&quot;
                                                processing-menu-spec)
        debug-menu      (gui/map-&gt;reactive-menu &quot;Debug&quot;
                                                debug-menu-spec)
        scripting-menu  (gui/map-&gt;reactive-menu &quot;Scripting&quot;
                                                scripting-menu-spec)
        help-menu       (gui/map-&gt;reactive-menu &quot;Help&quot;
                                                help-menu-spec)
        main-menu       (gui/menu-bar (:view project-menu)
                                      (:view processing-menu)
                                      (:view scripting-menu)
                                      (:view debug-menu)
                                      (:view help-menu))        
        menu-events     (obs/multimerge-obs [(-&gt; project-menu :control :event-stream)
                                             (-&gt; processing-menu :control :event-stream)
                                             (-&gt; debug-menu   :control :event-stream)
                                             (-&gt; help-menu    :control :event-stream)
                                             (-&gt; scripting-menu :control :event-stream)
                                             ])
        textlog         (gui/label &quot;Idle&quot;)
        audit           (gui/button &quot;Clear&quot; (fn [_] 
                                              (obs/notify! menu-events :clear)))
        handle-menu       (atom  (menu-handler rpl))
        reflect-selection (-&gt;&gt; menu-events 
                               (obs/subscribe  #(gui/change-label textlog %)))
        _                 (-&gt;&gt; menu-events 
                               (obs/subscribe  #(@handle-menu %)))        
        ]
    (mvc/make-modelview 
      (agent {:state (if project {:current-project project} {})
              :routes (merge default-routes project-routes)})       
      (gui/display (-&gt;&gt; (close-beh 
                          (gui/empty-frame &quot;Marathon Project Management&quot;)) 
                        (gui/add-menu main-menu))
                   (gui/stack textlog  
                              rpl
                              audit))
      {:menu-events menu-events
       :repl rpl
       :handle-menu handle-menu
       :set-handler (fn [f] (reset! handle-menu (menu-handler rpl)))})))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn reset-handler! [h]
  (let [h (:control h)
        r (:repl h)]
    (reset! (:handle-menu h) (menu-handler r))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -main [&amp; args]
  (hub :exit? true))</pre></div><div class="docs"><p>Just some mucking around with parallel mapping stuff.
Didn't see a boost.  Need to tweak this guy.
(defn chunked-pmap [f size coll]
  (->> coll 
       (partition-all size)
       (pmap (comp doall 
                   (partial map f)))
       (apply concat)))</p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.project" name="marathon.project"><h1 class="project-name">marathon.project</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Project management functions.
Provides protocols and schemas for manipulating Marathon projects 
in a variety of formats.  Current implements include Excel workbooks, 
Clojure serialized data, and tab delimited files.  JSON and XML are 
trivial to support. More to come.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.project
  (:require  [spork.util [io :as io]            
                         [table :as tbl] 
                         [clipboard :as board]              
                         [general :as general]]
             [clojure [string :as strlib]]))</pre></div><div class="docs"><p>I'm not sure how much of this we really
need.</p>
</div><div class="codes"></div><div class="docs"><p>The basic requirements for a marathon project
are to load a set of canonical tables from
somewhere, parse them using the canonical
schemas, and if they're valid, recognize
them as tables.</p>
</div><div class="codes"></div><div class="docs"><p>Since we just maintain a map of tables,
which is our project, or db,
we should be able to easily modify the
project by modifying the map.
For instance, patching the project
by mergeing new tables on top,
or performing slight alterations...</p>
</div><div class="codes"></div><div class="docs"><p>These are all preprocessing steps...
I vote for the simplest abstraction
possible.  Keep using a simple
map-based setup as the project
definition.  The map stores (typically)
tables.</p>
</div><div class="codes"></div><div class="docs"><p>To read a project, we simply read the
appropriate tables.  Easy.</p>
</div><div class="codes"></div><div class="docs"><p>Project serialization should be
as easy...we can just dump the serialized
project (i.e. the tables and friends)
using cryo, or any tsv, etc.</p>
</div><div class="codes"></div><div class="docs"><p>a list of resources we expect to find in any project.
We'll search for these and see if they </p>
</div><div class="codes"><pre class="brush: clojure">(def default-resources [:titles
                        :supply-records
                        :demand-records
                        :src-tag-records
                        :period-records 
                        :relation-records 
                        :in-scope 
                        :out-of-scope                        
                        :parameters 
                        :deployments 
                        :demand-trends])</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def default-table-order (conj default-resources
                          :high-water))</pre></div><div class="docs"><p>A map of paths to resources, relative to a project-path.</p>
</div><div class="codes"><pre class="brush: clojure">(def default-paths {:titles           [&quot;Titles.txt&quot;]
                    :supply-records   [&quot;SupplyRecords.txt&quot;]
                    :demand-records   [&quot;DemandRecords.txt&quot;]                      
                    :src-tag-records  [&quot;SRCTagRecords.txt&quot;]
                    :period-records   [&quot;PeriodRecords.txt&quot;]
                    :relation-records [&quot;RelationRecords.txt&quot;]
                    :in-scope         [&quot;InScope.txt&quot;]
                    :out-of-scope     [&quot;OutOfScope.txt&quot;]
                    :parameters       [&quot;Parameters.txt&quot;]
                    :deployments      [&quot;Deployments.txt&quot;]                    
                    :demand-trends    [&quot;DemandTrends.txt&quot;]})</pre></div><div class="docs"><p>(defn load-project [path] (io/folders->map (io/as-directory path)))
(defn save-project [path] (io/map->folders! (io/as-directory path)))</p>
</div><div class="codes"></div><div class="docs"><p>projects have names, a version, a set of required resources (dependencies), 
and a resource map, a map of {resource-name resource}, where resource is 
anything from a simple parameter, to a path, to an inline data structure, 
or any number of things.  </p>
</div><div class="codes"><pre class="brush: clojure">(defn make-project [name project-path 
                    &amp; {:keys [version dependencies paths tables] 
                       :or {version 0.1
                            dependencies nil
                            paths (assoc default-paths 
                                         :project-path project-path)
                            tables {}}}]
  {:name         name 
   :version      version 
   :dependencies dependencies 
   :paths        paths
   :tables       tables})</pre></div><div class="docs"><p>Fetch the project path, or the root folder where the project is located.</p>
</div><div class="codes"><pre class="brush: clojure">(defn project-path
  [prj] (get-in prj [:paths :project-path]))</pre></div><div class="docs"><p>Fetches any root-level key that is not a resource.  Typically simple 
   parameters.</p>
</div><div class="codes"><pre class="brush: clojure">(defn project-properties
  [proj]
  (reduce (fn [p k] (dissoc p k)) proj [:paths :tables]))</pre></div><div class="docs"><p>Conjoins a path to resource, resname, in the project under :paths.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-path 
  [prj name path]
  (assoc-in prj [:paths name] path))</pre></div><div class="docs"><p>Conjoins a simple filename as a relative path under resname.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-file 
  [prj name filename]
  (assoc-in prj [:paths name] [filename]))</pre></div><div class="docs"><p>Fetch an absolute path to a resource, as defined by the relative path 
   associated with resname.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-path
  [prj resname]
  (io/relative-path 
    (project-path prj) (get-in prj [:paths resname])))</pre></div><div class="docs"><p>Given a path to a Marathon Project, acquires paths to input tables.
   Depending on the processing we're doing, we may not need every table, so 
   we only locate the paths, saving on memory in the process.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-input-paths
  [project-path &amp; {:keys [paths] :or {files default-paths}}]
  :not-implemented)</pre></div><div class="docs"><p>Adds a table to the project.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-table
  [prj table-name table]
  (assert tbl/tabular? table)
  (assoc-in prj [:tables table-name] table))</pre></div><div class="docs"><p>Add a sequence of named tables to the project. 
   Typically, we use a map of {tablename table} here, 
   but any sequence of [tablename table] will work.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-tables
  [prj tables] 
  (reduce (fn [p [nm table]]
            (add-table p nm table))
          prj (seq tables)))</pre></div><div class="docs"><p>Returns a table local to the project.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-table
  [prj t]
  (get-in prj [:tables t]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn project-dispatch [obj &amp; options] 
  (cond (string? obj) (.toLowerCase (io/fext obj))
        (and  (map? obj) (:tables obj)) :map-project ;already mapproject, effectively identity
        :else (class obj)))</pre></div><div class="docs"><p>Method for loading a Marathon project from one or more formats.
   If obj is a string, it will be parsed as a path, by file
   extension.  Otherwise, project-dispatches on class.</p>
</div><div class="codes"><pre class="brush: clojure">(defmulti load-project 
  project-dispatch)</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod load-project :map-project [obj &amp; options]
  obj)</pre></div><div class="docs"><p>Method for saving or persisting a Marathon project to a destination. <br />
   If obj is a string, it will be parsed as a path, dispatching on 
   the file extension.</p>
</div><div class="codes"><pre class="brush: clojure">(defmulti save-project 
  (fn [proj destination &amp; options]
    (project-dispatch destination)))</pre></div><div class="docs"><p>Method for building a new project from an existing project.  At the most 
   basic level, it's a simple cloning process.  Primary impetus is to
   facilitate cloning legacy projects and making data migration easier.</p>
</div><div class="codes"><pre class="brush: clojure">(defmulti derive-project 
  (fn [proj destination &amp; options]
    [(project-dispatch proj) (project-dispatch destination)]))</pre></div><div class="docs"><p>Method for migrating data in an existing project to another, possibly new 
   project.  At the most basic level, it's a simple cloning process.  Primary 
   impetus is to facilitate cloning legacy projects and making data migration 
   easier.</p>
</div><div class="codes"><pre class="brush: clojure">(defmulti migrate-project 
  (fn [proj destination &amp; options]
    [(project-dispatch proj) (project-dispatch destination)]))</pre></div><div class="docs"><p>might be obe.  probably better to serialize this.</p>
</div><div class="codes"><pre class="brush: clojure">(defmethod save-project &quot;clj&quot; [proj destination &amp; {:keys [expanded?] 
                                                   :or {expanded? false}}]
  (let [p (add-path proj :project-path destination)]
    (if expanded? 
      (do (io/map-&gt;folders!  p destination)
        (io/hock destination (with-out-str 
                               (doseq [l (map tbl/field-&gt;string (keys proj))]
                                 (println l)))))
      (io/hock destination (prn p)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn keyvals-&gt;table [kvps &amp; {:keys [string-fields?]}]
  (let [f (if string-fields? 
            (fn [f] (cond (string? f) f
                          (keyword? f) (str (subs (str f) 1))
                          (coll? f) (str f)
                          :else f))
            identity)]
    (-&gt;&gt; tbl/empty-table
      (tbl/conj-fields  
        {&quot;key&quot;  (vec (map f (keys kvps)))
         &quot;val&quot;  (vec (map f (vals kvps)))}))))</pre></div><div class="docs"><p>Method for converting a project representation into a map of ITabular
   objects, either for insertion into a database, for rendering to a folder, 
   or for injecting into a workbook.  Anything that benefits from a tabular 
   representation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn project-&gt;tables
  [proj &amp; {:keys [string-fields? ordering] 
           :or {string-fields? true
                ordering default-table-order}}]
  (-&gt;&gt; (merge {:paths (keyvals-&gt;table (:paths proj) :string-fields? 
                                               string-fields? )
               :properties (keyvals-&gt;table (project-properties proj)
                                        :string-fields? 
                                        string-fields? )}
              (:tables proj))
       (general/align-fields-by ordering)))</pre></div><div class="docs"><p>Perform a sequence of tests on the project to verify its integrity.</p>
</div><div class="codes"><pre class="brush: clojure">(defn test-project
  [prj testcoll]
  (reduce (fn [p tst] (tst p)) testcoll))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def default-auditing-tables
  [:SupplyRecords
   :DemandRecords
   :PeriodRecords
   :RelationRecords
   :SRCTagRecords
   :Parameters])</pre></div><div class="docs"><p>Creates an audit trail of all the input files for a capacity run, primarily 
   to aid legacy post processing.  Files are stored in the same root path, 
   prefixed by AUDIT_</p>

<p>This could be re-located to marathon.project, but that's still
a bit in flux.  I'd like to anneal more before we do.  For now,
we'll just do something a bit more generic.
We're missing SRCsInScope and SRCsOutOfScope here...
We compute scope after creating the context...
So at a minimum, we'd maybe need to build up the fill network.</p>
</div><div class="codes"><pre class="brush: clojure">(defn audit-project
  [prj outroot &amp; {:keys [tables] :or
                  {tables default-auditing-tables}}]
  (do (println [:auditing-to outroot])
      (let [prj (load-project prj)]
        (doseq [k tables]
          (let [t    (get (:tables prj) k)
                tgt  (str outroot &quot;AUDIT_&quot; (name k) &quot;.txt&quot;)
                _    (println [:spitting k :to tgt])]
            (tbl/spit-table tgt t))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(derive ::csv        ::table)
(derive ::json       ::map)
(derive ::json-table ::table) 
(derive ::worksheet  ::table)
(derive ::workbook   ::db)</pre></div><div class="docs"><p>Clear the resources from a project.</p>
</div><div class="codes"><pre class="brush: clojure">(defn clear-project!
  [projectroot]
  (io/clear-folders! projectroot))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.project.excel" name="marathon.project.excel"><h1 class="project-name">marathon.project.excel</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Defines operations for building Marathon projects from legacy Excel
workbook-based data.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.project.excel
  (:use [marathon.project])
  (:require [marathon.schemas :as schemas]
            [spork.util.excel [core :as xl] [docjure :as docj]]
            [spork.util       [io :as io]
                              [table :as tbl]]))</pre></div><div class="docs"><p>From here on out, we're not worrying about post-processing legacy excel
projects.  This is strictly for loading a marathon input project
from a workbook, or finding whatever canonical tables we can, and
then preparing it for processsing.</p>
</div><div class="codes"></div><div class="docs"><p>We should be able to adapt this pretty easily to a project coming from
tsv, just use schemas to do it...</p>
</div><div class="codes"></div><div class="docs"><p>Note checking for canonical fields....this could
be problematic...</p>
</div><div class="codes"></div><div class="docs"><p>Given a Marathon workbook, we know that these are the tables we'll care about.</p>
</div><div class="codes"><pre class="brush: clojure">(def marathon-workbook-schema
  {:CompositePolicyRecords &quot;CompositePolicyRecords&quot;
   :DemandRecords          &quot;DemandRecords&quot;
   :SuitabilityRecords     &quot;SuitabilityRecords&quot;
   :PolicyTemplates        &quot;PolicyTemplates&quot;
   :SRCTagRecords          &quot;SRCTagRecords&quot;
   :Parameters             &quot;Parameters&quot;
   :PolicyDefs             &quot;PolicyDefs&quot;
   :PolicyRecords          &quot;PolicyRecords&quot;
   :SupplyRecords          &quot;SupplyRecords&quot;
   :RelationRecords        &quot;RelationRecords&quot;
   ;:demand-table-schema &quot;demand-table-schema&quot;
   :PeriodRecords          &quot;PeriodRecords&quot;})</pre></div><div class="docs"><p>Schemas that support requirements analysis...</p>
</div><div class="codes"><pre class="brush: clojure">(def marathon-requirements-schema
  (merge marathon-workbook-schema
     {:GhostProportionsAggregate &quot;GhostProportionsAggregate&quot;}))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def input-sheets marathon-workbook-schema)</pre></div><div class="docs"><p>When we parse from excel, sometimes we'll get results,
primarily numerics, that get parsed as something
other than we'd like (doubles...)
(defn coerce [s tbl])
We may need to perform coercions later...but for now
I think we're okay.</p>
</div><div class="codes"></div><div class="docs"><p>Since we know the schema, we can coerce the
schema value...
or we can just read as string values...</p>
</div><div class="codes"><pre class="brush: clojure">(defn try-long [x] (if (zero? (mod x 1) )
                       (long x)
                       x))</pre></div><div class="docs"><p>This is a little squirelly, and exists solely to
cope with excel's handling of numbers and autoparsing
text wierdness.</p>
</div><div class="codes"><pre class="brush: clojure">(defn coerce [s tbl]
  (let [numtypes {:int int
                  :int? (fn [x] (when x (int x)))                  
                  :long long
                  :long? (fn [x] (when x (long x)))
                  :text  (fn [x] (if (number? x)
                                   ;;we need to coerce this mofo.
                                   (str (try-long x))
                                   x))}]
    (spork.util.table/conj-fields 
     (for [[fld col] (tbl/enumerate-fields (tbl/table-fields tbl) (tbl/table-columns tbl))]
       (if-let [f (numtypes (s fld))]
         [fld (mapv f col)]
         [fld col]))
     spork.util.table/empty-table)))</pre></div><div class="docs"><p>Another option is to keep everything in tsv....and
edit/update from excel.  There are advantages and
disadvantages to this...</p>
</div><div class="codes"><pre class="brush: clojure">(defn marathon-book-&gt;marathon-tables 
  [wbpath &amp; {:keys [tables] :or {tables 
                                 marathon-workbook-schema}}]
  &quot;Extract a map of canonical tables to a map with the same name.  Caller can 
   supply additional tables, or supply the :all keyword to get all tables.&quot;
  (let [wb   (xl/as-workbook wbpath)]
    (into {} (filter identity
                     (for [[nm sheetname] (seq tables)]
                       (if-let [sht (xl/as-sheet sheetname wb)]
                         (let [tab (spork.util.table/keywordize-field-names
                                    (xl/sheet-&gt;table sht))
                               tab (if-let [s (schemas/get-schema nm)]
                                     (coerce s tab)
                                     tab)]
                           (do (println nm)                   
                               [(keyword nm)  tab]))
                         (println [:missing nm])))))))</pre></div><div class="docs"><p>This is all that really matters from marathon.project...   </p>
</div><div class="codes"><pre class="brush: clojure">(defmethod load-project &quot;xlsm&quot;
  [path &amp; {:keys [tables]
           :or {tables marathon-workbook-schema}}]
    (let [ts    (marathon-book-&gt;marathon-tables path :tables tables)
        paths (reduce-kv (fn [acc nm _]
                           (assoc acc nm
                                  [path
                                   (name nm)])) {} ts)]    
      (-&gt; (make-project
           (clojure.string/replace (io/fname path) #&quot;.xlsm&quot; &quot;&quot;)
           (io/as-directory (io/fdir path))) 
          (assoc :tables ts)
          (update :paths merge paths))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod load-project &quot;xlsx&quot;
  [path &amp; {:keys [tables]
           :or {tables marathon-workbook-schema}}]
  (let [ts    (marathon-book-&gt;marathon-tables path :tables tables)
        paths (reduce-kv (fn [acc nm _]
                           (assoc acc nm
                                  [path
                                   (name nm)])) {} ts)]
  (-&gt; (make-project
        (clojure.string/replace (io/fname path) #&quot;.xlsx&quot; &quot;&quot;)
        (io/as-directory (io/fdir path))) 
      (assoc :tables ts)
      (update :paths merge paths))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod save-project &quot;xlsx&quot; [proj path &amp; options]
  (xl/tables-&gt;xlsx path
     (project-&gt;tables
        (add-path proj :project-path 
            (io/as-directory (io/fdir path))))))</pre></div><div class="docs"><p>this should probably go in docjure..</p>
</div><div class="codes"><pre class="brush: clojure">(defn copy-sheet! [sheetname wb1 wb2]
  (if-let [from-sheet (docj/select-sheet sheetname wb1)]
     (let [to-sheet   (if-let [s (docj/select-sheet  sheetname wb2)]
                        (do (docj/remove-all-rows! s) s) ;this is probably slow
                        (do (docj/add-sheet!   wb2 sheetname)
                            (docj/select-sheet sheetname wb2)))]
       (-&gt;&gt; (xl/contiguous-rows from-sheet) 
            (map                xl/row-&gt;vec)
            (docj/add-rows!     to-sheet)))
     (throw (Exception. (str &quot;Sheet &quot; sheetname &quot;does not exist&quot;)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn copy-sheets! [sheetnames wb-from wb-to] 
  (doseq [sheetname sheetnames]
    (copy-sheet! sheetname wb-from wb-to)))</pre></div><div class="docs"><p>This is to support cloning from legacy projects to new projects.
The intent is to make higher order operations like case setups and design 
of experiments a lot easier to do.</p>
</div><div class="codes"><pre class="brush: clojure">(defmethod derive-project [&quot;xlsm&quot; &quot;xlsm&quot;] [proj destination &amp; {:keys [tables]}])</pre></div><div class="docs"><p>clone tables from one workbook to another.</p>
</div><div class="codes"><pre class="brush: clojure">(defmethod migrate-project [&quot;xlsm&quot; &quot;xlsm&quot;] 
  [proj destination &amp; {:keys [sheetnames] :or {sheetnames 
                                                (vals input-sheets)}}]
    (let [wb-from  (docj/load-workbook proj)
          wb-to    (if (io/fexists? destination) 
                     (docj/load-workbook destination)
                     (docj/create-workbook &quot;MigrationInfo&quot; [[&quot;Source&quot;]
                                                            [proj]]))]
      (do (copy-sheets! sheetnames wb-from wb-to)
          (docj/save-workbook! destination wb-to ))))</pre></div><div class="docs"><p>I don't like copy and pasting...</p>
</div><div class="codes"><pre class="brush: clojure">(defmethod migrate-project [&quot;xlsx&quot; &quot;xlsx&quot;] 
  [proj destination &amp; {:keys [sheetnames] :or {sheetnames
                                               (vals input-sheets)}}]
      (let [wb-from  (docj/load-workbook proj)
            wb-to    (if (io/fexists? destination) 
                     (docj/load-workbook destination)
                     (docj/create-workbook &quot;MigrationInfo&quot; [[&quot;Source&quot;]
                                                            [proj]]))]
      (do (copy-sheets! sheetnames wb-from wb-to)
          (docj/save-workbook! wb-to destination))))</pre></div><div class="docs"><p>testing</p>
</div><div class="codes"><pre class="brush: clojure">(comment
;;bad example, corrupeted, parameters doesn't show up.
;(def wbpath   &quot;C:\\Users\\tom\\Documents\\Marathon_NIPR\\MPI_3.760298326.xlsm&quot;)
(def wbpath2   &quot;C:\\Users\\tom\\Documents\\Marathon_NIPR\\MPI_3.76029832.xlsm&quot;)
(def destpath  &quot;C:\\Users\\tom\\Documents\\Marathon_NIPR\\MigrationTest.xlsm&quot;)
(migrate-project wbpath2 destpath)
;; (comment 
;; (def input-sheets
;;   (select-keys marathon-workbook-schema  
;;                [:supply-records
;;                 :demand-records
;;                 :period-records
;;                 :relation-records
;;                 :src-tag-records
;;                 :parameters]))
;; ;These are canonical outputs from a VBA Marathon run for capacity analysis. 
;; (def marathon-text-file-output 
;;   {:cycle-records  &quot;cycles.txt&quot; 
;;    :event-log      &quot;EventLog.csv&quot;
;;    :demand-trends  &quot;DemandTrends.txt&quot;
;;    :sand-trends    &quot;SandTrends.txt&quot;
;;    :locations      &quot;locations.txt&quot;})       
;; ))  </pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.core" name="marathon.ces.core"><h1 class="project-name">marathon.ces.core</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>marathon.sim.core is a glue library that provides access to a common set of 
subsystems upon which a more complicated federated simulation infrastructure
is implemented.  </p>
</div><div class="codes"></div><div class="docs"><p>Marathon utilizes a generic simulation context, defined in <strong>sim.simcontext</strong>, 
which provides primitive access to a generic simulation state - heterogenous 
chunks of data relevant to different domains of the simulation - and a basic
discrete event simulation framework. <br />
Systems are then defined over this shared architecture, and contribute special 
means to affect a simulation in their particular domain.  At the highest 
level, a coordinating function, or an engine, orders and composes the systems 
into a comprehensive state transition function that maps one simulation 
context to the next.  </p>
</div><div class="codes"></div><div class="docs"><p>This core namespace started as a dumping ground for shared or duplicate 
functionality from the original object oriented design.  It continues to 
evolve as the source is reorganized along clearer lines, and serves as a 
staging ground for general pending tasks and observations.  To that end, the 
casual reader may skim the rest of this section without losing a great deal of
insight. <br />
Even for intrepid readers, the section header <strong>Developer Notes</strong> may be 
largely ignored.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.core
  (:require 
            [spork.util [metaprogramming :as util]
                        [general  :as gen]
                        [tags     :as tag]
                        [table    :as tbl]
                        [reducers]
                        [cellular :as cells]
                        [inspection :as inspect]
                        [temporal :as temp]]
            [spork.cljgraph [jungapi :as jung]]
            [spork.sketch :as sketch]                        
            [spork.entitysystem.store :refer :all :exclude [entity-name merge-entity] :as store]
            [spork.sim.simcontext :as sim]
            [spork.ai.core        :as ai]
            [marathon.ces.basebehavior :as b]
            [marathon.data.store       :as simstate]
            [clojure.core.reducers     :as r]))</pre></div><div class="docs"><p>This is a lifesaver...</p>
</div><div class="codes"><pre class="brush: clojure">(def noisy            (atom true))
(defn toggle-noisy [] (swap! noisy (fn [n] (not n))))</pre></div><div class="docs"><p>From Stuart Sierra's blog post, for catching otherwise "slient" exceptions
Since we're using multithreading and the like, and we don't want
exceptions to get silently swallowed</p>
</div><div class="codes"><pre class="brush: clojure">(let [out *out*]
  (Thread/setDefaultUncaughtExceptionHandler
   (reify Thread$UncaughtExceptionHandler
     (uncaughtException [_ thread ex]
       (when @noisy 
         (binding [*out* out]
           (println [&quot;Uncaught Exception on&quot; (.getName thread) ex])))))))</pre></div><div class="docs"><h1>Providing Common Access to the State in the Simulation Context</h1>

<p>The simulation context contains the simulation state - a large nested map of 
information that is 'typically' partitioned by a particular domain. <br />
Some systems, like the fill function, need access to multiple domains to
fulfill their purpose.  In response, we maintain an open, broad structure for 
the state portion of the context, but provide a set of common paths or 
mappings to resources embedded in the state.  </p>
</div><div class="codes"></div><div class="docs"><p>As a result, subsystems can query resources by predefined paths - a higher 
level of abstraction and clarity - OR they may dip down to low level 
operations on the raw state.  </p>
</div><div class="codes"></div><div class="docs"><p>This should maintain a balance between flexibility and clarity.</p>
</div><div class="codes"></div><div class="docs"><h1>Common Paths to Simulation Resources</h1>
</div><div class="codes"></div><div class="docs"><p>In the previous implementation, the 'state' was implemented as a class, with 
concrete members to access each piece.  We retain that level of commonality
via the paths, but the underlying representation is based on a dynamic map 
structure, so we can still add new data as needed in a flexible manner.</p>
</div><div class="codes"></div><div class="docs"><p>Creates a set of accessors for our simulation state.  This allows us to 
dissect our nested map of state a bit easier.  Each symbol in the defpath 
binding returns a function that, given a simulation context, points to the 
named resource using standard clojure map operations via clojure.core/get-in.
(util/defpaths   [:state] 
  {parameters    [:parameters]
   supplystore   [:supplystore]
   demandstore   [:demandstore]
   policystore   [:policystore]
   fillstore     [:fillstore]
   fill-function [:fillstore :fillfunction]
   fillmap       [:fillstore :fillmap]
   behaviors     [:behaviormanager]
   supply-tags   [:supplystore :tags]
   demand-tags   [:demandstore :tags]})</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro defpath [name path]
  (if (coll? path)        
    `(do (defn ~(symbol (str &quot;get-&quot; name)) [ctx#]
           (store/get-ine  ctx# ~path))
         (defn ~(symbol (str &quot;set-&quot; name)) [ctx# v#]
           (store/assoc-ine  ctx# ~path v#)))
    `(do (defn ~(symbol (str &quot;get-&quot; name)) [ctx#]
           (with-meta (store/get-entity  ctx# ~path)
             {:ctx ctx#}))
         (defn ~(symbol (str &quot;set-&quot; name)) [ctx# v#]
           (store/add-entity  ctx# ~path v#)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro defpaths [&amp; name-paths]
  (assert (even? (count name-paths)))
  `(do ~@(for [[name path] (partition 2 name-paths)]
           `(defpath ~name ~path))))</pre></div><div class="docs"><p>generic get/set path functions.</p>
</div><div class="codes"><pre class="brush: clojure">(defpaths
  parameters    :parameters
  supplystore   :SupplyStore
  demandstore   :DemandStore
  policystore   :PolicyStore
  fillstore     :FillStore
  fill-function [:FillStore :fillfunction]
  fillmap       [:FillStore :fillmap])</pre></div><div class="docs"><p>probably not useful.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-behaviors   [ctx] (get-entity ctx :behaviormanager))
(defn get-demand-tags [ctx] (get (get-demandstore ctx) :tags))
(defn get-supply-tags [ctx] (get (get-supplystore ctx) :tags))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn demands [ctx]
  (for [id  (keys (:demandmap (get-demandstore ctx)))]
    (get-entity ctx id)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn units   [ctx]
    (for [id  (keys (:unitmap   (get-supplystore ctx)))]
      (get-entity ctx id)))</pre></div><div class="docs"><p>Wow...this is really really easy to do now....constructing queries on the
entity store is nice...</p>
</div><div class="codes"><pre class="brush: clojure">(defn locations
  ([t ctx]
   (-&gt;&gt; (store/only-entities ctx [:name :locationname :location :positionpolicy :src :component])
        (into [] (map #(assoc % :t t)))))
  ([ctx] (locations  (sim/get-time ctx) ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn fills
  ([t ctx]
   (let [ds (store/gete ctx :DemandStore :activedemands)]
         (-&gt;&gt; (store/only-entities ctx [:name :locationname :location])              
              (into [] (comp (filter (fn [r] (get ds (:locationname r))))
                             (map #(assoc % :t t)))))))
  ([ctx] (fills  (sim/get-time ctx) ctx)))</pre></div><div class="docs"><p>Tells us is the location is a demand</p>
</div><div class="codes"><pre class="brush: clojure">(defn demand? [ctx location]
  (contains? (store/gete ctx :DemandStore :demandmap) location))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn active-fills [ctx]
  (persistent!
   (reduce-kv (fn [acc id _]
                (let [d (store/get-entity ctx id)]
                  (as-&gt; acc inner
                    (reduce conj! inner (keys (:units-assigned d)))
                    (reduce conj! inner (keys (:units-overlapping d))))))
              (transient [])
              (store/gete ctx :DemandStore :activedemands))))</pre></div><div class="docs"><p>This is a pretty useful deployment query....
provides us with a map of </p>
</div><div class="codes"><pre class="brush: clojure">(defn deployments
  ([t ctx]
   (-&gt;&gt; (get-demandstore ctx)
        (:activedemands)
        (keys)
        (map #(store/get-entity ctx %))
        (map (fn [{:keys [category demandgroup operation vignette Command] :as d}]
               {:t t
                :name        (:name d)
                :src         (:src  d)
                :assigned    (count  (:units-assigned d))
                :overlapping (count  (:units-overlapping d))
                :quantity    (:quantity d)
                :filled      (count (:units-assigned d))
                :unfilled    (- (:quantity d) (count (:units-assigned d)))
                :category    category
                :demandgroup demandgroup
                :operation   operation
                :vignette    vignette
                :command     Command
                :total       (+ (count (:units-assigned d))  (count (:units-overlapping d)))}))))
  ([ctx]  (deployments (sim/get-time ctx) ctx)))</pre></div><div class="docs"><p>query the entity store to find deployments</p>
</div><div class="codes"><pre class="brush: clojure">(defn deployment-records  [ctx])</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn location-table [ctx]
  (let [t (sim/get-time ctx)]
    (-&gt;&gt; (store/only-entities ctx [:name :locationname :location])
         (map #(assoc % :t t))
         (tbl/records-&gt;table))))</pre></div><div class="docs"><p>Terrible, short-sighted hack just to get things working.</p>
</div><div class="codes"><pre class="brush: clojure">(defn srm-demand? [ctx nm]
  (when-let [c (gete ctx nm :Category)]
    (= c &quot;SRM&quot;)))</pre></div><div class="docs"><p>Functions for dealing with subsets of supply/demand,
for defining smaller simulations.</p>
</div><div class="codes"><pre class="brush: clojure">(defn entity? [x] (instance? spork.entitysystem.store.entity x))
(defn prune-children [prune? parent]
  (reduce-kv (fn [acc p c]
               (if (prune? p)
                 (dissoc acc p)
                 (cond (and (map? c) (not (entity? c)))  (assoc acc p (prune-children prune? c))
                                        ;(vector? c) (into [] (filter prune? c))
                                        ;(seq c) (filter prune? c)
                       :else 
                       acc)))
             parent parent))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn drop-units [names ctx]
  (let [drops (set names)
        prune! #(prune-children drops %)]
    (-&gt; ctx
        (store/updatee  :SupplyStore :unitmap prune!)
        (store/updatee  :SupplyStore :deployable-buckets prune!))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn drop-demands [names ctx]
  (let [drops (set names)
        prune! #(prune-children drops %)]
    (-&gt; ctx
        (store/updatee  :DemandStore :demandmap prune!)
        (store/updatee  :DemandStore :activations prune!)
        (store/updatee  :DemandStore :deactivations prune!)
        (store/updatee  :DemandStore :activedemands  prune!))))</pre></div><div class="docs"><p>we need to remove the entities from any reference too..
THis is akin to enabling/disabling....</p>
</div><div class="codes"><pre class="brush: clojure">(defn solo-src [solo ctx]
  (let [dropped (set (map :name
                          (store/select-entities ctx
                                                 :from [:src]
                                                 :where (fn [{:keys [src]}]
                                                          (not= src solo)))))
        ]
    (as-&gt;    (-&gt;&gt; (reduce (fn [acc e]
                               (store/drop-entity acc e)) ctx dropped)
                     (drop-units dropped)
                     (drop-demands dropped))
             dropped-ctx 
        (reduce (fn [ctx nm]
                  (store/add-entity ctx {:name nm :disabled true}))
               dropped-ctx 
               dropped))))</pre></div><div class="docs"><p>We're starting to build stats and queries...muahaha...this is where clojure kicks ass.
(defn deployed-population [ctx]
  (for [{:keys [name assigned overlapping quantity]}]
    (deployments ctx)))</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn periods [ctx] (:periods   (get-policystore ctx)))</pre></div><div class="docs"><p>Given a destructuring of [[path1 path2...] the-simstate], paired
   with an expression, evaluates the expression under a lexical context
   where the path symbols are bound to corresponding get-path variants 
   as defined for simstate.</p>

<p>THis is less useful now that we're in an entitystore...
might migrate away from this, treat it as a code smell
possibly.</p>
</div><div class="codes"><pre class="brush: clojure">(defmacro with-simstate 
  [[path-symbs state]  &amp; expr]
  (let [symb-&gt;path {'parameters    get-parameters
                    'supplystore   get-supplystore
                    'demandstore   get-demandstore
                    'behaviors     get-behaviors
                    'policystore   get-policystore
                    'fillstore     get-fillstore
                    'fill-function get-fill-function
                    }]
    `(let [~@(reduce (fn [acc [p v]]
                       (-&gt; acc (conj p) (conj v)))
                     []
                     (for [p path-symbs]
                       [p (if-let [res (get symb-&gt;path p)] 
                            `(~res ~state)                                   
                            (throw (Exception. (str &quot;Unknown path &quot; p))))]))]
       ~@expr)))</pre></div><div class="docs"><h1>Protocols</h1>

<p>Alias for entity protocol.  Helps us unify name access.</p>
</div><div class="codes"></div><div class="docs"><p>(defn entity-name [x] (get x :name))</p>
</div><div class="codes"></div><div class="docs"><h1>Operations for working with mutable references</h1>

<p>particularly working with pieces of state in a nested associative
structure.</p>
</div><div class="codes"></div><div class="docs"><p>Imports from spork.util.cellular and simcontext</p>
</div><div class="codes"><pre class="brush: clojure">(util/import-vars
 [spork.util.inspection
  tree-view]
 [spork.util.cellular
  with-cells
  with-transient-cells
  swap-cell!
  reset-cell!
  -&gt;cell]
 [spork.entitysystem.store
  entity-name]
 [spork.sim.simcontext ;minimal amount of stuff pulled in..
  merge-updates
  merge-entity
  get-time])</pre></div><div class="docs"><p>probably deprecate in near future.</p>
</div><div class="codes"><pre class="brush: clojure">(defmacro -&gt;msg
   ([t msg]              `(sim/-&gt;packet ~t :message (:from ~msg) (:to ~msg) ~msg))
   ([from to t msg]      `(sim/-&gt;packet ~t :message ~from ~to ~msg nil))
   ([from to t msg data] `(sim/-&gt;packet ~t :message ~from ~to ~msg ~data)))</pre></div><div class="docs"><p>all we need to do is create  a behavior context,
eval the behavior, and store the entity in the
evaluated context.
need to push this into simcontext...
Message handling is equivalent to stepping the entity
immediately.</p>
</div><div class="codes"><pre class="brush: clojure">(defn handle-message! [ctx e msg]  
  ;(println [:handling (:name e) msg])
  (b/step-entity! ctx e msg))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn set-parameter    [s p v] (assoce  s :parameters p v))
(defn merge-parameters [s ps]  (mergee  s :parameters  ps))</pre></div><div class="docs"><p>Operations for recording new units in the context.
We now just merge the new entity into the context; no need to
mess with the supplystore.  We may also get away with only
merging things that actually changed.</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-unit
  ([u ctx]   (mergee ctx (:name u) u)) 
  ([u s ctx] (mergee ctx (:name u) u)))</pre></div><div class="docs"><h1>Empty Simulation Contexts</h1>

<p>altered.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def emptystate    (simstate/-&gt;store)) ;;now using ces</pre></div><div class="docs"><p>now using ces
Testing purposes...
temporary testing purposes...</p>
</div><div class="codes"></div><div class="docs"><p>we could make emptysim dynamic...</p>
</div><div class="codes"><pre class="brush: clojure">(def emptysim   (sim/add-time 0 (sim/make-context :state emptystate)))</pre></div><div class="docs"><p>A useful debugging context for us.  Prints out everything it sees.</p>
</div><div class="codes"><pre class="brush: clojure">(def ^:dynamic *debug*   nil)
(def ^:dynamic *verbose* nil)
(def ^:dynamic *ignored* #{})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro debugging [&amp; expr]
  `(binding [~'marathon.ces.core/*debug* true]
     ~@expr))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro debugging! [&amp; expr]
  `(binding [~'marathon.ces.core/*debug* true
             ~'spork.ai.core/*debug* true]
     ~@expr))
(defmacro debug-entity [name &amp; expr]
  `(binding [~'marathon.ces.basebehavior/*observed* ~name]
    ~@expr))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro ignoring [es &amp; expr]
  `(binding [~'marathon.ces.core/*ignored*  (into ~'marathon.ces.core/*ignored* ~es)]
     ~@expr))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro noisy 
  ([es  expr]
     `(debugging 
       (ignoring ~es ~expr)))
  ([expr] `(debugging ~expr)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visible? [edata] 
  (and *debug*
     (not (*ignored* (spork.sim.data/event-type edata)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def ^:dynamic *event-filter* visible?)
(defmacro with-event-filter [f &amp; expr]
  `(binding [~'marathon.ces.core/*event-filter* ~f]
     ~@expr))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn debug-listener  [ctx edata name] 
  (do  (when (*event-filter* edata)
         (println (if *verbose* 
                    (sim/debug-msg  &quot;:debugger saw &quot; 
                                    {:type (spork.sim.data/event-type  edata) 
                                     :from (spork.sim.data/event-from edata)
                                     :to   (spork.sim.data/event-to edata)
                                     :msg  (sim/packet-message edata)
                                     :data (spork.sim.data/event-data  edata)})
                    (sim/debug-msg (sim/packet-message edata)))))
       ctx))</pre></div><div class="docs"><p>Note:
This is the primary simulation context we use from marathon.analysis,
particularly when we generate marathon-streams or histories.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def debugsim   
  (-&gt;&gt; (-&gt; (sim/make-debug-context 
            :debug-handler  
            debug-listener)
           (assoc :state emptystate))
       (sim/add-time 0)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn debug! [ctx] 
  (if (contains?  (spork.sim.pure.network/get-event-clients ctx :all)
                  :debugger)
    ctx
    (sim/add-listener :debugger debug-listener [:all] ctx)))</pre></div><div class="docs"><h1>State-wide queries...</h1>

<p>tbd</p>
</div><div class="codes"><pre class="brush: clojure">(defn features [ctx &amp; {:keys [where] :or {where identity}}]
  [:simstate
   (for [[nm obj] (seq (:state ctx))
         :when (where nm)]
     [nm (if (map? obj) (keys obj) obj)])])</pre></div><div class="docs"><p>TODO# port this over into the API in spork.sim</p>
</div><div class="codes"><pre class="brush: clojure">(defn events [ctx]   (spork.sim.data/event-seq ctx))
(defn times [ctx] (map :time (events ctx)))
(defn segments [ctx] 
  (-&gt;&gt; (partition 2 1 (events ctx))
       (map (fn [[l r]]
              [(assoc l :duration (- (:time r) (:time l)))
               r]))
       (map first)
       (map (fn [r] (if (:duration r) r (assoc r :duration 1))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn rvals [kvs]
  (reify
    clojure.lang.Counted 
    (count [this] (count kvs))
    clojure.lang.Seqable 
    (seq [this] (seq kvs))
    clojure.core.protocols/CollReduce
    (coll-reduce [this f1]
      (reduce-kv (fn [acc k v] (f1 acc v)) (f1) kvs))
    (coll-reduce [_ f1 init]
      (reduce-kv (fn [acc k v] (f1 acc v)) init kvs))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn rkeys [kvs]
  (reify
    clojure.lang.Counted 
    (count [this] (count kvs))
    clojure.lang.Seqable 
    (seq [this] (seq kvs))
    clojure.core.protocols/CollReduce
    (coll-reduce [this f1]
      (reduce-kv (fn [acc k v] (f1 acc k)) (f1) kvs))
    (coll-reduce [_ f1 init]
      (reduce-kv (fn [acc k v] (f1 acc k)) init kvs))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn collect [fs xs]  
  (let [f (if (coll? fs) (apply juxt fs) fs)]
    (map f xs)))</pre></div><div class="docs"><h1>Ephemeral Data</h1>

<p>Typically used for storing append-only daily logging
information.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-ephemeral
  ([ctx id component default]
   (if-let [state (store/gete ctx id component)]
     [ctx state]
     (let [atm (atom default)
           ctx (store/assoce ctx id component atm)]
       [ctx atm])))
  ([ctx id component] (get-ephemeral ctx id component (transient []))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn conj-ephemeral [ctx id component v]
  (let [[ctx state] (get-ephemeral ctx id component)]
    (swap! state conj! v)
    ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn reset-ephemeral [ctx id component v]
  (let [[ctx state] (get-ephemeral ctx id component)]
    (reset! state v)
    ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn swap-ephemeral [ctx id component f]
  (let [[ctx state] (get-ephemeral ctx id component)]
    (swap! state f)
    ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn some-ephemeral [ctx id component]
  (when-let [atm (store/gete ctx id component)]    
    (when (pos? (count @atm)) atm)))</pre></div><div class="docs"><p>Acts like juxt, except it returns the results in a map.
The map is implied by the args in kvps, where simple keys - numbers,
strings, keywords, are assumed to be field names. A map is built 
from the fields by getting the corresponding field in an input
record.  Vector keys are assumed to imply [key function-to-apply]</p>
</div><div class="codes"><pre class="brush: clojure">(defn juxtmap [&amp; ks]
  (let [fs  (reduce (fn [acc x]
              (cond (or  (keyword? x)  (string? x) (number? x))   (assoc acc x #(get % x))
                    (vector? x)  
                      (let [fld (first x) 
                            getter (second x)]
                        (assoc acc fld 
                          (cond (fn? getter) getter 
                                (or  (keyword? getter)  (string? getter) (number? getter))   
                                 #(get % getter)
                                :else (throw (Exception. (str &quot;unknown juxt-map getter &quot; getter))))))
                      :else (throw (Exception. (str &quot;unknown juxt-map arg &quot; x)))))
                   {} ks)]
    (fn [x] 
      (reduce-kv (fn [m fld f] (assoc m fld (f x))) {} fs))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro fields [xs]
  (cond (map? xs)
        `(marathon.sim.core/juxtmap ~@(:fields xs))
        (vector? xs) 
        `(juxt ~@xs)))</pre></div><div class="docs"><p>TODO maybe make this a reducer....dunno yet.</p>
</div><div class="codes"><pre class="brush: clojure">(defn collectr [fs xs]  
  (let [f (if (coll? fs) (apply juxt fs) fs)]
    (reify     
      clojure.core.protocols/CollReduce
      (coll-reduce [this f1]   (reduce f1 (f1) (r/map f xs)))        
      (coll-reduce [_ f1 init] (reduce f1 init (r/map f xs)))
      clojure.lang.Seqable 
      (seq [this]  (seq (map f xs))))))</pre></div><div class="docs"><p>legacy api, just using CES now.
(defmacro entities [ctx] `(entity-seq ~ctx))</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn demands-&gt;track [xs] 
  ;(sketch/-&gt;track (map (fn [r] (merge r {:start (:startday r)})) xs) :track-name name))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn demand-&gt;tracks  
  [xs &amp; {:keys [keyf] :or {keyf (juxt :demandgroup :src)}}]
  (for [[g xs] (group-by keyf xs)]
    [g (map (fn [r] (merge r {:start (:startday r)})) xs)]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-events [es track-keyf color-keyf]  
;;   (let [coloring (zipmap (map color-keyf es) (take (count es) (sketch/palette)))
;;         tracks   (demand-&gt;tracks es :keyf track-keyf)
;;         rendered-tracks (sketch/-&gt;tracks tracks)
;;         track-width     (:width (spork.graphics2d.canvas/shape-bounds rendered-tracks))
;; ;        lgnd     (sketch/-&gt;legend coloring)
;; ;        lwidth   (:width (spork.graphics2d.canvas/shape-bounds lgnd))
;;         ]
;;     (sketch/with-event-&gt;color (fn [e] (get coloring (color-keyf e)))
;;       (sketch/sketch-image
;;        (sketch/scale 1.0 1.5
;;                      (sketch/stack [(sketch/-&gt;tracks tracks)
;;                                    ; (sketch/translate 10 5 
;;                                    ;    (sketch/scale (float (/ track-width lwidth)) 2.0
;;                                    ;      lgnd))
;;                                     ]))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-demands [ctx  &amp; {:keys [track-keyf color-keyf] :or {track-keyf (juxt :demandgroup :src)
                                                                    color-keyf (juxt :vignette)}}]
  (visualize-events (vals (demands ctx)) track-keyf color-keyf))</pre></div><div class="docs"><p>This is going to be a little brittle; should access to updates
behind a protocol...</p>
</div><div class="codes"><pre class="brush: clojure">(defn updates [ctx] 
  (for [[ks xs] (-&gt; ctx :updater :updates)
        [ts  us]  xs
        [nm pckt] us]
    pckt))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn update-events [ctx] 
  (map (fn [{:keys [update-time request-time] :as r}]
         (assoc r :startday request-time :duration (- update-time request-time)))
       (updates ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-updates [ctx  &amp; {:keys [track-keyf color-keyf] :or {track-keyf (juxt :requested-by)
                                                                    color-keyf (juxt :update-type)}}]
  (visualize-events (update-events ctx) track-keyf color-keyf))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-supply [ctx]
  (-&gt;&gt; (units ctx)
       (map (fn [u] (update-in u [:policy] :name)))
       (spork.util.table/records-&gt;table)
       (spork.util.table/visualize)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-fillmap [ctx]
  (if-let [fm (:fillmap (get-fillstore ctx))]
    (-&gt;&gt; (for [[parent children] fm
               [child cost] children]
           {:donor parent :recepient child :cost cost})
         (spork.util.table/records-&gt;table)
         (spork.util.table/select :fields [:donor :recepient :cost] :from)
         (spork.util.table/visualize))
    (throw (Exception. &quot;No fill map to visualize!&quot;))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-graph [g]
  (jung/view-graph g jung/fr))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-fillgraph [ctx]
  (if-let [fg (:fillgraph (get-fillstore ctx))]
    (visualize-graph fg)
    (throw (Exception. &quot;No fillgraph to visualize!&quot;))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-store [ctx]
  (tree-view  (store/domains ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-data [ctx]
  (tree-view ctx))</pre></div><div class="docs"><p>Short queries...we should move these away from being a map for
entities, and into sets. Set access is actually faster than
maps, so bonus.</p>
</div><div class="codes"><pre class="brush: clojure">(defn demand-names    [ctx] (keys (gete ctx :DemandStore :demandmap)))
(defn unit-names      [ctx] (keys (gete ctx :SupplyStore :unitmap)))
(defn unit-entities   [s]   (store/get-domain s :unit-entity))
(defn demand-entities [s]   (store/get-domain s :DemandType))</pre></div><div class="docs"><p>Fetch the entity with it's current time interpolated as a :dt component.
   We use this to perform lightweight updates, particularly for computing <br />
   accumulated stats, so that we can interpolate statistics for things like 
   fill criteria.  Rather than invoke the machinery to update every entity, 
   we save time doing lightweight updates as a function of the computed 
   :dt component.</p>
</div><div class="codes"><pre class="brush: clojure">(defn current-entity
  ([ctx nm t]
   (let [e  (store/get-entity ctx nm)
         dt (- t (get e :last-update 0))]
     (assoc e :dt dt)))
  ([ctx nm] (current-entity ctx nm (sim/current-time ctx))))</pre></div><div class="docs"><p>fetch units with appended :dt information for
potential synchronization purposes.</p>
</div><div class="codes"><pre class="brush: clojure">(defn current-units
  ([ctx t]
    (for [id  (keys (:unitmap   (get-supplystore ctx)))]
      (current-entity ctx id t)))
  ([ctx] (current-units ctx (sim/current-time ctx))))</pre></div><div class="docs"><p>this is actually using our new positional stuff.
we need to map deployed-trend to risk....
I think we just want to use demand-trends...
demand-changes gets us the units...
we also need to compute the peak demand.</p>
</div><div class="codes"><pre class="brush: clojure">(defn all-demands [store]
  (store/select-entities store :from [:startday :duration :quantity :DemandType]))</pre></div><div class="docs"><p>not sure about this, we may want to break out by trends...
We'll see what use case pops up for this type of query.</p>
</div><div class="codes"><pre class="brush: clojure">(defn demand-profile [store]
  (-&gt;&gt; (temp/activity-profile 
        (all-demands store)
        :start-func :startday :duration-func :duration)
       (map (fn [[t {:keys [actives]}]]
              [t (reduce + 0 (map :quantity actives))]))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn peak-demand [store]
  (-&gt;&gt; (temp/peak-activities
        (all-demands store)
        :start-func :startday :duration-func :duration
        :peak-function (fn [{:keys [actives]}]
                         (reduce + 0 (map :quantity actives))))
       (first)
       (val)
       (:actives)
       (map :quantity)
       (reduce + 0)))</pre></div><div class="docs"><p>This is fairly close....</p>
</div><div class="codes"><pre class="brush: clojure">(defn visualize-entities [ctx]
  (let [demandnames    (demand-names ctx)
        unitnames      (unit-names   ctx)
        disabled       (keys (store/get-domain ctx :disabled))
        basic-entities (set  (concat demandnames unitnames disabled))
        stores         (clojure.set/difference
                        (set  (keys (store/entities ctx)))
                        basic-entities)
        named-entry (fn [e]
                      (if (instance? clojure.lang.MapEntry e) (inspect/entryvis e)
                          (inspect/entryvis (clojure.lang.MapEntry. (or (:name e)
                                                                        (store/entity-name e)) e))))]         
    (inspect/tree-view
       {:stores  (map (comp inspect/entryvis named-entry)  (sort-by :name inspect/generic-comp (store/get-entities ctx stores)))
        :demands (map (comp inspect/entryvis named-entry)  (sort-by :name inspect/generic-comp (store/get-entities ctx demandnames)))
        :units   (map (comp inspect/entryvis named-entry)  (sort-by :name inspect/generic-comp (store/get-entities ctx unitnames)))
        :disabled (map (comp inspect/entryvis named-entry)  (sort-by :name inspect/generic-comp (store/get-entities ctx disabled))) })))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn visualize-subscriptions [ctx] 
  (inspect/tree-view (:subscriptions (get-policystore ctx))))</pre></div><div class="docs"><p>TODO# define a visualization protocol, extend it to core datatypes...</p>
</div><div class="codes"><pre class="brush: clojure">(defn visualize-unit [u]   (inspect/tree-view u))    
(defn visualize-policy [p] (jung/view-graph (:positiongraph p) jung/fr))</pre></div><div class="docs"><h1>Shared Functions</h1>
</div><div class="codes"></div><div class="docs"><p>These functions were extracted due to use across multiple domains.  I may 
refactor them into core services, but for now, relocating them in sim.core 
allows every system access to them.</p>
</div><div class="codes"></div><div class="docs"><p>Consult the system clock for the current time.  Used for logging.</p>
</div><div class="codes"><pre class="brush: clojure">(defn now
  [] 
  (System/currentTimeMillis))</pre></div><div class="docs"><p>Tom hack 26 MAy 2016
We discriminate between known or canonical buckets, and
ad-hoc buckets (buckets that are created as ephemeral supply
for followon-demands.  In contrast, we will likely always have
:default and :SRM categories of supply, i.e. they never go away.</p>
</div><div class="codes"><pre class="brush: clojure">(def known-buckets #{:default :SRM &quot;SRM&quot;})</pre></div><div class="docs"><p>PERFORMANCE NOTE: This is on the HotSpot, Apparently....
maybe just clojure 1.7, but we're creating a keyseq for clojure.core/keys,
which is exploiting this hotspot.  Should be way faster.  we'll use
reduce-kv to alleviate it....</p>
</div><div class="codes"></div><div class="docs"><p>Returns a sequence of followon codes that are currently present in the 
   supply.  Used for constraining or preferring supply during the followon 
   fill phase.</p>

<p>The name here is a bit generic.  We're really trying to acquire the keys of 
a map that contains information about followon-eligible supply.  In this 
context, the keys are actually the followon-code of the unit, (typically a
demandgroup). </p>
</div><div class="codes"><pre class="brush: clojure">(defn get-followon-keys
  [ctx]
  (let [m  (reduce-kv (fn [acc k _]
                        (if-not (known-buckets k) (conj! acc k) acc)) (transient #{})
                        (store/gete ctx :SupplyStore :deployable-buckets))]
    (when (pos? (count m)) (persistent! m))))</pre></div><div class="docs"><p>Returns a sequence of followon codes that are currently present in the 
   supply.  Used for constraining or preferring supply during the followon 
   fill phase.</p>
</div><div class="codes"><pre class="brush: clojure">(comment ;old
(defn get-followon-keys
  [ctx]
  (let [m (into #{} (filter (complement known-buckets)) (keys (store/gete ctx :SupplyStore :deployable-buckets)))]
    (when (pos? (count m)) m))))</pre></div><div class="docs"><p>Associates unit u into the context's supply store, using the unit's name 
   as a key.</p>

<p>Check the validity here...
Do we need so much redundancy now?</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-unit
  [u ctx]                    
  (set-unit u ctx)  )</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ghost? [unit] (= (clojure.string/upper-case (:src unit)) &quot;GHOST&quot;))
(defn followon? [u] (:followoncode u))
(defn ghost-followon? [u] (and (ghost? u) (followon? u)))</pre></div><div class="docs"><h1>TODO get this working like it used to, right now it's not important.</h1>

<p>(defn interval->date  [t ctx]
  (let [ps (get-parameters ctx)
        start-date (get ps :StartDate)
        time-scale (get ps :time-scale 1)] 
    (+ start-date (* time-scale t))))</p>
</div><div class="codes"></div><div class="docs"><p>interval->date is a simple stub, maybe unnecessary (although I like
having it around for records in the output)</p>
</div><div class="codes"><pre class="brush: clojure">(defn interval-&gt;date  [t ctx]  t)</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn in-scope? [params src]
  (and (not (get-in params [:SRCs-Out-Of-Scope src]))
       (get-in params [:SRCs-In-Scope src])))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn scope-info [ctx]
  {:in-scope     (get (get-parameters ctx) :SRCs-In-Scope)
   :out-of-scope (get (get-parameters ctx) :SRCs-Out-Of-Scope)})</pre></div><div class="docs"><h1>Tag Related Functions</h1>

<p>Another useful bit of higher order, or meta data, is the notion of simple 
tags.  We use tags as a simple mechanism to track all kinds of effects and 
information, without having to embed data in lower classes.  This way, when
an entity - or even a system - needs to be grouped or categorized we can 
use tags.  As a result, we see a lot of shared tags that represent common 
effects, like whether an entity is enabled or disabled.</p>
</div><div class="codes"></div><div class="docs"><p>Generic tag-related....These apply equally to supplystore, demandstore, etc.
The interface is identical.  Only the interpretation of the tags is different.</p>
</div><div class="codes"><pre class="brush: clojure">(defn enabled? [store item]
  (tag/has-tag? (:tags store) :enabled item))
(defn disabled? [store item] (not (enabled? store item)))
(defn enable [store item]
  (update-in store [:tags] tag/tag-subject :enabled item))
(defn disable [store item]
  (update-in store [:tags] tag/untag-subject :enabled item))
(defn special-src? [tags src] (when tags (tag/has-tag? tags src &quot;Special&quot;)))</pre></div><div class="docs"><h1>Fill Related Functions</h1>
</div><div class="codes"></div><div class="docs"><p>find-eligible-demands is implemented as multimethod that dispatches based on 
type of the category that's passed in.  category-type provides a simple 
dispatch mechanism.  Note-> could use built-in hierarchy functions to do this.</p>
</div><div class="codes"><pre class="brush: clojure">(defn category-type [x]
  (cond (or (keyword? x) (string? x))  :simple            
        (vector? x) :src-and-group 
        (map? x)    :rule-map
        :else (throw (Exception. &quot;Unknown category type &quot; (type x)))))</pre></div><div class="docs"><h1>Utility Functions and Macros</h1>
</div><div class="codes"></div><div class="docs"><p>A collection of shared functions, might turn into protocols someday...
This should contain only core functionality shared across subsystems defined 
in other namespaces, to eliminate redunancy.
I started this due to the fact that several functions - primarily accessors, 
were bubbling up in each of the domain-specific modules.  As a result, we'll 
just shove them in here.  If we don't, we'll get circular dependencies.</p>
</div><div class="codes"></div><div class="docs"><p>We alias the more efficient make-string function, rather than 
using core/str.  This is commonly used for logging messages 
and other things.  Since there are lots of events flying 
around with string data, this is a serious bottleneck.</p>
</div><div class="codes"><pre class="brush: clojure">(def msg gen/make-string)</pre></div><div class="docs"><p>Stubs were used during the initial port to toss exceptions if an unimplemented
or deferred function was called.  </p>
</div><div class="codes"><pre class="brush: clojure">(defmacro stub [msg &amp; empty-body]  
  `(~'fn ~'[&amp; args] (~'throw (~'Exception. ~msg))))</pre></div><div class="docs"><p>This is a general utility function, that allows us to derive predicates based
on atomic values, sets, or maps.  Used for filtering (currently in demand 
categories and supply categories).
Can probably extend this to allow for arbitrary predicate functions (later).</p>
</div><div class="codes"><pre class="brush: clojure">(defn make-member-pred [g]
  (if (or (set? g) (map? g))
    #(contains? g %)
    #(= g %)))</pre></div><div class="docs"><p>If function results in an empty map, contained within another map, 
removes the entry associated with the empty map.</p>
</div><div class="codes"><pre class="brush: clojure">(defn prune-in [m ks f &amp; args]
  (let [updated (apply update-in ks f args)]
    (if (empty? (get-in updated ks))
      (let [path   (butlast ks)
            parent (get-in m path)]            
        (assoc-in m path (dissoc parent (last ks))))
      updated)))</pre></div><div class="docs"><p>Predicate for determining if a map has a key equal to a val.</p>
</div><div class="codes"><pre class="brush: clojure">(defn key= [k v] (fn [m] (= (get m k) v)))</pre></div><div class="docs"><p>Creates a little keyword factory that allows to to define descriptive 
   tags using keywords efficiently and consistently.</p>

<h1>TODO evaluate memoize here and see if we're paying a useless</h1>

<p>penalty.</p>
</div><div class="codes"><pre class="brush: clojure">(defn key-tag-maker
  [base] (gen/memo-1
          (fn [tag] (keyword (str base tag)))))</pre></div><div class="docs"><p>helper macro for defining key-building functions.</p>
</div><div class="codes"><pre class="brush: clojure">(defmacro defkey [name base] `(def ~name (key-tag-maker ~base)))</pre></div><div class="docs"><p>We tend to prefer unique names, and often times we accomplish that by concatenating the 
   count of a container onto a non-unique name.  ensure-names generalizes this stuff.</p>

<h1>Utils</h1>
</div><div class="codes"><pre class="brush: clojure">(defn ensure-name
  [named names]                  
  (let [nm (entity-name named)]
    (if (contains? names nm)
      (assoc named :name 
             (msg nm &quot;_&quot; (count names)))
    named)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(definline empty-string? [x] `(= ~x ))
(defn debug-print [msg obj] (do (println msg) obj))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn as-records [record-source]
  (if (and (seq? record-source) (map? (first record-source))) record-source      
      (tbl/record-seq record-source)))</pre></div><div class="docs"><p>Utility function for getting incrementing indices.  Used for 
     naming entities.  Passing an argument resets the index to the arg,
     and returns the arg.  Otherwise, a mutable counter is incremented 
     and the result is returned.</p>
</div><div class="codes"><pre class="brush: clojure">(let [idx (atom 0)]
  (defn next-idx 
    ([] (let [i @idx]
          (do (swap! idx unchecked-inc)
              i)))
    ([new-idx] (do (reset! idx new-idx)
                   new-idx))))</pre></div><div class="docs"><p>Imported from spork.util.general</p>
</div><div class="codes"><pre class="brush: clojure">(util/import-vars 
 [spork.util.general  
  deep-assoc
  deep-get
  deep-update 
  deep-dissoc])</pre></div><div class="docs"><p>TODO de-duplicate this from marathon.data.protocols
look into replacing this with a universal constant, or upperbound
for longs</p>
</div><div class="codes"><pre class="brush: clojure">(def ^:constant +inf+ 9999999)</pre></div><div class="docs"><h1>Wrapper around spork.simcontext</h1>

<p>As it stands, update requests aren't events...
They're disconnected...since the updater is handling the event
separately...
Maybe we can clear that up at some point....</p>
</div><div class="codes"><pre class="brush: clojure">(defn request-update [tupdate requested-by request-type ctx]
  (-&gt;&gt; ctx
       (sim/request-update tupdate requested-by request-type)
       ;(sim/trigger-event request-type requested-by :update-manager 
       ;                   (msg requested-by &quot; requested an &quot; request-type &quot; at &quot; tupdate) nil)))</pre></div><div class="docs"><p>Note/TODO: Probable Performance Enhancement for generating events.
We call sim/trigger-event quite a bit from the manager libraries.
We basically have a call to build strings when we trigger events.
If we aren't debugging or capturing output...we can just as easily
skip firing off the event.
So, events only matter if we want them to, thus we only pay the
cost if we want to...
We can make this a semi-dynamic call to sim/trigger-event
using a macro.
What we'd really like to do is....if there's no listener...
we preclude the event from happening...
We can probably save a shitload of time going this route.
Alternately, we can write a macro to rip out messages...
eliminate all the string building.
Something like...</p>
</div><div class="codes"></div><div class="docs"><p>Macro optimization to allow messages to be stripped out 
   if the context is not actively messaging (i.e. debugging).
   This is a nifty cheat, since we avoid allocation for 
   strings entirely. Behaves as a replacement for <br />
   spork.sim.context/trigger-event , while restricting 
   certain argument combinations, i.e. non-variadic.</p>

<p>Before: 6  </p>
</div><div class="codes"><pre class="brush: clojure">(defmacro trigger-event
  ([id from to msg-form data ctx] ;;changce to strip message.
   `(let [msg# (when ~'marathon.ces.core/*debug* ~msg-form)]  
      (sim/trigger-event ~id ~from ~to  msg# ~data ~ctx)))
  ([e ctx] ;event is already baked.
   (sim/trigger-event ~e ~ctx)))</pre></div><div class="docs"><h2>Developer Notes</h2>
</div><div class="codes"></div><div class="docs"><h1>Transitioning from Effectful Simulation and State Updating</h1>

<p>One problem area in the port from VBA->Clojure was the handling of 
decentralized state updates.  This primarily happened via event dispatch, or 
through side-effects called during management functions.  The solution for our
pure simulation is to formalize batch updates to the simulation by using 
simcontext/merge-updates.  This allows us to pass maps of updates around, and 
the updates are merged with the simulation state in a predefined manner. <br />
We may wish to formalize this as a language feature (i.e. macro) to define 
different types of update.</p>
</div><div class="codes"></div><div class="docs"><h1>Conventions for Notifications/Events/Messaging Functions</h1>

<p>Message functions are suffixed by the ! character, by convention, to denote 
the possibility of side effects. The function signatures are pure, in that 
they return a context.  The naming convention will help identify when 
"messaging" is occuring.  While effects may happen, in the form of logging 
or display updating, the internal simulation mechanics are still pure.
<strong>TODO</strong> -> implement defmessage macro....</p>
</div><div class="codes"></div><div class="docs"><h1>Cries for Better Abstractions</h1>

<p>Note--> I'm noticing some patterns emerging that might make for nice 
abstractions...
We seem to be doing a lot of nested updates for particular bits of a system.
A lot of updates also appear to be existential in nature, i.e. if the 
update is a dissoc, and the resulting collection is empty, we want to 
remove the empty entry from the parent container.</p>
</div><div class="codes"></div><div class="docs"><p>Also, we have a class of functions that specifically shovels context around.
By context, I mean the environment in which the simulation is happening, as 
in a simcontext from sim.simcontext.  We can clean up some of the function 
signatures by allowing macros to operate in this context, possibly even a 
special evaluator.</p>
</div><div class="codes"></div><div class="docs"><p>On the topic of special evaluators, in each namespace, we end up defining 
pure functions that act to update specific bits of a context, sometimes 
acting on isolated structures within the context.  There's typically a 
nested structure in the context's :state, which destructure and update in 
pieces.  It might be nice to have something like #'doto. </p>
</div><div class="codes"></div><div class="docs"><p>It might be nice to have a macro that lets us define ways to address or query
the context's state.  This leads directly to the entity-store stuff I already 
built, and facilitates a component-based architecture.</p>
</div><div class="codes"></div><div class="docs"><p>Finally, we probably want some kind of language for specifying different 
types of updates to the context.  For instance, we end up -inside the local 
namespaces - defining functions that operate on a specific area of the context
often with deep nesting paths.  I already introduced the notion of updates and
merge-updates in the simcontext.  It might be as simple as defining
multimethods, or a protocol, that implements the merge protocol.</p>
</div><div class="codes"></div><div class="docs"><p>what would a nice abstraction look like? 
adjust-max-utilization!, from marathon.sim.supply is a great candidate..
there are a couple of bread-n-butter items of interest...
1) we're updating a unit functionally, storing the result of the update, 
  a new unit
2) we're updating the supplystore, to reflect the updated unit from 1).
3) we're merging the new supplystore into the updated context, by 
  passing it to a generic "update" handler that knows how to interpret 
  the key :supplystore, the new supply, and a context, to transition to 
  a new context.
One improvement is to wrap the operation behind a function to provide a clean
API....namely, update-unit 
This would fetch the appropriate unit, apply a function to it (like update-in),
and return a new supplystore with the unit updated.
 In this sense, we're lifting a specific function, updating the policyq of 
 a unit, into the context of a container for units. 
 In haskell speak, the supplystore is a functor, we're applying an update to 
 an element of the container.  It's the container's job to understand how 
 to lift the updating function into the proper context, and return the new 
 container.  monads/monoids anyone? </p>
</div><div class="codes"></div><div class="docs"><h1>Policy Management Notes</h1>

<p>Policy changes were encapsulated in the IRotationPolicy implementations.
This assumed that units would change policies, regardless of event-context.
That's actually a decent assumption.
However, when we tell unitdata to change policy, it evokes a change state 
evaluation.
Under the decoupled architecture, this requires simulation context.</p>
</div><div class="codes"></div><div class="docs"><p>I'm going to have the policy ops define a function (really just adapted from 
policymanager), that passes the context needed.  This is in-line with other 
decoupled, functional representations.
I have to rewire the IRotationPolicy implementation.....specifically taking 
out the onperiodchange event handling.
Rather, we'll let policy ops take care of changing units' composite policies. <br />
The good news is, all the bits are here.  Just need to re-organize the code.</p>
</div><div class="codes"></div><div class="docs"><p>Is there a way we can create shallow maps?  For instance, if we're 
trying to update a nested map, and we don't want to make the whole 
thing transient, can we pass around a temporarily mutable version? </p>
</div><div class="codes"></div><div class="docs"><p>one idea here, is to have something that wraps the map and creates 
a map of transient info...
When we do reads, we use the transient, when we do writes, we 
use the transient.  Then, when we want to reify, 
we merge the transient with the original.  Ideally, this 
keeps the copy paths nice and small.</p>
</div><div class="codes"></div><div class="docs"><p>the simplest way is to have a mutable collection, i.e. 
a hashtable, with the values along the path.
Then for get-in and assoc-in, we can look at the 
path cache and see if the path exists there.  Then, we 
can apply the ops to the pathcache. </p>
</div><div class="codes"></div><div class="docs"><p>Operations optimized for speed.  the -in and friends 
are not sufficient...</p>
</div><div class="codes"></div><div class="docs"><p>&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;                                    >>>>>>>>>>>>>>>>>
This was an early idea to improve perf, but the side-effects are
causing simulation history to end up out-of-order...</p>
</div><div class="codes"></div><div class="docs"><p>Aborted Performance Optimization Tests
For now, we're putting row-store operations on hold.  Quite a bit of issues here...</p>
</div><div class="codes"></div><div class="docs"><h1>_(println [:<<<<<TODO :TEST-ROWSTORE 'marathon.ces.core/emptystate :TODO>>>>>])</h1>

<h1>_(def emptystate (simstate/->store :init-store store/empty-rowstore))</h1>
</div><div class="codes"></div><div class="docs"><p>Shitty hacks.
(defn row-state! []
  (do ;;Testing purposes...
      (throw (Exception. "Currently disabled due to changes row-store incurs against reproducibility."))
      (def emptystate    (simstate/->store :init-store spork.entitysystem.store/empty-rowstore))
       ;;temporary testing purposes...
       ;;we could make emptysim dynamic...
      (def emptysim   (sim/add-time 0 (sim/make-context :state emptystate)))
      (def debugsim <br />
        (->> (-> (sim/make-debug-context 
                  :debug-handler <br />
                  debug-listener)
                 (assoc :state emptystate))
             (sim/add-time 0)))))</p>
</div><div class="codes"></div><div class="docs"><p>(defn col-state! []
    (do ;;Testing purposes...
      (def emptystate    (simstate/->store :init-store spork.entitysystem.store/emptystore))
       ;;temporary testing purposes...
       ;;we could make emptysim dynamic...
      (def emptysim   (sim/add-time 0 (sim/make-context :state emptystate)))
      (def debugsim <br />
        (->> (-> (sim/make-debug-context 
                  :debug-handler <br />
                  debug-listener)
                 (assoc :state emptystate))
             (sim/add-time 0)))))</p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.engine" name="marathon.ces.engine"><h1 class="project-name">marathon.ces.engine</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><h2>Overview</h2>

<p>sim.engine contains the higher-level operations that define Marathon.  It acts 
as a harness around the simulation context, and guides the flow of control 
throughout the simulation.  At a high level of abstraction, the engine is a 
process that coordinates one or more concurrent processes to calculate 
new simulation contexts from prior simulation contexts. <br />
From a functional perspecive, the engine defines an ordered composition of 
simpler transfer functions - or systems - that, when applied to a initial
context, returns a new simulation context.  </p>
</div><div class="codes"></div><div class="docs"><p>When performed repeatedly, feeding preceding simulation contexts into
the transfer function, a recurrence relation between previous contexts and 
future contexts emerges.  The result is effectively a snapshot of simulation 
contexts, which are computed via a simple transfer function, <strong>sim-step</strong>, <br />
which simulates multiple domains relevant to Marathon: <br />
1. The flow of units through a supply <br />
2. The presence of demands <br />
3. The flow of units between supply and demand via fills.    </p>
</div><div class="codes"></div><div class="docs"><p>Thus, the engine serves as the causal backbone, and coordinating mechansim, 
for every bit of logic executed during the course of the simulation. The 
primary function, <strong>event-step-marathon</strong>, prescribes the order of application 
of each logical subsystem. </p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.engine
  (:require [marathon.ces.core   :as core :refer [now]]           
            [marathon.ces.supply :as supply :refer [manage-supply manage-followons update-all]]
            [marathon.ces.demand :as demand :refer [manage-demands]]
            [marathon.ces.fill.demand       :refer [fill-demands]]
            [marathon.ces.policy :as policy :refer [manage-policies]]
            [marathon.data [store :as simstate]]
            [marathon      [observers :as obs]]
            [spork.sim     [simcontext :as sim]]))</pre></div><div class="docs"><h1>Auxillary functions, and legacy functions</h1>
</div><div class="codes"></div><div class="docs"><h1>Auxillary functions from the old simstate module</h1>
</div><div class="codes"><pre class="brush: clojure">(defn guess-last-day 
  ([ctx lastday]
     (if-let [first-non-zero
              (first (filter #(and (not (nil? %)) (pos? %))
                             [lastday 
                              (-&gt; ctx :state :parameters :last-day)
                              (-&gt; ctx :state :parameters :last-day-default)]))]
       first-non-zero
       0))
  ([ctx] (guess-last-day ctx 0)))</pre></div><div class="docs"><p>Predicate to determine if we continue drawing time from the stream, i . e . simulating.
If an endtime is specified, we use that in our conditional logic, else we keep working until
no more eventful days are upon us.</p>
</div><div class="codes"></div><div class="docs"><p>This is costing us a lot of time in profiling.  Almost 1/3 of the simulation
runtime....function invocation is weak.
THis is a pretty weak port....</p>
</div><div class="codes"><pre class="brush: clojure">(defn keep-simulating? [ctx]
  (let [state (:state ctx)]
    (if (-&gt; state :truncat-time)
      (let [tlastdemand (-&gt; state :demandstore :tlastdeactivation)]        
        (if (&gt;= (sim/get-time ctx) tlastdemand)
          (if (neg? tlastdemand) 
            (throw (Error. &quot;No demands scheduled.  Latest deactivation never initialized!&quot;))
            (do (core/trigger-event :Terminate (:name state) (:name state) 
                                   (str &quot;Time &quot; (sim/current-time ctx) &quot;is past the last deactivation: &quot;
                                        tlastdemand &quot; in a truncated simulation, terminating!&quot;) nil ctx)
                false))
          true))
      (sim/has-time-remaining? ctx))))        </pre></div><div class="docs"><p>Initialize the start and stop time of the simulation context, based on 
   last-day.</p>

<h2>Simulation Initialization</h2>
</div><div class="codes"><pre class="brush: clojure">(defn set-time
  [last-day ctx]  
 (sim/set-time-horizon 1 (guess-last-day ctx last-day) ctx))</pre></div><div class="docs"><h1>Initialization</h1>

<p>Initialization consists of 3 tasks: <br />
1. Prep the system for day 0 <br />
2. Adjust the context so that it defines a finite time horizon for simulation.
  The last  day of the simulation is determined either by passing in value, 
  or by allowing the context to derive its own last day dynamically. <br />
3. Tell observers to sync themselves to the simulation state.  Some observers 
  need access to the specific elements of the state.  This makes it easy 
  (and indirect) to advertise the state, and to allow the observers to link 
  to it as needed. Observers/watchers will need to be expanded on, since 
  watches will involve effects.  </p>
</div><div class="codes"></div><div class="docs"><h1>Temporary Stubs</h1>

<p>Used to be entityfactory.start-state supplymanager
Intent is to apply initial conditions to the simulation state,
particularly moving unit entities to where they need to be.</p>
</div><div class="codes"><pre class="brush: clojure">(defn start-state [ctx]
  (do (println (str *ns*) &quot;start-state is a stub.  Should be setting entities to their starting states.&quot;)
      ctx))</pre></div><div class="docs"><p>Given an initial - presumably empty state - and an optional upper bound on 
   on the simulation time - lastday - returns a simulation context that is 
   prepared for processing, with default time horizons and any standard 
   preconditions applied.</p>
</div><div class="codes"><pre class="brush: clojure">(defn initialize-sim
  [ctx &amp; {:keys [lastday observer-routes]
          :or {observer-routes obs/default-routes}}]
  (-&gt;&gt; ctx
       (sim/register-routes observer-routes)
       (start-state)
       (set-time lastday)
       (supply/manage-supply   0)
       (policy/schedule-periods)
       (policy/manage-policies 0)))</pre></div><div class="docs"><h2>Simulation Termination Logic</h2>

<p>When we exit the simulation, we typically want to perform some final tasks.
For instance, any resources (for logging, display, etc.) may need to be freed.
The default mechanism for this is to propogate some events through the context
and let interested parties handle themselves appropriately.</p>
</div><div class="codes"></div><div class="docs"><p>Shifts the simulation period into a final period.  Forces sampling and any
   other cleanup actions, like computing final statistics, truncating unit 
   lifecycles, etc. Notify any other listeners that the simulation has 
   terminated.  Such notification is particularly important for observers that 
   may be stewarding resources.</p>

<p>Note-> I bolted on manage-policies before.  I think we can just move
that to a handler...manage-policies enters units into the final period.</p>
</div><div class="codes"><pre class="brush: clojure">(defn finalize
  [t ctx]
  (let [final-ctx  (-&gt; (manage-policies t ctx :final) ;;this just captures
                       ;;the final period in a period-driven update.
                       ;;really triggers an update-all-units action,
                       ;;relative to the final period.
                       (assoc-in [:state :parameters :work-state] :terminating) ;useless?
                       (assoc-in [:state :time-finish] (now)))]
    (core/trigger-event :Terminate :Engine :Engine &quot;Simulation OVER!&quot; nil final-ctx)))</pre></div><div class="docs"><h2>Begin Day Logic</h2>

<p>Prior to starting a new time inteval (currently a day), we typically want to 
perform some pre-processing or updating. </p>
</div><div class="codes"></div><div class="docs"><p>In an interactive simulation, like the legacy sim, this hook lets us check 
   for user intervention each active day.  DEPRECATED.</p>
</div><div class="codes"><pre class="brush: clojure">(defn day-msg [msg day]  (str &quot;&lt;-------- &quot; msg &quot; Day &quot; day &quot; ----------&gt;&quot;))
(defn check-pause
  [ctx] 
  (if (-&gt; ctx :state :pause)
     (core/trigger-event :pause-simulation :Engine :Engine 
                  &quot;Simulation Paused&quot; [(sim/get-time ctx) 
                                       (sim/get-next-time ctx)] ctx)
     ctx))</pre></div><div class="docs"><p>Update Logic for beginning a day.  Broadcasts the beginning of the current 
   day on the simulation context's event stream.  Also, if a GUI is involved, 
   notifies listeners whether a user has paused the simulation.</p>

<p><em>Note</em>: in <em>begin-day</em>, check-pause is incidental to the ui, not the repl. 
The call should be yanked.</p>
</div><div class="codes"><pre class="brush: clojure">(defn begin-day
  [day ctx]
  (-&gt;&gt; ctx
    (core/trigger-event :begin-day :Engine :Engine
                       (day-msg &quot;Begin&quot; day) [day (sim/get-next-time ctx)
                                              ])))  </pre></div><div class="docs"><h2>End Day Logic</h2>

<p>At the end of each "day" or discrete time step, we typically mark the passage 
of time with some processing.  This notion could be abstracted into a higher 
order function to wrap the simulation, along with the aforementioned begin-day
logic.  The default behavior is to trigger a sampling event, to record daily 
samples, and to broadcast the end-of-day to interested parties.</p>
</div><div class="codes"></div><div class="docs"><p>Logs the passing of the day, notifies listeners of a need to generate samples
   for the day, and possibly truncates the simulation early if criteria have 
   been met.</p>
</div><div class="codes"><pre class="brush: clojure">(defn end-day
  [day ctx]
  (-&gt;&gt; ctx 
    (core/trigger-event :log-status :Engine :Engine 
       (str &quot;Processed day &quot; day &quot; of &quot; (sim/get-final-time ctx) &quot; of Simulation&quot;) nil)
    (core/trigger-event :sample :Engine :Engine &quot;Sampling&quot; nil)
    (core/trigger-event :end-of-day :Engine :Engine (day-msg &quot;End&quot; day) nil)))</pre></div><div class="docs"><p>Simple predicate to ensure we have supply and demand in 
   the simulation state.  If we don't, we currently toss an 
   error.</p>
</div><div class="codes"><pre class="brush: clojure">(defn can-simulate? 
  [ctx] 
  (let [dem  (core/get-demandstore ctx)
        supp (core/get-supplystore ctx)]
    (and 
     (supply/can-simulate? supp)
     (demand/can-simulate? dem))))</pre></div><div class="docs"><h2>Primary Simulation Logic</h2>

<p>We enter the main engine of the Marathon simulation, which implements a 
single-threaded, discrete event simulation by default.</p>
</div><div class="codes"></div><div class="docs"><p>The simulation is technically a discrete event simulation, although it's 
relatively "coarse-grained" in that, rather than having a ton of fine-grained 
events on the queue, we only really enqueue "eventful" times.  The simulation
step function is written as a high-level process, that is intended to be 
invoked on every eventful day (every time on the simulation context's agenda).
We primarily use the event system to communicate changes, and to notify 
- potentially effectful - observers that could be logging, updating displays,
or doing other things.  Internal simulation workings are handled in a fairly 
bulk or batch manner by the coarse functions that comprise the step function.</p>
</div><div class="codes"></div><div class="docs"><p>The end result is that control flow is fairly simple: we only really have 
pending "times" to evaluate the step function against, rather than a slew of 
smallish events to trace.  In a sense, it is very similar to the "game loop" 
or simulation loop of time-step simulations, except for the ability to vary the
time intervals.  Also, we retain the flexibility to push more fine-grained 
events onto the queue if we need to.  It's the best of both worlds.  </p>
</div><div class="codes"></div><div class="docs"><p>We want to ensure that there is an enabled supply and /or 
demand that will actually provide some meaningful simulation output.  If not, 
we should warn the user about missing data leading to the absence of "stuff"
to simulate.</p>
</div><div class="codes"></div><div class="docs"><h1>State Transition Function</h1>

<p>We simulate each eventful day using a composition of simulation systems in 
Marathon.  Each system acts in turn, computing updates to pieces of the overall
simulation state.  Some systems communicate with eachother via events. <br />
All systems have access to the entire simulation context, including the event 
queue, for communication purposes.</p>
</div><div class="codes"></div><div class="docs"><p>Primary state transition function for Marathon.  Threads the next day and
   an initial state through a series of transfer functions that address 
   high-level state transfers for supply, policy, demand, filling, and more. 
   Computes the resulting state - either the final state, or the initial state
   for the next step.</p>

<p>In one sense, this defines higher-order behavior for a simulation
entity....
It handles steps by trying to achieve each of the steps in turn,
as with a [seq] behavior.  Another, less-structured way of looking
at this is that we are trying to get the system into a consistent
state by the end of the day.  In order to achieve consistency,
we can have no further pending events for the day.  So, distributing
the responsibilities by system is perhaps less meaningful if we're using
a kind of actor context.  One way we could partition these responsibilities
is to have each store implement its own messaging system.  For example, managing
the supply means allowing entities under the supply's purvue to process
updates for the day.</p>
</div><div class="codes"><pre class="brush: clojure">(defn sim-step
  ([day ctx]
   (-&gt;&gt; ctx 
        (begin-day        day)  ;Trigger beginning-of-day logic and notifications.
        (manage-supply    day)  ;Update unit positions and policies.
        (manage-policies  day)  ;Apply policy changes, possibly affecting supply.
        (manage-demands   day)  ;Activate/DeActiveate demands, handle affected units.      
        (fill-demands     day)  ;Try to fill unfilled demands in priority order. 
        (manage-followons day)  ;Resets unused units from follow-on status. 
        (end-day day)           ;End of day logic and notifications.))
  ([ctx] (sim-step (sim/get-time ctx) ctx)))</pre></div><div class="docs"><p>in ECS parlance, the functions in sim-step are just systems.
Each of these systems operates on the ECS, or more specifically,
the components within the ECS that are of interest, and
then narrowly computes the new components for the system from
the inputs.  We have composition of system by applying them
in-order to the input ECS; however, it's entirely possible that
we could define different means of composition, namely parallel
composition and the like, to allow the system execution to
run any way we'd like.
Since systems are just functions, we can build them up from smaller
systems (functions) and layer the behavior.
This is right and proper and functional;</p>
</div><div class="codes"></div><div class="docs"><p>Thinking of systems as vertical (in the sense of operating on columns of components),
we can think of single-purpose systems the operate on broad-swaths of components
-namely on an entity-by-entity basis- like messaging and behaviors - as
horizontal systems.  Horizontal systems may act at sporadic times, and
across many components (for instance at the entity level rather than
at the component level);   If we have an abstract entity that is
able to receive messages, its behavior is dictated by some system.
This system will be called as a function of events;  we'd like the
convenience of "triggering" events now or later.  One type of apparent
event that gets called quite a bit is the "behavior" or update event,
which we currently implement as handling a message.  We can let
the entity handle the message in any number of ways, but this means
we have an ambient system that can be invoked concurrently with
any currently running system (or really, we can queue it for invokation).
Do we really need to use messaging, or can we just apply the behavior
system on ad-hoc basis?   I think we can go adhoc, and just allow
other systems to have access to the behavior system if they need it.
For now, we can just do everything synchronously and not worry about
scaling it via messaging.  Alternately, we can queue the messages/events
and have them handled in-between system calls (part of binding the system)
Before and afte running any system, we maybe handle pending messages.
Either that, or we deal with messages in-line.  Either way, it works out and
can be handled synchronously.</p>
</div><div class="codes"></div><div class="docs"><p>Higher order simulation handling function.  Given an initial state and an 
   upper bound on simulated time, computes the resulting simulation context via
   a state transfer function, typically sim.engine/sim-step.</p>

<h1>Simulation Interface</h1>

<p>sim.engine/event-step-marathon is the entry point for Marathon.</p>
</div><div class="codes"><pre class="brush: clojure">(defn event-step-marathon
  [last-day ctx] 
  (let [init-ctx (initialize-sim
                  ctx ;(initialize-output ctx)
                  last-day)]
    (assert (can-simulate? init-ctx) 
            &quot;There's nothing to simulate. Check Supply, Demand, and Relations!&quot;)
    (loop [day    0
           ctx    init-ctx]
      (if (not (keep-simulating? ctx))
          (finalize day ctx) ;base case, return the final state and clean up.
          (let [next-ctx   (sim/advance-time  ctx) ;WRONG
                next-day   (core/get-time     next-ctx)
                next-ctx   (sim-step next-day next-ctx)] ;Transition to next state.
            (recur next-day next-ctx))))))</pre></div><div class="docs"><p>testing </p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(keep-simulating? (sim/add-time  22 emptysim))
)</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.fill" name="marathon.ces.fill"><h1 class="project-name">marathon.ces.fill</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><h2>Filling</h2>

<p>A collection of functions that define the process of mapping classes of demand
to eligible supply, and filling demand with suitable supply.  The fill system
acts as a service for the engine, and provides operations used - primarily - 
by the demand simulation.  The process of filling pushes changes on the 
supply, since the act of filling usually consumes some resources in supply and
motivates a kind of motion in the supply simulation.</p>
</div><div class="codes"></div><div class="docs"><p>Note: This is one of the more involved pieces of documentation, and could 
benefit from refinement.  However, filling has proven to be
a sensitive subject, so the extra layer of commentary is still useful.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.fill
  (:require [marathon.data   [protocols :as protocols]]
            [marathon.fill   [filldata :as filldata]]
            [marathon.demand [demanddata :as d]]
            [marathon.supply [unitdata :as udata]]
            [marathon.ces [core :as core] [demand :as dem] [supply :as supply]
                          [policy :as policy] [unit :as u] 
                          [deployment :as deployment]
                          [query :as query]]
            [marathon.ces.fill [fillgraph :as fg]]
            [spork.sim  [simcontext :as sim] [updates :as updates]]
            [spork.util [tags :as tag]]
            [spork.entitysystem.store :as store]
            [spork.util.reducers]
            [clojure.core [reducers :as r]]))</pre></div><div class="docs"><p>The old ManagerOfFill class actually handled the creation of a couple of
dependent chunks of data; namely a FillFunction, a FillGraph,
and a SupplyGenerator.  Functions in this module fill the role
of creating and composing each of these elements in kind.</p>
</div><div class="codes"></div><div class="docs"><h1>Primitive Operations</h1>

<p>account for the fill in the fillstore, basically just conj it to the history.</p>
</div><div class="codes"><pre class="brush: clojure">(defn record-fill [fillstore fill] 
  (let [fillcount (count (:fills fillstore))]
    (assoc-in fillstore [:fills] (inc fillcount) fill)))</pre></div><div class="docs"><h1>Fill-Related Notifications</h1>
</div><div class="codes"></div><div class="docs"><p>notify everyone that we've filled a demand...</p>
</div><div class="codes"><pre class="brush: clojure">(defn filled-demand! [demand-name unit-name ctx] 
  (core/trigger-event :FillDemand demand-name unit-name &quot;Filled Demand&quot; nil ctx))  </pre></div><div class="docs"><p>ghosts raise special attention when they deploy.</p>
</div><div class="codes"><pre class="brush: clojure">(defn ghost-deployed! [demand-src ctx]
  (core/trigger-event :GhostDeployed demand-src demand-src 
       &quot;Filled demand with  ghost&quot;  :normal ctx))</pre></div><div class="docs"><p>ghosts raise special attention if they followon.</p>
</div><div class="codes"><pre class="brush: clojure">(defn ghost-followed! [demand-src ctx]
  (core/trigger-event :GhostDeployed demand-src demand-src 
     &quot;Ghost followed on to another demand&quot; :followon ctx))</pre></div><div class="docs"><p>Auxillary function to broadcast information about just-in-time, or "ghost" 
unit utilization.  May be replaced with something more general in the future.</p>
</div><div class="codes"><pre class="brush: clojure">(defn check-ghost [unit ctx]
  (do ;(println unit)
      (if (not (core/ghost? unit)) ctx
          (if (core/followon? unit) 
            (ghost-followed! unit ctx) 
            (ghost-deployed! unit ctx)))))</pre></div><div class="docs"><h2>Decomposing the Fill Process....</h2>

<p>Sourcing a demand is really the composition of three simpler tasks: 
find-supply, take n items from the supply, fill the demand with the n items.
The following text dissects each of these compenents into atomic, composable 
elements, and defines the higher-order demand-filling behavior from the
primitive elements.  Before that, we take a brief detour through history to 
examine the original object-based mechanisms for the fill process, and how 
they remain in their functional counterparts.</p>
</div><div class="codes"></div><div class="docs"><h2>Understanding the Legacy Implemention of Fill Functions</h2>

<p>The legacy notion of a fill-function is central to the idea of finding an 
ordered set of candidate supply. In the old object model, the fill-function was
effectively a partially-applied function that closed over a fillgraph and a 
supplygenerator.  Since we only had one type of supply generator, the supply 
generator was really just a function that used the fill graph to provide an 
ordered list of supply on demand, where the fill graph is a set of relations 
between elements of supply and elements of demand envisioned as a directed 
acyclic graph.</p>
</div><div class="codes"></div><div class="docs"><h1>Legacy Filling Via the FillFunction Object</h1>

<p>The FillFunction used to be an object that provided a high-level interface for 
querying a set of rules about feasible and desired relations between elements
of supply &amp; demand, aka. Fill Rules, along with a candidate supply of
units, provided a prioritized sequence of units that can fill said
demand.  Fill Rules were embodied in a Directed Acyclic Graph,
known as the FillGraph, the topology of which encoded weighted paths
from demand sinks to sources of supply.  These abstractions were necessary,
because the concept of priority is highly variable (even time/event dependent),
and may change from study to study or run to run.  Hence, the desire to make 
the rules and semantics for filling supply highly variable and data-driven.
In the modern functional variant, we still have the notion of a fill-function, 
but it does not perform the same amount of "heavy lifting" the old object did.
In fact, the fill-function is really a simple chunk of data that contains the 
contextual rules for filling any demand.  It is used in explicit queries, vs. 
containing a query method relative to a fillfunction object.</p>

<h1>Fill Rules and The Fill Graph</h1>

<p>FillRules, encoded in a FillGraph, actually tell us a lot before we simulate.
The FillGraph is generated, as a pre-process step, by analyzing the supply 
entity records, the demand entity records, and the relation records for 
Marathon.  Each source provides a unique element of the graph: supply populates
the graph with source nodes, or terminal nodes that can supply units of a 
specific type (usually encoded as an SRC).  Demand populates sink nodes of 
Demand on the graph, which consume units of a specific type.  Relations add 
nodes to the interior region between source and sink nodes, creating new paths 
(via substitution and equivilancies), which further relate supply and demand. <br />
Together, each dataset is parsed to derive a set of rules, which form the
topology (or connections) of the graph.  We can then bash the graph with some
useful algorithms that make it easy to search, scope out useless rules, and
even do some error checking. Unlike the fill-function, the fill graph maintains
its structure and uses from the legacy version, since it was pure data then as
well.</p>
</div><div class="codes"></div><div class="docs"><p>When building the FillGraph, we actually create an implicit dependency graph
that can tell us which elements of supply and demand are A) Reachable B)Not 
Reachable. Nodes (usually coded as SRCs, but any string is valid) that are
Reachable also provide information on how many other nodes they can reach. <br />
In most cases, there will be a 1:1 match between a source node, say a Supply 
of SRC1, and a sink node, say a Demand for SRC1.  In this case, we know that 
both Supply and Demand contain SRC1, there will be a zero-cost path from 
SINK<em>SRC1 -> SRC1 -> SOURCE</em>SRC1.  Since we allow the possibility of 
substitutions in our ruleset, there may be more than 1 path from SINK_SRC1, 
maybe to another source of substitutible supply like SRC2 
(SINK<em>SRC1->SRC1</em>SRC2->SOURCE_SRC2).
In this scenario, supply for both SRC1 and SRC2 are related, in that there's a 
dependency introduced by the fill rules.  At a minumum, any simulation for SRC1
must include SRC2, even if there's no demand for SRC2, because SRC2 "may" serve
as supply for SRC1.  In this case, the set #{SRC1 SRC2} can be said to form an 
equivalence class, or they form a strongly connected component.</p>
</div><div class="codes"></div><div class="docs"><h1>Ancillary Pre-Processing Via the FillGraph</h1>

<p>While strictly related to the higher-level notion of filling demands, we can 
exploit properties of the fillgraph - during a pre-processing phase - to make 
searching the fillgraph more efficient, identify possible problems with the 
data, and identify possible areas for exploting data-parallelism.  </p>
</div><div class="codes"></div><div class="docs"><h1>Islands Denote Possible Data Errors</h1>

<p>In the case where there is NO path from either supply or demand, we have 
"islands", or nodes that are unreachable (class B from the paragraph above). <br />
These islands are usually the result of data errors, and indicate missing 
supply (in the case of unfillable demand), missing demand (in the case of 
unusable supply), or missing relations (in either case). Pre-processing will 
automatically find islands, and all equivalence classes / strongly connected
components in the FillGraph.</p>
</div><div class="codes"></div><div class="docs"><h1>PreProcessing Identifies Independent Data and Simplifies The Fill Graph</h1>

<p>One of the benefits of finding equivalence classes is that we can choose to 
only simulate SRCs that are dependent. This lets us reduce the amount of work 
into independent batches and divide the simulation into N smaller simulation 
runs. This can provide a big cost savings for certain analyses by reducing the 
total number of events and entity updates that must be processed, and 
independent simulations can be computed in parallel.  Finally, pre-processing 
the FillGraph actually reduces the complex web of interior nodes, and provides
a simplified graph that is very quick to search due to every path in the 
reduced graph having, at most, 2 steps from unfilled to filled.</p>
</div><div class="codes"></div><div class="docs"><h2>Default Implementation for Querying Rules to Find the Most Suitable Supply</h2>

<p>The default scheme for prioritizing supply is to query the ruleset to
find an ordered set of matches between sets, or buckets, of supply and the
demand in need of filling.  Due to substitution and other criteria, the buckets
of supply may be of lower "cost" to utilize for the demand than others.  This 
corresponds to a weighted path in the FillGraph.  The query is essentially a 
variation of the K-shortest paths algorithm, where the shortest path is found, 
then the next, ... as needed.  These paths describe a context, or a 
justification for selecting a sub set of supply, and serve to classify the 
entire subset of supply as a certain class, with a uniform priority.  This is
desirable, as it effectively partitions the search space and provides an 
efficient means of selecting sets of units for possible deployment.    </p>
</div><div class="codes"></div><div class="docs"><p>When time permits, I intend to take this to the next logical step and just
implement a min-cost max-flow fill algorithm instead of the k shortest <br />
paths.</p>
</div><div class="codes"></div><div class="docs"><h1>Fill Rule Interpretation</h1>

<p>Given a common description of a demand category, the fill function should be 
able to interpret the demand rule into a corresponding supply rule.  After
converting to a common supply rule, different fill functions may interpret 
the same rule in completely different manners, or we can have a robust 
language for describing and interpreting rules.  The end result should be a 
way to map classes of demand to ordered sets of supply in a general and 
flexible fashion.</p>
</div><div class="codes"></div><div class="docs"><p>In the legacy implementation, the rule structure is actually embedded in the 
topology of a directed graph.  Labelled 'sink nodes' on the graph represent 
possible demand categories, while primitive 'source nodes' are primitive 
elements of supply.  Complex rules for substitution and equivalence are 
encoded in the intermediate arcs of the graph.  These functions help interpret
to and from the graph encoding in the legacy implementation.</p>
</div><div class="codes"></div><div class="docs"><p>Standard labels for defining source and sink rules.  Maybe memoize these.</p>
</div><div class="codes"><pre class="brush: clojure">(def sink-label   (memoize (fn [x] (fg/sink-label x))))
(def source-label (memoize (fn [x] (fg/source-label x))))</pre></div><div class="docs"><p>Dispatch function for reading demands as demand rules.</p>
</div><div class="codes"><pre class="brush: clojure">(defn supply-cat 
  ([demand]                    (core/category-type (get demand :src)))
  ([demand category] (core/category-type category)))</pre></div><div class="docs"><p>Old...no need for the fillstore as of yet.
(defn supply-cat 
  ([demand]                    (core/category-type (get demand :src)))
  ([demand fillstore]          (core/category-type (get demand :src)))
  ([demand fillstore category] (core/category-type category)))</p>
</div><div class="codes"></div><div class="docs"><p>Not yet implemented, but the intent is to have a simple idiom for parsing 
abstract categories into rules that can be used to query supply or demand 
or anything.</p>
</div><div class="codes"><pre class="brush: clojure">(defn rule-&gt;supply-rule [rule]
  (throw (Exception. &quot;Not implemented!&quot;)))</pre></div><div class="docs"><p>Refactor -> we don't need a separate rule here really, just wrapping 
sink-label.  Note: we're passing in a new notion of categories when we 
fill demands now.  This means we can't just derive the rule and be done.
We need to dispatch on the category, and map the demand category into an 
appropriate rule that query can apply to the supply to find elements
of supply.</p>
</div><div class="codes"></div><div class="docs"><p>Originally implemented as a multimethod, currently refactored into a
function for performance (and ostensibly simpler).  We'll see if we
need to expand beyond this and go with a protocol or a multimethod. <br />
Doubtful.
TODO# determine if fillstore is necessary here.  It may just be a
stub.  Also revisit different types of rules, currently only
handling simply rules, where the rule is the demand's src.  Note: 
we could opt to use complex rules in lie of the SRC for the demand, 
or have the SRC map to a pattern....</p>
</div><div class="codes"><pre class="brush: clojure">(defn derive-supply-rule
  ([demand category] 
    (case (supply-cat demand category)
                                        ;for simple categories, ala &quot;SRC_1&quot; or :SRC_1, we just use the existing 
                                        ;label for the demand, which maps to a node in the fill graph.  This label is 
                                        ;typically a standard alphanumeric SRC, but it could be any identifier the user
                                        ;chooses.
      :simple         category ;(sink-label category)
                                        ;For categories that require a demand group, namely follow-on fills, we 
                                        ;just inject the sink-label into the vector: 
                                        ;     [src group] -&gt;  [(sink-label src) group]
      :src-and-group  (rule-&gt;supply-rule category) ;[(sink-label (first category)) (second category)]
                                        ;For complex categories that contain information in a map structure, we 
                                        ;will have a way to parse the supply rule, which could be arbitrarily complex.
      :rule-map       (rule-&gt;supply-rule category)))
  ([demand] (derive-supply-rule demand  (get demand :src))))</pre></div><div class="docs"><h1>TODO elevate stock queries into user-defined rules.</h1>
</div><div class="codes"><pre class="brush: clojure">(def stock-queries
  (let [m {&quot;ac-first&quot;  query/ac-first
           &quot;AC&quot;        query/ac-first
           &quot;rc-first&quot;  query/rc-first
           &quot;RC&quot;        query/rc-first
           &quot;RCAD&quot;      query/RCAD
           &quot;RCAD-BIG&quot;  query/RCAD-BIG
           &quot;uniform&quot;   query/uniform}]
    (reduce-kv (fn [acc nm r]
                 (assoc acc (keyword nm) r))
               m m)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn resolve-source-first [sf]
  (if-let [r  ( get stock-queries sf)]
    r
    (throw (Exception. (str &quot;unknown source-first rule: &quot; sf)))))</pre></div><div class="docs"><p>Tom Hack 26 May 2016
If we're not SRM demand, i.e. the category is something other than
SRM, we use the default category so as to not restrict our fill.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def restricted-categories #{&quot;SRM&quot; :SRM})</pre></div><div class="docs"><p>Ensures that we only allow StartStates
that exist in the unit's policy....</p>
</div><div class="codes"><pre class="brush: clojure">(defn has-transition? [st]
  (fn [u]
    (protocols/next-position (:policy u) st)))      </pre></div><div class="docs"><p>Note: this is pretty crucial for the fill process, it provides all of
the ordering and filtering context, derived from the demand record.</p>
</div><div class="codes"></div><div class="docs"><p>TODO# flesh this out, for now it fits with our match-supply expressions.</p>
</div><div class="codes"><pre class="brush: clojure">(defn demand-&gt;rule [d]
  (let [category (let [c (get d :category :default)]
                   (if (restricted-categories c) c
                       :default))
        r   {:src  (get d :src)
             :cat  category
             :name (get d :name)
             :order-by (resolve-source-first (get d :source-first &quot;uniform&quot;))
             :required (d/required d)
             }]
    (if  (or (= category :default) (nil? (:StartState d)))
      r
      ;;we have a preference for startstate...
      (assoc r :where  (has-transition? (:StartState d))))))</pre></div><div class="docs"><h2>Finding and Ordering Supply</h2>
</div><div class="codes"></div><div class="docs"><h1>Legacy Means For Generating A Stream of Deployable Supply</h1>

<p>In the legacy implementation,  a SupplyGenerator object served as a poor man's 
version of a sequence abstraction (or an iterator in other languages).  It used
internal state, combined with a reference to one or more buckets of supply, to
walk the shortest possible paths defined by an external query, visiting each
set of supply and stitching together what appeared to be a single sequence of 
units.  The abstract sequence of units returned by the generator was thus an 
ordered traversal of the supply, as dictated by the fillgraph.</p>
</div><div class="codes"></div><div class="docs"><p>The SupplyGenerator also used a secondary prioritization function to determine
the order for each subsequence of units it found. When the generator visited 
each "bucket" of supply, it used a prioritization function to sort the bucket, 
then collated the ordered subsequence of units into an abstract 
"total ordering" of all supply, using fairly complex and dynamic prioritization
rules and supply->demand relationships.  Thankfully, the underlying traversal 
and ordering mechanism was hidden behind a simple stream-like API, which 
facilitated higher-order expressions like "take" and "next" to allow consumers
to view the SupplyGenerator as a sequence of units.</p>
</div><div class="codes"></div><div class="docs"><h1>Default Unit Comparison</h1>

<p>To deal with highly variable supply ordering rules, the SupplyGenerator had a 
modular unit prioritization object (a UnitComparer) for establishing the 
fine-grained ordering of subsequences of units.  The default UnitComparer 
prioritization was (and remains) based on a Unit's absolute position in its 
current rotational policy.  This position, or policy coordinate, is a value 
between [0.0 1.0]. The policy coordinate is computed by comparing the unit's 
time in the current cycle, with the expected length of the cycle, or 
CycleTime / CycleLength, where CycleTime &lt;= CycleLength.  Computing the policy 
coordinate provides a normalized representation of each unit's "progress" in 
its lifecycle.  Since typical rotational policies indicate a positive relation 
between cycle time and readiness, the proportional representation of the policy
coordinate provides a convenient measure of readiness as well.</p>

<p><strong>Note</strong> , this assumption holds for known rotational policies, but may fail if 
readiness is not a function of time in cycle.  Also, other unit prioritization 
functions exist, including preferences by component (either AC or RC first). <br />
In the end, notions of prioritization are highly context sensitive, depending 
on the goals of the study.  They are designed to be modular, easily changed,
composed, and selectively applied.</p>
</div><div class="codes"></div><div class="docs"><h2>Default Legacy Total Ordering of Supply</h2>

<p>The default notion of ordering used in the legacy object model will remain the 
default in the functional programming version, with ostensibly identical 
mechanisms (minus the reliance on objects and mutable state).
Using the policy coordinate as a comparator, the FillFunction orders each 
subset of units so that their policy coordinate, and thus readiness, is sorted
in descending order. <br />
Thus, the total ordering is a sorting of units by Min Path Length, then Max 
policy coordinate.  This provides a natural ordering that corresponds with 
rotational policy, in that units, regardless of component, are drawn evenly 
according to relative readiness, starting with units that directly match the
capability demanded, and that have had the most time to increase readiness 
(most capable, most ready), ending with units that least match the capability 
demanded, with the least amount of time to increase readiness (least capable, <br />
least ready). When units deploy, the context of the fill path is annotated on 
their deployment record, in addition to other stats such as path length.  </p>
</div><div class="codes"></div><div class="docs"><h1>Effectful Filling Under the Legacy FillFunction</h1>

<p>Under the legacy FillFunction object, we typically prepped it with a query, 
which loaded the supply generator (providing a total ordering of eligible 
supply), and applied the "take" method of the FillFunction to a numeric 
argument.  The result of "taking" 10 items, for example, would provide a 
collection - implicitly the 10 (or less) most "suitable" elements of supply, 
represented by a collection of FillData objects.    </p>
</div><div class="codes"></div><div class="docs"><p>Some forms of fill could cause the creation of just-in-time units, or Ghosts,
which caused the side-effect of actually creating supply upon generation 
(inside the SupplyGenerator). Going forward in the functional design, we make 
such side effects explicit data that must be interpreted and evaluated, rather
than using hidden mutation.  </p>
</div><div class="codes"></div><div class="docs"><p>With a valid, prioritized order of units in hand, the FillFunction tried to 
fill the demand by selecting units in order until demand is filled, or no more
units exist.  Completely filling a demand would trigger additional effects. <br />
Under the functional version, we maintain the spirit of these features - i.e. 
the communication of success or failure to fill - but again, we use explicit 
data structures to communicate effects.</p>
</div><div class="codes"></div><div class="docs"><h2>Legacy (Mutable Object-Based) Fill Summary</h2>

<p>All the fill function did was wrap both the fill graph and a mutable generator, 
where the generator served as a live "cursor" to buckets or partitions of 
supply.  This was effectively a poor man's inelegant version of a stream.
It provided an interface to initialize queries and maintain state.  Since we 
were pulling from multiple "buckets" of supply, according to an ordering 
dictated by shortest paths in the fillgraph, we had the "generator" 
automatically pointing at multiple buckets</p>
</div><div class="codes"></div><div class="docs"><h2>Filling Functionally</h2>

<p>Under the new functional design, the fill-function is a chunk of data that 
contains the rules necessary for ordering a set of units relative to a demand. 
When combined with a query function, the data in the fill-function will 
inform the ordering of any supply relative to any demand, and provide an 
ordered lazy sequence of candidates. This eliminates the complexity from have 
multiple mutable buckets to draw from in the legacy verison.  Now, we simply 
have an abstract "sequence" of candidates to draw from while we fill.  The 
function that generates said sequence, <strong>query</strong>, may be very complex, but it 
hides all of the complexity for us and allows us to trivially change how supply
is ordered.</p>
</div><div class="codes"></div><div class="docs"><p>The protocol ISupplier provides an abstraction for systems that can interpret
a rule that describes classes of supply, find and order eligible supply in a 
given store.  While rules are abstract, they will be implemented in a common
language for describing fill rules, which should facilitate communication 
between a party asking for supply, and the supplier who can provide it.  This 
should allow for a very flexible arrange of rule descriptions, as well as
varying degrees of interpretation rule interpretation, and the generation of 
promised supply.</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol ISupplier 
  (query [s rule store] 
  &quot;Given a rule that orders eligible supply, s applies the
   rule to store to return an ordered sequence of promised supply.&quot;))</pre></div><div class="docs"><p><strong>TODO</strong> Provide a default implementation of the ISupplier that can parse 
simple rules.  Specifically, one that can match src to src for instance.
<strong>TODO</strong> Provide a set of extended Supplier definitions, possibly combinators
for compound supply rules, that allow users to easily define prioritization 
and possible supply generation criteria.  For instance, we need a way to 
implement the existing default stack of preferences: ordered by fence, 
followon status, capability (i.e. substitution), max normalized dwell. <br />
Another would be a function that can generate new supply according to some 
constraint (possibly unconstrained).</p>
</div><div class="codes"></div><div class="docs"><h2>High Level Fill</h2>
</div><div class="codes"></div><div class="docs"><h1>It's all about finding supply.</h1>

<p>The ultimate purpose of querying a fill-function is to answer a simple query: <br />
Given a demand (or a rule that describes the demand), and a supplystore
(which contains supply), which elements of supply are are most suitable to fill 
the demand, based on the interpretation of the fill-function?</p>
</div><div class="codes"></div><div class="docs"><h1>First: "Find the most suitable supply".</h1>

<p>This represents an ordered sequence of candidate fills....we may not, in fact,
utilize every candidate.  A better description is that <strong>find-supply</strong> provides
a list of  fill-promises, which are realized as needed.  A fill-promise is a 
function that consumes the current context and returns a pair of 
[promised-unit, new-context].  That way we can update the context by realizing
the fill-promise (i.e. applying it against a context we thread through), and 
then do something with the unit that was promised.  Since these are just 
promises, i.e. potential supply, we don't mutate anything or make any changes
to the context until we need to.  </p>
</div><div class="codes"></div><div class="docs"><p>find-supply::(rule->demand->demandgroup->name->supply->phase->[fill-promise]) <br />
            ->supply->rule->[fill-promise] <br />
where fill-promise::(simcontext->'a->[filldata,simcontext])  </p>
</div><div class="codes"></div><div class="docs"><p>Note: filldata == {:keys [rule fillPath pathlength followon source]}
simple....
TODO# replace with record or type.
BUGFIX: we strip out the :dt here if necessary.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unit-&gt;filldata [cat src length u]
  ;;we're out of position here..
                                        ;rule ;fillPath ;pathLength
  (-&gt;&gt; (dissoc u :dt)
       (filldata/-&gt;fill  cat src length nil)))</pre></div><div class="docs"><p>all we expect from fills is that there is a quantity
if there is a key for :actions, then we have some requirement.
otherwise, it's a default fill, we just do what's necessary to
deploy the unit.</p>
</div><div class="codes"></div><div class="docs"><p>Do we need unit->filldata?  Maybe for future supply....i.e.
intended fills.  Dunno.  It's okay to go greedy atm...
Note: we can retroactively go back in time (using imm data)
and update the unit's status (i.e. require it to go to mob/demob,
ctc training, change it's state, etc....this makes us rewind
the simulation though, invalidating any currently rendered
state.  Generalizes into searching though...which may be useful.</p>
</div><div class="codes"></div><div class="docs"><p>Returns an ordered sequence of actions that can result in supply.
   This effectively applies the suitability function related to fillfunc to the 
   rule, the demand, and the supply.  The result is a sequence of 
   potential fills....where potential fills are data structures that contain 
   the context of the fill (i.e. the unit, the actions required to realize the 
   fill, and other meta data), typically a filldata record.</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-supply
  ([fillfunc supplystore rule]     
     (query fillfunc rule supplystore))
  ([supplystore rule]
     (map (fn [[[cat src length] u]] 
            (unit-&gt;filldata cat src length u))
          (query/match-supply rule supplystore))))</pre></div><div class="docs"><p>TODO# fillPath in our supply query is currently pretty rudimentary.
It may be nice, for feature parity, to have then entire fillpath
relayed rather than the endpoint.</p>
</div><div class="codes"></div><div class="docs"><p>An element of supply has a quantity associated with it.
It also has a set of actions associated with delivering said supply.</p>
</div><div class="codes"></div><div class="docs"><p>A supplier provides units at the cost of updates...
A supplier can provide 1 or more (possibly infinite) units.
Suppliers may nest inside each other (i.e. a unit living inside
another).</p>
</div><div class="codes"></div><div class="docs"><p>Applies the a function, fill-promise, that maps a context to a pair of 
   [filldata, updated-context].  The updated-context should represent the result
   of realizing the promised fill.</p>

<p>We can coerce our list of fill promises into actual fills by applying 
<strong>realize-fill</strong> to them.  Assuming a fill promise consumes a context, we <br />
apply the promise to a given context.  This should produce a pair of the 
filldata --information about the unit realized for filling-- and an updated 
simulation context.
Note: we need to alter this...I understand the reason it exists, namely
to allow for things like supply-generation in the face of constraints,
but we're losing information from the filldata as a consequence.
we get a fill-promise :: marathon.fill.filldata, and
we project it onto :: [marathon.supply.unitdata ctx]</p>
</div><div class="codes"><pre class="brush: clojure">(defn realize-fill
  [fill-promise ctx] 
  [(if (map? fill-promise) fill-promise
       (throw (Exception. (str &quot;no other promise types supported&quot;))))
                                        ;(get fill-promise :source)
   (if-let [actions (get fill-promise :actions)]
     (actions ctx) ;;perform any actions necessary 
     ctx)])</pre></div><div class="docs"><h1>Second: Allocate a candidate fill against a demand.</h1>

<p>Assuming we have a candidate fill, and a demand that needs filling, we define
the consequences of using the candidate (via some filldata) to logically "fill"
the demand.  The result is a new context, since there may be additional 
consequences to the context due to a fill.</p>
</div><div class="codes"></div><div class="docs"><p>While the demand is assumed to have inspired the list of candidates, it's 
not consequential for allocation purposes.  In fact, the list of candidates 
could be completely random or drawn in an otherwise arbitrary fashion.
<strong>Note</strong> that would make a great <em>test</em>, having a random fill function.  </p>
</div><div class="codes"></div><div class="docs"><p>Assuming we have a chunk of realized filldata, we define a way to apply it to 
a demand to accomplish any updates necessary for filling.  This is a primitive
function that will support the higher-order notion of "filling" a demand. <br />
<strong>apply-fill</strong> should represent the new context emerging from applying a 
realized fill, in the form of filldata, to a demand.  </p>
</div><div class="codes"></div><div class="docs"><p>Originally, this meant that fills would always result in a deployment at the
end.  By elevating apply-fill into the API, we can actually implement things 
that would otherwise be difficult, i.e. delayed fills (pre-allocating units 
and scheduling them to deploy at a later date, while nominally "filling" the 
demand).</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def ^:dynamic *fill-testing* true)</pre></div><div class="docs"><p>Deploys the unit identified in filldata to demand via the supply system.</p>
</div><div class="codes"><pre class="brush: clojure">(defn fill!
  [t period demand deployment-count filldata  ctx]
  (let [;unit (or (:unit filldata) filldata)
        unit     (:source filldata) ;;this is not an updated unit.
        ctx      (deployment/deploy-unit  ctx unit  t demand                                
                                          (core/followon? unit))
        new-unit (store/get-entity ctx (:name unit))]        
      (supply/log-deployment! t (:locationname unit) demand new-unit   
                              deployment-count filldata nil  period ctx)))</pre></div><div class="docs"><p>Enacts filling a demand, by realizing a vector of promised fills, logging if any ghosts 
   were used to fill (may change this...) and updating the context.  Applies the
   result of one promised fill to the demand, which may or may not satisfy the 
   demand.</p>

<p>temporarily changing this</p>
</div><div class="codes"><pre class="brush: clojure">#_(defn fill!
 &quot;Deploys the unit identified in filldata to demand via the supply system.&quot;
  [t period demand deployment-count filldata  ctx]
  (let [;unit (or (:unit filldata) filldata)
        unit   (:source filldata) ;;this is not an updated unit.
        ]
    (-&gt;&gt; (deployment/deploy-unit  ctx unit  t demand                                
                                 (core/followon? unit))
         (supply/log-deployment! t (:locationname unit) demand unit   
                                 deployment-count filldata nil  period))))
;;#Incremental Demand Filling
;;The atomic fill process rests inside a high-level function, __fill-demand__ .
;;__fill-demand__ takes any fill-promise, realizes the fill-promise, and applies
;;the the realized filldata to fill a demand. It wraps the low-level context
;;shuffling that is necessary behind a simple, high-level interface amenable to 
;;use in a reduction ala __clojure.core/reduce__ .  
;;The end result is a new context, representing the consequences of filling said 
;;demand with the promised fill.  Under this scheme, __apply-fill__ will 
;;automatically handle the realization of a fill-promise, and thread its updated
;;context through the process of deploying the unit associated with the realized 
;;filldata.  Since fill-promises are typically for single elements of supply,  
;;__fill-demand__ will typically only apply a single unit towards a demand.
;;Note: we have the demand here...so, we can pass along the details..
(defn fill-demand*
  [t period demand  promised-fills ctx]
  (let [deployment-count (atom (or (store/gete ctx :SupplyStore :deployment-count) 0))]
    (-&gt;  (reduce (fn [ctx promised-fill]            
                   (let [[filldata ctx] (realize-fill promised-fill ctx) ;reify our fill.
                                        ;_ (println fd)
                         unit     (:source filldata)
;                         unit     (or (:unit filldata)    filldata)
                         cnt      (swap! deployment-count unchecked-inc)
                         ] 
                     (-&gt;&gt; ctx 
                          (filled-demand! (:name demand) (:name unit))
                          (check-ghost unit)
                          (fill! t period demand cnt filldata))))
                 ctx promised-fills)
         (store/assoce :SupplyStore :deployment-count @deployment-count))))</pre></div><div class="docs"><h1>Trying to Completely Satisfy a Demand</h1>
</div><div class="codes"></div><div class="docs"><p>Since we know how to effectively apply promised fills towards demands via 
<strong>fill-demand</strong> in an atomic fashion, we can define the notion of completely 
filling a demand as finding the supply for the demand, using <strong>fill-demand</strong> on 
each candidate element of supply, and drawing from the supply until either the
demand is filled, or the candidates are exhausted.  </p>
</div><div class="codes"></div><div class="docs"><ol>
<li>Assumes candidate preference is invariant.  There may be a time when we need
to re-evaluate the ordering of candidates while we're filling, i.e. the 
amount of fill may impact the order of candidates.  For now, we assume that 
the ordering of candidates is independent of the demand fill.</li>
</ol>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def last-sel (atom nil))</pre></div><div class="docs"><p>Attempts to satisfy the demand by finding supply and applying promised 
   fills to the demand.  Returns a result pair of 
   [:filled|:unfilled updated-context], where :filled indicates the demand is 
   satisifed, and updated-context is the resulting simulation context.</p>

<p>Filling in batch now.  Should be mo betta.</p>
</div><div class="codes"><pre class="brush: clojure">(defn satisfy-demand  
  [demand category ctx]
  (let [rule        (demand-&gt;rule demand)
        period      (:name (policy/get-active-period (core/get-policystore ctx)))
        t           (core/get-time ctx)
        demand-name (:name demand)  
                                        ;1)
        req      (d/required demand)
        selected (-&gt;&gt; (find-supply ctx rule)
                      (into []    (take req)))
        _           (reset! last-sel selected)
        actual-fill (count selected)
        status      (if (== actual-fill req) :filled :unfilled)
        ;; _ (when (seq selected)
        ;;     (println [:filling rule (map (comp :name :source) selected)
        ;;                                 ;(first selected)
        ;;              ]))
        ]
    [status (fill-demand* t period demand selected ctx)]))</pre></div><div class="docs"><p>testing</p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(require '[marathon.sim.testing :as test])
(require '[clojure.test :refer [deftest is run-tests]])
(defn count-by [keyf xs] 
  (reduce-kv (fn [acc k v] 
               (assoc acc k (count v))) {} (group-by keyf xs)))
(def fillstore (core/get-fillstore test/testctx))
(def ds (vals (:demandmap test/test-dstore)))
(def rules (map #(derive-supply-rule % fillstore) ds))
(def complex-rule (derive-supply-rule (first ds) fillstore :category [&quot;Alpha&quot; &quot;SomeGroup&quot;]))
(deftest supply-rules 
  (is (= (count-by second rules)
         {&quot;SRC1&quot; 21, &quot;SRC2&quot; 14, &quot;SRC3&quot; 36})
      &quot;Should have consistent number of srcs in supply rules.&quot;)
  (is (= complex-rule 
         [[:fillrule &quot;Alpha&quot;] &quot;SomeGroup&quot;])
      &quot;Should have a simple pair of [fillrule group] as a result.&quot;))
;some dumb demands 
;(def demands )</pre></div><div class="docs"><h1>Pending</h1>

<p>Port fill store generation functions and IO functions/constructors from legacy 
code.</p>
</div><div class="codes"></div><div class="docs"><p>Process that encapsulates creating a new fillstore from coredata, appending 
the fillstore to the core data, and then returning a scoped set of core data, 
where the supply and demand have been reduced according to the relations
embodied by the fillgraph.
Assumes simState has valid supply, demand, and policystore instances 
(i.e. they've been initialzed, probably from tables). Returns updated simState.
Public Function simStateToScopedSimState(simstate As TimeStep_SimState, 
   Optional generator As TimeStep<em>SupplyGenerator) As TimeStep</em>ManagerOfFill</p>

<p>Dim ff As TimeStep_FillFunction
Dim fg As TimeStep_FillGraph
Dim fs As TimeStep_ManagerOfFill</p>

<p>With simstate
   Set fg = composeFillGraph(.supplystore, .demandstore, .policystore)
   If generator Is Nothing Then _
       Set generator = makeSupplyGenerator(simstate, , , 
            simstate.parameters.getKey("DefaultSupplyPriority") = "RCPreSurge")
   Set ff = makeFillFunction("FillFunction", .supplystore, fg, .parameters, 
                               .context, generator)
   Set fs = makeFillStore(fg, ff, generator)
End With</p>

<p>Set simstate.fillstore = fs
'Scopes the data as a final step, since we have a handle on the fillgraph.
Set simstate = scopeSimState(fg, simstate)
Set ff = Nothing
Set fg = Nothing
Set fs = Nothing</p>

<p>End Function</p>
</div><div class="codes"></div><div class="docs"><p>'Constructor for building fill stores from component pieces.
'Note, the fill store has a fillgraph, a fill function, and a supply generator.
Public Function makeFillStore(fillgraph As TimeStep_FillGraph, fillfunction As 
  TimeStep<em>FillFunction, generator As TimeStep</em>SupplyGenerator) 
        As TimeStep_ManagerOfFill</p>

<p>Set makeFillStore = New TimeStep_ManagerOfFill
With makeFillStore
   Set .fillgraph = fillgraph
   Set .fillfunction = fillfunction
End With
End Function</p>
</div><div class="codes"></div><div class="docs"><p>'Produces a new fill function from inputs.
Public Function makeFillFunction
(nm As String, supplystore As TimeStep_ManagerOfSupply, _
   graph As IGraph, parameters As TimeStep_Parameters, _
      context As TimeStep_SimContext, _
          generator As TimeStep<em>SupplyGenerator) As TimeStep</em>FillFunction</p>

<p>Set makeFillFunction = New TimeStep_FillFunction
With makeFillFunction
   .name = nm
   'Decoupled
   Set .parent = supplystore
   'Eh...this is dubious....TODO -> separate further.
   Set .FillRules = .AddFill(graph)
   'Decoupled
   Set .generator = generator
End With</p>

<p>End Function</p>
</div><div class="codes"></div><div class="docs"><p>'This is the simplest initializer for building and initializing a fill store. <br />
'Closest to the legacy stuff as well.
Public Function fillStoreFromTables(simstate As TimeStep_SimState, 
  sources As GenericTable, sinks As GenericTable, relations As GenericTable) 
     As TimeStep_ManagerOfFill
Dim fg As TimeStep_FillGraph
Dim ff As TimeStep_FillFunction
Dim sg As TimeStep_SupplyGenerator</p>

<p>Set fg = New TimeStep_FillGraph
Set fg = FillGraphFromTables(fg, sources, sinks, relations)</p>

<p>Set sg = makeSupplyGenerator(simstate)
Set ff = makeFillFunction("FillFunction", simstate.supplystore, fg.graph, 
                             simstate.parameters, simstate.context, sg)
Set fillStoreFromTables = makeFillStore(fg, ff, sg)</p>

<p>Set sg = Nothing
Set ff = Nothing
Set fg = Nothing</p>

<p>End Function</p>
</div><div class="codes"></div><div class="docs"><p>Private Function getDependencies(gr As IGraph) As Dictionary
Dim nd
Dim x As String</p>

<p>Set getDependencies = New Dictionary
For Each nd In GraphLib.getNodes(gr)
   x = translateRule(CStr(nd))
   If Not (getDependencies.exists(x)) Then
       getDependencies.add x, 0
   End If
Next nd</p>

<p>End Function</p>
</div><div class="codes"></div><div class="docs"><p>Public Function translateRule(ByRef inrule As String) As String
Dim tmp
tmp = Split(inrule, "_")
If UBound(tmp, 1) = 1 Then
   translateRule = tmp(1)
Else
   Err.Raise 101, , 
     "Irregular rule :" &amp; inrule &amp; " should be delimited by a single _ "
End If
End Function</p>
</div><div class="codes"></div><div class="docs"><p>'Aux function to describe the type of island, whether a source or a sink.
Private Function islandType(nodename As String) As String
If InStr(1, nodename, "SOURCE") > 0 Then
   islandType = "Supply"
ElseIf InStr(1, nodename, "FILLRULE") > 0 Then
   islandType = "Demand"
Else
   Err.Raise 101, , "Island is neither supply nor demand"
End If</p>

<p>End Function</p>
</div><div class="codes"></div><div class="docs"><h1>Constructors and Data Munging Functions</h1>

<p>Constructors to create all three, independently, now exist in this module. <br />
Along with decoupled construction, operations for sourcing demands, relative to
rules specified in a FillFunction, from a supply to a demand, are provided. <br />
sourceDemand is probably the most notable/used function, as it...sources 
demand!</p>
</div><div class="codes"></div><div class="docs"><p>Implement defquery or defgenerator, to allow easy composition of fill 
functions.  This requires cljgraph.</p>
</div><div class="codes"></div><div class="docs"><p>(defn apply-fill
  "Deploys the unit identified in filldata to demand via the supply system."
  [filldata demand ctx]
  (core/with-simstate [[fillstore supplystore policystore parameters] ctx]
    (let [unit        (or (:unit filldata) filldata)
          ou          (spork.entitysystem.store/get-entity ctx (:name unit))
          _ (println [:apply-fill (:locationname unit) (:locationname ou)])
          t           (sim/get-time ctx)
          ]
      (deployment/deploy-unit ctx unit t demand
                              (core/followon? unit)))))</p>
</div><div class="codes"></div><div class="docs"><p>(defn fill-demand
  "Enacts filling a demand, by realizing a promised fill, logging if any ghosts 
   were used to fill (may change this...) and updating the context.  Applies the
   result of one promised fill to the demand, which may or may not satisfy the 
   demand."
  [demand ctx promised-fill]
  (let [[fd ctx] (realize-fill promised-fill ctx) ;reify our fill.
        ;_ (println fd)
        unit     (or (:unit fd) fd)</p>
</div><div class="codes"></div><div class="docs"><pre><code>    ;_ (println [:fill-demand (:locationname unit)])
    ] 
(-&gt;&gt; ctx 
     (filled-demand! (:name demand) (:name unit))
     (check-ghost unit)
     (apply-fill fd demand))))
</code></pre>
</div><div class="codes"></div><div class="docs"><p> think category is akin to rule here...
(defn satisfy-demand-  "Attempts to satisfy the demand by finding supply and applying promised 
   fills to the demand.  Returns a result pair of 
   [:filled|:unfilled updated-context], where :filled indicates the demand is 
   satisifed, and updated-context is the resulting simulation context."
  [demand category ctx]
  (let [;fillstore   ;(core/get-fillstore     ctx)
        ;fillfunc    ;(core/get-fill-function ctx)
        ;supplystore (core/get-supplystore   ctx)
        rule        (demand->rule demand)
        demand-name (:name demand)
       ; _ (println [:satisfying-demand demand (d/required demand)])
        ;1)
        candidates  (find-supply ;fillfunc
                                        ;supplystore</p>
</div><div class="codes"></div><div class="docs"><pre><code>                            ctx
                             rule)]
(loop [d           demand           
       xs          candidates 
       fill-status :unfilled
       remaining   (d/required d)
       current-ctx ctx]
  (do ;(println remaining)
      (cond (zero? remaining)      [:filled     current-ctx]
            (empty? xs)            [fill-status current-ctx]
            :else  
            (let [
                  nextctx (fill-demand d current-ctx (first xs))   ;;first/next recursion slow.
                  nextd (-&gt; (core/get-demandstore nextctx)
                            (dem/get-demand demand-name))]
              (recur nextd (rest xs) :added-fill (unchecked-dec remaining) nextctx)))))))
</code></pre>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.deployment" name="marathon.ces.deployment"><h1 class="project-name">marathon.ces.deployment</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Deploying entities requires operating on multiple systems.  This namespace
builds on the services provided by supply, demand, and policy, to coordinate 
changes to the simulation context necessary to physically allocate supply to 
demand - or to execute deployments. <br />
Primarily used by <strong>marathon.sim.fill</strong> .</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.deployment
  (:require [marathon.demand [demanddata :as d]]
            [marathon.supply [unitdata :as udata]]
            [marathon.ces    [core :as core] [demand :as dem] 
                             [policy :as policy] [supply :as supply] 
                             [unit :as u]]
            [marathon.data   [protocols :as protocols]]
            [spork.entitysystem.store :as store]
            [spork.sim       [simcontext :as sim]]
            [spork.util      [tags :as tag]]))</pre></div><div class="docs"><h1>Functions for Deploying Supply</h1>

<p>(defn get-max-bog [unit policystore]
  (let [bog-remaining (udata/unit-bog-budget unit)
        p             (:policy unit)
        p             (if (protocols/policy? p) p
                          (policy/get-policy    (-> unit :policy :name) policystore))
        ]
    (- bog-remaining  (protocols/overlap p))))</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn location-based-policy? [d]
  (and (:StartState d) (:EndState d)))</pre></div><div class="docs"><p>These seem like lower level concerns.....
Can we push this down to the unit entity behavior?
Let that hold more of the complexity?  The unit can be responsible
for the bulk of the implementation detail of what a
deployment entails...
Since units have access to the simulation context, like
every other system, they could apply all the updating necessary.
Now, we move the updates into a behavior function, where
we can more efficiently handle the state updates...
For instance, we can perform bulk updates with the same
or a simular behavior context.....this is more appealing.</p>
</div><div class="codes"><pre class="brush: clojure">(defn deploy!  [followon? unit demand t ctx]
  (let [supply (core/get-supplystore ctx)
        newlocation (:name demand)        
        ]
    (cond (location-based-policy? demand)  (u/location-based-deployment unit demand ctx) ;;allow location to override policy.
          followon?    (let [newctx  (supply/record-followon supply unit newlocation ctx)
                             newunit (store/get-entity newctx (:name unit))] ;;we've updated the unit at this point...               
                         (u/re-deploy-unit  newunit  demand t (or (:deployment-index unit) 0) newctx))
          :else 
          (u/deploy-unit unit demand  t (or (:deployment-index unit) 0) ctx))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn check-first-deployer!   [store unitname ctx]
  (let [unit (supply/get-unit store unitname)]  
    (if (supply/first-deployment? unit store)
      (-&gt;&gt; (core/set-supplystore ctx (supply/tag-as-deployed unit store))
           (supply/first-deployment! store unit)
           (supply/adjust-max-utilization! store unit)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def last-deploy (atom nil))</pre></div><div class="docs"><p>Deploys a unit entity, registered in supply, at time t, to demand.  The 
   expected length of stay, bog, will determine when the next update is 
   scheduled for the unit.  Propogates logging information about the context 
   of the deployment.</p>

<p>TODO# fix bog arg here, we may not need it.  Also drop the followon?
arg, at least make it non-variadic..</p>
</div><div class="codes"><pre class="brush: clojure">(defn deploy-unit
  ([ctx unit t demand   followon?]
   (if (not  (u/valid-deployer? unit))
     (do (reset! last-deploy [unit ctx])
         (throw (Exception. (str [:unit (:name unit) :invalid-deployer &quot;Must have bogbudget &gt; 0, 
     cycletime in deployable window, or be eligible or a followon  deployment&quot;]))))
    (core/with-simstate [[supplystore parameters policystore demandstore fillstore] ctx]
      (let [fillcount     (count (:fills fillstore))         
            unitname      (:name unit)
            ;;This may be a little problematic.  We're pre-loading the move.
            ;;It may be more idiomatic to delegate the move to the entity behavior system.
            from-location (:locationname    unit) ;may be extraneous
            from-position (:position-policy unit);
            to-location   (:name demand)
            ;;Some demands have a special position associated with them...
            to-position   :deployed
            unit-delta    {:position-policy to-position
                           :dwell-time-when-deployed (udata/get-dwell unit)}
            unit          (merge unit ;MOVE THIS TO A SEPARATE FUNCTION? 
                                 unit-delta)
            ;;TODO - rip out all stuff relate to fencing....no longer necessary.
            supplystore   (assoc supplystore :tags  (supply/drop-fence (:tags supplystore)
                                                                       unitname))
            ]
        ;;Ideally, we don't store the entire unit under units-assigned, only the name.
        (-&gt;&gt; ;;modified to just store unitname.
             (store/updatee ctx to-location :units-assigned assoc unitname unitname) ;need to update this in ctx..  ;;estore version.       
             (sim/merge-entity {unitname     unit-delta
                                ;;TODO - rip out all stuff relate to fencing....no longer necessary.
                                :SupplyStore {:tags (:tags supplystore)} ;(supply/add-unit supplystore unit)
                                })                       
             (deploy! followon?  unit demand t)  ;;apply state changes.)))))
  ([ctx unit t demand]
    (deploy-unit  ctx unit t demand (core/followon? unit))))</pre></div><div class="docs"><p>another option here..is to use the system approach.  We look for entities that have a
pending deployment component, and process them.  A pending deployment component could
include the name of the target demand, so we can lookup information we need for it.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn deploy-units [ctx us d]
  (let [t      (core/get-time ctx)
        period (:name (policy/get-active-period (core/get-policystore ctx)))
        ;cnt   (atom (store/gete ctx :SupplyStore :deployment-count 0))
        ]
    ;(-&gt;
     (reduce (fn [acc u]
                   (let [res (deploy-unit acc u t d ;period
                                          ;@cnt)]
                         ;_ (swap! cnt unchecked-inc)]
                     res))
                 ctx us)
         ;(store/assoce :SupplyStore :deployment-count @cnt)))</pre></div><div class="docs"><p>)</p>
</div><div class="codes"><pre class="brush: clojure">(comment   
           
           
           (u/deploy-unit unit t (supply/get-next-deploymentid supplystore))
           (check-first-deployer! supplystore unitname) ;THIS MAY BE OBVIATED.
           (supply/update-deployability unit false false) 
           (supply/log-deployment! t from-location demand unit fillcount filldata 
                                   deploydate (policy/find-period t policystore))
           (supply/supply-update! supplystore unit nil))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.demand" name="marathon.ces.demand"><h1 class="project-name">marathon.ces.demand</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>The demand system provides functions for scheduling demands, as well as 
defining the order in which demands are filled.  The namespace contains 
primitive functions for operating on demandstores, as well as demand-related
notifications and a high-level demand management API. <br />
Functions for creating, initializing, resetting, and updating state related to
the demand simulation are also found here.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.demand
  (:require  [marathon.demand [demanddata :as d]]
             [marathon.ces    [core :as core] 
                              [supply :as supply] 
                              [policy :as policy]
                              [unit :as u]]
             [spork.entitysystem.store :as store
              :refer [gete assoce mergee assoc-ine updatee get-entity add-entity drop-entity
                      update-ine update-entity get-ine] ]
             [spork.sim       [simcontext :as sim]]
             [spork.ai.core :refer [debug]]
             [spork.util      [tags :as tag] [general :as gen] [temporal :as temporal]]))</pre></div><div class="docs"><h2>Primitive Demand and DemandStore Operations</h2>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn can-simulate? [demandstore]
  (&gt; (count (tag/get-tags (:tags demandstore) :enabled)) 0))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn add-fillable [fillrule demandstore]
  (assert (not (contains? (-&gt; demandstore :fillables) fillrule))  
          &quot;Tried to add fillrule multiple times&quot;)
  (gen/deep-update demandstore [:fillables] conj fillrule))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn remove-fillable [fillrule demandstore]
  (assert (contains? (-&gt; demandstore :fillables) fillrule)  
          &quot;Tried to remove non-existent fillrule&quot;)
  (gen/deep-update demandstore [:fillables] disj fillrule))</pre></div><div class="docs"><p>I think we can alter this to push to the entitystore instead of
the demandmap....
All the calls to add-demand need to be changed though...
the demandstore is now the ctx itself...
it's actually okay if we can tree the entitystore as
a demandstore - this works out okay with the existing api.
Actually, get-demandstore is just identity then....
Another option, which may seem wierd, is that we add a
reference to the parent context (Although we may
screw up gc)....
So, if the demandstore's parent is the entitystore,
if we get the demandstore, and the dstore has a ctx
reference, we can just shim demandstore operations to
that....</p>
</div><div class="codes"></div><div class="docs"><p>TOM ADDED 30 MAy 2013 </p>
</div><div class="codes"><pre class="brush: clojure">(defn add-demand [demandstore demand]
  (gen/deep-assoc demandstore [:demandmap (:name demand)] demand))</pre></div><div class="docs"><p>notice, we manage change notifications by
munging state inside the demandstore....
How about we manage change altogether at
the end of the day?
DEPRECATED
(defn manage-changed-demands [day state] ;REDUNDANT
  (gen/deep-assoc state [:demand-store :changed] {}))
DEPRECATED
(defn clear-changes [demandstore] (assoc demandstore :changed {}))</p>
</div><div class="codes"></div><div class="docs"><p>Might think about elevating this..
Alternately, we could have a "dirty" component.
That keeps track of entities that are known to have
changed...</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-change [demandstore demandname]
  (if (contains? (:changed demandstore) demandname)
    demandstore 
    (gen/deep-assoc demandstore [:changed demandname]  0)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn active-demand? [demandstore demandname]
  (contains? (get demandstore :activedemands) demandname))</pre></div><div class="docs"><p>TOM Note 20 May 2013 -> need to abstract fillrule, etc. behind a function, 
preferably one that uses keywords.
inject appropriate tags into the GenericTags</p>
</div><div class="codes"><pre class="brush: clojure">(defn tag-demand 
  ([demand demandstore extras]
     (-&gt;&gt; (tag/multi-tag (:tags demandstore) 
                         (:name demand) 
                         (into   [(core/msg &quot;FILLRULE_&quot; (:src demand)) ;USE KEYWORD
                                  (core/msg &quot;PRIORITY_&quot; (:priority demand)) ;USE KEYWORD
                                  :enabled]
                                  extras))
          (assoc demandstore :tags)))
  ([demand demandstore] (tag-demand demand demandstore nil)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn tag-demand-sink [demandstore sink]
  (gen/deep-update demandstore [:tags] tag/tag-subject  :Sinks sink))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-demand-sinks [demandstore] 
  (tag/get-subjects (:tags demandstore) :Sinks))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn clear-demands [demandstore] ;REDUNDANT?
  (merge demandstore
         {:demandmap {}
          :tlastdeactivation nil
          :unfilledq {}
          :activations {}
          :active-demands {}
          :fillables {}
          :tags (tag/add-tag tag/empty-tags :Sinks)}))</pre></div><div class="docs"><p><strong>TODO</strong> Possibly move unit-related functionality to supply/unit simulations..</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn set-followon [unit code] (assoc unit :followoncode code))
(defn ghost? [unit] (= (:src unit) &quot;Ghost&quot;))
(defn ungrouped? [g] (= g &quot;UnGrouped&quot;))
(defn unit-count [d] (count (:units-assigned d)))
(defn demand-filled? [d] (= (count (:units-assigned d)) (:quantity d)))
(defn empty-demand? [d] (zero? (unit-count d)))
(defn priority-key [demand] [(:name demand) (:priority demand)]) </pre></div><div class="docs"><p>We can break the fill into a couple of simple queries...</p>

<p>we've got a category of demand...
This is a priorityq of unfilled demands.
We traverse the priorityq in priority order, trying to fill.
If we can't fill, or only partially fill the next demand, we stop traversing.
enforces the hierchical fill constraints. 
so...filling a category implies traversing a sorted map of unfilled demands. 
note -> we can modify the sorting key to include followon information, to make 
things homogenous, just adding a special comparison function. </p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn unfilled-categories [demandstore] 
  (keys (:unfilledq demandstore)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn unfilled-demandnames [category demandstore]
  (get-in demandstore [:unfilledq category]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn unfilled-demands
  ([category demandstore ctx]
    (into (sorted-map)
          (for [[k nm] (unfilled-demandnames category demandstore)]
            [k (store/get-entity ctx nm)])))
  ([category demandstore]
   (if-let [ctx (:ctx (meta demandstore))]
     (unfilled-demands category demandstore ctx)   
     (throw (Exception. (str [:no-context-in-meta]))))))</pre></div><div class="docs"><p>Query to support requirements analysis and the like.
   If we have unfilled demands, we report the quantity 
   of misses by category.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unfilled-demand-count
  [ctx]
  (for [[cat d-pris] (:unfilledq (core/get-demandstore ctx))
        [priority id] d-pris]
    (let [{:keys [quantity src units-assigned]} (store/get-entity ctx id)]
      {:id id :src src
       :category cat  :unfilled (- quantity (count units-assigned))})))</pre></div><div class="docs"><p>Right now, we're storing demands in their entirety in the demandmap...
We really just want to store the entity's name...
Optionally, we can elevate this to a core function, using the
store, and from there, we have access to the demand from a sole source...
I think that's the best thing to do...</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-demand [demandstore name]
  (store/get-entity (:ctx (meta demandstore)) name))</pre></div><div class="docs"><p>Simple api function to group active demands from the store by their src. </p>
</div><div class="codes"><pre class="brush: clojure">(defn demands-by-src [store src] (get-in store [:unfilledq src]))</pre></div><div class="docs"><p>Looks like this is the only one that's holding demand information...</p>
</div><div class="codes"></div><div class="docs"><p>1) Tom Note 20 May 2013 -> It would be nice to have a function or macro for 
  defining nested updates like this, as it will probably happen quite a bit.</p>
</div><div class="codes"><pre class="brush: clojure">(defn remove-demand [demandstore demandname]
  (if (contains? (:demandmap demandstore) demandname)
    (let [{:keys [activations deactivations demandmap]} demandstore
          demand (get demandmap demandname)
          dname  (:name demand)
          tstart (:startday demand)
          tfinal (+ tstart (:duration demand))]
      (-&gt; demandstore                                                        ;1)
        (gen/deep-update [:demandmap] dissoc    dname)
        (gen/deep-update [:activations tstart]   dissoc dname)
        (gen/deep-update [:deactivations tfinal] dissoc dname)))
    demandstore)) </pre></div><div class="docs"><p>procedure that allows us to process a set of tags indicating associated demands
that should be disabled.  if removal is true, the demands will be 
removed from memory as well. in cases where there are a lot of demands, this 
may be preferable.</p>
</div><div class="codes"><pre class="brush: clojure">(defn scope-demand [demandstore disable-tags &amp; {:keys [removal]}]
  (let [tags    (:tags demandstore)
        f       (if removal #(remove-demand %1 %2) (fn [m k] m))]     
    (reduce (fn [store demand-name] 
              (let [demands (:demandmap store)]
                (if (contains? demands demand-name)
                  (f (core/disable store demand-name) demand-name) store)))
      demandstore (mapcat (partial tag/get-subjects tags) disable-tags))))</pre></div><div class="docs"><p>Simple wrapper for demand update requests.  </p>
</div><div class="codes"><pre class="brush: clojure">(defn request-demand-update! [t demandname ctx]
  (sim/request-update t demandname :demand-update ctx))</pre></div><div class="docs"><h1>Demand Notifications</h1>
</div><div class="codes"><pre class="brush: clojure">(defn request-fill! [demandstore category d ctx]
  (core/trigger-event :RequestFill (:name demandstore) (:name demandstore)
     (core/msg &quot;Highest priority demand in Category &quot; category &quot; is &quot; (:name d) 
          &quot; with priority &quot; (:priority d)) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn trying-to-fill! [demandstore category ctx] 
  (core/trigger-event :RequestFill (:name demandstore) (:name demandstore) 
     (core/msg &quot;Trying to Fill Demand Category &quot; category) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn fill-demand! [demandstore demandname ctx]
   (core/trigger-event :FillDemand (:name demandstore) (:name demandstore)
      (core/msg &quot;Sourced Demand &quot; demandname) nil ctx ))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn can-fill-demand! [demandstore demandname ctx]
  (core/trigger-event :CanFillDemand (:name demandstore) 
       demandname (core/msg &quot;Completely Filled &quot; demandname) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn demand-fill-changed! [demandstore demand ctx]
  (core/trigger-event :DemandFillChanged (:name demandstore) (:name demand) 
     (core/msg &quot;The fill for &quot; (:name demand) &quot; changed.&quot;) demand ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn sourced-demand! [demandstore demand ctx]
  (core/trigger-event :FillDemand (:name demandstore) (:name demandstore) 
     (core/msg &quot;Sourced Demand &quot; (:name demand)) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn activating-demand! [demandstore demand t ctx]
  (let [demandname (:name demand)]
    (core/trigger-event :ActivateDemand (:name demandstore)  demandname
                       (core/msg &quot;Activating demand &quot; demandname &quot; on day &quot; t) nil ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn deactivating-demand! [demandstore demand t ctx]
  (let [dname (:name demand)]
    (core/trigger-event :DeActivateDemand (:name demandstore) dname
       (core/msg &quot;DeActivating demand &quot; dname &quot; on day &quot; t) dname ctx)))</pre></div><div class="docs"><p>Look into unifying this with deactivating-unfilled....seems redundant.</p>
</div><div class="codes"><pre class="brush: clojure">(defn deactivating-empty-demand! [demand t ctx]
  (core/trigger-event :DeActivateDemand :DemandStore (:name demand)  
       (core/msg &quot;Demand &quot; (:name demand) &quot; Deactivated on day &quot; t
            &quot; with nothing deployed &quot;) nil ctx))    </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn deactivating-unfilled! [demandstore demandname ctx] 
  (core/trigger-event :DeActivateDemand (:name demandstore) demandname 
       (core/msg &quot;Demand &quot; demandname &quot; was deactivated unfilled&quot;) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn removing-unfilled! [demandstore demandname ctx] 
  (core/trigger-event :FillDemand (:name demandstore) demandname
     (core/msg &quot;Removing demand &quot; demandname &quot; from the unfilled Q&quot;) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn adding-unfilled! [demandstore demandname ctx] 
  (core/trigger-event :RequestFill (:name demandstore) demandname  ;WRONG                   
     (core/msg &quot;Adding demand &quot; demandname &quot; to the unfilled Q&quot;) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ghost-returned! [demand unitname ctx]
  (core/trigger-event :GhostReturned (:src demand) unitname 
     (core/msg &quot;Ghost for src &quot; (:src demand) &quot; left deployment.&quot;) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn sending-home! [unitname ctx] 
  (core/trigger-event :supply-update :DemandStore unitname 
     (core/msg &quot;Send Home Caused SupplyUpdate for &quot; unitname) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn disengaging! [demand unitname ctx]
  (core/trigger-event :DisengageUnit :DemandStore unitname 
     (core/msg &quot;Disengaging unit&quot; unitname &quot; from de-activated demand&quot; 
        (:name demand)) nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn disengaging-home! [demandstore demand unit ctx]
  (core/trigger-event :DisengageUnit (:name demandstore)  (:name unit) ;WRONG
     (core/msg &quot;Sending unit&quot; (:name unit) 
          &quot;home from demand&quot; (:name demand)) unit ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn overlapping! [demandstore demand unit ctx]
  (core/trigger-event :overlapping-unit (:name demandstore) (:name unit)
        (core/msg &quot;Overlapping unit&quot; (:name unit) &quot; in demand&quot; 
             (:name demand)) unit ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn registering-demand! [demand ctx]
  (core/trigger-event :added-demand &quot;DemandStore&quot; &quot;DemandStore&quot; 
                     (core/msg &quot;Added Demand &quot; (:name demand)) nil ctx))</pre></div><div class="docs"><p>We can revisit this in the entitystore context in the future...
Can probably store this in a flatter context.</p>

<h1>Demand Registration and Scheduling</h1>
</div><div class="codes"><pre class="brush: clojure">#_(defn get-activations   [dstore t]
  (let [dmap (:demandmap dstore)]
    (set (filter dmap (get-in dstore [:activations t] nil)))))
(defn get-activations   [dstore t]
  (let [dmap (:demandmap dstore)
        outer (.valAt ^clojure.lang.ILookup dstore :activations)
        inner (.valAt ^clojure.lang.ILookup outer t)]
    (set (filter dmap inner))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn set-activations   [dstore t m] (gen/deep-assoc dstore [:activations t] m)) ;;requires a double assoc.</pre></div><div class="docs"><p>requires a double assoc.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-deactivations [dstore t]
  (let [dmap (:demandmap dstore)]
    (set (filter dmap  (get-in dstore         [:deactivations t] nil)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn set-deactivations [dstore t m] (gen/deep-assoc dstore [:deactivations t] m))</pre></div><div class="docs"><p>TOM note 27 Mar 2011 ->  I'd like to factor these two methods out into a single 
function, discriminating based on a parameter, rather than having two entire 
methods.
Register demand activation for a given day, given demand.
TOM Change 7 Dec 2010</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-activation [t demandname dstore]
  (let [actives (get-activations dstore t)]
    (set-activations dstore t (conj actives demandname))))</pre></div><div class="docs"><p>Register demand deactviation for a given day, given demand.
1)Tom Note 20 May 2013 -> Our merge-entity function looks alot like entity 
 updates in the component-based model.  Might be easy to port...</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-deactivation [t demandname demandstore]
  (let [inactives (get-deactivations demandstore t)
        tlast     (max (:tlastdeactivation demandstore) t)]   
    (-&gt; (assoc demandstore :tlastdeactivation tlast)
        (set-deactivations t (conj inactives demandname)))))</pre></div><div class="docs"><p>Schedule activation and deactivation for demand. -> Looks fixed.</p>
</div><div class="codes"><pre class="brush: clojure">(defn schedule-demand [demand demandstore ctx]
  (let [{:keys [startday name duration]} demand
        endday (+ startday duration)
        demandname (:name demand)]
    (-&gt;&gt; ctx
         (request-demand-update! startday demandname)
         (request-demand-update! endday demandname)
         (core/merge-entity 
          {:DemandStore
           (-&gt;&gt;  demandstore
                 (add-activation   startday name)
                 (add-deactivation endday name))}))))</pre></div><div class="docs"><p>Maybe we make this reaallllly simple and focused.  WE only use this 
when it makes sense for bulk updates.  There should be a few
hotspots where we're doing bulk updates (particularly updating
supply).</p>
</div><div class="codes"></div><div class="docs"><p>Can we efficiently register demands using this api?  Let alone 
anything else....</p>
</div><div class="codes"></div><div class="docs"><p>Another option....we have a dynamic var: <em>mutables</em> 
From we assoc all these guys on there...
Inside a transaction, when we create a mutable, we just 
assoc it to the existing mutables.
Then define functions that, when acquiring resources, prefer 
to use the mutable version first.
If the mutable version exists, operations like repacking are 
not necessary.
This brings us back to splicing alternate code paths.....where 
we have a mutable and an imperative version that are largely
identical.  Some of these are mitigated by unifying assoc 
and friends...</p>
</div><div class="codes"></div><div class="docs"><p>efficiently register demands...This is a trial run of the new cells 
API, to see what practical problems arise when we actually try to
use it!</p>
</div><div class="codes"></div><div class="docs"><p>At the very least, having an interface to call out high level 
mutation and push it to specific functions is nice....better than 
what was there...
(comment) </p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn register-demand! [ctx demand demands dstore pstore]
  (assert false &quot;Only use persistent version for now pls..&quot;)
  (let [demand   (core/ensure-name demand demands)
        dname    (core/entity-name   demand) ;;replace with entity-name                      
        newstore (tag-demand demand (add-demand dstore demand))
        _        (policy/register-location dname pstore)]
    (-&gt;&gt; (store/add-entity ctx demand)
         (registering-demand! demand)     ;;doesn't care.         
         ;;this should still be fast.  Alternately just modify locs directly...
         (schedule-demand demand newstore))))  </pre></div><div class="docs"><p>Note -> there's a setup here for bad things to happen.  I forgot
that the reduction function I was using, while happily
side-effecting as an optimization, was actually tossing out 
(i.e. not aggregating) the activation and deactivations for 
the demands.  Good news was it wasn't a bug in the cellular 
stuff, it was a bug in my logic...I was retaining persistent 
information in dstore.  So, the net effect is that if you 
want to take advantage of fine-grained mutation, you have 
to call out where the mutation lies.  This could lead to some 
problems and oversight if we're not careful....</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-demands!
  ([register-f xs ctx]
    (assert false &quot;Only use persistent version for now pls..&quot;)
     ;;Cleaner representation, allow multiple cells to be defined in a
     ;;single binding.
     ;; (core/with-cells [{locations     [:state :policystore :locationmap]
     ;;                    demandtags    [:state :demandstore :tags]  
     ;;                    demands       [:state :demandstore :demandmap]
     ;;                    activations   [:state :demandstore :activations] ;forgot this guy, has
     ;;                    deactivations [:state :demandstore :deactivations]
     ;;                    :as txn}    ctx]
     ;;   (update-txn!
     ;;    (core/with-transient-cells [locations demandtags demands activations deactivations]
     ;;      (reduce  (fn [acc demand]                     
     ;;                 (-&gt; (register-demand! acc demand demands (core/get-demandstore acc) (core/get-policystore acc))
     ;;                     (register-f  demand))) txn xs)))))
  ([xs ctx] (register-demands! (fn [ctx d] ctx) xs ctx)))</pre></div><div class="docs"><p>(defn register-demands! 
  ([register-f xs ctx]
     ;;Cleaner representation, allow multiple cells to be defined in a
     ;;single binding.
     (core/with-cells [{locations     [:state :policystore :locationmap]
                        demandtags    [:state :demandstore :tags] <br />
                        demands       [:state :demandstore :demandmap]
                        activations   [:state :demandstore :activations] ;forgot this guy, has
                        deactivations [:state :demandstore :deactivations]
                        :as txn}    ctx]
       (update-txn!
        (core/with-transient-cells [locations demandtags demands activations deactivations]
          (let [pstore    (core/get-policystore txn) ;has mutable cells inside txn
                dstore    (core/get-demandstore txn) ;has mutable cells inside txn <br />
                ]
          (reduce  (fn [acc demand] <br />
                     (-> (register-demand! acc demand demands (core/get-demandstore acc) (core/get-policystore acc))
                         (register-f  demand))) txn xs))))))
  ([xs ctx] (register-demands! (fn [ctx d] ctx) xs ctx)))</p>
</div><div class="codes"></div><div class="docs"><p>Non-mutable version...</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-demand 
  ([demand demandstore policystore ctx]
     (let [dname    (:name demand)
           newstore (tag-demand demand (add-demand demandstore demand))]
       (-&gt;&gt; (store/add-entity ctx (:name demand) demand)
            (registering-demand! demand)
            (core/merge-entity {:PolicyStore (policy/register-location dname policystore)})
            (schedule-demand demand newstore))))
  ([demand ctx] (register-demand demand (core/get-demandstore ctx)
                                 (core/get-policystore ctx) ctx)))</pre></div><div class="docs"><p>persistent version is back for now...</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-demands
  [xs ctx] (reduce (fn [acc d] (register-demand d acc) ) ctx xs))</pre></div><div class="docs"><p>another way to look at this guy is that we're modifying disparate
domains via a transaction.  Specifically, we're working on multiple
things simultaneously.</p>
</div><div class="codes"></div><div class="docs"><p>Maybe we create a transactional system that understands how to
provide mutable references for processing "inside" the transaction.
This is like STM....transactions expect to have access to 
resources so they can do their jobs.  So we can provide a 
transactional context, to decouple the "storage" of stuff from 
the processing of stuff.  This is close to how the entity system 
decouples component data from how that data is operated on in 
systems.</p>
</div><div class="codes"></div><div class="docs"><p>In an ideal world, we'd really just love to have a flat map of 
resources, or bindings, that form the local transactional context.
Given that, we can drastically simplify the operations...i.e. 
a transactional function operates on a map and returns a map.
What can transactions do? 
 Some times we want to add resources to the transaction, i.e.
 establish a handle to them for bulk-loading or more efficient 
 processing (via mutation).  Maybe we just don't want to pay 
 the lookup cost over and over again. <br />
 These resources should be shared within a transaction....;
 In other words, we allow transactions to a) bind resources 
 to the transactional context, b) fetch resources from 
 the transactional context, and c) commit resources to the 
 transactional context. </p>
</div><div class="codes"></div><div class="docs"><p> Under this paradigm, we spend time defining "where" resources 
 are, and "how" to acquire them -> the current example is 
 using the cells methodolgy to establish resource paths in 
 nested maps.  This is a clean divide between acquiring and 
 freeing resources...</p>
</div><div class="codes"></div><div class="docs"><p> Transactions can "assume" they have access to everything 
 they need, along with facilities for altering the transactional 
 context.  When this assumption is violated, we can bomb out 
 with an error.  This is akin to a transactional contract.</p>
</div><div class="codes"></div><div class="docs"><h1>simple contract, but gets us away from simple, focused computation.</h1>

<p> Thus, transactional functions operate without any consideration 
 of how the resources are managed.  They retain the pure functional
 aspect of the current design.  We know what the "input" contract
 is explicitly:  transactional functions request specific resources 
 from the context, and if those do not exist, they bomb.</p>
</div><div class="codes"></div><div class="docs"><p> What about the output contract?  What should a transactional 
 function "return"?  Perhaps a sequence of effects, if any? <br />
 At the very least, it needs to return the transactional 
 context.  This lets us define a monadic setting for operating 
 on this stuff.  It also keeps the interface uniform, akin to 
 the state monad.  Transactors take a context, and other args, 
 and return the context.  This is pretty consistent with the 
 majority of our functions that operate on simstate, but 
 small auxillary functions are - currently - at a loss.
 The aux functions like those in sim.demand, expect to 
 operate on demandstore's for the most part, or policystores.
 We can (and do) pack that into the transactional context.
 However, </p>
</div><div class="codes"></div><div class="docs"><p>utility function....</p>
</div><div class="codes"><pre class="brush: clojure">(defn pop-priority-map [m]
  (if (empty? m) m (dissoc m (first (keys m)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn drop-unfilled-demand [demandstore demand  ctx]
  (let [unfilled (:unfilledq   demandstore)
        src      (:src demand)
        fill-key (priority-key demand)]
        ;;basically - drop-unfilled-demand
    (cond (contains? unfilled src) ;either filled or deactivated
              (let [demandq      (get unfilled src)
                    nextq        (dissoc demandq fill-key)
                    nextunfilled (if (zero? (count nextq))
                                   (dissoc unfilled src) 
                                   (assoc  unfilled src nextq))]
                (-&gt;&gt; (removing-unfilled! demandstore (:name demand) ctx)
                     (core/merge-entity {:DemandStore (assoc demandstore :unfilledq nextunfilled)})))
           (not (:active demand))
                 (deactivating-unfilled! demandstore (:name demand) ctx)     ;notification
       :else ctx)  ;;nothing to change..))</pre></div><div class="docs"><p>Register the unfilled demand entity and update the demandstore's unfilled.  We
just track the name of the entity.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-unfilled-demand [demandstore demand ctx]
  (let [unfilled  (:unfilledq   demandstore)
        src       (:src demand)
        demandq   (or (get unfilled src) (sorted-map))
        fill-key  (priority-key demand)
        _ (debug [:adding fill-key :to src ;:/ demandq
                  ])
        ]  
    (if (contains? demandq fill-key) ctx ;pass-through
        (-&gt;&gt; (core/merge-entity ;add to unfilled 
              {:DemandStore 
               (gen/deep-assoc demandstore [:unfilledq src] 
                               (assoc demandq fill-key (:name demand)))} ctx) ;WRONG?
             (adding-unfilled! demandstore (:name demand))))))</pre></div><div class="docs"><h1>Managing the Fill Status of Changing Demands</h1>

<p>Unfilled demands exist in a priority queue, UnfilledQ, ordered by the demand's 
priority field value - typically an absolute, static ordering, set at 
construction. <br />
UnfilledQ partitions the set of active demands that are unfilled.
When we go to look for demands that need filling, we traverse keys in 
priority order. <br />
We use a priority queue to effeciently respond to changes in a demand's fill 
status, and to only try to fill demands when we need to.  Older algorithms 
naively polled the demands, and led to quadratic complexity.  In this case, 
the priority queue lets us implement a push algorithm, and if we're filling 
hierarchically, we can terminate the fill process early if we fail to satisfy
a demand.  </p>
</div><div class="codes"></div><div class="docs"><p>Derives a demand's fill status based on its current data.  Satisfied demands 
   are removed from the unfilled queue, unsatisfied demands are kept or added to
   the unfilled queue.  Deactivating unfilled demands are detected as well.
   Propogates notifications for each special case.</p>

<p>Basic demand events are Activation, Deactivation, Fill, Unfill.
Activation and unfill events manifest in demandnames being added to the 
unfilledQ. Deactivation and filled events manifest in demandnames being 
removed from the unfilledQ. We want to effeciently find out if 
there are unfilled demands,  what the most important unfilled demand is, 
and what happens when we fill the demand (take the demand off the q or not?)
Using the fill queue, the update-fill function provides a general hub to 
enforce these invariants.  You'll see it get used a bit when we make changes
to a demand, either filling, activating, etc.  It applies the appropriate 
processing to keep a demand's fill status consistent.
TODO# Simplify this guy?  Maybe break up the detection phase by
activated/deactivated....</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-fill
  [demandstore demandname ctx]
  (let [demand   (store/get-entity ctx demandname)]
    (cond  (nil? (:src demand)) (throw (Exception. (str &quot;NO SRC for demand&quot; demandname)))
           (nil? demandname)    (throw (Exception. (str &quot;Empty demand name! &quot; demandname)))
           :else
           (let [ _ (debug [:updfill demandname :required (d/required demand)
                           ; :quantity (:quantity demand)
                           ; :assigned (:units-assigned demand)
                           ; :overlapping (:units-overlapping demand)
                            ])]
             ;;The demand is inactive or has no fill, either way we should remove it from fill consideration.
             (if (or (zero? (d/required demand))  ;;if we move to components, active-demand? doesn't need the store..
                     (not (:active demand))) ;demand is filled, remove it
               (drop-unfilled-demand demandstore demand ctx)        
               ;;basically - add-unfilled-demand
                                        ;demand is unfilled, make sure it's added
               (add-unfilled-demand demandstore demand ctx))))))</pre></div><div class="docs"><h2>Describing Categories of Demand To Inform Demand Fill Rules</h2>

<p>Demands have typically been binned into gross categories, based on the type 
of capability required to meet a demand.  Additional complexities arose as
subcategories - such as the notion of follow-on demands - became a necessity.
This resulted in a multi-phase fill process: where we initially selected 
demands to fill based on a simple priority - supplied by the user - we quickly
found a set of conditional or meta priorities that required "trying to fill"
a class of demands - follow-on eligible demands - with supply first.  This 
mapped to the need to utilize pre-deployed supply to avoid incidental waste of 
resources, when pre-deployed supply - supply already local to the demand - 
could be flowed directly to compatible concurrent local demands. 
The need to utilize a special class of supply resulted in a duplication
of the fill logic, where the first "phase" tried to exhaust all follow-on 
supply, with the second or general phase determining demand priority under 
a simple priority scheme.   </p>
</div><div class="codes"></div><div class="docs"><h1>Categories are a Little Language for Relating Supply to Demand</h1>

<p>As the potential for additional "special cases" of fill arose, it became 
obvious that a general mechanism for unambiguously describing cases would 
simplify the filling logic, and allow for future rule expansions.
After a lengthy thinking cycle, I resolved to define a useful little language
for describing categories, that is, elements of demand and the contextual 
information for how they should be filled.  Categories are encoded as simple 
clojure data structures, and interpreted by both the demand system and the 
supply system to affect queries.  Thus, they act as a cross-domain 
protocol for matching and ordering entities.</p>
</div><div class="codes"></div><div class="docs"><p>This should eliminate a slew of duplication and complexity from the legacy 
implementation, since we can use the category of fill to select eligible 
demands, and to inform suitability of supply.  </p>
</div><div class="codes"></div><div class="docs"><h1>Category Examples</h1>
</div><div class="codes"></div><div class="docs"><p>In the simple case, when the category is a string, or a key, we act like 
normal filling..
<strong>(fill-category "SRC2")</strong> 
=> find all eligible demands for SRC2.</p>
</div><div class="codes"></div><div class="docs"><p>In a complex case, when the category is a sequence, we parse it according to 
the following:
Pairs define a more constrained category, which is interpreted as a category 
of SRC and a grouping.  </p>
</div><div class="codes"></div><div class="docs"><p><strong>(fill-category ["SRC2" "Group1"])</strong> 
=> find the eligible demands for SRC2, where the demand group is group1.</p>
</div><div class="codes"></div><div class="docs"><p>If the category rule is a pair, and the second element is also a sequence, 
the sequence is parsed as a simple set filter.  The second element then forms
a union query that can incorporate multiple demand groups into the criteria.</p>
</div><div class="codes"></div><div class="docs"><p><strong>(fill-category ["SRC2" ["Group1" "Group2"]])</strong> 
=> find the eligible demands for SRC2, where the demand group is either Group1 
or Group2.</p>
</div><div class="codes"></div><div class="docs"><p>Detailed categories come in the forms of maps, which are interpreted as a 
category pair, and a set of filters by default.  We can use tags to create 
general filters as well, which should let us create a unique set of queries.
A trivial (and useful) extension will be to allow arbitrary tags to be 
included.  For instance, the map associated with the :supply-tags key in the 
example could result in an additional tag query to be executed against 
candidate supply.</p>
</div><div class="codes"></div><div class="docs"><p>(fill-category {:demand {:src "SRC1" :demandgroup "Group2"} <br />
               :supply-tags {:just-in-time :state-side}})  </p>
</div><div class="codes"></div><div class="docs"><p>Categories serve to link supply AND demand, since categories are parsed by 
ISupplier functions into supply ordering queries.
For example,  from the supply-side, we determine which supply is eligible to 
fill an ["SRC1" "Group2"] category of demand: <br />
By default, the query should look for supply matching "SRC1", and all feasible
substitutes for "SRC1", where the constraint that the supply followon code 
also equals "Group2".</p>
</div><div class="codes"></div><div class="docs"><p>Categories can be interpreted an arbitrary number of ways, but the preceding
conventions should cover both the 90% use cases, for simple SRC matches, and 
almost unlimited extensibility via encoding categories as maps, to be 
interpreted by an ISupplier.  This also simplifies the demand fill logic, 
since we can implement the same "phased" or hierarchical fill process by 
encoding the information in the category being filled.  The solution to the 
existing "follow-on" fill still provides a phased fill approach, but it uses
the same demand ordering function (rather than duplicating and slightly 
modifying).  This makes it possible to define a plethora of filling schemes
by either querying or building demand categories, and composing eligibilty 
functions in a desired order.</p>
</div><div class="codes"></div><div class="docs"><h1>Demand Category Methods</h1>

<p>Categories are used by two new functions: <strong>find-eligible-demands</strong> , 
defined here, and <strong>find-supply</strong>,  defined in marathon.sim.fill.</p>
</div><div class="codes"></div><div class="docs"><p>placeholder for allowing out of order definitions, defined later.</p>
</div><div class="codes"><pre class="brush: clojure">(declare find-eligible-demands)</pre></div><div class="docs"><p>Note -> <strong>find-eligible-demands</strong> is...in a general sense, just a select-where 
query executed against the demandstore...        </p>
</div><div class="codes"><pre class="brush: clojure">(defmulti category-&gt;demand-rule core/category-type)</pre></div><div class="docs"><p>Interprets a category as a rule that finds demands based on an src.
Note -> we should probably decouple the get-in part of the definition, and 
hide it behind a protocol function, like get-demands.  </p>
</div><div class="codes"><pre class="brush: clojure">(defmethod category-&gt;demand-rule :simple [src]
  (fn [store ctx] (get-in store [:unfilledq src]))) ;priority queue of demands.</pre></div><div class="docs"><p>priority queue of demands.</p>
</div><div class="codes"></div><div class="docs"><p>Interprets a category as a composite rule that matches demands based on an 
src, and filters based on a specified demand-group.
[src demandgroup|#{group1 group2 groupn}|{group1 _ group2 _ ... groupn _}]  </p>
</div><div class="codes"><pre class="brush: clojure">(defmethod category-&gt;demand-rule :src-and-group [[src groups]]
  (let [eligible? (core/make-member-pred groups)] ;make a group filter
    (fn [store ctx]
      (-&gt;&gt; (seq (find-eligible-demands store src ctx)) ;INEFFICIENT
        (filter (fn [[pk d]] (eligible? (:demandgroup d))))
        (into (sorted-map)))))) ;returns priority-queue of demands.</pre></div><div class="docs"><p>returns priority-queue of demands.</p>
</div><div class="codes"></div><div class="docs"><p>matches {:keys [src group]}, will likely extend to allow tags...
Currently, provides a unified interface for rules, so we can just use simple 
maps. Should probably migrate other calls to this simple format.</p>
</div><div class="codes"><pre class="brush: clojure">(defmethod category-&gt;demand-rule :rule-map [category]
  (let [has-every-key? (comp every? #(contains? category %))]
    (cond (has-every-key? [:src :groups]) 
             (category-&gt;demand-rule ((juxt :src :groups) category))  
          (has-every-key? [:src]) 
             (category-&gt;demand-rule (:src category))                  
          :else ;Future extensions.  Might allow arbitrary predicates and tags. 
             (throw (Exception. &quot;Not implemented!&quot;)))))      </pre></div><div class="docs"><h1>Finding Demands by Category</h1>

<p>High-level API to find a set of eligible demands that match a potentially 
complex category.  Uses the category->demand-rule interpreter to parse the 
rule into a query function, then applies the query to the store.</p>
</div><div class="codes"></div><div class="docs"><p>Given a demand store, and a valid categorization of the demand, interprets
   the category into a into a demand selection function, then applies the query
   to the store.</p>

<p>Tom update 19 May 2016 -> used to return [[pk demand]] map, but
now it implictly returns [[pk demandname]] map, so we need to add a layer
to get the actual demands...</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-eligible-demands 
  [store category ctx]
  (-&gt;&gt; ((category-&gt;demand-rule category) store ctx)
         (map (fn [[pk demand]] ;;if we only have demand names, we coerce them to demands.
                [pk (if (map? demand) demand (store/get-entity ctx demand))]))))</pre></div><div class="docs"><h2>Demand Scheduling</h2>

<p>In addition to serving demands for filling, scheduling demands for activation 
and deactivation is a primary service of the demand system.  The following 
functions define operations that pertain to the timing and updating of 
demands. </p>
</div><div class="codes"></div><div class="docs"><h1>Demand Activation</h1>

<p>Over time, we maintain a set of active demands which will help us only fill 
active demands. How do demands get added to the set? Upon initialization, we 
schedule their activation day and deactivation day (start + duration). During
the course of the simulation, we have a listener that checks to see if the 
current day is a day of interest, specifically if it's an activation day or
a deactivation day. </p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn activations? [t demandstore] 
  (contains? (:activations demandstore) t))
(defn deactivations? [t demandstore] 
  (contains? (:deactivations demandstore) t))</pre></div><div class="docs"><p>(defn  get-activations  [demandstore t] (get (:activations demandstore) t))
(defn  get-deactivations [demandstore t] (get (:deactivations demandstore) t))</p>
</div><div class="codes"></div><div class="docs"><p>activate-demand => add the demand to the active set.
update the fill for the active demand
more specifically - list the newly activated demand as unfilled.
  --given the demand's category, update the unfilled queue...
  --alternative, sort demands as needed when filling.</p>
</div><div class="codes"></div><div class="docs"><p>note: we have some simple component-level queries that pop out here...
active-demands == entities with a demand component, and an active component...
inactive-demands == entities with a demand component, not in active component...
most of the time, we only care about active...</p>
</div><div class="codes"></div><div class="docs"><p>unfilled-demands == active demands with an unfilled component.</p>
</div><div class="codes"></div><div class="docs"><p>Rather than mutating a structure in a nested object,
we can see activating a demand as marking the demand active,
and computing the requirement for the demand.
Note: we can update the unfilledq at each step, after activating
or deactivating demands...
If we activate demands, the unfilledq is dirty.
We need to reorder the queue(s).</p>
</div><div class="codes"></div><div class="docs"><p>Shifts demand named dname to the active set of demands, updates its fill status, and 
   notifies any interested parties.</p>

<p>Really, we have one or more lists of fills based on the category of
demand...</p>
</div><div class="codes"><pre class="brush: clojure">(defn activate-demand
  [demandstore t d ctx]
  (let [dname (:name d) 
        store (-&gt; (gen/deep-assoc demandstore [:activedemands dname] dname)
                  (register-change dname))]               
    (-&gt;&gt; (assoc d :active true)
         (store/add-entity ctx)
         (activating-demand! store d t)
         (update-fill store dname))))</pre></div><div class="docs"><p>For the set of demands registered with the context's demand store, relative 
   to time t, any demands scheduled to start at t are activated.</p>

<p>We should make activate-demands a bulk operation...
and phrase activate-demand in terms of a singleton.</p>
</div><div class="codes"><pre class="brush: clojure">(defn activate-demands
  [t ctx]
  (let [demandstore (core/get-demandstore ctx)]
    (reduce (fn [ctx dname]
              (let [store (core/get-demandstore ctx)]
                (activate-demand store t
                                 (store/get-entity ctx dname) ;(get-demand store dname)
                                 ctx))) 
            ctx 
            (get-activations demandstore t))))</pre></div><div class="docs"><h1>Shifting Elements of Supply To and From Demand</h1>

<p>As supply is selected to fill demand, the supply is actively assigned to a 
specific demand.  From this status, we may see supply stay there indefinitely,
shift from an actively assigned state to an overlapping state, or completely 
disengage from the demand and return to the global supply.  The following 
functions implement these scenarios.</p>
</div><div class="codes"></div><div class="docs"><p>Auxillary function that dissociates an element of supply, unit, from a 
   related element of demand, demand.  Typically used when a demand deactivation
   prematurely sends a unit home.  Shifts the unit entity into a withdraw state,
   and notifies systems of the entity's abrupt withdraw.</p>
</div><div class="codes"><pre class="brush: clojure">(defn withdraw-unit
  [unit demand ctx]
  (let [demandgroup (:demandgroup demand)
        unitname    (:name unit)
        _ (debug [:withdraw-unit unitname])
        ]
	  (cond 
	    (and demandgroup (not= &quot;&quot; demandgroup) (not (ungrouped? demandgroup)))
            (do  (debug :abw1)
                 (let [ctx (store/assoce ctx unitname :followoncode  demandgroup)
                       _ (debug [:pre-abw unitname (store/gete ctx unitname :last-update)])]
                   (u/change-state (store/get-entity ctx unitname) :abrupt-withdraw 0 0 ctx)))
            (not (ghost? unit))
            (do  (debug :abw2)
                 (u/change-state (store/get-entity ctx unitname) :abrupt-withdraw 0 0 ctx))
	    :else (-&gt;&gt; (if (ghost? unit) (ghost-returned! demand unitname ctx) ctx)  
                       (u/change-state (store/get-entity ctx unitname) :Reset 0 nil)))))                     </pre></div><div class="docs"><p>Implements the state changes required to deactivate a demand, namely, to send
   a unit back to reset. The cases it covers are times when a demand is 
   deactivated, and units are not expecting to overlap. If units are 
   overlapping at a newly-inactive demand, then they get sent home
   simultaneously.</p>

<p>We can swap out with-draw-unit with something else...
Since we don't need to alter the unit's state, it's not an immediate withdraw,
Specifically, we have location-based-behavior telling us when to go home.</p>
</div><div class="codes"><pre class="brush: clojure">(defn send-home
  [t demand unit ctx] 
  (let [unitname    (:name unit)
        startloc    (:locationname unit)
        demandgroup (:demandgroup demand)
        _ (debug [:demand/send-home (:name unit) :t t])
        ]    
    (-&gt;&gt; (u/unit-update unit ctx)      ;;we don't want to get caught in an update cycle.
         (withdraw-unit unit demand) 
         (disengaging! demand unitname)))) </pre></div><div class="docs"><h1>Notes on calling change-state for the unit-level system</h1>

<p>there WILL be things happening to the ctx, possible mutations and such, that 
we may need to carry forward (although we can discipline ourselves for now).</p>
</div><div class="codes"></div><div class="docs"><p>change-state will have to return the unit that changed, as well as updated 
supply, demand, etc, even context.  so change-state will have big changes...
We need a way to dispatch based on the changes.
Again, event handling could work....
change-state is a high-level simulation transition function for either the 
unit simulation, or the supply simulation.</p>
</div><div class="codes"></div><div class="docs"><h1>Disengagement</h1>

<p>Disengagement is the primitive process for shifting a unit of supply's role 
from actually filling a demand, into an optional overlapping status. <br />
Overlapping supply is still associated with the demand, i.e. proximate and 
in use, but it is not ready to return to the global supply.</p>
</div><div class="codes"></div><div class="docs"><p>TEMPORARY private helper function.....until I figure out a cleaner solution.
broke out uber function into a smaller pairing of disengagement functions, to 
handle specific pieces of the contextual change.</p>
</div><div class="codes"><pre class="brush: clojure">(defn- disengage-unit [demand demandstore unit ctx &amp; {:keys [overlap]}]
  (if overlap
    (let [_ (debug [:pre demand (sim/get-time ctx)])
          demand (d/send-overlap demand unit)
          ;_ (println [:overlapping demand])
          ]
      (-&gt;&gt; (store/add-entity ctx demand )
          (overlapping! demandstore demand unit)))
    (-&gt;&gt; (send-home (sim/current-time ctx) demand unit ctx)
         (disengaging-home! demandstore demand unit))))</pre></div><div class="docs"><p>Shifts the unit from being actively assigned to the demand, to passively 
   overlapping at the demand.  Updates the demand's fill status.</p>

<p>This is also called independently from Overlapping_State.....
Remove a unit from the demand.  Have the demand update its fill status.
Move the unit from the assigned units, to Overlapping Units.</p>
</div><div class="codes"><pre class="brush: clojure">(defn disengage
 ([demandstore unit demandname ctx overlap]
  (let [demand    (store/get-entity ctx  demandname)
        nextstore (register-change demandstore demandname)
        ctx       (disengage-unit demand demandstore unit ctx :overlap overlap)]  
   ; (if (zero? (d/required demand))
      (update-fill nextstore demandname ctx)  ;;always check...
;      (update-fill demandname (:unfilledq demandstore) demandstore ctx)
  ;    ctx)))
 ([demandstore unit demandname ctx] ;hack....
  (disengage demandstore unit demandname ctx false)))</pre></div><div class="docs"><p>Shifts the unit from being actively assigned to the demand, to passively 
   overlapping at the demand.  Updates the demand's fill status.  Does not 
   update the unit.</p>

<p>sword of verboseness +1 </p>
</div><div class="codes"><pre class="brush: clojure">(defn remove-unit-from-demand
 [demandstore unit demandname ctx]
 (let [demand    (d/send-home (store/get-entity  ctx demandname)
                              unit)
       nextstore (register-change demandstore demandname)                   
       ;;ctx       (disengage-unit demand demandstore unit ctx :overlap overlap)       
       ]
   (-&gt;&gt; (store/add-entity ctx demand)
        (update-fill  demandstore demandname))))</pre></div><div class="docs"><p>Sends home all units from a demand, essentially freeing consumed resources. <br />
   Only called against active demands as part of the deactivation process.  If
   demand is empty, a notification is sent, otherwise the demand is cleared of 
   units.</p>

<p>Note: we're using demandmap for information here...rather than
the context...</p>
</div><div class="codes"><pre class="brush: clojure">(defn send-home-units
  [demand t ctx]
  (if (empty-demand? demand)
    (do (debug [:empty-demand! (:name demand)])
        (deactivating-empty-demand! demand t ctx))
    (let [us      (vec (concat (keys   (:units-assigned    demand))
                               (keys   (:units-overlapping demand))))
          _       (debug [:sending-home us :from (:name demand) :t t])
          sent    (atom #{})
          nextctx (reduce (fn [acc nm]
                           (do (if (contains? @sent nm)
                                 (throw (Exception. (str [:already-sent-home nm])))
                                 (do (swap! sent conj nm)
                                     (send-home t demand (store/get-entity acc nm) acc)))))
                         ctx us)]         
      (-&gt; nextctx
          (update-entity
           :DemandStore       
           #(gen/deep-assoc % [:demandmap (:name demand)]
                            (assoc demand :units-assigned {}
                                          :units-overlapping {})))))))</pre></div><div class="docs"><p>Frees resources associated with a demand, sending home any units proximate 
   to the demand.  Removes the demand from the active set.</p>

<p>==todo== stop storing activedemand information in demandstore/activedemands
lift it out to a component instead....causing some problems and inefficiencies.</p>

<h1>Demand DeActivation</h1>
</div><div class="codes"><pre class="brush: clojure">(defn deactivate-demand
  [demandstore t d ctx]
  (assert (active-demand? demandstore (:name d))
    (throw (Exception. (str &quot;DeActivating an inactive demand: &quot; (:name d))))) 
  (let [store (-&gt; (gen/deep-update demandstore [:activedemands] dissoc (:name d))
                  (register-change (:name d)))
;        _ ;(println [:demand d])
        _ (debug [:deactivating (:name d) :assigned  (keys (:units-assigned d))
                  :overlapping            (keys (:units-overlapping d))])
        d (dissoc d :active)]
    (-&gt;&gt; (-&gt; ctx
             (store/add-entity d)
             (store/add-entity store))                      
         (deactivating-demand! store d t)
         (send-home-units d t)
         (update-fill store (:name d)))))    </pre></div><div class="docs"><p>Deactivates any demands - in the demandstore of the context - scheduled to 
   end at time t.</p>
</div><div class="codes"><pre class="brush: clojure">(defn deactivate-demands
  [t ctx]
  (let [demandstore (core/get-demandstore ctx)]
    (reduce (fn [ctx dname] 
              (let [store (core/get-demandstore ctx)                    
                    d     (store/get-entity ctx dname);(get-demand store dname)
                    ]
                (deactivate-demand store t                                  
                                   d
                                   ctx))) 
            ctx 
            (get-deactivations demandstore t))))</pre></div><div class="docs"><p>Builds a temporal profile of all the demands in the store.</p>

<h1>Analysis...</h1>
</div><div class="codes"><pre class="brush: clojure">(defn profile 
  [store]
  (temporal/active-intervals 
   (temporal/activity-profile (vals (:demandmap store)) :start-func :startday :duration-func :duration)))</pre></div><div class="docs"><p>High level demand management API.  The primary system service used by the 
   simulation engine.  Processes the activation and deactivation of demands 
   at time t, which adds demands to the active set, queuing them for filling,
   or removes active demands, freeing supply resources in the process.</p>

<h2>Demand Management</h2>
</div><div class="codes"><pre class="brush: clojure">(defn manage-demands
  [t ctx]
  (-&gt;&gt; ctx
    (activate-demands t)
    (deactivate-demands t))) </pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.supply" name="marathon.ces.supply"><h1 class="project-name">marathon.ces.supply</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>An implementation of the supply simulation used by Marathon. <br />
All the operations for pushing supply, in the context of a simulation are 
maintained here.  Backing structure is an entitystore.  Supporting
Entity is the supply manager.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.supply
  (:require [marathon.demand [demanddata :as d]]
            [marathon.supply [unitdata :as udata]]
            [marathon.ces    [core :as core]
                             [policy :as policy] 
                             [unit :as u]]
            [marathon.data.protocols :as protocols]
            [spork.entitysystem.store :as store
             :refer [gete assoce mergee assoc-ine updatee get-entity add-entity drop-entity
                     update-ine update-entity get-ine]]
            [spork.ai.core :refer [debug]]
            [spork.sim    [simcontext :as sim] [updates :as updates]]
            [spork.util   [tags :as tag]
             [general :as gen]]
            [clojure.core.reducers :as r]))</pre></div><div class="docs"><h1>Primitive Operations and Supply Queries</h1>

<p>'TODO -> formalize dependencies and pre-compilation checks....
estore version....</p>
</div><div class="codes"><pre class="brush: clojure">(defn can-simulate? [supply]
  (-&gt; supply
      (:tags) 
      (tag/get-tags :enabled)
      (empty?)
      (not)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-stats
  ([nm ctx]
   (let [e (store/get-entity ctx nm)]
     (core/msg &quot;Policy: &quot;    (protocols/atomic-name (:policy e)) &quot; &quot;
               &quot;Cycletime: &quot; (:cycletime e)))))</pre></div><div class="docs"><p>no change for estore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unit-msg [unit ctx]
  (str &quot;Updated Unit &quot; (:name unit) &quot; &quot; (get-stats (:name unit) ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ghost?     [tags unit] (tag/has-tag? tags :ghost (:name unit)))</pre></div><div class="docs"><p>estore version</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-ghosts [x ctx]  (assoce :SupplyStore :has-ghosts x))</pre></div><div class="docs"><p>estore version</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-unit
  ([supply store unit]
   (-&gt; store       
       (add-entity (:name unit) unit)
       (store/mergee :SupplyStore (assoc-in supply [:unitmap (:name unit)] (:name unit)))))
  ([store unit] (add-unit (get-entity store :SupplyStore) store unit))) </pre></div><div class="docs"><p>might be able to ditch the unit-map entirely.</p>
</div><div class="codes"><pre class="brush: clojure">(defn drop-unit  [store unitname]
  (-&gt; store
      (drop-entity unitname)
      (update-ine  [:SupplyStore :unitmap] #(dissoc % unitname))
      (update-ine  [:SupplyStore :tags]    #(tag/drop-tag % unitname))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn drop-units [store names] (reduce drop-unit store names))</pre></div><div class="docs"><p>this has changed....we no longer need the supplystore...</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-unit [store name] ;(get-in supplystore [:unitmap  name]))
  (get-entity store name))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn unit? [store name] (get-in store [:unitmap name])) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn has-behavior? [unit] (not (nil? (:behavior unit))))</pre></div><div class="docs"><h1>TODO  Generalize this.  We have a single case statement for</h1>

<p>assigning behaviors.  Works okay, but it's kind of a choke point...</p>
</div><div class="codes"><pre class="brush: clojure">(defn assign-behavior
  [behaviors unit]
   (-&gt;&gt;  (case (clojure.string/upper-case (:component unit))
           &quot;AC&quot; :ac
           (&quot;NG&quot; &quot;RC&quot;) :rc
           &quot;GHOST&quot; :ghost 
           (throw (Exception. (str &quot;Trying to assign behavior based on unknown component: &quot; (:component unit)))))
         (assoc unit :behavior)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn empty-position? [unit] (nil? (:positionpolicy unit)))</pre></div><div class="docs"><p>Note: these may become obsolete...</p>
</div><div class="codes"></div><div class="docs"><h1>Keyword Tag Builders</h1>
</div><div class="codes"><pre class="brush: clojure">(core/defkey source-key &quot;SOURCE_&quot;)
(core/defkey sink-key   &quot;SINK_&quot;)
(core/defkey compo-key  &quot;COMPO_&quot;) 
(core/defkey behavior-key &quot;BEHAVIOR_&quot;)
(core/defkey title-key   &quot;TITLE_&quot;)
(core/defkey policy-key  &quot;POLICY_&quot;)
(def ghost-source-tag (source-key &quot;Ghost&quot;))</pre></div><div class="docs"><h1>Tag Operations</h1>
</div><div class="codes"></div><div class="docs"><p>'TOM Change 27 Sep 2012
Adds meta data to the tags, to identify the unit as being a member of a fenced
group of supply.  Fenced groups of supply automatically provide a special set 
of supply that fill functions can utilize when making demand decisions.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tag-as-fenced [tags fencegroup unitname]
  (-&gt; (tag/tag-subject tags fencegroup unitname)
      (tag/tag-subject unitname :fenced)))        </pre></div><div class="docs"><p>'TOM Change 27 Sep 2012 -> using tags to delineate fence states, including 
one-time fences, specifically for future force gen stuff.</p>
</div><div class="codes"><pre class="brush: clojure">(defn drop-fence [tags unitname]
  (if (and (tag/has-tag? tags :one-time-fence unitname) 
           (tag/has-tag? tags :fenced unitname))
    (-&gt; (tag/untag-subject tags unitname :fenced)
        (tag/tag-subject unitname :dropped-fence))
    tags)) </pre></div><div class="docs"><p>default unit tags</p>
</div><div class="codes"><pre class="brush: clojure">(defn default-tags [{:keys [src component behavior oi-title policy]}] 
  [(compo-key component) (behavior-key behavior) (title-key oi-title) 
   (policy-key (:name policy)) (source-key src) :enabled])</pre></div><div class="docs"><p>Note -> we should generalize this into some special.  Like deftag, or 
defsupply tag, which looks at a library of tags to find out if it should do
any special processing.  </p>
</div><div class="codes"><pre class="brush: clojure">(defn tag-extras [unit extras tags]
  (let [unitname (:name unit)]
    (reduce (fn [tags tg] 
              (case tg 
                :fenced (tag-as-fenced tags tg unitname)
                :keep-fenced (tag/tag-subject tags unitname :one-time-fence)
                (tag/tag-subject tags unitname tg))) tags extras)))</pre></div><div class="docs"><p>register source as being a member of sources, so it can be looked at when 
filling supply.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tag-source [source tags] (tag/tag-subject tags source :sources))</pre></div><div class="docs"><p>inject appropriate tags into the supply tags.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tag-unit
  ([supply unit extra-tags]
   (let [sourcename (source-key (get unit :src))]
      (-&gt;&gt; ; (into (default-tags unit) extra-tags)) 
           (tag/multi-tag (get  supply :tags) (get unit :name) (default-tags unit))
           (tag-source sourcename)
           (tag-extras unit extra-tags)
           (assoc supply :tags))))
  ([supply unit] (tag-unit supply unit nil)))</pre></div><div class="docs"><p>helper function for dropping a tag from multiple units at once.</p>
</div><div class="codes"><pre class="brush: clojure">(defn untag-units [supplystore tag units]
  (reduce #(tag/untag-subject (:tags %1) %2 tag) supplystore units))</pre></div><div class="docs"><h1>Supply Population Operations</h1>

<p>this might be suitable to keep in the supplymanager...</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-src [supply src] 
  (let [scoped (:srcs-in-scope supply)]
    (if (contains? scoped src) supply 
      (assoc-in supply [:srcs-in-scope src] (count scoped)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn remove-src [supply src] (update-in supply [:srcs-in-scope] dissoc src))</pre></div><div class="docs"><p>Operations on units like add/remove happen at a high level, since the
supply store, via the unit-map, served as the logical "container" for
all the unit entities.</p>
</div><div class="codes"></div><div class="docs"><p>There might be a general container entity type...
If an entity is contained by another, then we want
to remove all of its relations.
Perhaps we can have a generalized relational setup.
As we create entities, we could specify relationships.
If an entity is removed, it's no longer contained by
any dependent entities.  Rather than manually managing
this stuff, we can let the framework do it.  Or we can
define supplemental functions that help us.</p>
</div><div class="codes"></div><div class="docs"><p>For instance, removing demands is probably identical to
removing units.</p>
</div><div class="codes"></div><div class="docs"><p>DOUBLE CHECK....do we really mean to drop the entire src? </p>
</div><div class="codes"><pre class="brush: clojure">(defn remove-unit [store unitname]
  (let [tags (store/gete store :SupplyStore)]                         
  (-&gt; store
      (drop-unit unitname)
      (update-entity :SupplyStore remove-src (gete store unitname :src)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-buckets 
  ([supply bucket] (get (:deployable-buckets supply) bucket))
  ([supply]        (get (:deployable-buckets supply) :default)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn add-bucket [supply bucket-name]
  (let [buckets (:deployable-buckets supply)]
    (if (contains? buckets bucket-name) supply 
      (assoc-in supply [:deployable-buckets bucket-name] {}))))</pre></div><div class="docs"><h1>Tag-Related Supply Queries</h1>
</div><div class="codes"><pre class="brush: clojure">(defn get-sources [supply] (tag/get-subjects (:tags supply) :sources))
(defn multiple-ghosts? [supplytags]
  (&gt; (count (tag/get-subjects supplytags ghost-source-tag)) 1))</pre></div><div class="docs"><p>procedure that allows us to, using the fillgraph, derive a set of tags whose 
associated units should be deactivated.  if removal is true, the units will be
removed from memory as well. in cases where there are a lot of units, this may 
be preferable.</p>
</div><div class="codes"><pre class="brush: clojure">(defn scope-supply [supply disable-tags &amp; [removal]]
  (let [f (if removal remove-unit (fn [s u] s))]
    (-&gt;&gt;  (tag/and-tags (:tags supply) (set disable-tags)) 
          (reduce (fn [s u] (-&gt; (core/disable s u) f u)) supply))))</pre></div><div class="docs"><p>----FOREIGN -> THESE SHOULD BE MOVED, THEY'RE MORE GENERAL.....</p>
</div><div class="codes"><pre class="brush: clojure">(defn conj-policy [unit policy] (update-in unit [:policy-queue] conj policy))</pre></div><div class="docs"><p>----------END FOREIGN------</p>
</div><div class="codes"></div><div class="docs"><h1>Supply Updating</h1>

<p>The supply simulation has many concurrent process - unit simulations - 
that are in various states of motion.  For efficiency, we treat these 
processes as relatively independent, with the exception of periodic 
synchronization via updating.  The supply system updates either specific 
entities, or all entities, by evaluating the passage of time relative to the 
entity.  Certain functionality, such as sampling and logging, may require 
the entire supply to be synchronized, and thus updated to a common point in 
time.  For the most part, the supply will proceed eventfully, with each 
process updating on an as-needed basis.</p>
</div><div class="codes"></div><div class="docs"><p><strong>TODO</strong> move up-to-date? to the simcontext library.
This is a pretty general function, we can probably elevate to the core or to
sim context.
CES version...
we can change sim/last-update to be a general function.
store/last-update
This is generic...we can check to see if any entity is up to date by
examining its update component.</p>
</div><div class="codes"><pre class="brush: clojure">(defn up-to-date? [t ctx unitname]
  (= (gete ctx unitname :last-update) t))</pre></div><div class="docs"><p>Notifies the context of a supply update.</p>
</div><div class="codes"><pre class="brush: clojure">(defn supply-update! 
  [supply unit msg ctx]
  (sim/trigger-event :supplyUpdate (:name supply) (:name unit) msg nil ctx))</pre></div><div class="docs"><p>Get all units with pending supply updates.</p>

<p>we wrap this accessor behind a entity called updates.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-supply-updates  
  [t ctx]
  ;;transition this out...
                                        ;  (get-ine ctx [:updates t :supply-update]
  (sim/get-updates :supply-update t ctx))</pre></div><div class="docs"><p>Schedule an update for unit at time t.</p>
</div><div class="codes"><pre class="brush: clojure">(defn request-unit-update!  
  [t unit ctx] 
  (sim/request-update t (:name unit) :supply-update ctx))</pre></div><div class="docs"><p>we can just get the entity here...</p>
</div><div class="codes"></div><div class="docs"><h1>Performance NOTE: we can possibly shift to using an</h1>

<p>atom to wrap the supplystore and the ctx, and perform
updates in parallel.  Could see a significant improvement
for large scale runs - iff there are multiple units updating
on the same date.</p>
</div><div class="codes"></div><div class="docs"><p>Ages an individual unit, based on how much time has elapsed - for the unit -
   between time t and its last update.</p>

<p>Note: We can factor this out using filter in update-units.</p>
</div><div class="codes"><pre class="brush: clojure">(defn apply-update
  [t supplystore unitname ctx]
  (if ;(core/disabled? supplystore unitname)
       (gete ctx unitname :disabled);lame hack
           (do ;(println [:update unitname t :disabled])
                ctx)
      (let [unit (get-unit ctx unitname)
            ;_ (println [:updating unitname])
            ]
          (-&gt;&gt; ctx       
               (u/unit-update unit) ;(updates/elapsed t (or (sim/last-update unitname ctx) 0)))
               ((fn [ctx]  ;;inlined unit-msg to avoid eager msg creation.
                  (supply-update! supplystore unit (unit-msg unit ctx) ctx)))))))</pre></div><div class="docs"><p>Performance: Interesting hotspot here as well. We have some overhead
due to function calls.  Also, faster using reduce-kv, vs creating
seqs using (keys ..).  In general (keys ..) is pretty performant.</p>
</div><div class="codes"></div><div class="docs"><p>Given a sequence of unit keys, xs, brings each unit up to date according to 
   day, relative to the supply and the simulation context.</p>

<p>This is an area that is ripe for parallelism.  We have an explicit
synchronization point, each unit is logically independent of the
other.  We should be able to split work out across multiple
cores and perform updates in parallel.  The ctx is a shared
resource though....Most of the unit updates will consist
of modifying the unit entity atomically during the behavior,
then committing the entity at the end.  So we have that
behavior covered...Each unit update will create its
own behavior context as well.</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-units
  [t supply ctx xs]       
  (reduce-kv (fn update-units-r [acc x _] (apply-update t (core/get-supplystore acc) x acc))  
             ctx xs))</pre></div><div class="docs"><p>Forces an update for every unit in the supply to bring all entities to a 
   common point in time.  Typically used prior to sampling.</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-all
  [t supply ctx &amp; [unitnames]]
  (-&gt;&gt; (or unitnames (keys (get supply :unitmap)))
       (r/filter (partial up-to-date? t ctx))
       (update-units t supply ctx)))</pre></div><div class="docs"><h1>General Supply Notifications</h1>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn spawning-unit! [unit ctx]
  (core/trigger-event :SpawnUnit (:name unit) (:name unit)
     (str &quot;Spawned Unit &quot; (:name unit)) nil ctx))             </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn spawning-ghost! [unit ctx]
  (core/trigger-event :SpawnGhost (:name unit) (:name unit)
     (str &quot;Spawned a ghost &quot; (:name unit)) nil ctx))  </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn new-deployable! [unit ctx]
  (assert (not= (:policy-position unit) :Recovery) &quot;Recovery is not deployable&quot;)
  (core/trigger-event :NewDeployable &quot;SupplyManager&quot; (:name unit) 
      (str &quot;Unit &quot; (:name unit) &quot; at position &quot; (:positionpolicy unit) 
           &quot; is deployable&quot;) nil ctx))
(defn new-followon! [unit ctx] 
  (core/trigger-event :NewFollowOn &quot;SupplyManager&quot; (:name unit)
      (str &quot;Unit &quot; (:name unit) &quot; able to followon for demandgroup &quot; 
           (:followoncode unit)) nil ctx))
(defn more-src-available! [unit ctx]
  (let [src (get unit :src)]
    (core/trigger-event :MoreSRCAvailable &quot;SupplyManager&quot; src 
       (str &quot;Unit &quot; (:name unit) &quot; at position &quot; (:positionpolicy unit) 
            &quot;has just been added to deployables for SRC &quot; src) nil ctx))) 
(defn new-src-available! [src ctx]
  (core/trigger-event :NewSRCAvailable &quot;SupplyManager&quot; src 
     (str &quot;A new category of SRC now has deployable supply &quot; src) nil ctx))
(defn not-deployable! [unit ctx] 
  (core/trigger-event :NotDeployable &quot;SupplyManager&quot; (:name unit) 
     (str &quot;Unit &quot; (:name unit) &quot; at position &quot; (:positionpolicy unit) 
          &quot; is no longer deployable&quot;) nil ctx))
(defn out-of-stock! [src ctx]
  (core/trigger-event :outofstock &quot;SupplyManager&quot; src 
     (str &quot;SRC &quot; src &quot; has 0 deployable supply&quot;) (source-key src) ctx))</pre></div><div class="docs"><p>Aux function for logging/recording the fact that a unit changed locations</p>
</div><div class="codes"><pre class="brush: clojure">(defn log-move!
  ([t fromloc toloc unit duration ctx]
   (core/trigger-event :unitMoved (:name unit) toloc (core/msg (:name unit) &quot; moved from &quot; fromloc &quot; to &quot; toloc)
                      [(:name unit) fromloc toloc] ctx))
  ([t fromloc toloc unit ctx] (log-move! t fromloc toloc unit nil ctx)))</pre></div><div class="docs"><p>TODO -> This should be renamed like positionEvent or something.
Main dependencies are in the unit Behaviors.
Unit behaviors currently use parent to refer to a supply manager.
We can probably do better than this.
Actually, unit behaviors aren't maintaining any state....
So we can probably just plug them in as modules....they're all pure functions.
'TOM Change 6 June 2011 -> Added logging for unit positioning specifically..</p>
</div><div class="codes"><pre class="brush: clojure">(defn log-position! [t frompos topos unit  ctx]
  (core/trigger-event :PositionUnit &quot;SupplyManager&quot; (:name unit) 
                     (core/msg &quot;UIC &quot; (:name unit) &quot; has repositioned from &quot; frompos &quot; to &quot; topos)
                     [(:name unit) frompos topos] ctx))</pre></div><div class="docs"><p>Aux function for logging/recording the fact that a unit deployed</p>
</div><div class="codes"><pre class="brush: clojure">(defn log-deployment! 
  [t fromname demand unit fillcount filldata deploydate  period ctx]
  (core/trigger-event :deploy &quot;SupplyManager&quot; (:name unit)              
     (core/msg &quot;Deployed unit &quot; (:name unit) 
          &quot; from &quot; fromname &quot; to demand &quot; (:name demand))
     {:fromloc   fromname  :unit unit :demand demand :fill filldata 
      :fillcount fillcount :period period :t t :deploydate deploydate}  ctx))</pre></div><div class="docs"><p>records unit changes in state....new</p>
</div><div class="codes"><pre class="brush: clojure">(defn log-state! 
  [t unit from to ctx]
  (let [unitname (:name unit)]
    (core/trigger-event :StateChange &quot;SupplyManager&quot; unitname              
                       (core/msg &quot;Unit &quot; unitname 
                                 &quot; changed state from &quot; from &quot; to &quot; to)
                       [unitname from to] ctx)))</pre></div><div class="docs"><p>When a unit engages in a followon deployment, we notify the context.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unit-followon-event! [unit demandname ctx]
  (core/trigger-event :FollowingOn  (:name unit) demandname 
     (core/msg &quot;Unit &quot; (:name unit) &quot; is following on to demand &quot; demandname)
        nil ctx))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn first-deployment! [supply unit ctx]
  (core/trigger-event :firstDeployment (:name supply) (:name supply) 
       (core/msg &quot;Unit &quot; (:name unit) &quot; Deployed for the First Time&quot;) nil ctx))</pre></div><div class="docs"><h1>Supply Availability</h1>
</div><div class="codes"></div><div class="docs"><h1>TODO revamp our data model to store sets of unit names, rather than</h1>

<p>map of name->unit.  This, again, fits in nicely with tags if we
centralize our queries off a tag data model.  It's more legible for
interactive debugging if we just see the names (note: I can write a
view that will accomplish the same thing; in some cases it might be 
preferable to retain the name->unit info....pending.</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-availability [unit supply ctx]
  (if (contains? (get-buckets supply) (get unit :src))
    (more-src-available! unit ctx)
    (-&gt;&gt; (new-src-available! (get unit :src) ctx)
      (new-deployable! unit))))</pre></div><div class="docs"><p>Tom hack 26 MAy 2016
We discriminate between known or canonical buckets, and
ad-hoc buckets (buckets that are created as ephemeral supply
for followon-demands.  In contrast, we will likely always have
:default and :SRM categories of supply, i.e. they never go away.</p>
</div><div class="codes"><pre class="brush: clojure">(def known-buckets #{:default :SRM &quot;SRM&quot;})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn derive-bucket [unit]
  (let [fc  (:followoncode unit)]
    (if (and fc (not (or (= fc ) (= fc &quot;UnGrouped&quot;))))
      fc
      (or (:default-bucket unit)                  
          :default))))</pre></div><div class="docs"><p>Rather than specifying followons manually, we let them be derived from
the unit's followon code.  If it has one, it's inferred we have a
followon supply.  We store this information in the unit's bucket component.
Consolidated this from update-deployability, formalized into a function.
We also indicate the presence of followon units at the component level,
rather than storing in the supply.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-deployable-supply 
  ([supply bucket src unit ctx]
   (let [components {:deployable-bucket bucket
                     :deployable-cat    src
                     :deployable true}
         components (if (known-buckets bucket) components
                        (do ;(println [:followon bucket])
                            (assoc components :followon bucket)))
         _ (debug [(:name unit) components :bucket bucket])
         ]         
   (-&gt;&gt; ctx
        (sim/merge-entity {:SupplyStore (assoc-in supply [:deployable-buckets bucket src (:name unit)] unit)
                           (:name unit) components ;;tacking on component data to help with queries.
                           })
        (update-availability unit supply))))
  ([supply src unit ctx]                                                                  
   (add-deployable-supply supply
                          (derive-bucket unit) src unit ctx)))</pre></div><div class="docs"><p>follow on supply was treated as special, but now it's not.  We expected 
a function called get-followon-supply before...
I think it's OBE now...
<strong>TODO</strong> Determine if get-followon-supply is OBE, and that can ignore it.</p>
</div><div class="codes"></div><div class="docs"><p>Consolidated this from update-deployability, formalized into a function.</p>
</div><div class="codes"><pre class="brush: clojure">(defn remove-deployable-supply 
  ([supply bucket src unit ctx]
   (let [ctx (store/update-entity ctx (:name unit)
                                  (fn [m] (-&gt; m (dissoc :deployable-bucket)
                                                (assoc  :deployable false))))] ;no longer deployable, tracking with component data.
     (if-let [newstock (-&gt; (get-in supply [:deployable-buckets bucket src])
                           (dissoc (get unit :name)))]
       (sim/merge-entity  {:SupplyStore (assoc-in supply [:deployable-buckets bucket src] newstock)} ctx)
       (-&gt;&gt;  (sim/merge-entity  {:SupplyStore (update-in supply [:deployable-buckets bucket] dissoc src)} ctx) ;we can phase this out maybe
             (out-of-stock! (get unit :src))))))
  ([supply src unit ctx]
   (remove-deployable-supply supply (derive-bucket unit) src unit ctx)))</pre></div><div class="docs"><p>Sets a unit's deployable status, depending on the current context and the 
   unit's policy state.</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-deployability
  ([supply unit followon spawning ctx]
;     (assert (not (empty-position? unit)) (core/msg &quot;invalid position!&quot; (:positionpolicy unit)))
   (let [position   (:positionpolicy unit)         
         src        (get unit :src)
         can-deploy (u/can-deploy? unit spawning)]
       (if (or followon can-deploy)                         ;1)
         (-&gt;&gt; (if followon  ;notifiying of followon data...
                (new-followon!   unit ctx) 
                (new-deployable! unit ctx))
              (add-deployable-supply supply src unit)) ;add stuff to buckets...   
                                        ;unit is not deployable
         (-&gt;&gt; (not-deployable! unit ctx)
              (remove-deployable-supply supply src unit)))))
  ([unit followon spawning ctx] 
     (update-deployability (core/get-supplystore ctx) unit followon spawning ctx)))</pre></div><div class="docs"><p><strong>TODO</strong>Determine if we can yank this and just use update-deployability.
We used to have this as a firewall that would, depending onthe unit's followon 
status, select from an alternate set of supply buckets.  Since we're tracking 
supply status via tags now, we don't need to partition the buckets separately.
I removed the buckets args, and this function got hollowed out. <br />
<strong>DEPRECATE</strong></p>
</div><div class="codes"><pre class="brush: clojure">(defn update-deploy-status
  ([supply unit followon? spawning? ctx]
   (update-deployability supply unit followon? spawning? ctx))
  ([unit followon? spawning? ctx]
   (update-deployability unit followon? spawning? ctx)))</pre></div><div class="docs"><h1>Registering New Supply</h1>
</div><div class="codes"></div><div class="docs"><p>Note: this is a current bottleneck for run setup (we spend a lot of time
in here, could benefit from mutation, or anything that avoids
all the associng and get calls.</p>
</div><div class="codes"></div><div class="docs"><p>Note -> the signature for this originally returned the supply, but we're not 
returning the context.  I think our other functions that use this guy will be
easy to adapt, just need to make sure they're not expecting supplystores.
Conjoins a unit to the supply, under the context.  Optional parameters for 
communicating whether the unit is a ghost, as well as additional tags to be 
added on-top-of the default tags derived from the unit data.</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-unit [supply behaviors unit ghost extra-tags ctx]
  (let [unit   (if (has-behavior? unit) unit (assign-behavior behaviors unit))
        newctx    (-&gt;&gt; (-&gt; supply
                           (tag-unit unit extra-tags)
                           (add-src   (get unit :src))
                           (add-unit  ctx unit)
                           (store/assoce (:name unit) :supply true) ;starting to shift to component tagging.                           )
                       (request-unit-update!  (max (:spawntime unit) 0) unit ))        
        ]
    (if ghost 
      (-&gt;&gt; (spawning-ghost! unit newctx)
           (set-ghosts true))
      (-&gt;&gt; (spawning-unit! unit newctx)
           (update-deployability unit nil nil)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn register-unit! [supply behaviors unit ghost extra-tags ctx]
  (let [unit   (if (has-behavior? unit) unit (assign-behavior behaviors unit))
        supply (-&gt; (add-unit supply unit)
                   (tag-unit unit extra-tags)
                   (add-src (get unit :src)))]
    (if ghost 
      (-&gt;&gt; (spawning-ghost! unit ctx)
           (set-ghosts true))
      (-&gt;&gt; (spawning-unit! unit ctx)
           (update-deployability supply unit nil nil)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn create-unit [&amp; args]
  (throw (Exception. &quot;create-unit is a stub....&quot;)))</pre></div><div class="docs"><p>creates a new unit and stores it in the supply store...returns the supply 
store.</p>
</div><div class="codes"><pre class="brush: clojure">(defn new-unit [supplystore parameters policystore behaviors name src title 
                component cycletime policy &amp; [behavior ctx]]
  (let [new-unit (create-unit name src title component cycletime policy 
                              parameters policystore behavior)]
    (register-unit supplystore behaviors (ghost? new-unit) ctx)))</pre></div><div class="docs"><p><strong>TODO</strong> DEPRECATE
NOTE -> replace this with a simple map lookup...</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-near-max-policy [policy policystore]
  (let [id (case (policy/atomic-name policy) 
             :MaxUtilization         :NearMaxUtilization
             :MaxUtilization_Enabler :NearMaxUtilization_Enabler)]
    (get-in policystore [:policies id])))</pre></div><div class="docs"><p>WEAK...hard coded, should be data driven.</p>
</div><div class="codes"><pre class="brush: clojure">(defn should-change-policy? [{:keys [component] :as unit}]
  (not= component :AC :Ghost))
(defn check-max-utilization [params] (get params :TAA1519MaxUtilizationHack))</pre></div><div class="docs"><p>This is an aux function that serves as a weak patch...probably unnecessary.
<strong>TODO</strong>Remove the need for adjust-max-utilization!</p>
</div><div class="codes"><pre class="brush: clojure">(defn adjust-max-utilization! [supply unit ctx] 
  (if (and (check-max-utilization (core/get-parameters ctx))
           (should-change-policy? unit))
    (let [new-policy (get-near-max-policy (:policy unit) 
                                          (core/get-policystore ctx))]
      (update-entity ctx (:name unit) conj-policy new-policy))                                                
    ctx))</pre></div><div class="docs"><h1>Tracking Follow-On Supply</h1>
</div><div class="codes"></div><div class="docs"><h1>Alteration</h1>

<p>I'm changing the existing scheme of storing followon unit
information, as well as non-followon, or generic unit information.
One (still) tempting idea is to just shove everything into tags, 
and use the tag annotation to execute queries.  We're heading
towards components at that point (which IS the right direction).
For now, a bridging strategy is to unify the buckets and followons, 
basically making a standard bucket, :default, and having everything
else be inferred as "non-generic" (currently meaning followon, or 
associated with some demand group).
Note# 
There is a general relation here...the fact is that the unit is
related to some element of demand...either the demandgroup, or
something else.  That makes tags an interesting prospect....
Further, if we shift to using tags to denote relationship facts, 
we get a consistent API, an option for batched mutable updates, and 
other features.  We have more facts associated with a unit than
merely its followon status....right now we're tracking lots of extra
state when it's simpler to just use tags....</p>
</div><div class="codes"></div><div class="docs"><p>Registers the unit as eligible for follow on status.</p>

<p>The call for update-deploy-status is UGLY.  Might be nice to use keyword args..</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-followon
  [supply unit ctx] 
                                        ;(-&gt; ;(assoc-in supply [:followons (get unit :name)] unit)      
      (update-deploy-status unit true nil ctx))</pre></div><div class="docs"><p>Drops the supply entity from supply store's registry of units in follow-on 
   status.</p>
</div><div class="codes"><pre class="brush: clojure">(defn remove-followon
  [unit ctx]
  (let [unitname (:name unit) 
        fcode    (:followoncode unit)
        src      (:src unit)
        fbucket  (store/get-ine ctx [:SupplyStore :deployable-buckets fcode])
        bucket   (get fbucket src)
        fbucket  (if (== (count bucket) 1)
                   (when (&gt; (count fbucket) 1) (dissoc fbucket src))
                   (assoc fbucket src (dissoc bucket (:name unit))))
        unit    (dissoc :followon)
        ]
    (-&gt; ctx
        (store/update-ine  [:SupplyStore :deployable-buckets]
                           (fn [fcodes]
                             (if fbucket
                               (assoc fcodes fcode fbucket)
                               (dissoc fcodes fcode))))
        (store/dissoce unitname :followon))))</pre></div><div class="docs"><p>Determines if a particular unit is known to be eligible for follow-on use.</p>
</div><div class="codes"><pre class="brush: clojure">(defn followon-unit?
  [store unit] (contains? (:followons store) (get unit :name)))</pre></div><div class="docs"><p><strong>TODO</strong>Detangle release-followon-unit.</p>
</div><div class="codes"></div><div class="docs"><p>Convoluted.  Need to detangle this guy. 
   Assuming a unit associated with unitname was held in follow-on status, the 
   unit is released from holding and allowed to progress back into the global 
   supply.</p>

<p>I think we're missing something here; it doesn't look like we
are unloading our followon supply from the deployable
buckets...
Relook this, I think we can manage the same effects much simpler.</p>
</div><div class="codes"><pre class="brush: clojure">(defn release-followon-unit
  [ctx unitname]
  (let [;_     (println [:releasing unitname :followon])
        ctx   (store/assoce ctx unitname :followoncode nil)
        ctx   (-&gt;&gt; ctx ;(update-entity ctx :SupplyStore remove-followon unitname)                   
                   (u/change-state (store/get-entity ctx unitname)
                                   :abrupt-withdraw 0 0))
        ;store 
        ]   
    (update-deploy-status 
     (core/get-supplystore ctx)
     (store/get-entity ctx unitname)  nil nil ctx)))</pre></div><div class="docs"><p>__Currently, we just wipe out any categories of supply that are not
consistent with our default bucket, :default;  This may change in the
future, especially if we just stick the :followon supply in their
own nested category.  We'll need to do this for SRM and other
more general remissionable supplies.
Process the unused follow-on units, changing their policy to complete cycles.</p>
</div><div class="codes"><pre class="brush: clojure">(defn release-followons [fons ctx]
  (-&gt;  (reduce release-followon-unit  (store/drop-domain ctx :followon) (keys fons))
       (store/updatee :SupplyStore :deployable-buckets
                      (fn [m]
                        (reduce (fn [acc k]
                                  (assoc acc k (get m k))) {} known-buckets)))))</pre></div><div class="docs"><p><strong>TODO</strong> Deprecate release-max-utilizers
This is probably a deprecated function.  It was a corner case to ensure that 
we handled a special class of follow on units, who followed a special max 
utilization policy.  We can probably replace it with something more general.</p>
</div><div class="codes"><pre class="brush: clojure">(defn release-max-utilizers [supplystore &amp; [ctx]]
  (let [{:keys [followons normal]} 
           (group-by #(if (followon-unit? supplystore %) :followon :normal)
                      (tag/get-subjects (:tags supplystore) :MaxUtilizer))
         updates {:SupplyStore (untag-units supplystore :MaxUtilizer 
                                            (concat followons normal))}]   
    (reduce release-followon-unit (sim/merge-entity updates ctx)
            followons)))</pre></div><div class="docs"><h1>Deployment Related</h1>
</div><div class="codes"></div><div class="docs"><p>announce that the unit is in fact following on, remove it from followons.</p>
</div><div class="codes"><pre class="brush: clojure">(defn record-followon [supply unit demandname ctx]
  (-&gt;&gt; ctx
       (remove-followon unit)
       (unit-followon-event! unit demandname)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-next-deploymentid [s] (inc (:uniquedeployments s)))
(defn tag-as-deployed [unit store] 
  (update-in store [:tags] tag/tag-subject (get unit :name) :hasdeployed))</pre></div><div class="docs"><p>NOTE -> this should be OBSOLETE after the port, since we can handle policies 
much more gracefully.
Jeff had me put in some special case for handling initial deployment logic.</p>
</div><div class="codes"><pre class="brush: clojure">(defn first-deployment? [unit store]
  (not (tag/has-tag? (:tags store) (get unit :name) :hasdeployed))) </pre></div><div class="docs"><h2>Supply Management</h2>

<p>the supply system queries the entity store to find entities with
supply updates.
From here ,it updates each entity in turn; really it invokes the
unit-update system.</p>
</div><div class="codes"></div><div class="docs"><p>High level hook for the supply system.  For entities that have scheduled 
   updates at time t, they are brought up to date and have their changes 
   incorporated into the context.  The entity behaviors will typically 
   use some of the supply system functions defined above to alter the context.</p>

<h1>Performance note: manage-supply is a relatively large bottleneck, one we could</h1>

<p>possibly alleviate with a parallel version of update-units.  Legacy version
passed the units as a keyseq via (keys ...), new version passes the
supply updates as a map and uses reduce-kv, which is marginally faster.</p>
</div><div class="codes"><pre class="brush: clojure">(defn manage-supply
  ([t ctx]
   (let [supply (get-entity ctx :SupplyStore)
         ;_ (println [:supply t])
         ]
     (if-let [today-updates (get-supply-updates t ctx)]
       (update-units t supply ctx today-updates)
       ctx)))
  ([ctx] (manage-supply (core/get-time ctx) ctx)))</pre></div><div class="docs"><p>Ensures that entities held in a temporary follow-on status are released and
   circulated back into supply.  Typically used after we try to fill demands.</p>

<p>A simple wrapper to unify the high level supply management.  We were calling 
this inline, it's more consistent now.</p>
</div><div class="codes"><pre class="brush: clojure">(defn manage-followons
  [day ctx]
  (let [fons   (into {} (filter second) (store/get-domain ctx :followon))
        fcount (count fons)]
    (if (pos? fcount)
      (do  (debug [:releasing! fcount :followon])
           (release-followons fons ctx))
      (do (debug [:No-followons-to-release!])
          (store/drop-domain ctx :followon) ;;covering down on a weird issue with nil valued fons.))))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.policy" name="marathon.ces.policy"><h1 class="project-name">marathon.ces.policy</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>This is the source of functionality for the policy system in Marathon.
Policies define ordered transitions that entities follow, and usually map 
directly to a state transition graph for a finite state machine.  Each 
entity may follow a unique policy, or participate in a global policy, or 
alternate as needed.  Some policies are scheduled to change at discrete times
in the simulation, with a sub policy assigned to various periods of simulation
time.  The policy system manages the definitions for a library of policies, 
tracks the current scheduled or conditional periods in the simulation, and 
handles system-wide policy changes for relevant policies.  </p>
</div><div class="codes"></div><div class="docs"><p>The primary functions contained herein surround the management of an abstract 
policy context in the simulation, which is embodied in a policystore.  Most 
of the functions here deal with creating policies, composing policies, 
registering policies with the policystore, registering simulation periods with 
the policystore, and managing policies and periods during the simulation.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.policy
  (:require [marathon.data   [protocols   :as protocols] 
                             [period      :as period]
                             [store :as simstate]]
            [marathon.policy [policydata  :as p]]
            [marathon.ces    [core        :as core]
                             [policyops   :as pops]
                             [unit        :as u]]            
            [spork.util [tags    :as tag]
                        [general :as gen]]
            [spork.entitysystem [store :as store]]
            [spork.sim  [simcontext :as sim]]))</pre></div><div class="docs"><p>----------TEMPORARILY ADDED for marathon.sim.demand!</p>
</div><div class="codes"><pre class="brush: clojure">(declare register-location atomic-name find-period)</pre></div><div class="docs"><p>Missing, likely from marathon.policydata
NOTE -> THERE IS A DUPLICATE FUNCTION IN sim.policy.policydata</p>
</div><div class="codes"><pre class="brush: clojure">(declare get-policy) </pre></div><div class="docs"><p><strong>TODO</strong> Replace references to TimeStep_
<strong>TODO</strong> Replace util.graph with either cljgraph or the topograph from cljgui.</p>
</div><div class="codes"></div><div class="docs"><h2>Policy Simulation Overview</h2>

<p>Policies are the backbone of the entity behavioral system and provide a 
high level mechanism for parameterizing entity behavior.  Policies 
are the scripts that entities consult to determine where to go, how long to 
stay, and how to transition between states.  The other significant component
of the behavioral system are entity behaviors, which act as policy 
interpreters, and actually implement (or ignore) state transitions described 
by a unit's policy structure.  Behaviors are detailed in another namespace.</p>
</div><div class="codes"></div><div class="docs"><h1>What is a policy context?</h1>

<p>Policy is vital because it determines the criteria for both the eligibility and 
suitability of supply to fill demand.  A conservative policy may provide few 
opportunities for units to fill demand, limiting the deployable supply 
(presumably for some benefit like reduced costs), while a liberal policy may
allow units to deploy almost any time, eliminating the previous limitations on 
supply (likely at some cost).  Marathon generally examines policies across the 
spectrum, from liberal to conservative. Policy contexts may not be homogenous 
(applicable to every unit); there may be individual, custom policies for each
unique unit entity.  Additionally, policy contexts may change in response to
conditions in the simulation;  It may be appropriate to have a liberal policy
when demand is low, presumably minimizing the cost to maintain a large 
available supply, while shifting to a liberal policy during periods of higher
demand.  In some cases, there are known strategic events that prompt the change
of rotational policy, typically due to increased demand for units, which
prompts a shift to a different, less constrained policy.  Conversely, after 
demand has receded, the simulation typically tries to return to the 
pre-existing policy context, or an intermediate policy that re-establishes 
stability in the rotational supply.  All of this behavior is scriptable, and
can be modified by changing policy data rather than rewiring logic.  As such,
policies provide a simple, yet powerful scripting mechanism.  </p>
</div><div class="codes"></div><div class="docs"><p>Marathon has historically maintained a notion of an overarching policy context
throughout the simulation.  In fact, the simulation timeline is typically 
viewed as a mapping of policy periods to segments of time.  Periods typically 
serve to segment the timeline into epochs that are easily categorized, and may
trigger changes in the policy context.  For instance, the most common period
set is a sequential #{Pre-Surge, Surge, Post-Surge} set, where Pre-Surge covers
the simulation time in which demand is "low", Surge is a particularly high 
demand that occurs over a short time, and Post-Surge is the remainder of the 
time, categorized as a lower demand but more intense than the Pre-Surge period.
Technically, a timeline in Marathon can have any different number of periods,
not just the common Pre/Surge/Post periods.  The ability to specify periods, 
and then dictate policy changes in reponse to active periods, is a powerful 
mechanism for parameterizing the simulation and managing varied policy 
contexts.  Marathon is currently structured with one default timeline, which is
composed of N contiguous periods.  As the periods change, any policies that 
depend upon a period being active are engaged, and units following to these
policies alter their behavior accordingly.  This is how Marathon manages a 
policy context that can either be simple and uniform (i.e. one policy, one 
period), or very unique (N different policies, K periods).  </p>
</div><div class="codes"></div><div class="docs"><h1>What are policies?</h1>

<p>Policies describe a set of states and durations that -usually- conform to a
rotational policy. Policies are very important, as they serve as the 
instruction set for unit entity behavior.  </p>
</div><div class="codes"></div><div class="docs"><p>Unit entities "act" on policies with their unit behavior, in which the meaning
of the states in the policy is interpreted and acted upon.  Additionally, unit
behaviors consult a policy to figure out what the next state should be, how 
long the unit will stay in said state, etc.
In the language of Finite State Machines, policies describe the states that a
machine can be in, as well as the state transitions that occur. Typical states
include Bogging, Dwelling, Waiting, Moving, StartCycle, EndCycle, Spawning, 
etc.  All the policy has to do is specify which state a unit is in at a 
particular policy position, specify a starting and stopping position, and 
indicate the transition time between state changes.  Policies can have at most
one cycle, and are typically represented as a Directed Graph.  </p>
</div><div class="codes"></div><div class="docs"><p>Note -> Unit behaviors are typically implemented statically, as functions
where policies are much specified as data.  </p>
</div><div class="codes"></div><div class="docs"><p>Next to supply and demand, policy is the most variable higher-order data.  As 
such, we need a robust, flexible way to specify different policies easily, so
that rather than changing code, an end-user can simply modify the data that
describes the policy (not unlike a script) and affect a change in unit entity 
behavior easily and transparently.  </p>
</div><div class="codes"></div><div class="docs"><p>One way to provide flexibility is to use a template system, where users can
derive a policy from an existing template, and then apply a set of parameters
to transform or "mold" the policy into a desired form.  Marathon currently has
several built-in templates, and a language for specifying policy templates is 
very near on the horizon.  Existing policy templates are located in the
MarathonPolicyCreation and MarathonPolicy modules.  The PolicyCreation module
serves as a central dispatch for invoking policy templates, applying
modifications, and deriving new policies.  The MarathonPolicy module contains 
the actual structure for each policy template, as well as routines that provide
default policies for multiple contexts (rather than reading data).  </p>
</div><div class="codes"></div><div class="docs"><p>Technically, anything that implements the IRotationPolicy protocol can serve
as a policy, so developers can extend policy responsibilities to many different
implementations. Marathon provides two implementations of IRotationPolicy, 
which work in tandem to fulfill a composite design pattern.  The current 
implementation, TimeStep<em>Policy, and TimeStep</em>PolicyComposite, provide a 
flexible mechanism for defining policies and composing multiple policies 
together.  They both implement the IRotationPolicy protocol, albeit 
differently.  The key to their flexibility is that composite policies are 
defined in terms of Atomic policies.  So users can, without changing any logic,
add new policy definitions by supplying data that describes how to combine
pre-existing policies.  </p>
</div><div class="codes"></div><div class="docs"><h1>Atomic Policies</h1>

<p>Normal TimeStep_Policy objects are effectively Atomic policies, in that they
represent a single set of instructions that describe a rotational policy.  They
do not change.  Therefore, if a unit entity subscribes to such an atomic 
policy, it will always follow the same set of instructions.</p>

<h1>Composite Policies</h1>

<p>Composite policies represent an association of one or more Atomic policies. <br />
This allows us to capitalize on the atomic policies, and express new policies
as simple compositions of N atomic policies.  </p>
</div><div class="codes"></div><div class="docs"><p>The current implementation of composite policies was built under the notion of
a simple labeling or association of a set of sub policies, where a period label
serves as an index to an associated atomic policy.  Technically, periods are 
just strings or text and can be any valid value.  By convention, periods refer 
to a particular epoch in the simulation, and serve as a way of labeling the 
simulation timeline.  As a consequence, we can define composite policies as a
composition of atomic policies, labelled by period, which will then 
automatically change the governing policy as the simulation period changes. <br />
Note, if the periods that the composite policy are labelled by never occur in 
the simulation, then only the periods that intersect the simulation will ever 
be used. This is useful for describing possible behaviors, where the periods
correspond to corner-cases that may be triggered by external events.</p>
</div><div class="codes"></div><div class="docs"><h2>Implementation</h2>

<h1>Defining Time Periods</h1>
</div><div class="codes"></div><div class="docs"><p>Utility function.  </p>
</div><div class="codes"><pre class="brush: clojure">(defn flip [f] (fn [x y] (f y x)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn policy-update! [t ctx] 
  (sim/request-update t :PolicyManager :policy-update ctx))  </pre></div><div class="docs"><p>Registers a period data structure with the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-period
  [policystore per]
  (let [{:keys [from-day to-day name]} per
        _ (when-let [xs (get-in policystore [:periodchanges from-day])]
            (throw (Exception. (str [:intersecting-periods! per xs]))))]            
    (-&gt; policystore
        (gen/deep-assoc  [:periods name] per)
        (gen/deep-assoc  [:periodchanges from-day] per))))</pre></div><div class="docs"><p>Import a sequence of periods into the policystore</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-periods    
  [periods policystore] 
  (reduce add-period policystore periods))</pre></div><div class="docs"><p>a little sanity checking...
(defn validate-periods [store])</p>
</div><div class="codes"></div><div class="docs"><p>Notifies interested parties of the beginning and ending of a period.
   Schedules a policy update to coincide with the beginning and ending of the 
   period, so that policy management runs when a period changes.</p>
</div><div class="codes"><pre class="brush: clojure">(defn added-period!
  [per ctx]
  (sim/trigger-event :added-period (:name per) (:name per) 
               (str &quot;Added period &quot; per) nil ctx))</pre></div><div class="docs"><p>Arranges for policy updates on the beginning and end of known periods.</p>
</div><div class="codes"><pre class="brush: clojure">(defn schedule-period
  [per ctx]
  (-&gt;&gt; ctx 
    (added-period! per)
    (policy-update! (:from-day per))
    (policy-update! (:to-day per))))</pre></div><div class="docs"><p>Yield registered periods in the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-periods 
  [policystore] 
  (:periods policystore))</pre></div><div class="docs"><p>Find a period in the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-period 
  [policystore periodname] 
  (get (get-periods policystore) periodname))</pre></div><div class="docs"><p>Schedule multiple periods as policy update events..</p>
</div><div class="codes"><pre class="brush: clojure">(defn schedule-periods
  ([policystore ctx] 
   (reduce (fn [acc p]
                 (schedule-period p acc)) ctx (vals (get-periods policystore))))
  ([ctx] (schedule-periods (core/get-policystore ctx) ctx)))</pre></div><div class="docs"><p>Note: Optimization
We're doing this every time, which is costing us in performance.
About 1/3 of our time in simulation is spent checking for
periods due to this function...</p>
</div><div class="codes"></div><div class="docs"><p>One option is to schedule period changes a-priori, then
execute at the appropriate time.</p>
</div><div class="codes"></div><div class="docs"><p>Finds all periods in the policy store that intersect time t.</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-periods
  [t policystore]
  (reduce-kv (fn [p pname per]
               (if (period/intersects-period? t per)
                 (conj p per)
                 p))
             []
             (get-periods policystore)))</pre></div><div class="docs"><p>Finds the first arbitrary period in the policy store that intersects time t.</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-period 
  [t policystore]
  (reduce-kv (fn [p pname per]
               (if  (period/intersects-period? t per)
                 (reduced per)
                 p))
             nil
             (get-periods policystore)))</pre></div><div class="docs"><p>Finds the first arbitrary period in the policy store that intersects time t.</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-period-in 
  [t xs]
  (reduce-kv (fn [p pname per]
               (if  (period/intersects-period? t per)
                 (reduced per)
                 p))
             nil
             xs))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-period-change [ctx t]
  (gen/deep-get (core/get-policystore ctx)
                [:periodchanges t]))</pre></div><div class="docs"><p>Returns the the period currently active in the policy store.  This may change 
when I introduce multiple timelines....</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-active-period [policystore] (:activeperiod policystore))</pre></div><div class="docs"><h1>Policy Location Queries</h1>

<p>As we define policies, we parse their node labels to derive abstract policy 
locations.   </p>
</div><div class="codes"></div><div class="docs"><p>Defining abstract locations.  </p>
</div><div class="codes"><pre class="brush: clojure">(defn get-locations [policystore] (:locationmap policystore))</pre></div><div class="docs"><h1>Decision point for determining how smaller aux functions may</h1>

<p>consume pre-existing mutation information...</p>
</div><div class="codes"></div><div class="docs"><p>register-location follows the assumptions that we want to "update" 
the policystore that's passed in by fetching the existing value of
the locationmap, then conjing a new location name onto it, then 
packing the value back in.  What's the difference if this guy 
is called on a cellular policystore, where locationmap is already 
available? </p>
</div><div class="codes"></div><div class="docs"><p>This sub helps us to keep track of demand and policy locations.
Conjoins a location to the set of known locations...</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-location [locname policystore]
  (gen/deep-update policystore [:locationmap]  conj  locname)) </pre></div><div class="docs"><p>Register multiple locations in the locs collection with the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-locations [locs policystore] 
  (reduce (flip register-location) policystore locs))</pre></div><div class="docs"><p>Register canonical ARFORGEN locations with the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(def default-locations [:available :ready :train :reset :deployed :overlapping])
(defn register-default-locations [policystore] 
  (register-locations default-locations policystore))  </pre></div><div class="docs"><p>Derives locations from the policy.
each location in a policy should be registered in the locations dictionary.
<strong>TODO</strong> Abstract out the call to graph, maybe have policy handle it...</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-policy-locations [p] (protocols/get-locations p))</pre></div><div class="docs"><p><strong>TODO</strong> formalize this...it's really general right now...</p>
</div><div class="codes"><pre class="brush: clojure">(defn composite-policy? [p] (contains? p :policies))
(defn atomic-policy?  [p]  (not (composite-policy? p)))</pre></div><div class="docs"><p>Predicate to determine if a Rotation Policy is defined over a period.</p>
</div><div class="codes"><pre class="brush: clojure">(defn policy-defined? [period policy] 
  (or (atomic-policy? policy) (not (nil? (protocols/get-policy policy period))))) </pre></div><div class="docs"><p>Adds a composite policy to the policystore.  Special, because we keep track of 
composite policies for special consideration during management of the policy 
context.
WEAK, but gets the job done...need a cleaner way to annotate composites.</p>
</div><div class="codes"><pre class="brush: clojure">(defn register-composite [p policystore]
  (if (composite-policy? p) 
    (gen/deep-assoc policystore [:composites (:name p)] p)
    policystore))</pre></div><div class="docs"><p>method for adding atomic and composite policies to the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-policy [p policystore]
  (assert (not (nil? (:name p))) (str &quot;Policy has no name &quot; p))
  (-&gt;&gt; (gen/deep-assoc policystore [:policies (:name p)] p)
       (register-composite p)
       (register-locations (get-policy-locations p))))</pre></div><div class="docs"><p>adds a list of either atomic or composite policies to a policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-policies [policies policystore]
  (reduce (flip add-policy) policystore policies)) </pre></div><div class="docs"><p>Shorthand for triggering a period change in the simulation context.</p>
</div><div class="codes"><pre class="brush: clojure">(defn period-change! [fromname toname ctx]
  (sim/trigger-event :periodChange :PolicyManager toname 
      (str &quot;Period changed from &quot; fromname &quot; to &quot; toname) nil ctx))</pre></div><div class="docs"><p>Event notifying the need to update all units due to a change in the the period, 
or epoch, of the simulation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn period-driven-update! [fromname toname ctx]
  (sim/trigger-event :updateAllUnits :PolicyManager :PolicyManager 
     (str &quot;Period change from &quot; fromname 
          &quot; to &quot;  toname &quot; caused all units to update.&quot;) toname ctx))</pre></div><div class="docs"><p>Acquisition means we have to find a value, or else we throw an
exception. We expect there to be a period associated. </p>
</div><div class="codes"><pre class="brush: clojure">(defn acquire-period [policystore toname]
  (do ;(println [:acquiring toname])
      (if-let [
               res (or (get-period policystore toname)
                       (get-period policystore (:name toname))
                       (get-period policystore (name (:name toname))))]
        res
        (throw (Exception. (str &quot;Period &quot; toname &quot; does not exist in the policystore!&quot;))))))</pre></div><div class="docs"><p>Swaps out the active period.  If the new period is the final period, then caps
the final period to the current day.</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-period [day toname policystore]
  (-&gt;&gt; (if (= toname :final) (period/-&gt;period :final day day) 
                             (acquire-period policystore toname))
       (assoc policystore :activeperiod)))</pre></div><div class="docs"><p>wrapper for any tasks we need to perform in the final period.</p>
</div><div class="codes"><pre class="brush: clojure">(defn final-period [fromname toname ctx] 
  (period-driven-update! fromname toname ctx))</pre></div><div class="docs"><h1>Changing Policies in Response to Period Changes</h1>
</div><div class="codes"></div><div class="docs"><p>queue-policy-change could probably be in the unit level simulation.
Note -> returns unit-updates....CONSUME WITH sim/merge-updates</p>
</div><div class="codes"></div><div class="docs"><p>Queues a unit's status as having a pending policy change.  Right now, status 
   is maintained in unit data.  When the unit has an opportunity to change 
   policies, if it can't change immediately, it retains the policy change until
   the opportuntity arises.</p>
</div><div class="codes"><pre class="brush: clojure">(defn queue-policy-change
  [unit newpolicy period ctx]
  (let [current-policy (protocols/get-active-policy (:policy unit))
        atomic-policy  (protocols/get-policy newpolicy period)
        unit           (u/change-policy atomic-policy ctx)]
    (if (= (:name (:policy unit)) (:name atomic-policy))
           {:unit-update (assoc unit :policy newpolicy)}
           {:unit-update (-&gt; (assoc unit :policy current-policy)
                             (assoc  :policystack [newpolicy]))})))        </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn update-policy [policystore p] 
  (gen/deep-assoc policystore [:policies (:name p)] p))</pre></div><div class="docs"><p>Affects a change in policy.  This is currently only caused when periods 
   change in a composite policy.  I'd really like to get more reactive behavior 
   involved.</p>
</div><div class="codes"><pre class="brush: clojure">(defn alter-unit-policies
  [subscribers period newpolicy ctx]
  (-&gt;&gt; (map #(queue-policy-change %1 newpolicy period) subscribers) 
       (reduce #(sim/merge-updates %1 %2) ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn policy-name [p] (if (keyword? p) p (:name p)))
(defn get-subscribers [policy policystore] 
  (-&gt; policystore 
      :subscriptions
      (get (policy-name policy))))</pre></div><div class="docs"><p>Applies f to the subscriptions associated with policy in policystore, then
   stores the updated result, returning the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-subscribers 
  [f policy policystore]
  (gen/deep-update policystore [:subscriptions (policy-name policy)] f))</pre></div><div class="docs"><p>High level policy management.  For policies that are period-driven, enforces 
   a policy shift to the sub policy defined over the new period.  If the period
   is undefined, no change happens.</p>
</div><div class="codes"><pre class="brush: clojure">(defn change-policy
  [current-period new-period policy policystore ctx]
  (let [subscribers (get-subscribers policy policystore)
        new-policy  (protocols/on-period-change policy new-period)]
        (-&gt;&gt; (alter-unit-policies subscribers new-period policy ctx)
             (core/merge-entity 
               {:PolicyStore (update-policy policystore new-policy)}))))</pre></div><div class="docs"><p>(defn subscribe-unit 
  "Subscribes a unit to policy by establishing a relation with the policy in
   the policy store.  Rather than storing subscriptions in the policy, we now
   keep them in the policystore."
  [unit policy policystore]
  (let [old-policy (policy-name (:policy unit))
        new-policy (policy-name policy)
        nm         (:name unit)
        s          (:subscriptions policystore)
        oldsubs    (disj (get s old-policy #{})  nm)
        newsubs    (conj  (get s new-policy #{}) nm)]
    (->> (assoc s old-policy oldsubs)
         (assoc new-policy newsubs))
         (assoc policystore :subscriptions)))</p>
</div><div class="codes"></div><div class="docs"><p>Subscribes a unit to policy by establishing a relation with the policy in
   the policy store.  Rather than storing subscriptions in the policy, we now
   keep them in the policystore.</p>

<p>TODO clean up the if's in here, the conditions are pretty nasty.</p>
</div><div class="codes"><pre class="brush: clojure">(defn subscribe-unit 
  [unit policy policystore]
  (let [new-policy (policy-name policy)
        nm         (:name unit)
        scripts    (:subscriptions policystore)
        newsubs    (conj  (get scripts new-policy #{}) nm)
        s          (assoc scripts  new-policy newsubs)]
    (-&gt;&gt;  (if-let [old-policy (policy-name (:policy unit))]
            (if (identical? old-policy new-policy) 
              s
              (let [oldsubs    (disj (get s old-policy #{})  nm)]
                (assoc s old-policy oldsubs)))
            s)
          (assoc policystore :subscriptions))))</pre></div><div class="docs"><p>TODO  faster mutable version.  lots of map and set munging.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-sub! [scripts policy nm]
  (assoc! scripts policy
          (conj!  (if-let [xs (get scripts policy)]
                    xs
                    (transient #{}))
                  nm)))
(defn drop-sub! [scripts policy nm]
  (assoc! scripts policy
          (disj!  (if-let [xs (get scripts policy)]
                    xs
                    (transient #{}))
                  nm)))</pre></div><div class="docs"><p>Subscribes a unit to policy by establishing a relation with the policy in
   the policy store.  Rather than storing subscriptions in the policy, we now
   keep them in the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn subscribe-unit! 
  [unit policy  scripts]
  (let [new-policy (policy-name policy)
        nm         (:name unit)
        scripts (add-sub! scripts new-policy nm)]
    (if-let [old-policy (policy-name (:policy unit))]
      (if (identical? old-policy new-policy) 
        scripts
        (do (drop-sub! scripts old-policy nm) 
            scripts)))))</pre></div><div class="docs"><p>Subscribes a unit to policy by establishing a relation with the policy in
   the policy store.  Rather than storing subscriptions in the policy, we now
   keep them in the policystore.</p>

<p>Note: If we want to recycle the policy store, we can
by dropping subscriptions.  Resetting the period...</p>
</div><div class="codes"><pre class="brush: clojure">(defn unsubscribe-unit 
  [unit policy policystore]
  (let [old-policy (policy-name policy)
        nm         (:name unit)
        s          (:subscriptions policystore)
        oldsubs    (disj (get s old-policy)  nm)]
    (-&gt;&gt; (-&gt; s (assoc old-policy oldsubs))
         (assoc policystore :subscriptions))))</pre></div><div class="docs"><p>Returns a sequence of policies that have active subscriptions.</p>
</div><div class="codes"><pre class="brush: clojure">(defn active-policies [pstore]
  (let [ps        (:composites pstore)]
    (filter identity 
       (for [[nm xs] (:subscriptions pstore)]
         (when-let [p (ps nm)]
           p)))))</pre></div><div class="docs"><p>We define change in a composite policy by the existence of both the new period 
and the old period in the composite policy.  Atomic policies are defined across 
all periods.  So the only ones that should show up here are policies that 
contained both the old and new, or current and new periods. </p>
</div><div class="codes"></div><div class="docs"><p>This function is a predicate that effectively filters out composite policies 
that are undefined over both periods.</p>
</div><div class="codes"></div><div class="docs"><p>Returns a filtered sequence of all the composite policies that have changed.
   We only examine policies that have active subscribers.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-changed-policies
  [current-period new-period candidates]
  (filter (fn [p] (and (policy-defined? current-period p)
                       (policy-defined? new-period p))) candidates))</pre></div><div class="docs"><p>Transcription Note -> in the original design, we delegated a lot of control 
to each of the policies associated with the unit.  Now, we're going to treat
the policies more like pure data, and record the policy associated with each
entity.  When we change policies, we do it from the policystore in a \
controlled fashion. </p>
</div><div class="codes"></div><div class="docs"><p>This routine informs subscribers of the need to try to change their policies
at the next available opportunity.  Only happens for composite policies, when 
a new, valid period has been engaged.</p>
</div><div class="codes"></div><div class="docs"><p>Tom Change 12 July 2011
tell each policy to have its subscriber change to a new policy.
Simple algorithm -> fetch the new policy associated with the period.
Tell each policy to change to the new policy.</p>
</div><div class="codes"></div><div class="docs"><p>you know, this is actually really easy in the CES system...
all we have to do is pull out entities with a policy component.
then send them messages to change-policy....
Note: policy changes, like supply updates, can also be done in
parallel / async.</p>
</div><div class="codes"></div><div class="docs"><p>High level system that propogates policy changes all the way down to entities 
   that participate in the affected policies.  Typically called in response to 
   period changes.</p>
</div><div class="codes"><pre class="brush: clojure">(defn change-policies
  [current-period new-period ctx]  
  (let [policystore (core/get-policystore ctx)]
    (if (= current-period :Initialization) ctx ;short-circuit 
        (-&gt;&gt; (active-policies policystore)
             (get-changed-policies current-period new-period)
             (reduce #(change-policy current-period new-period %2
                        (core/get-policystore %1) %1) ctx)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn has-subscribers? [policy policystore] 
  (pos? (count (get (:subscribers policystore) policy))))</pre></div><div class="docs"><h1>Managing Policies and Periods</h1>

<p>This is the primary routine to manage policies for a policy store, which are 
driven by period changes.  Many policies are defined over abstract periods, 
so if periods are scheduled to change, they will propogate a change in entity
policies.  One flaw with the existing design is that there is, assumably, a 
single overarching period in effect.  A nice extension would be to allow 
any number of concurrent periods, or time-lines, which would facilitate 
sophisticated behaviors, or policy-states, for unique elements of the supply.
TODO -> extend from a single-active period to multiple active periods.</p>
</div><div class="codes"></div><div class="docs"><p>The policy system checks to see if we entered a new period, and changes 
   the governing policies to fit the new period.  High level entry point, 
   typically called by the simulation engine.</p>

<p>PERFORMANCE NOTE: calling find-period-in is a minor hotspot.
We can explicitly schedule period changes when we read in periods,
rather than scanning every day...</p>
</div><div class="codes"><pre class="brush: clojure">(defn manage-policies
  ([day ctx newperiod]
     (let [policystore (core/get-policystore ctx)
           toname      (:name          newperiod)
           period      (:activeperiod  policystore)
           fromname    (:name period)]
       (if (= fromname toname) ctx
           (-&gt;&gt; (if (= toname :final) (final-period fromname toname ctx) ctx)
                (core/merge-entity {:PolicyStore (update-period day toname policystore)})
                (period-change!  fromname toname)
                (change-policies fromname toname)))))
  ([day ctx]
   (if-let [new-period (get-period-change ctx day)]
   ;;Optimizing.  We only look for periods if necessary vs. every day.
     (manage-policies day ctx
                      new-period
                      #_(find-period-in day
                                      (store/gete ctx :PolicyStore :periods)))
     ctx ;;otherwise no change.)))</pre></div><div class="docs"><p>(defn manage-policies
  "The policy system checks to see if we entered a new period, and changes 
   the governing policies to fit the new period.  High level entry point, 
   typically called by the simulation engine."
  ([day ctx newperiod]
     (let [policystore (core/get-policystore ctx)
           toname      (:name newperiod)
           period      (:activeperiod policystore)
           fromname    (:name period)]
       (if (= fromname toname) ctx
           (->> (if (= toname :final) (final-period fromname toname ctx) ctx)
                (core/merge-entity {:PolicyStore (update-period day toname policystore)})
                (period-change! fromname toname)
                (change-policies fromname toname)))))
  ([day ctx] (manage-policies day ctx 
                              (find-period day
                                              (core/get-policystore  ctx)
                                           ))))</p>
</div><div class="codes"></div><div class="docs"><p>Fetches a policy, by name, from the policystore.
TODO -> add in a policy does not exist exception...</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-policy [policy-name policystore] 
  (get-in policystore [:policies policy-name]))</pre></div><div class="docs"><p>get all pending policy updates for time t.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-policy-updates [t ctx] (sim/get-updates :policy t ctx))</pre></div><div class="docs"><p>MIGHT BE OBSOLETE
clear all the locations from the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn clear-locations [policystore] (assoc policystore :locationmap #{}))</pre></div><div class="docs"><p>TODO -> THIS IS WEAK, SHOULD CONSULT TAGS, REFACTOR.
Simple predicate to determine if a location is actually a demand.
Demands, upon creation, have their start and duration encoded as
a textual range: [1..blah], so a predicate only needs to check for
a left bracket.  This is somewhat brittle, and dependent upon the
demand representation never changing, but it works for now and
is relatively easy to patch.</p>
</div><div class="codes"><pre class="brush: clojure">(defn demand-location? [location-name] (= (first location-name) \[))</pre></div><div class="docs"><h1>Policy Construction and Composition</h1>
</div><div class="codes"></div><div class="docs"><p>Currently, composite policies are built purely from atomic policies.  In 
theory, one could compose a new policy from atomic OR composite policies. <br />
This is currently not implemented or tested.</p>
</div><div class="codes"></div><div class="docs"><p>REVISIT 
Primitive constructore for composite policy.  To define a composite, we need at
least one period and one atomic policy.</p>
</div><div class="codes"><pre class="brush: clojure">(defn create-composite [policyname period atomic-policy]
  (-&gt; (assoc p/empty-policymap :name policyname) 
      (protocols/add-policy  period atomic-policy))) </pre></div><div class="docs"><p>TODO -> Add an existence check for the child policies...
creates a composite policy from n policies defined in periodpolicymap 
(a dictionary). periodpolicymap is assumed to be a map, where the keys are the 
names of periods over which the associated policy values are defined.  Using a 
dictionary/hashmap ensures that only unique values for period names are entered
We only need a dictionary<string,string>, or ::string->string</p>
</div><div class="codes"><pre class="brush: clojure">(defn compose-policies [policyname period-policy-map child-policies]
  (reduce (fn [acc [period childname]] 
            (protocols/add-policy acc period (get child-policies childname)))
          (-&gt; p/empty-policymap (assoc :name policyname)) 
          (seq period-policy-map)))</pre></div><div class="docs"><p>TODO -> add existence checks for child policies.
A constructor for building a sequential policy from a collection of policies. 
The sequential policy will represent an ordered list of policies, drawn from 
child policies.  At this point, only atomic policies may be members of a 
sequence.</p>
</div><div class="codes"><pre class="brush: clojure">(defn sequence-policies [policyname names child-policies]
  (if (== (count names) 1) ;single policy...no need to sequence
    (-&gt; (get child-policies (first names))
        (assoc :name policyname))
    (reduce (fn [acc child-name] (protocols/add-policy acc (get child-policies child-name)))
            (-&gt; p/empty-policyseq (assoc :name policyname)) names)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn sequential-policy? [p] (vector? p))
(defn build-policy [name pieces policy-lib] 
  (cond  (vector? pieces)   (sequence-policies name pieces policy-lib)
         (map? pieces)      (compose-policies  name pieces policy-lib)         
         :else ; (sequence-policies name [pieces] policy-lib)))
         (throw (Exception. (str &quot;unknown policy type: &quot; [name pieces])))))</pre></div><div class="docs"><p>Given a set of composite policy descriptions, and a set of child policies, 
produces a list of composite policies derived from the compositions.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compositions-&gt;composites [compositions child-policies]
  (reduce (fn [acc [policy-name pieces]]
            (conj acc (build-policy policy-name pieces child-policies)))  [] compositions))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn permanent-record? [r] (= (get r :Period) &quot;Permanent&quot;))</pre></div><div class="docs"><p>Modified to simplify representation...</p>
</div><div class="codes"><pre class="brush: clojure">(defn equivalence-key [delim recepient donor] 
  ;(keyword (str  recepient delim donor))
  [recepient delim donor])</pre></div><div class="docs"><p>accesor for equivalency relations in a policystore</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-equivalencies [policystore] 
  (get-in policystore [:rules :equivalencies]))</pre></div><div class="docs"><p>accessor for substitution relations in a policystore</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-subs [policystore] (get-in policystore [:rules :substitutions]))</pre></div><div class="docs"><p>Adds an equivalence relationship to the policystore</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-equivalence [recepient donor policystore]
  (let [delim (:ruledelim policystore)] 
    (gen/deep-assoc policystore 
        [:rules :equivalencies (equivalence-key := recepient donor)] 0)))</pre></div><div class="docs"><p>Adds a substitution relationship to the policystore</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-substitution [recepient donor cost policystore]
  (let [delim (:ruledelim policystore)]
    (gen/deep-assoc policystore 
        [:rules :substitutions (equivalence-key :|&gt; recepient donor)] cost)))</pre></div><div class="docs"><p>determine if the policystore has a registered rule</p>
</div><div class="codes"><pre class="brush: clojure">(defn has-rule? [rule policystore] 
  (or (contains? (get-subs policystore) rule)
      (contains? (get-equivalencies policystore) rule)))</pre></div><div class="docs"><p>Function to add relations to a policystore.  dispatches based on relation type.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-relation [policystore relation recepient donor &amp; [cost]]
  (case relation 
    :equivalence (add-equivalence recepient donor policystore)   
    :sub         (add-substitution recepient donor cost policystore)
    (throw (Exception. (str &quot;unknown relation &quot; relation)))))</pre></div><div class="docs"><p>Assuming a list of (relation, recepient, donor, cost) entries, maps 
add-relation to each entry.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-relations [relations policystore] 
  (reduce (fn [acc [x y z w]] (add-relation acc x y z w)) 
          policystore relations))</pre></div><div class="docs"><p>Accessor function for the policies in the policystore</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-policies [policystore] (:policies policystore))</pre></div><div class="docs"><p>Get a list of the names of policies in the policy store.</p>
</div><div class="codes"><pre class="brush: clojure">(defn policy-names [policystore] (keys (get-policies policystore)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def policy-cache (atom {}))</pre></div><div class="docs"><p>Get a policy associated with Pname, relative to the policystore.</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-policy [pname policystore] 
  (if-let [p (or (get (get-policies policystore) pname)
                 (get @policy-cache pname)
                 (when-let [pol (get pops/aliases pname)]
                   (if-let [res (get @policy-cache pol)]
                     (do (swap! policy-cache assoc pname res)
                         res)
                     (let [res (pol)]
                       (do (swap! policy-cache assoc pol res)
                           res)))))]
    p
    (throw (Exception. (str &quot;Unknown policy! &quot; pname)))))</pre></div><div class="docs"><p>Return the set of policy graphs</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-policy-graphs [policystore]
  (into {} (for [p (vals (get-policies policystore))]
             [(protocols/policy-name p) (protocols/get-position-graph p)])))</pre></div><div class="docs"><h1>Policystore Creation</h1>

<p>'TODO -> get this constructor back online.
'Rewire this....
'What we're really doing is building a policymanager from several sources...
'relations::     list&lt;(relation, recepient, donor, cost)>
'periods::       list<genericperiod>
'atomicpolicies::list&lt;TimeStep_Policy></p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn make-policystore 
  [relations periods atomic-policies &amp; [composite-policies store]]
  (-&gt;&gt; (or store simstate/empty-policystore)
       (add-relations relations)
       (add-periods periods)
       (add-policies atomic-policies)
       (add-policies composite-policies)))      </pre></div><div class="docs"><p>'TOM Change 10 SEP 2012 OBE</p>
</div><div class="codes"><pre class="brush: clojure">#_(defn initialize-policystore [policystore ctx]
    (schedule-periods policystore ctx))
;Since composite policy loading is dependent on atomic policy loading, we 
;provide an auxillary function to ensure the order is correct, and specify 
;inputs. atomics is a map of policyname-&gt;Timestep_Policy, compositions is a map
;of policyname-&gt;(map of periodname-&gt;(either policyname or Timestep_Policy)
(defn add-dependent-policies [atomics compositions policystore]
  (-&gt;&gt; policystore 
       (add-policies (vals atomics))
       (add-policies (compositions-&gt;composites compositions atomics))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn period-schedule [policystore]
  (sort-by (juxt :from-day :to-day) (vals (:periods policystore))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn invalid-periods [policystore]
  (-&gt;&gt; (period-schedule policystore)
       (partition 2 1)
       (filter (fn [[l r]]
                 (let [from (:to-day l)
                       to   (:from-day r)]
                   (not= (- to from) 1))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn validate-periods! [ctx] 
  (if-let [xs (seq (invalid-periods (core/get-policystore ctx)))]
    (throw (Exception. (str [:non-adjacent-periods! xs])))
    true))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn policy-at [p period]
  (marathon.data.protocols/on-period-change p period))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn policy-change-info [p from to]
  (let [old (policy-at p from)
        new (policy-at p to)]
    [:name (marathon.data.protocols/policy-name p)
     :from (marathon.data.protocols/atomic-name old)
     :to   (marathon.data.protocols/atomic-name new)]))</pre></div><div class="docs"><p>it'd be nice to have a sort of policy-summary...
lay out the policy changes over time that will
be active during the simulation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn policy-schedule [ctx]
  (let [pstore  (core/get-policystore ctx)
        periods (period-schedule pstore)]
    (for [[l r] (partition 2 1  periods)]
      (let [from (:name l)            
            to   (:name r)]
        (-&gt;&gt; (active-policies pstore)
             (get-changed-policies from to)             
             (map #(policy-change-info % from to))
             (sort-by first)
             (vector :from l
                     :to r
                     :changes))))))</pre></div><div class="docs"><h5>;Redundant, replaced by protocols/add-policy</h5>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment 
;Primitive wrapper for appending atomic policies to composite policies.
;TODO -&gt; extend this to incorporate the semantics for generalized rotation 
;policies....specifically, allow composite policies to be defined over composite
;policies as the intersection of periods across the policies.
(defn append-composite [composite period atomic-policy] 
  (protocols/add-policy composite atomic-policy period))
;REDUNDANT
;This is the typical append operation.  When we compose an atomic policy with a 
;composite, we simply register the atomic as a sub policy under the key period.
(defn append-composite-atomic [composite period sub-policy]
  (protocols/add-policy composite sub-policy period)) )</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.ces.policyio" name="marathon.ces.policyio"><h1 class="project-name">marathon.ces.policyio</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.ces.policyio
  (:require [marathon.ces [policyops :as policyops]
                          [policy :as pol]]
            [marathon.data [protocols :as core]
                           [period :as per]
                           [store :as simstate]]
            [spork.util [table :as tbl]]))</pre></div><div class="docs"><p>Data related to the policystore, is actually quite disparate.  There are
multiple data sources that must be read to compose and initialize a policystore 
that has information on simulation periods, rotational policies, and 
substitution relations.  As such, policyIO has enough code to justify breaking
it out into a separate module, for organizational sanity.</p>
</div><div class="codes"></div><div class="docs"><p>The functions in this module concern reading data regarding policies and 
converting it into internal data structures.  Many of the records and other 
data forms Marathon uses serve as a specification or a list of instructions 
that are intended to be parsed to build policy structures.  The following 
functions support the transformation of records to various policystore related
structures, such as relations, atomic rotational policies, composite rotational
policies, tables of policy records, etc.  Most of these functions will be 
wrapped in higher level constructors, like tablesToPolicyStore, or 
policyStoreFromExcel, which glue together the lower level IO and parsing 
functions for the end user.  Additional parsing functions, such as JSON and 
Clojure data readers/writers, will also crop up here as needed.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def deployable-templates
  (atom #{ ;core/MaxUtilization core/NearMaxUtilization core/FFGMission
          :MaxUtilization :NearMaxUtilization :FFGMission}))</pre></div><div class="docs"><p>Flag for policies that don't need have their deployable ranges set. <br />
Only applies to MaxUtilization.</p>
</div><div class="codes"><pre class="brush: clojure">(defn deployable-set? [template-name]
  (contains? @deployable-templates template-name)) </pre></div><div class="docs"><p>LEGACY issue.
this is a little weak, we could use a map here instead of a list of values.</p>
</div><div class="codes"><pre class="brush: clojure">(defn record-&gt;relation [inrec] 
  ((juxt :Relation :Donor :Recepient :Cost) inrec))</pre></div><div class="docs"><p>TODO -- Defer policy loading so that these are delayed.  Or make
policy generation faster (we're bottlenecking there a bit).  We don't
use all the policies, so we simply defer them until necessary, and
throw in a check for realized? when we go to lookup a policy.
(_   _    _  PolicyName Template MaxDwell MinDwell MaxBOG StartDeployable StopDeployable Overlap Recovery BOGBudget Deltas  _)</p>
</div><div class="codes"><pre class="brush: clojure">(defn record-&gt;policy 
  [{:keys [Template PolicyName MaxBOG MaxDwell MinDwell Overlap 
           StartDeployable StopDeployable Deltas]}]
  (let [deltas (if (= Deltas &quot;{}&quot;) {}
                   (clojure.edn/read-string
                    (clojure.string/replace Deltas
                                            &quot;\\&quot; )))
        ]
    (-&gt; (if (= Template &quot;Ghost&quot;) 
          (policyops/register-ghost-template PolicyName MaxBOG  :overlap Overlap)
          ;;we'd like to delay this if possible...          
          (policyops/register-template Template MaxDwell MinDwell MaxBOG 
                                 StartDeployable StopDeployable
                                 :overlap Overlap 
                                 :deltas  deltas
                                 :deployable-set? (deployable-set? Template)))
        (assoc :name PolicyName))))           </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def reltbl {&quot;SUB&quot; :sub
             &quot;EQUIVALENCE&quot; :equivalence})
(defn rel-&gt;key [r]
  (get reltbl (clojure.string/upper-case (clojure.string/trim r))))</pre></div><div class="docs"><p>generate a sequence of relations from the table records</p>
</div><div class="codes"><pre class="brush: clojure">(defn table-&gt;relations [t]
  (-&gt;&gt; (tbl/table-records t)
       (filter (fn [r] (:Enabled r)))
       (map (fn [r] (if-let [rel (rel-&gt;key (:Relation r))]
                      (assoc r :Relation rel)
                      (throw (Exception. (str &quot;unknown relation: &quot; (:Relation r)))))))                                  
       (map record-&gt;relation)))</pre></div><div class="docs"><p>generate a collection of atomic policies from the table records</p>
</div><div class="codes"><pre class="brush: clojure">(defn table-&gt;policies [t] (map table-&gt;policies (tbl/table-records t)))</pre></div><div class="docs"><p>generate a dictionary of atomic policies from a table, where the keys are
policy names.  Enforces unique policy names.</p>
</div><div class="codes"><pre class="brush: clojure">(defn table-&gt;policy-map [t]
  (reduce (fn [m r]
            (let [p (record-&gt;policy r)]
              (assoc m (:name p) p)))
          {} (tbl/table-records t))) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def literals #{&quot;#&quot; &quot;[&quot; &quot;(&quot; &quot;{&quot;})
(defn data-literal?  [s] (literals (subs s 0 1)))
(defn implicit-seq? [^String s] (.contains s &quot;,&quot;))
(defn read-composition [x]
  (cond (data-literal? x) (clojure.edn/read-string x)
        (implicit-seq? x) (mapv str (clojure.edn/read-string (str &quot;[&quot; x &quot;]&quot;)))
        :else x))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ensure-vec [x]
  (if (coll? x) x
      [x]))</pre></div><div class="docs"><p>MAY BE OBSOLETE...
Reads an expression from a record
with keys (CompositeName Policy), 
vals [somestring, {policy dictionary}/or [policy list]]
We use our evaluator to transform the policy string into a policy dictionary.
Returns a pair of [rulename, {policy dict}], or [rulename [policy sequence]]</p>
</div><div class="codes"><pre class="brush: clojure">(defn record-&gt;composition [r] 
  [(:CompositeName r) (clojure.edn/read-string (:Composition r))])</pre></div><div class="docs"><p>Evaluates a record as into a key-val pair that describes a rule.
Keys in the dictionary correspond to the name of the rule, and vals correspond 
to a map of period names to policy names/ policies.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-composition [acc r]
  (if (contains? r :Composition)
    (conj acc (record-&gt;composition r))
    (let [{:keys [CompositeName CompositionType]} r]
      (case CompositionType 
        &quot;Periodic&quot; (update-in acc [CompositeName] assoc (:Period r) (:Policy r))
        &quot;Sequential&quot; (do (assert (not (contains? acc CompositeName)))
                         (assoc-in acc [CompositeName]
                             (ensure-vec (read-composition (:Policy r)))))
        (throw (Exception. &quot;Error parsing composition policy!&quot; 
                           CompositeName))))))</pre></div><div class="docs"><p>Generates a map of composition rules from a table.</p>
</div><div class="codes"><pre class="brush: clojure">(defn table-&gt;compositions [t]
  (reduce add-composition {} (tbl/table-records t)))</pre></div><div class="docs"><p>Create a policystore from a set of tables.
much more robust, uses the generictable interface to simplify loading.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tables-&gt;policystore 
  ([relation-table period-table atomic-table composite-table]
     (-&gt;&gt; simstate/empty-policystore
          (pol/add-relations (table-&gt;relations relation-table))
          (pol/add-periods   (map per/record-&gt;period (tbl/table-records period-table)))
          (pol/add-dependent-policies (table-&gt;policy-map atomic-table) 
                                      (table-&gt;compositions composite-table))))
  ([{:keys [RelationRecords PeriodRecords PolicyRecords CompositePolicyRecords]}]
     (tables-&gt;policystore RelationRecords PeriodRecords PolicyRecords CompositePolicyRecords)))</pre></div><div class="docs"><p>testing</p>
</div><div class="codes"><pre class="brush: clojure">(comment
(require '[marathon.sim.sampledata :as sd])
;; (def atomics     (sd/get-sample-records :PolicyRecords))
;; (def composites  (sd/get-sample-records :CompositeRecords))
(def atomics     (get sd/sample-tables :PolicyRecords))
(def composites  (get sd/sample-tables :CompositePolicyRecords))
(def rels        (get sd/sample-tables :RelationRecords))
(def pers        (get sd/sample-tables :PeriodRecords))
(def pstore      (tables-&gt;policystore rels pers atomics composites)))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.analysis" name="marathon.analysis"><h1 class="project-name">marathon.analysis</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Defines utilities and workflows for
performing higher-order analysis
of simulations.  Specifically, we
define ways to process simulation history
and produce dynamic analysis.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.analysis
  (:require [spork.util.table       :as tbl]            
            [marathon.ces [core     :as core]
                          [engine   :as engine]
                          [setup    :as setup]
             ]
            [clojure.core.reducers :as r]
            [spork.util.reducers]
            [clojure.pprint :refer [pprint]]
            [marathon [project  :as proj]]
            [marathon.project [linked :as linked]
                              [excel  :as xl]]
            [spork.entitysystem
             [diff     :as diff]
             [store :as store]]
            [spork.sim.simcontext     :as sim]
            [marathon
             [schemas   :as schemas]
             [observers :as obs]
             [serial    :as ser]
             [util      :as util]]))</pre></div><div class="docs"><p>ripped from clojure.core.reducers temporarily...</p>
</div><div class="codes"><pre class="brush: clojure">(defn- do-curried
  [name doc meta args body]
  (let [cargs (vec (butlast args))]
    `(defn ~name ~doc ~meta
       (~cargs (fn [x#] (~name ~@cargs x#)))
       (~args ~@body))))</pre></div><div class="docs"><p>Builds another arity of the fn that returns a fn awaiting the last
  param</p>
</div><div class="codes"><pre class="brush: clojure">(defmacro  defcurried
  [name doc meta args &amp; body]
  (do-curried name doc meta args body))</pre></div><div class="docs"><p>A reducible collection of [seed, (f seed), (f (f seed)), ...]</p>

<p>Note: there's a problem with the compile-time trick here...
in-ns, used in spork.util.reducers, actually produces
Huh...well, we'll have to cop this.
we're going to add in iterate, range, and friends
Reducers patch for Clojure courtesy of Alan Malloy, CLJ-992, Eclipse Public License</p>
</div><div class="codes"><pre class="brush: clojure">(defcurried r-iterate
  {:added &quot;1.5&quot;}
  [f seed]
  (reify
    clojure.core.protocols/CollReduce
    (coll-reduce [this f1] (clojure.core.protocols/coll-reduce this f1 (f1)))
    (coll-reduce [this f1 init]
      (loop [ret (f1 init seed), seed seed]
        (if (reduced? ret)
          @ret
          (let [next (f seed)]
            (recur (f1 ret next) next)))))
    clojure.lang.Seqable
    (seq [this]
      (seq (clojure.core/iterate f seed)))))</pre></div><div class="docs"><h1>Move these into core...</h1>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;simreducer [stepf init]  
  (r/take-while identity (r-iterate (fn [ctx]
                                       (when  (engine/keep-simulating? ctx)
                                          (let [init ctx
                                                t  (sim/get-time ctx)
                                                processed  (stepf t  ctx)
                                                nxt        (sim/advance-time processed)]
                                            (with-meta nxt {t {:start init
                                                               :end processed}}))))
                                    init)))</pre></div><div class="docs"><p>I think we want to convert this into a stream with the simulation
state.  So, instead of just [t ctx], we get [t ctx :begin|:end]
That way, other streams can filter on either begin/end or use both.</p>
</div><div class="codes"></div><div class="docs"><p>A wrapper for an abstract simulation.  Can produce a sequence of
simulation states; reducible.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;simulator [stepf seed]
  (let [simred (-&gt;simreducer stepf seed)]
    (reify     
      clojure.lang.Seqable 
      (seq [this]  
        (take-while identity (iterate (fn [ctx] 
                                        (when  (engine/keep-simulating? ctx)
                                          (let [init       ctx
                                                t          (sim/get-time     ctx)
                                                processed  (stepf t          ctx)
                                                nxt        (sim/advance-time processed)]
                                            (with-meta nxt {t {:start init
                                                               :end processed}}))))
                                      seed)))
      clojure.core.protocols/CollReduce
      (coll-reduce [this f1]   (reduce f1 simred))
      (coll-reduce [_ f1 init] (reduce f1 init simred)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;history-stream [tfinal stepf init-ctx]
  (-&gt;&gt; init-ctx
       (-&gt;simulator stepf)
       (map (fn [ctx] [(core/get-time ctx) ctx]))
       (take-while
        (fn [^clojure.lang.Indexed v]
          (&lt;= (.nth v 0) tfinal)))))</pre></div><div class="docs"><p>Now using transducers.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;history [tfinal stepf init-ctx]
  (into {} (comp (map (fn [ctx] [(core/get-time ctx) ctx]))
                 (take-while #(&lt;= (first %) tfinal)))        
        (-&gt;simulator stepf init-ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ending [h t] (get (meta (get h t) :end  )))
(defn start  [h t] (get (meta (get h t) :start)))</pre></div><div class="docs"><p>most metrics should be collected at the end of the
day.  For debugging and verification purposes, we'd
like to have the history at the beginning of each day.
We technically provide access to both via the history stream.
we embed the previous day's sample in the meta.</p>
</div><div class="codes"><pre class="brush: clojure">(defn end-of-day-history [h]
  (-&gt;&gt; h
       (map #(first (meta (second %))))
       (filter identity)
       (map (fn [[t {:keys [start end]}]] 
              [t end]))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn expanded-history [h]
  (mapcat (fn [[t ctx]]
            (let [{:keys [start end]} (get (meta ctx) t)]
              [[t start  :start]
               [t end :end]])) h))</pre></div><div class="docs"><p>Note: we probably want to vary the resolution
here, currently we're hardwired to sample
every day.  Based on the post-processing
libs, we don't have to do this, and can use
discrete event sampling to compute a minimal
set of samples, then down-sample / upsample  based on that.</p>
</div><div class="codes"></div><div class="docs"><p>We can speed this up by not using for/range..
It's not a huge bottleneck at the moment...</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;map-samples [f h]
  (let [ks    (sort (keys h))
        pairs (partition 2 1 ks)]
    (into (vec (apply concat
                    (-&gt;&gt; pairs
                         (mapcat (fn [[l r]]
                                   (let [ctx (get h l)]
                                     ;;sample in between...
                                     (for [t (range l r)]
                                       (f t ctx))))))))
          (f (last ks) (get h (last ks))))))</pre></div><div class="docs"><h1>OPTIMIZATION</h1>

<p>my gut says we can do this more efficiently, with regards to
final, since it holds onto the tail of the stream
Also, allow sampling rate to vary...
currently we sample every day.
Changed to reflect end-of-day sampling.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;seq-samples [f kvs]
  (let [pairs (partition 2 1 kvs)
        ;final (last kvs) ;no longer necessary, possible memory leak.
        ]
    (apply concat
       (-&gt;&gt; pairs
            (mapcat (fn [[ [l ctx] [r nxt] ]]
                      ;;sample in between...
                      (for [t (range l r)]
                        (f t ctx))))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;collect-samples [f h]
  (cond (seq? h) (-&gt;seq-samples f h)
        (map? h) (-&gt;map-samples f h)
        :eles (throw (Exception. (str &quot;Dunno how to do samples with &quot; (type h))))))</pre></div><div class="docs"><h1>Canonical Sampling Functions</h1>
</div><div class="codes"></div><div class="docs"><p>These samplers transform a stream of
history into a stream of sampled output.
We typically have a set of canonical outputs
we expect for post-processing.  This lets us
define them using higher-level sequence functions
so we can define sampling based on the "history"
rather than imperatively logging and myopically
processing.</p>
</div><div class="codes"></div><div class="docs"><p>It'd be nice to define a channel-based version of this so that
we can compute samples state by state...
at any given point in time, we have n samples we're collecting.
as we transition through the state stream, we run each sampler
to see if it computes a sample.</p>
</div><div class="codes"></div><div class="docs"><p>Some samples are event-based...
like dwell-before deployment stats...</p>
</div><div class="codes"></div><div class="docs"><p>Can we just append a deployment record? 
dumb sampler...probably migrate this to
use spork.trends sampling.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;location-samples   [h]  (-&gt;collect-samples core/locations   h))</pre></div><div class="docs"><p>I think this is similar to demand-trends.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;deployment-samples [h]  (-&gt;collect-samples core/deployments h))</pre></div><div class="docs"><p>compute the deployments table</p>
</div><div class="codes"></div><div class="docs"><p>so, we basically just pipe th deployments component
to out and concat....</p>
</div><div class="codes"></div><div class="docs"><p>derives a stream of deployments across the history.
daily deployments are stored in the :deployments component.
so we just extract that and boom.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;deployment-records  [h]
  (-&gt;&gt; h 
       (mapcat (fn [[t ctx]]
                 (when-let [deps (store/get-domain ctx :deployments)]
                    (first (vals deps)))))
       (filter identity)
       (map-indexed (fn [idx d] (assoc d :DeploymentID idx)))))</pre></div><div class="docs"><p>note: we may need to replicate the audit trail for completeness
sake....this should be fairly easy...it's simple io stuff.</p>
</div><div class="codes"></div><div class="docs"><p>we only need to capture this when demands change..</p>
</div><div class="codes"></div><div class="docs"><p>If we can define trends as a map
or a reduction....
this is legacy support...
Note: this should work with our </p>
</div><div class="codes"><pre class="brush: clojure">(defn demand-trends
  ([t ctx]
   (let [qtr     (unchecked-inc (quot t 90)) ;;1-based quarters.         
         changes (store/gete ctx :demand-watch :demands)
         actives (store/gete ctx :DemandStore :activedemands)]
     (when (seq changes)
       (-&gt;&gt; actives
            (keys)
            (map #(store/get-entity ctx %))
            (map  (fn [{:keys [category demandgroup operation vignette Command] :as d}]
                    (let [assigned     (:units-assigned    d)
                          overlapping  (:units-overlapping d)
                          ua           (count              assigned)
                          uo           (count              overlapping)
                          compo-fills  (-&gt;&gt; assigned
                                            (keys)
                                            (map (fn [nm]
                                                   (store/gete ctx nm :component)))
                                            (frequencies))
                        {:strs [AC RC NG Ghost]
                         :or   {AC 0 RC 0 NG 0 Ghost 0}} compo-fills]                      
                      {:t             t
                       :Quarter       qtr
                       :SRC           (:src      d)
                       :TotalRequired (:quantity d)
                       :TotalFilled   (+ uo ua)
                       :Overlapping   uo
                       :Deployed      ua
                       :DemandName    (:name d)
                       :Vignette      vignette
                       :DemandGroup   demandgroup
                       :ACFilled      AC
                       :RCFilled      RC
                       :NGFilled      NG
                       :GhostFilled   Ghost
                       :OtherFilled   (- ua (+ AC RC NG Ghost))})))))))
  ([ctx] (demand-trends (sim/get-time ctx) ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;demand-trends      [h]  (-&gt;collect-samples demand-trends h))</pre></div><div class="docs"><p>Note: locations are really "policypositions", should rephrase
this....otherwise we get :locationname confused.  We actually
do want policy-position changes....Another option is
for us to reconcile locations with known-locations 
location is easy, we just track any entities with :location-delta
components...</p>
</div><div class="codes"></div><div class="docs"><p>Note: Cloned from quilsample.bridge, temporary</p>
</div><div class="codes"><pre class="brush: clojure">(defn delta-seq [s domain]
   (when-let [es (seq (store/get-domain s domain))]
     (for [[id {:keys [init current]}] es]
       [id init current])))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn location-changes [s] (delta-seq s :location-delta))
(defn position-changes [s] (delta-seq s :position-delta))
(defn state-changes    [s] (delta-seq s :state-delta))</pre></div><div class="docs"><p>Ideal solution is to port the incubated stuff in quilsample.bridge,
but for now, we'll stick with the dumb way.  Just get the
table computed....</p>
</div><div class="codes"></div><div class="docs"><p>replicating output for locations.txt 
T, EntityFrom, EntityTo, EventName, Msg</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord location-rec [T EntityFrom EntityTo EventName Msg])
(defn location-trends
  ([t ctx]
   (when-let [xs (location-changes ctx)]
     (for [[id from to] xs]
       (-&gt;location-rec t  id to  &quot;Unit Moved&quot;  ))))
  ([ctx] (location-trends (sim/get-time ctx) ctx)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;location-records [h]
  (mapcat (fn [[t ctx]]
            (location-trends t ctx)) h))</pre></div><div class="docs"><p>creating legacy output from basic data..
fills are a join of unit&lt;>demanddata&lt;>deployments</p>
</div><div class="codes"></div><div class="docs"><p>(def fillrecord {:Unit      :text
                 :category :text
                 :DemandGroup :text
                 :SRC :text
                 :FillType :text
                 :FollowOn :boolean
                 :name :text
                 :Component :text
                 :operation :text
                 :start :int
                 :DeploymentID :int
                 :duration :int
                 :dwell-plot? :boolean
                 :DwellYearsBeforeDeploy :float
                 :DeployDate :text
                 :FollowOnCount :int
                 :AtomicPolicy :text
                 :Category :text
                 :DeployInterval :int
                 :fill-type :text
                 :FillPath :text
                 :Period :text
                 :unitid :int
                 :deltat :int
                 :Demand :text
                 :PathLength :int
                 :OITitle :text
                 :BogBudget :int
                 :CycleTime :int
                 :DeploymentCount :int
                 :DemandType :text
                 :quantity :int
                 :end :int
                 :FillCount :int
                 :Location :text
                 :location :text
                 :compo :text <br />
                 :DwellBeforeDeploy :int
                 :Policy :text
                 :sampled :boolean
                 })</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro or-get [m k &amp; else]
  `(if-let [res# (get ~m ~k)]
    res#
    ~@else))</pre></div><div class="docs"><h1>API Definition</h1>
</div><div class="codes"><pre class="brush: clojure">(defn load-project [p &amp; {:keys [tables]}]
  (if tables 
    (proj/load-project p :tables tables)
    (proj/load-project p)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn load-requirements-project [p]
  (proj/load-project p :tables xl/marathon-requirements-schema))</pre></div><div class="docs"><p>Given a viable Marathon Project, p, we derive and initial 
   simulation context, from which we can create a simulation
   history.  An optional function table-xform may be supplied 
   to pre-process the project tables, to implement options 
   like filtering, etc.  The project may be a path to a string, </p>

<p>This is the core of doing a "run"...</p>
</div><div class="codes"><pre class="brush: clojure">(defn load-context
   [p &amp; {:keys [table-xform] :or {table-xform identity}}]
   (-&gt;&gt;  (setup/simstate-from ;;allows us to pass maps in, hackey
          (table-xform (or-get p :tables
                         (:tables (proj/load-project p))))
          core/debugsim)  
         (sim/add-time 1)
         (sim/register-routes obs/default-routes)))</pre></div><div class="docs"><p>Like analysis/load-context, except we perform some io in the parent folder.
   Generates 'AUDIT_...' files from raw inputs and computed input.</p>

<p>TimeStamp   SRC Reason</p>
</div><div class="codes"><pre class="brush: clojure">(defn load-audited-context
  [path-or-proj &amp; {:keys [table-xform root] :or {table-xform identity}}]
  (let [proj (proj/load-project path-or-proj)
        root (or root (proj/project-path proj))
        ctx  (load-context proj :table-xform table-xform)
        scope-table (fn [m]
                      (let [t (System/currentTimeMillis)]
                        (-&gt;&gt;  (for [[src reason] (seq m)]
                                {:TimeStamp t :SRC src :Reason reason})
                              (tbl/records-&gt;table))))                      
        computed-tables  (let [params   (core/get-parameters ctx) 
                               inscope  (:SRCs-In-Scope      params)
                               outscope (:SRCs-Out-Of-Scope  params)]
                           {:InScope  (scope-table inscope)
                            :OutScope (scope-table outscope)})
        _    (proj/audit-project (proj/add-tables proj computed-tables)
                                 root
                                 :tables (into proj/default-auditing-tables
                                               (keys computed-tables)))]
    ctx))</pre></div><div class="docs"><p>Coerces x to a marathon simulation context.  Optionally, 
   will provide and audit-trail of information if x is 
   a project and audit? is truthy.</p>
</div><div class="codes"><pre class="brush: clojure">(defn as-context
  [x &amp; {:keys [table-xform audit? audit-path]
                       :or {table-xform identity}}]
  (cond (string? x) (if audit?
                      (load-audited-context x :table-xform table-xform :root audit-path)
                      (load-context x :table-xform table-xform))
        (util/context? x) x
        :else (throw (Exception.
                      (str &quot;Invalid MARATHON sim context &quot; x)))))</pre></div><div class="docs"><p>Create a stream of simulation states, indexed by time.
   Optionally, set the maximum simulation time, define transformations 
   on the project tables, like src filters, provide a custom step function, 
   and choose to generate auditing information upon initializing the 
   stream.</p>
</div><div class="codes"><pre class="brush: clojure">(defn marathon-stream
  [path-or-ctx &amp; {:keys [tmax table-xform step-function audit? audit-path]
                  :or {tmax 5001
                       table-xform identity
                       step-function engine/sim-step
                       audit? false}}]
  (-&gt;&gt; (as-context path-or-ctx :table-xform table-xform :audit? audit? :audit-path audit-path)
       (-&gt;history-stream tmax step-function)
       (end-of-day-history)))</pre></div><div class="docs"><p>Given a sequence of srcs to keep, pre-processes the project tables 
   to retain only records with an associated :SRC value, where the value 
   is in the set defined by srcs.  Defaults to filtering supply and demand 
   records.</p>

<p>simple-project xforms               </p>
</div><div class="codes"><pre class="brush: clojure">(defn filter-srcs
  [srcs &amp; {:keys [tables]
                             :or {tables [:SupplyRecords :DemandRecords]}}]
  (let [srcs        (set srcs)
        tbl-filter #(spork.util.table/filter-records (fn [r]  (srcs (:SRC r))) %)]
      (fn [tbls]
        (reduce (fn [acc t] (update acc t tbl-filter)) tbls tables))))</pre></div><div class="docs"><p>Another useful feature...
We'd like to optionally audit our project, when we create a stream and
initialize it.
We can do this by hooking into the table-xforms, since this allows us
to audit.</p>
</div><div class="codes"></div><div class="docs"><p>serializing all the snapshots is untenable...
can we compute diffs?
All we really care about, as we traverse forward,
is information regarding who changed...
So if any entity was touched or updated during the
t, the it'll show...
In theory, any last-updates to entities
will show up....so that limits our diffs
to the entities with last-update components..
From there, we can just compare them with their previous selves...</p>
</div><div class="codes"></div><div class="docs"><p>The goal here is to easily serialize our entity database...
Note...we have some options for how we do this...
We could do an initial state + diffs (similar to
git...) and save our stuff that way.  For now we
have a stream of state snapshots which have internal
references via persistent structures....so...
we should? be able to persist our stuff efficiently.
We're going to stream this rather than do it all in
memory...we can also add a diff buffer that can
be serialized at the end of the day...
So, anytime an entity is modified (via gete adde
assoce, etc.), the diff buffer (or dirty flag)
gets mutated in the db.  Then we compare dirty
entities with their previous versions to see
what the differences are...seems plausible...
the brute-force approach is to just use
hashing to compare...assuming we have hash
equality, we just hash-compare the stores, and
then the components in the stores, and then
the entities...
probably makes more sense to diff the components...
structural diffing is a pretty powerful way to
compute deltas...and laid back.  It "would" be
nice if we'd cached the values though.</p>
</div><div class="codes"><pre class="brush: clojure">(defn diff-stores [l r]
  (let [lcomps (-&gt; l :state :store :domain-map)
        rcomps (-&gt; r :state :stote :domain-map)]
    ;;many components will be the same..
    ;;man, we can actually save time if the hash hasn't been computed yet...
    (if (identical? lcomps rcomps) nil
        (reduce-kv (fn [acc lk lv]
                     (if-let [rv (get rcomps lk)]
                       (if (not (identical? lv rv))
                         (conj acc lk) acc) (conj acc lk))) [] lcomps))))</pre></div><div class="docs"><p>since components are maps...we can recursively diff to see which
entities changed.</p>
</div><div class="codes"></div><div class="docs"><p>If we constrain all access to go through assoce, etc,
then we can get away with diffing...</p>
</div><div class="codes"><pre class="brush: clojure">(defn diff-store [l r]
  (let [le (:store (sim/get-state l))
        re (:store (sim/get-state r))]
    (if (identical? (:domain-map le) (:domain-amp re))
      nil
      (diff/entity-diff le re))))</pre></div><div class="docs"><p>we might have a memory leak here if we're force the first and traversing the
rest of the history...</p>
</div><div class="codes"><pre class="brush: clojure">(defn patch-history [h]
  {:init    (first h)
   :patches (for [[[t1 l] [t2 r]] (partition 2 1 h)]
              [t2 (diff/entity-diffs-&gt;patch (diff-store l r))])})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn     write-history  [h path]  (ser/freeze-to (patch-history h)  path))
(defn     write-history! [h path]  (ser/freeze-to! (patch-history h) path))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro with-print [{:keys [level length]} &amp; body]
  `(let [before-level# ~'*print-level*
         before-length# ~'*print-length*
         lvl#    ~level
         length# ~length]
    (do (set! ~'*print-level*  lvl#)
        (set! ~'*print-length* length#)
        ~@body
        (set! ~'*print-level*  before-level#)
        (set! ~'*print-length* before-length#))))</pre></div><div class="docs"><p>textual, printed version
if we use pprint, we get killed here.</p>
</div><div class="codes"><pre class="brush: clojure">(defn print-history [h path]
  (with-print {}
    (with-open [writer (clojure.java.io/writer path)]
      (binding [*out* writer]
        (let [{:keys [init patches]} (patch-history h)]
          (println &quot;{:init&quot;)
          (pr init)
          (println &quot; :patches&quot;)
          (doseq [[t patches] patches]
            (println &quot;[&quot; t)
            (pr patches)
            (println &quot;]&quot;))
          (println &quot;}&quot;))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn print-patches [h path]
  (with-print {}
    (with-open [writer (clojure.java.io/writer path)]
      (binding [*out* writer]
        (let [{:keys [init patches]} (patch-history h)]
          (println &quot;{:patches &quot;)
          (doseq [[t patches] patches]
            (println &quot;[&quot; t)
            (pr patches)
            (println &quot;]&quot;))
          (println &quot;}&quot;))))))</pre></div><div class="docs"><p>hmmm...can we actually slurp this up?  It's 28 mb...so maybe...
ahh...this poorly named...</p>
</div><div class="codes"><pre class="brush: clojure">(defn string-&gt;history [path]
  (println [:warning 'read-history &quot;you're using read-string, vs. clojure.edn/read-string&quot;])
  (read-string (slurp path)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn read-history! [path]
  (let [{:keys [init patches]} (ser/thaw-from path)
        store  (atom (second init))]
    (into [init]
          (map (fn [[t patch]]
                 (let [prev @store
                       nxt  (diff/patch-&gt;store prev patch)
                       _    (reset! store nxt)]
                   [t nxt]))
               patches))))</pre></div><div class="docs"><p>hmm...</p>
</div><div class="codes"></div><div class="docs"><h1>IO  Routines</h1>

<p>can we spit out demandtrends?
Yes....
They're basically location-samples...</p>
</div><div class="codes"></div><div class="docs"><p>note: if we stream, we don't compress, but we do
get a differential compression. We might
use lz4 to compress after the fact....once the
file has been written.  For now, it's about 28 mb for
a patch set for 13 years.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def all-outputs #{:history
                   :locsamples
                   :locations
                   :depsamples
                   :deployment-records
                   :demandtrends
                   :patches})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def legacy-outputs #{:deployment-records
                      :demandtrends
                      :locations})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmulti spit-output (fn [t h path] t))
(defmethod spit-output :history [t h hpath]
  (do  (println [:spitting-history hpath])
       (println [:fix-memory-leak-when-serializing!])
       (write-history h hpath)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod spit-output :location-samples [t h lpath]
  (do (println [:spitting-location-samples lpath])
      (tbl/records-&gt;file (-&gt;location-samples h) lpath)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod spit-output :locations [t h locspath]
  (do (println [:spitting-locations locspath])
      (tbl/records-&gt;file (-&gt;location-records h) locspath)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod spit-output :deployed-samples [t h dpath]
  (do (println [:spitting-deployed-samples dpath])
      (tbl/records-&gt;file (-&gt;deployment-samples h) dpath)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod spit-output :deployment-records [t h dpath]
  (do (println [:spitting-deployed-samples dpath])
      (tbl/records-&gt;file (-&gt;deployment-records h) dpath))) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmethod spit-output :demandtrends [t h dtrendpath]
  (do (println [:spitting-demandtrends dtrendpath])
      (tbl/records-&gt;file (-&gt;demand-trends h) dtrendpath
                         :field-order schemas/demandtrend-fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def ^:dynamic *outputs* legacy-outputs)
(defmacro with-outputs [os &amp; body]
  `(binding [~'marathon.analysis/*outputs* ~os]
     ~@body))
(defmacro with-all-outputs [&amp; body]
  `(with-outputs ~all-outputs
     ~@body))</pre></div><div class="docs"><p>this is basically the api for performing a run....
We'll automatically audit when we do this...</p>
</div><div class="codes"><pre class="brush: clojure">(defn spit-history! [h path &amp; {:keys [outputs] :or
                               {outputs *outputs*}}]
  ;;hackneyed way to munge outputs and spit them to files.
  (let [paths {:history     (str path &quot;history.lz4&quot;   )
               :location-samples      (str path &quot;locsamples.txt&quot;)
               :locations   (str path &quot;locations.txt&quot;)
               :deployed-samples      (str path &quot;depsamples.txt&quot;)
               :deployment-records(str path &quot;AUDIT_Deployments.txt&quot;) 
               :demandtrends (str path &quot;DemandTrends.txt&quot;)} ;probably easier (and lighter) to just diff this.
        ]    
    (doseq [[k path] paths
            :when (outputs k)]      
      (spit-output k h path))))</pre></div><div class="docs"><p>spits a log of all the events passing through.</p>
</div><div class="codes"><pre class="brush: clojure">(defn spit-log
  ([h root nm]
   (println [:logging-to (str root nm)])
   (with-open [wrtr (clojure.java.io/writer (str root nm))]
     (binding [*out* wrtr]
       (core/debugging
        (doseq [hd h])))))
  ([h root] (spit-log h root &quot;events.txt&quot;)))</pre></div><div class="docs"><p>spits a verbose log of all the events and
behavioral updates that are performed...</p>
</div><div class="codes"><pre class="brush: clojure">(defn spit-log!
  ([h root nm]
   (println [:logging-to (str root nm)])
   (with-open [wrtr (clojure.java.io/writer (str root nm))]
     (binding [*out* wrtr]
       (core/debugging!
        (doseq [hd h])))))
  ([h root] (spit-log! h root &quot;events.txt&quot;)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment 
;;testing
(def ep &quot;C:\\Users\\tspoon\\Documents\\srm\\notionalbase.xlsx&quot;)
;;local diff.
(def ep &quot;C:\\Users\\1143108763.C\\srm\\notionalbase.xlsx&quot;)
(def ctx (load-context ep))
(def h (take 2 (marathon-stream  ep)))
(def l (first  h))
(def r (second h)))</pre></div><div class="docs"><p>We can compare the event logs too...
See where history diverges.
(defn divergence [lh rh]
  (map (fn [l r]
         {:t (sim/get-time l)
         (core/locations l)
         (core/location  r)
          (seq lh) (seq rh)</p>
</div><div class="codes"></div><div class="docs"><p>we need to create a pipeline that allows us</p>
</div><div class="codes"></div><div class="docs"><p>Right now, we're looking
Actual output from a Marathon run will include....</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"></div><div class="docs"><p>obe</p>
</div><div class="codes"><pre class="brush: clojure">(comment
  (def demand-trend-schema
  {:t  	           :int
   :Quarter	   :int ;;derived...
   :SRC	           :text
   :TotalRequired  :int
   :TotalFilled	   :int
   :Overlapping	   :int
   :Deployed	   :int
   :DemandName	   :text
   :Vignette 	   :text
   :DemandGroup	   :text
   :ACFilled	   :int
   :RCFilled	   :int
   :NGFilled	   :int
   :GhostFilled	   :int
   :OtherFilled	   :int})
(def dt-fields   [:t  	           
                  :Quarter	   
                  :SRC	           
                  :TotalRequired   
                  :TotalFilled	   
                  :Overlapping	   
                  :Deployed	   
                  :DemandName	   
                  :Vignette 	   
                  :DemandGroup	   
                  :ACFilled	   
                  :RCFilled	   
                  :NGFilled	   
                  :GhostFilled	   
                  :OtherFilled]))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.analysis.requirements" name="marathon.analysis.requirements"><h1 class="project-name">marathon.analysis.requirements</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Requirements Analysis implementation.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.analysis.requirements
  (:require [spork.util [record :as r] [table :as tbl] [io :as io]]
            [spork.sim [simcontext :as sim]]
            [spork.entitysystem [store :as store]]
            [clojure [pprint :as pprint]]
            [marathon.ces [core :as core]
                          [engine :as engine]
                          [setup :as setup]
                          [demand :as demand]]
            [marathon [analysis :as a] [observers :as obs]]))</pre></div><div class="docs"><h1>Utility functions</h1>
</div><div class="codes"><pre class="brush: clojure">(defn hpath [p]
  (str io/home-path p))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro get-or [m k &amp; else]
  `(if-let [res# (get ~m ~k)]
     res#
     ~@else))</pre></div><div class="docs"><p>this isn't a huge deal; multiplying by ratios returns bigints...</p>
</div><div class="codes"><pre class="brush: clojure">(defn distribute-rationally [n xs] (mapv (fn [r] (* n r)) xs))
(defn sums-to-one?   [xs] (== 1.0  (double (reduce + xs))))</pre></div><div class="docs"><p>useful utility function...</p>
</div><div class="codes"><pre class="brush: clojure">(defn sum-by [f init xs] (transduce (map f) (completing +) init xs))</pre></div><div class="docs"><p>Given schema s and table t, attempts to coerce the table entries into 
   the appropriate data format for all fields defined in s.  Coerces 
   field entries to strings prior to conversion, so there may be a 
   penalty.  Typically most useful working with string-ified data, 
   such as a literal table.  Fieldnames must match exactly, i.e. <br />
   string fieldnames will not match keyword schema names.</p>

<p>useful function for spork.util.table todo: move there...</p>
</div><div class="codes"><pre class="brush: clojure">(defn apply-schema
  [s t]
  (let [parse-field (fn [fld col]
                      (if-let [f (spork.util.parsing/parse-defaults
                                    (get-or s fld))]
                        [fld (mapv (comp f str) col)]
                        [fld col]))]
    (spork.util.table/order-fields-by
     (spork.util.table/table-fields t)
     (-&gt;  (map parse-field
               (spork.util.table/table-fields  t)
               (spork.util.table/table-columns t))           
          (spork.util.table/conj-fields spork.util.table/empty-table)))))</pre></div><div class="docs"><p>Replace the values associated with field k in t, with 0 values.</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-field
  [t k v]
  (let [n (tbl/count-rows t)]
    (tbl/conj-field  [k (vec (repeat n v))] t)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn zero-supply [t] (set-field t :Quantity 0))
(defn increment-key [r k n] (update r k (fn [q] (+ q n))))</pre></div><div class="docs"><p>use tbl/subtables-by to get this implemented.
Useful for splitting up requirements states...
(defn split-by-field
  "Given a field to split on, creates n new databases, 
   where each database contains tables (with the field) 
   that have identical values for the field."
  [tbls &amp; {:keys [field tables]}]
  (let [[base variable]</p>
</div><div class="codes"></div><div class="docs"><h1>Data munging and records</h1>
</div><div class="codes"></div><div class="docs"><p>If we use records, we get ordered fields automatically.  Better strategy.
generic supply record.  Should probably tie these to marathon.schemas</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord srecord [Type Enabled Quantity SRC Component OITitle
                    Name Behavior CycleTime Policy Tags Spawntime Location Position Original])</pre></div><div class="docs"><p>outstreaam/mystream is output....canonically RequirementsGeneratedSupply.csv
may not use this guy...we'll see.</p>
</div><div class="codes"><pre class="brush: clojure">(r/defrecord+ outrecord [[Iteration 0]
                         [SRC ]
                         [Component ]
                         [Quantity   0]])</pre></div><div class="docs"><p>generate a new supplyrecord.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;supply-record
  ([src component count]
   (-&gt;srecord &quot;SupplyRecord&quot; true count src component (str &quot;Generated_&quot;  src)
              &quot;Auto&quot; &quot;Auto&quot; 0 &quot;Auto&quot; &quot;Auto&quot; 0 &quot;Auto&quot; &quot;Auto&quot; false))
  ([src component] (-&gt;srecord src component 0)))</pre></div><div class="docs"><h1>Distributors</h1>

<p>distributors need to be implemented....
default is binned, provides deterministic
round-robin growth.
Note: We can also have deterministic growth
using a seeded prng...</p>
</div><div class="codes"></div><div class="docs"><p>kind of lame at the moment
should return a map of [compo val]</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol IDistributor
  (distribute- [obj n]))</pre></div><div class="docs"><p>NOTE: This is a TEMPORARY HACK to get
around the breaking change in clojure 1.8,
extends? no longer works as God intended.
Prefer satisfies? with memoization for now.
inst? is coming in 1.9.</p>
</div><div class="codes"><pre class="brush: clojure">(def inst?
  (memoize (fn [protocol x]
             (satisfies? protocol x))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def bad (atom nil))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn distribute-by [f n]
  (let [tf f #_(type f)]
    (cond (#_extends? inst? IDistributor tf)
            (distribute- f n)
          (#_extends? inst? clojure.core.protocols/IKVReduce tf)
            (reduce-kv (fn [acc k prop]
                         (assoc acc k (* prop n))) {} f)
          (fn? f) (f n)
          :else
          (do (reset! bad f)
              (throw (Exception. (str &quot;unknown distributor!&quot; f)))))))</pre></div><div class="docs"><h1>Requirements State</h1>

<p>creates a "lightweight" context
for requirements analysis, so we can
go faster.  Basically, drop any observers that
aren't useful.
For now, we don't do anything special, although
ripping out some of the observer stats could be useful.
 We don't need the capacity-analysis defaults for now.
 I'll look into ripping them out in the future,
 since they add some overhead.  But for requirements,
 we only care about demand fill.  Anything else is
 incidental.</p>
</div><div class="codes"><pre class="brush: clojure">(defn requirements-ctx [tbls &amp; {:keys [observer-routes]
                                :or   {observer-routes obs/default-routes}}]
  ;;we'll basically do the same thing we normally do.
  ;;For now at least...
  ;;use init-context here, but not setting up observers.  
  (-&gt;&gt;  (setup/simstate-from ;;allows us to pass maps in, hackey
         tbls
         core/emptysim)  
        (sim/add-time 1)
        ;(sim/register-routes obs/default-routes)))</pre></div><div class="docs"><p>Note: we need a higher-order function that wraps
performing RA for multiple srcs...
I think the chain of causality is...
Given an SRC, some tables,
 Filter the supply,demand,policy records...
 Compute requirements (however, typically iterative convergence)
   ;;Create a simcontext from filtered tables.
This gives us the mapping of src->requirements
really, src->supply-records</p>
</div><div class="codes"></div><div class="docs"><p>if we have an initial supply, we have a floor on the
supply estimates.  RA will not go below this
amount.  We want to compute a supply-table
that reflects the initial supply.
If the supply-table is empty, then
we need to build one.</p>
</div><div class="codes"><pre class="brush: clojure">(defn initial-supply [src supply-table compo-distros
                      &amp; {:keys [zero?] :or {zero? true}}]
  (let [growth-compos (set (for [[k v] compo-distros :when (pos? v)]  k))
        known         (set (tbl/field-vals
                            (tbl/get-field :Component supply-table)))
        new-compos    (clojure.set/difference growth-compos known)
        new-records   (for [compo new-compos
                            :when (pos? (compo-distros compo))]
                        (-&gt;supply-record src compo 0))]
    (do (println [:computing-initial-supply])    
        (concat (tbl/table-records supply-table)
                new-records))))</pre></div><div class="docs"><p>Simple function to zero our supply records.  Replaces 
   quantity (if any) with a value of 0.</p>
</div><div class="codes"><pre class="brush: clojure">(defn zero-supply
  [xs]
  (mapv (fn [r] (assoc r :Quantity 0)) xs))</pre></div><div class="docs"><p>we'll explicitly pass in SRC as a filter for now.
It'd be really nice to share the context once we've
created it....although policies and stuff might change...
there's a bit of overhead in the policy stuff, so it's
easier to move from ctx->ctx than otherwise...
For now, we'll just suck it up. And redo every time,
see how expensive it ends up being.</p>
</div><div class="codes"></div><div class="docs"><p>Given a map of tables (a marathon project), 
   creates a map that contains all of the state 
   we'll need for our requirements analysis.</p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;requirements-state
  [tables src compo-distros]
  (let [;ctx0 (requirements-ctx tables)
        s    (initial-supply  src (:SupplyRecords tables) compo-distros)]
    {;:ctx    ctx0 ;initial simulation context.
     :tables tables
     :supply s    ;initial seq of supply records.
     :src src
     :distributions compo-distros
     :steps     []
     :iteration 0}))</pre></div><div class="docs"><p>interesting notes on machine precision and clojure's numeric tower.
(def rats '(1696969696969697/4000000000000000 0N 5757575757575757/10000000000000000))
(reduce + rats) => 19999999999999999/20000000000000000 
(/ 19999999999999999.0 20000000000000000.0) => 1.0
(long   (double (reduce + rats))) => 1
(double (reduce + rats)) => 1.0
(long   (reduce + rats)) => 0
(bigint (reduce + rats)) => 0N</p>
</div><div class="codes"></div><div class="docs"><h1>Basic Algorithm</h1>

<p>Requirements analysis is the process of calculating some required additional
supply in the face of a given demand signal.  Technically, requirements
analysis is indifferent to the existence of supply.  We can calculate a
requirement regardless of pre-existing supply.  In fact, we can grow a
requirement.</p>
</div><div class="codes"></div><div class="docs"><p>Traditional requirements analysis consisted of a fixed-point function:
- RequiredSupply(SupplyInitial) = SupplyInitial + Generated(SupplyInitial, Demand)
 - Do until SupplyNext = SupplyInitial
   - SupplyInitial &lt;- SupplyNext
   - SupplyNext &lt;- Distribute(RequiredSupply(SupplyInitial), SupplyInitial)</p>
</div><div class="codes"></div><div class="docs"><h1>Estimating Bounds</h1>

<p>We will use DemandAnalysis and Supply Analysis to help the convergence go
much faster. As a pre-process step, we utilize Static Demand Analysis to
determine the peak demands and the maximum deployment acceleration
experienced during the run.
- This provides definite constraints on our minimum required supply.
 - ANY supply must have a theoretical capacity >= the peak demand.</p>
</div><div class="codes"></div><div class="docs"><p>We then utilize Static Supply Analysis to determine the theoretical
rotational capacity for the initial supply.  (If we have no supply,
capacity is nil). Prior to starting the convergence algorithm, we
distribute this intial gap in supply.</p>
</div><div class="codes"></div><div class="docs"><p>Then run until convergence.
Should take less time.</p>
</div><div class="codes"></div><div class="docs"><p>Note -> Requirements analysis does not utilize substitutions.
- This is a pure 1:1 demand to supply.
- This makes the problem essentially much easier (and faster).</p>
</div><div class="codes"></div><div class="docs"><p>It also makes calculating requirements even faster and more effecient,
because we can parallelize the entire analysis into a set of n
independent simulations, which only considers the supply and demand of
a single type.</p>
</div><div class="codes"></div><div class="docs"><p>Changes from VBA
What we'll do instead of having file i/o driving this, is we'll
derive any necessary i/o from the sequence we compute as we converge.
Basically, using reductions, we'll derive the supply table each iteration.</p>
</div><div class="codes"></div><div class="docs"><p>oh, we need to be able to generate supply...
Well, we can delegate that to RA....
Instead of creating "supply generators"
that are complicated, we can add additional
supply after-the-fact, and then fill again with
the next context.  So, basically, add-ghosts if
there are missed demands.</p>
</div><div class="codes"></div><div class="docs"><h1>Growing Supply</h1>

<p>note:
the act of "creating supply" from a supply record
transforms a serialized form into a sequence of instructions
that create entities and schedule initial behavior, like spawning.
So, one way to view it is that the record maps to a sequence of
instructions, which yield entities.</p>
</div><div class="codes"></div><div class="docs"><p>We're basically altering the initial supply via supply records....
The reason we do so is because the system is setup to initialize
the context from raw tables, so changing the data creates
new sim contexts automagically.</p>
</div><div class="codes"></div><div class="docs"><p>As we look at how to vary supply programmatically, rather than
"just" varying the table, we could look into varying the
context directly....</p>
</div><div class="codes"></div><div class="docs"><p>Given a table of supply-records, computes a sequence of 
   records by src, compo, summing by the Quantity field.</p>

<p>reads distributions from a table of [src ac rc ng]
probably a better way to do this...legacy implementation
We can also provide a way to compute this empirically right?</p>
</div><div class="codes"><pre class="brush: clojure">(defn compute-aggregate-supply
  [xs]
  (let [quantities (fn quantities [xs]
                     (sum-by :Quantity 0 xs))]
    (-&gt;&gt; (for [[src src-groups] (group-by :SRC       xs)]
           (let [compo-xs       (group-by :Component src-groups)]
             {:Type &quot;GhostProportionsAggregateRecord&quot;
              :Enabled true :SRC src :AC (quantities  (get compo-xs &quot;AC&quot;))
              :NG (quantities (get compo-xs &quot;NG&quot;))
              :RC (quantities (get compo-xs &quot;RC&quot;))})))))</pre></div><div class="docs"><p>Computes proportional values for each record in xs, by component, 
   where the associated component value is a proportion of the sum of 
   component values.  Retains rational precision by default.</p>
</div><div class="codes"><pre class="brush: clojure">(defn aggregate-proportions
  [xs &amp; {:keys [float?]}]
  (let [divide (if float? (fn [l r] (double (/ l r)))
               / )]
    (into [] (map (fn [{:keys [AC NG RC] :as r}]
                    (let [sum (+ AC NG RC)]
                      (merge r {:AC (divide AC sum)
                                :NG (divide NG sum)
                                :RC (divide RC sum)}))))
        xs)))</pre></div><div class="docs"><p>Given a map of tables, computes the aggregate supply proportions <br />
   from the input.  User may specify alternate tables to use for the 
   proportions.  If no table is found, will compute the proportions 
   from the input supply.</p>
</div><div class="codes"><pre class="brush: clojure">(defn aggregate-distributions
  [tbls &amp; {:keys [distribution-table dtype float?]
           :or   {distribution-table :GhostProportionsAggregate
                  dtype :bin}}]
  (let [make-distributor (fn [n] (fn [k] (* k n)))] 
    (-&gt;&gt; (get-or tbls  distribution-table
                 (-&gt;&gt; (:SupplyRecords tbls)                                           
                      (tbl/table-records)
                      (filter :Enabled)
                      (compute-aggregate-supply)
                      (aggregate-proportions)))
         (transduce (filter :Enabled)
                    (completing
                     (fn [acc r]
                       (let [{:keys [SRC AC RC NG]} r]
                         (assoc acc SRC {&quot;AC&quot; AC &quot;RC&quot; RC &quot;NG&quot; NG}))))
                                {}))))</pre></div><div class="docs"><p>fill this in...
probably need some state.
TOM Change 19 April 2012
For an src, use our local distributor to compute how x ghosts should be converted into
[X,Y,Z..] units of supply, by component
Note: renamed 'ns to 'steps.  Embeding stuff in a requirements state
map.
we have the supply records in reqstate/supply
goal is to update the quantities incrementally.</p>
</div><div class="codes"></div><div class="docs"><p>this creates a map of {compo amount}</p>
</div><div class="codes"><pre class="brush: clojure">(defn compute-amounts [reqstate src n]
  (distribute-by (:distributions reqstate) n))</pre></div><div class="docs"><p>Given a requirementstate ,reqstate, and 
   a map of {component amount}, increments the 
   supply records in reqstate where compo matches.</p>

<p>Replacement method for an earlier hack.  We now separate the process of calculating and applying
distributions.  Given a set of distributions, by component, apply them (whatever that means)
to the src.  Our goal is to update the the supply-table.
Note: it doesn't actually matter if they're a spork.util.table
or records...We can just keep the supply records
as a record seq now, don't have to stick with
table...</p>
</div><div class="codes"><pre class="brush: clojure">(defn apply-amounts
  [reqstate compo-amounts]
  (update reqstate :supply          
   #(-&gt;&gt; %
         (map (fn [r]
                (if-let [n (get compo-amounts (:Component r))]                        
                  (assoc r :Quantity n)
                  r)                )))))</pre></div><div class="docs"><p>So, each time we add supply, we conceptually take a growth step.</p>
</div><div class="codes"><pre class="brush: clojure">(defn distribute [reqstate src n]
  (let [steps   (or (:steps reqstate) [])
        total   (if (empty? steps) n
                     (:total-ghosts (last steps)))
        amounts (compute-amounts reqstate src total)]
    (-&gt; reqstate
        (apply-amounts  amounts) 
        (assoc  :steps ;;record the step we took.
           (conj steps {:src    src
                        :count  amounts
                        :total-ghosts (+ total n)
                        :added  amounts
                        :total  total ;n
                        })))))</pre></div><div class="docs"><p>This is an auxillary function to handle each run of the requirements analysis.
Given a simulation that is already primed and loaded, and possibly an initial supply of units, calculate the
units needed (the requirement), as represented by the amount of ghosts created by SRC.  The requirement is then
applied to the distributor, which transforms the homogeneous supply of ghosts into a set of units that are to be added
to the final result. The return is a dictionary of (SRC|Component, count) pairs.  This allows us to trivially update
the supplytable, by incrementing.</p>
</div><div class="codes"></div><div class="docs"><p>The idea here is to just layer on another fill step,
if there are unmet demands, we allow ghosts to be created and
used to fill.  This is different than the scheme in vba, where
we had "supply generators" that were a little squirrely.  We'll
just move to a multipass fill, and use a ghost-fill function as
the last stage.  Easy peasy. [IF WE WANT TO USE GHOSTS].</p>
</div><div class="codes"></div><div class="docs"><p>Primary state transition function for Marathon Requirements Analysis. </p>

<p>[No Ghosts]
There's actually a simpler way to do this.  If we ignore ghosts,
we don't need to generate ghost entities at all, just stop on the
first day we miss demand(s).  Then use the quantities missed as
a hueristic to generate ghosts.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unconstrained-ghost-step 
  [ctx]
  ;;At this point
  (throw (Exception. (str &quot;placeholder for stepping with ghost-fills.&quot;))))</pre></div><div class="docs"><p>Computes a scalar quantity of unfilled demand from a simulation
   context.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unfilled-demand
  [ctx]
  (-&gt;&gt; ctx
       (demand/unfilled-demand-count) 
       (map :unfilled)
       (reduce +)))</pre></div><div class="docs"><p>probably want to stick this in marathon.analysis...
Given a history, compute the maximum amount of ghosts
(high-water mark) over time.  We should be able to
determine this easily by selecting entities with a
"Ghost" component at the end of the simulation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn history-&gt;ghosts [h]
  ;;The crude idea here is to traverse the history until
  ;;we find the first time we actually miss demand.
  ;;We compute total misses on said day, and report the
  ;;number.  Simple.
  (-&gt;&gt; h
       (map (comp unfilled-demand second))
       (filter identity)
       (filter pos?)
       (first)))</pre></div><div class="docs"><p>I think we'll prefer to work with the history, so probably using a marathon-stream
instead of this approach...
TODO: Replace event-step-marathon with the appropriate simreducer or whatnot.
Returns the next requirement state, if we actually have a requirement.
Otherwise nil. </p>
</div><div class="codes"><pre class="brush: clojure">(defn calculate-requirement
  ([reqstate distance-function]
   (calculate-requirement reqstate distance-function requirements-ctx))
  ([{:keys [tables src steps supply] :as reqstate} distance-function tables-&gt;ctx]
   (-&gt; (assoc tables :SupplyRecords supply)
       (tables-&gt;ctx)
       (distance-function))))</pre></div><div class="docs"><p>calculate-requirement works on one requirement...
to perform a requirements analysis, we want to </p>
</div><div class="codes"><pre class="brush: clojure">(def default-distance (comp history-&gt;ghosts a/marathon-stream))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def prior (atom nil))</pre></div><div class="docs"><p>Given a requirements-state, searches the force structure 
   space by varying the supply of the requirements, until 
   it converges on a minimum feasible force structure.
   At the low end, we'll just be performing multiple 
   capacity analyses...</p>

<p>We may be able to fold this into calculate-requirements...</p>
</div><div class="codes"><pre class="brush: clojure">(defn iterative-convergence
  [reqstate &amp; {:keys [distance]
               :or   {distance default-distance}}]
  (let [echo (fn [{:keys [src iteration] :as reqs} dist]
               (do (println
                    (pprint/cl-format nil &quot;Generated ~a ghosts of ~a on iteration ~a&quot;
                                      dist src iteration))
                   reqs))]
  (loop [reqs      reqstate]
    (if-let [dist (calculate-requirement reqs distance)] ;;naive growth.
      (-&gt; reqs
            (echo dist)
            (distribute (:src reqstate) dist)
            (update :iteration inc)            
            (recur))
      reqs))))</pre></div><div class="docs"><p>We can save a lot of redundant effort if
we limit ourselves to only loading supply...
I.e., we keep policy and demand (initial demand)
in place.</p>
</div><div class="codes"></div><div class="docs"><p>We can call this the root context.
The root context then only has to build units
from records....so...</p>
</div><div class="codes"></div><div class="docs"><p>If we want to reset a requirements context....
We need to drop the supply.
Demand doesn't change.
We could reset the demand....</p>
</div><div class="codes"></div><div class="docs"><p>To create a root context...
Build from a file.
From wipe out the supply.
Wiping supply implies</p>
</div><div class="codes"></div><div class="docs"><p>Given a context, removes a unit entity from the context.</p>
</div><div class="codes"><pre class="brush: clojure">(defn clear-supply
  [ctx]
  (let [us     (core/units ctx)
        ids    (map :name   us)
        pstore (reduce (fn [acc u]
                      (marathon.ces.policy/unsubscribe-unit u (:policy u) acc))
                   (core/get-policystore ctx)
                   us)
        _ (println (:subscriptions pstore))]
    (-&gt; (-&gt;&gt; (marathon.ces.supply/drop-units ctx ids)
             (sim/merge-entity {:PolicyStore pstore}))
        (sim/drop-entity-updates (set ids)))))</pre></div><div class="docs"><p>We could use a heuristic function, for the big
entity runs.  Alternately, make supply updates
and unit construction/registration much cheaper.</p>
</div><div class="codes"></div><div class="docs"><p>Yields a function that provides a reusable context 
   so that we don't pay i/o costs everytime we build a 
   new supply excursion.  Strips down the initial context
   into a simplified context that has no unit-entities or 
   supply.</p>
</div><div class="codes"><pre class="brush: clojure">(defn quick-context
  [tbls]
  (let [base-ctx (requirements-ctx tbls)     
        base-ctx (clear-supply base-ctx)]    
    (fn [tbls]
      (-&gt; base-ctx
          (setup/default-supply :records (:SupplyRecords tbls))))))</pre></div><div class="docs"><p>Given a requirements-state, searches the force structure 
   space by varying the supply of the requirements, until 
   it converges on a minimum feasible force structure.
   At the low end, we'll just be performing multiple 
   capacity analyses...Uses a shared base context to 
   save time on i/o.</p>
</div><div class="codes"><pre class="brush: clojure">(defn iterative-convergence-shared
  [reqstate &amp; {:keys [distance]
               :or   {distance default-distance}}]
  (let [tables-&gt;ctx (quick-context  (:tables reqstate))
        echo (fn [{:keys [src iteration] :as reqs} dist]
               (do (println
                    (pprint/cl-format nil &quot;Generated ~a ghosts of ~a on iteration ~a&quot;
                                      dist src iteration))
                   reqs))]
  (loop [reqs      reqstate]
    (if-let [dist (calculate-requirement reqs distance tables-&gt;ctx)] ;;naive growth.
      (-&gt; reqs
            (echo dist)
            (distribute (:src reqstate) dist)
            (update :iteration inc)            
            (recur))
      reqs))))</pre></div><div class="docs"><p>Currently 2x slower than ic....wonder if we can speed this
up?  Problem is, we end up doing a lot of higher-supply
runs, which hurts performance.  Doing more volume of
work than IC.  IC makes many small jumps.  BS
makes some large jumps, and some small jumps.</p>
</div><div class="codes"><pre class="brush: clojure">(defn bisecting-convergence
  [reqstate &amp; {:keys [distance init-lower init-upper]
               :or   {distance default-distance
                      init-lower 0
                      init-upper 50}}]
  (let [known? (atom #{})]
    (loop [reqs      reqstate
           lower init-lower
           upper init-upper]
      (let [hw    (quot (- upper lower) 2)
            mid   (+ lower hw)         
            rtest (distribute reqs (:src reqstate) mid)
            reqs  (update reqs :iteration inc)]
        (if (= mid lower) ;need a new bound...double upper?
          (recur reqs lower (* upper 2))
          (do (swap! known? conj mid)
              (if-let [res (calculate-requirement rtest distance)] ;;naive growth.
                (do (println [:guessing [lower upper] :at mid :got res])
                    (recur reqs mid upper))
                (do (println [:guessing [lower upper] :at mid :got 0])
                    (if (== hw 1)
                      (do (println [:converged mid])
                          rtest)
                      (recur reqs lower mid))))))))))</pre></div><div class="docs"><p>The iterative convergence function is a fixed-point function that implements the algorithm described in the declarations section.
During iterative convergence, we don;;t care about intermediate results, only the final fixed-point calculation.
After we determine the fixed-point, we can perform a final dynamic analysis (capacity analysis) on the output.
The concrete implementation follows:
Assuming we have a simulation object, we can call its FromExcel method to load all demand and supply from Excel.
Future iterations will avoid re-parsing demand and supply, but for now, we;;ll just reload the whole thing everytime.
Possibly use a "limited-reload? or hot-load" method.
Each time the simulation runs, it will load supply from the SupplyRecords input (which is a worksheet).
Our goal is to effectively generate supply records.
In the extreme case, we start with no supply, thus no supply records.
We must have ghost relation rules in effect (i.e. ghostables for all the SRCs), and a set of demands to simulate.
Prior to the first iteration, we attach a special observer to the simulation;;s event pump.
This observer, the GhostWatcher, will maintain statistics for all the ghosts spawned, by SRC, etc. during the simulation.
The GhostWatcher will serve as the GhostRecord generator that we will need in our distribution function.</p>
</div><div class="codes"></div><div class="docs"><p>On the first iteration, the simulation is initialized "fromexcel", which pulls in all supply, demand, policy, etc.
Note, again, there may be no supply.</p>
</div><div class="codes"></div><div class="docs"><p>We then pass the primed simulation, a valid distribution function, and the ghostwatcher, into the CalculateRequirement function.
The simulation is run in a non-interactive mode, with no supply, which triggers the generation of ghosts.
We want each run to be as fast as possible, thus we run the sim in its most effecient state, avoiding log files
and other detritus.</p>
</div><div class="codes"></div><div class="docs"><p>The externally-attached Ghost Watcher observes all of these ghost spawning events, noting the SRC count of ghosts
generated during the run.</p>
</div><div class="codes"></div><div class="docs"><p>CalculateRequirement;;s return value is simply a function of the application of the distributor to the observerd quantities of ghosts, by SRC,
in the ghostwatcher.  This should be a number of units, by SRC, by component.</p>
</div><div class="codes"></div><div class="docs"><p>Given a set of new units, we simply update the supply records data (worksheet), possibly recording the amount of supply added during each
iteration.</p>
</div><div class="codes"></div><div class="docs"><p>Given a set of no new units (i.e. zero ghosts generated), iterative convergence returns the reported supply.  The data is already on-hand for
additional analysis (namely capacity analyis), if desired.</p>
</div><div class="codes"></div><div class="docs"><p>So, need a way to apply the step-function to the
current supply, compute new supply records, etc.
should be keeping a running tally of the
ratioal totals at any given time.
Perhaps, we store the actual value
in the supply records.
From there, we apply the growth step
by adding the rationals.
Then we coerce prior to running...</p>
</div><div class="codes"></div><div class="docs"><p>So, when we go to distribute</p>
</div><div class="codes"></div><div class="docs"><p>Maybe we have search do the work of creating
the context?
So the context is local to the search state..</p>
</div><div class="codes"></div><div class="docs"><p>Given a database of distributions, and the required tables for a marathon 
   project, computes a sequence of [src {compo requirement}] for each src.</p>

<p>We have an alternate implementation....
This is our entry point....</p>
</div><div class="codes"><pre class="brush: clojure">(defn tables-&gt;requirements
  [tbls &amp; {:keys [dtype search] :or {search iterative-convergence
                                     dtype  :proportional}}]
  (let [;;note: we can also derive aggd based on supplyrecords, we look for a table for now.
        distros (aggregate-distributions tbls :dtype dtype)]
    (-&gt;&gt; distros
         (mapv (fn [[src compo-&gt;distros]] ;;for each src, we create a reqstate
                 (let [_          (println [:computing-requirements src])
                       src-filter (a/filter-srcs [src])
                       src-tables (src-filter     tbls) ;alters SupplyRecords, DemandRecords
                       reqstate   (-&gt;requirements-state src-tables ;create the searchstate.
                                                        src compo-&gt;distros)]
                   [src (search reqstate)]))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def supply-fields [:Type :Enabled :Quantity :SRC :Component :OITitle :Name
                    :Behavior :CycleTime :Policy :Tags :Spawntime :Location :Position :Original])</pre></div><div class="docs"><p>Computes a finalized table of supply records representing the 
   required supply.</p>
</div><div class="codes"><pre class="brush: clojure">(defn requirements-&gt;table
  [rs]
  (-&gt;&gt; rs 
       (mapcat (comp :supply second))       
       (tbl/records-&gt;table)
;       (tbl/order-fields-by supply-fields)
       (tbl/map-field :Quantity long)))</pre></div><div class="docs"><p>Primary function to compute  requirements analysis.  Reads requirements 
   project from inpath, computes requirement, and spits results to a tsv 
   table in the same root folder as inpath, requirements.txt</p>
</div><div class="codes"><pre class="brush: clojure">(defn requirements-run
  [inpath]
  (let [inpath (clojure.string/replace inpath #&quot;\\&quot; &quot;/&quot;)
        base (-&gt;&gt; (clojure.string/split inpath #&quot;/&quot;)
                  (butlast)
                  (clojure.string/join &quot;/&quot;))
        outpath (str base &quot;/requirements.txt&quot;)]
    (do (println [&quot;Analyzing requirements for&quot; inpath])        
        (-&gt;&gt; (-&gt; (a/load-requirements-project inpath)
                 (:tables)
                 (tables-&gt;requirements  :search iterative-convergence-shared)
                 (requirements-&gt;table)
                 (tbl/table-&gt;tabdelimited))
             (spit outpath))
        (println [&quot;Spit requirements to &quot; outpath]))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment ;testing
  (def root (hpath &quot;\\Documents\\srm\\tst\\notionalv2\\reqbase.xlsx&quot;))
  (require '[marathon.analysis [dummydata :as data]])
  (def dummy-table
    (apply-schema (marathon.schemas/get-schema :SupplyRecords)
                  (tbl/keywordize-field-names (tbl/records-&gt;table  data/dummy-supply-records))))
  (def tbls (a/load-requirements-project root))
  ;;derive a requirements-state...
  (def icres (requirements-&gt;table
              (tables-&gt;requirements (:tables tbls) :search iterative-convergence)))
  (def bsres (requirements-&gt;table
              (tables-&gt;requirements (:tables tbls) :search bisecting-convergence)))
  (def s1 {&quot;AC&quot; 1696969696969697/4000000000000000
           &quot;RC&quot; 0N
           &quot;NG&quot; 5757575757575757/10000000000000000})
  (def rootbig &quot;C:/Users/tspoon/Documents/srm/tst/notionalv2/reqbasebig.xlsx&quot;)
  (def tbls  (a/load-requirements-project rootbig))
  (def icres (requirements-&gt;table
              (tables-&gt;requirements (:tables tbls) :search iterative-convergence)))
  (def bsres (requirements-&gt;table
              (tables-&gt;requirements (:tables tbls) :search bisecting-convergence)))
  (def icsres  (requirements-&gt;table
                (tables-&gt;requirements (:tables tbls) :search iterative-convergence-shared))))</pre></div><div class="docs"><p>'TOM Change 3 August -> implemented a bracketing algorithm not unlike binary search.
'This is meant to be performed on a single SRC, i.e. a single independent requirement.
'Bisection requires an src as the arguement.
Public Sub Bisect(sim As TimeStep_Engine, ns As Collection, left As Dictionary, right As Dictionary, Iteration As Long)</p>
</div><div class="codes"></div><div class="docs"><p>Dim searchstate As Collection
Dim middle As Long
Dim lower As Long
Dim upper As Long
Dim src As String
Dim lowest As Long
Dim uppermoved As Boolean
Dim idx As Long, bin As Long
Dim binstate As Dictionary</p>
</div><div class="codes"></div><div class="docs"><p>Dim ghosts As TimeStep_ObserverGhostWatch</p>
</div><div class="codes"></div><div class="docs"><p>Set searchstate = New Collection</p>
</div><div class="codes"></div><div class="docs"><p>lower = left.item("totalghosts")
lowest = lower
upper = right.item("totalghosts")
middle = lower + (upper - lower) \ 2</p>
</div><div class="codes"></div><div class="docs"><p>src = left("src")</p>
</div><div class="codes"></div><div class="docs"><p>'determine what the next step should be</p>
</div><div class="codes"></div><div class="docs"><p>While upper - lower > 1
    Iteration = Iteration + 1
    Debug.Print "Iteration " &amp; Iteration &amp; ", Bracketing solution between n = [" &amp; lower &amp; ", " &amp; upper &amp; "] ghosts."</p>
</div><div class="codes"></div><div class="docs"><pre><code>Set supplyTable = copysupply(left("total")) 'starting from our last step
Distribute src, middle - lowest, , searchstate  'add our ghosts.
</code></pre>
</div><div class="codes"></div><div class="docs"><pre><code>If noio Then 'don't bother writing to the sheet
    sim.Reset_Engine_FromExcel True, supplyTable 'this will reset marathon, using the GeneratedSupply Worksheet to pull in initial supply.
Else
    updateGeneratedSupply
    sim.Reset_Engine_FromExcel True
End If
</code></pre>
</div><div class="codes"></div><div class="docs"><pre><code>Set ghosts = sim.outputmanager.observers("Ghosts")
</code></pre>
</div><div class="codes"></div><div class="docs"><pre><code>'test sufficiency with new supply
If Not CalculateRequirement(sim, ghosts, , searchstate) Then
    'did not generate ghosts.....
    'this means our middle value is now our right, upperbound.
    upper = middle 'move the bracket &lt;&lt;&lt;&lt;&lt;&lt;-
    middle = lower + (upper - lower) \ 2
    'no need to redistribute.
    uppermoved = True
Else
    'we added ghosts, which means middle is insufficient.
    lower = middle 'move the bracket -&gt;&gt;&gt;&gt;&gt;&gt;&gt;
    middle = lower + (upper - lower) \ 2
    'Set left = searchstate(searchstate.count)
    uppermoved = False
End If
</code></pre>

<p>Wend</p>
</div><div class="codes"></div><div class="docs"><p>If upper - lower = 1 Then 'ubound is the answer
    lower = upper
    Set supplyTable = copysupply(left("total")) 'starting from our last step
    Distribute src, upper - lowest, , searchstate  'add our ghosts.
ElseIf upper - lower = 2 Then 'middle is the answer
     If uppermoved Then
        lower = lower + 1
     Else
        lower = upper
     End If
     Distribute src, upper - lowest, , searchstate
Else
    Err.Raise 101, , "convergence is off"
End If</p>
</div><div class="codes"></div><div class="docs"><p>Debug.Print "No More ghosts to generate.  Binary search converged on " &amp; lower &amp; " Ghosts for src " &amp; src
If noio Then finalIO sim
updateGeneratedSupply
Set sim = Nothing
End Sub</p>
</div><div class="codes"></div><div class="docs"><p>Private Sub makeghost()</p>
</div><div class="codes"></div><div class="docs"><p>Dim grecord As GenericRecord
Set grecord = New GenericRecord</p>
</div><div class="codes"></div><div class="docs"><p>With grecord
    .AddField "Type", "SupplyRecord"
    .AddField "Enabled", True
    .AddField "Quantity", 1
    .AddField "SRC", "Ghost"
    .AddField "Component", "Ghost"
    .AddField "OITitle", "Anything"
    .AddField "Name", "Auto"
    .AddField "Behavior", "Ghost365_45"
    .AddField "CycleTime", 0
    .AddField "Policy", "Ghost365_45"
    .AddField "Tags", "Auto"
    .AddField "SpawnTime", 0
    .AddField "Location", "Auto"
    .AddField "Position", "Auto"
    .AddField "Original", False
End With</p>
</div><div class="codes"></div><div class="docs"><p>supplyTable.add "Ghost", grecord</p>
</div><div class="codes"></div><div class="docs"><p>Debug.Print "Asked to do requirements analysis without a ghost," &amp; _
            " added Default ghost record to generated supply table."
End Sub</p>
</div><div class="codes"></div><div class="docs"><p>GeneratedSupply.csv  is out default output, apparently.
Don't think we really need these...</p>
</div><div class="codes"></div><div class="docs"><h1>Distributors</h1>

<p>I think we're going to skip this and just define a
distribute function..</p>
</div><div class="codes"></div><div class="docs"><p>Private Function addDistributor(src As String, compoDistributions As Dictionary, Optional dtype As DistributorType)
Dim distributor As Dynamic_Distributors
Dim compo</p>
</div><div class="codes"></div><div class="docs"><p>For Each compo In compoDistributions
    If compoDistributions(compo) = 0 Then
        compoDistributions.Remove (compo)
    End If
Next compo</p>
</div><div class="codes"></div><div class="docs"><p>Set distributor = New Dynamic_Distributors
Select Case dtype
    Case binned
        distributor.initBinned compoDistributions, src
        SRCdistributors.add src, distributor
    Case continuous1418
        distributor.initContinuous1418 compoDistributions
        SRCdistributors.add src, distributor
    Case rounding1418
        distributor.initRounding1418 compoDistributions
        SRCdistributors.add src, distributor
End Select</p>
</div><div class="codes"></div><div class="docs"><p>End Function</p>
</div><div class="codes"></div><div class="docs"><p>note: we need to filter only positive compodistriutions.</p>
</div><div class="codes"></div><div class="docs"><p>multimethod for constructing different distributors.</p>
</div><div class="codes"><pre class="brush: clojure">(defmulti distributor identity)
(defmethod distributor :binned [n] nil)
(defmethod distributor :continuous1418 [kw] nil)
(defmethod distributor :rounding1418 [kw] nil)</pre></div><div class="docs"><p>''TOM Change 3 August -> implemented a bracketing algorithm not unlike binary search.
''This is meant to be performed on a single SRC, i.e. a single independent requirement.
''Bisection requires an src as the arguement.
Public Sub BisectionConvergence(Optional logevents As Boolean, Optional addcapacity As Boolean)</p>
</div><div class="codes"></div><div class="docs"><p>Dim tstrt As Single
Dim logger As TimeStep_ObserverLogFile
Dim ghosts As TimeStep_ObserverGhostWatch
Dim max As Long, min As Long
Dim nextX As Long
Dim generatedGhosts As Boolean
Dim fX As Long
Dim bracketed As Boolean
Dim src As String
Dim ky</p>
</div><div class="codes"></div><div class="docs"><p>Iteration = 0
importSupplyRecords
importAggregateDistributions
Err.Raise 101, , "Needs updating!"</p>
</div><div class="codes"></div><div class="docs"><p>If sim Is Nothing Then
    Set sim = New TimeStep_Engine
    sim.noio = noio
    sim.Initialize<em>Engine</em>FromExcel New TimeStep_SimState, True 'this will cause overhead....
Else
    sim.noio = noio
    sim.Reset<em>Engine</em>FromExcel
End If</p>
</div><div class="codes"></div><div class="docs"><p>If logevents Then
    Set logger = New TimeStep_ObserverLogFile
    logger.init "ReqEvents" &amp; Iteration, sim.EventManager.evtstream
End If</p>
</div><div class="codes"></div><div class="docs"><p>For Each ky In sim.DemandManager.demandmap
    src = sim.DemandManager.demandmap.item(ky).src
    If src &lt;> "Ghost" Then Exit For
Next ky</p>
</div><div class="codes"></div><div class="docs"><p>If src = "Ghost" Then Err.Raise 101, , "Only registered ghost srcs"</p>
</div><div class="codes"></div><div class="docs"><p>tstrt = Timer()</p>
</div><div class="codes"></div><div class="docs"><p>max = 10
min = 0
fX = max
nextX = max
bracketed = False</p>
</div><div class="codes"></div><div class="docs"><p>While max &lt;> min
    Set ghosts = sim.outputmanager.observers("Ghosts")
    Iteration = Iteration + 1
    'determine what the next step should be
    Debug.Print "Searching for solution using " &amp; nextX &amp; " ghosts."
    fX = search(src, nextX, sim, ghosts)</p>
</div><div class="codes"></div><div class="docs"><pre><code>If fX = 0 Then
    bracketed = True
    max = nextX
    nextX = (max - min) \ 2 + min
ElseIf fX &gt; 0 Then
    If bracketed Then
        min = max
        max = 2 * max
        nextX = (max - min) \ 2
    Else
        If fX &gt; max Then max = max + fX
        'ElseIf fX &lt; max Then
            'max = fX
        'End If
        min = max
        max = 2 * max
        nextX = max
    End If
End If
</code></pre>
</div><div class="codes"></div><div class="docs"><pre><code>tstrt = Timer() - tstrt
</code></pre>
</div><div class="codes"></div><div class="docs"><pre><code>If noio Then 'don't bother writing to the sheet
    sim.Reset_Engine_FromExcel True, supplyTable 'this will reset marathon, using the GeneratedSupply Worksheet to pull in initial supply.
Else
    updateGeneratedSupply
    sim.Reset_Engine_FromExcel True
End If
</code></pre>
</div><div class="codes"></div><div class="docs"><pre><code>If logevents Then
    Set logger = Nothing
    Set logger = New TimeStep_ObserverLogFile
    logger.init "ReqEvents" &amp; Iteration, sim.EventManager.evtstream
End If
</code></pre>

<p>Wend</p>
</div><div class="codes"></div><div class="docs"><p>Debug.Print "No More ghosts to generate.  Binary search converged on " &amp; max &amp; " Ghosts for src " &amp; src</p>
</div><div class="codes"></div><div class="docs"><p>If noio Then finalIO sim</p>
</div><div class="codes"></div><div class="docs"><p>updateGeneratedSupply</p>
</div><div class="codes"></div><div class="docs"><p>Set logger = Nothing
Set sim = Nothing</p>
</div><div class="codes"></div><div class="docs"><p>End Sub</p>
</div><div class="codes"></div><div class="docs"><p>'write out the final, summary report, specifically the final supply, the number of ghosts, etc.
Private Sub finalIO(sim As TimeStep_Engine, Optional addcapacity As Boolean)</p>
</div><div class="codes"></div><div class="docs"><p>updateGeneratedSupply
If addcapacity Then
    sim.noio = False
    sim.Reset<em>Engine</em>FromExcel True
    sim.EventStepMarathon
End If</p>
</div><div class="codes"></div><div class="docs"><p>End Sub</p>
</div><div class="codes"></div><div class="docs"><p>Public Function search(src As String, ghostcount As Long, sim As TimeStep<em>Engine, ghostwatcher As TimeStep</em>ObserverGhostWatch) As Long
Static counts As Dictionary
search = 0
Distribute src, ghostcount, True 'update the ghost solution
sim.EventStepMarathon 'execute the simulation, may produce ghosts.
Set counts = getGhostCounts(ghostwatcher)
If counts.count > 0 Then
    Debug.Print "Generated ghosts on iteration " &amp; Iteration
    search = counts(src)
End If
End Function</p>
</div><div class="codes"></div><div class="docs"><p>Eliminate all the unit entities from the context.</p>
</div><div class="codes"><pre class="brush: clojure">(comment ;;possibly obe
  ;;we add a ghost record though
  (defn make-ghost []
    (supply-record  &quot;SupplyRecord&quot;  true 1 &quot;Ghost&quot; &quot;Ghost&quot;
                    &quot;Anything&quot; &quot;Auto&quot;  &quot;Ghost365_45&quot; ;default behavior...
                    0 &quot;Ghost365_45&quot; &quot;Auto&quot;  0 &quot;Auto&quot; &quot;Auto&quot; false))
  ;;import the original provided supply records (currently from excel) into the supplytable
  (defn import-supply-records [ctx]) ;;may be uncessary.
  (defn clear-supply
    [ctx])
  #_(defn reload-supply [ctx]
      (default-supply))
  ;;allows a nice handle on 
  #_(defn load-variable-supply-context [tbls]
      (fn [supply-records])))</pre></div><div class="docs"><p>Possibly OBE...</p>
</div><div class="codes"></div><div class="docs"><p>Compute a sequence of "empty" supply records
from the proportions indicated </p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.data.store" name="marathon.data.store"><h1 class="project-name">marathon.data.store</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>The entity store for MARATHON and some supplemental
entity definitions and aux functions.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.data.store
   (:require 
    [spork.entitysystem.store :refer :all]
    [spork.sim.core :as sim]
    [spork.util.tags :as tag]
    [marathon.data [period :as p] [fsm :as fsm]]))</pre></div><div class="docs"><h1>Cleanup - WORK IN PROGRESS</h1>
</div><div class="codes"></div><div class="docs"><p>The original implementation of the entitystore
originated in a parallel, experimental build of a lightweight
simulation.  Much of the functionality that now resides in
spork.entitystore and marathon.ces.core was colocated with this
namespace (hence the entity definitions, event "notifications"
and other auxillary functions).</p>
</div><div class="codes"></div><div class="docs"><p>As I've migrated generic things out into spork, and integrated
the basic entity store into the overarching simulation infrastructure,
we're left with relatively little here.  Technically, we don't need
special entitystore implementation, we could use the barebones from
spork.entitysystem.store in theory.</p>
</div><div class="codes"></div><div class="docs"><p>We're also still using legacy entity definitions in other "data"
namespaces.  Since the entity store will happily accept records
as entities (infering keys map to components) this is no problem
and allows a smooth migration to useing the entity store API
for operating on our simstate.</p>
</div><div class="codes"></div><div class="docs"><p>I'll leave the entity definitions in place for now, although they
are not technically in use.</p>
</div><div class="codes"></div><div class="docs"><p>Additionally pruning to follow....</p>
</div><div class="codes"></div><div class="docs"><p>The only functions we "actually" use here are ->store to
create the entity store....</p>
</div><div class="codes"></div><div class="docs"><h1>Pending DEPRECATION</h1>

<p>Originally a simple API to process the act of handling
"events" in an entity store-based simulation.  Supplanted
by the functionality in spork.sim.simcontext.</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol INotification
  (notify! [obj e msg]
           [obj m])) </pre></div><div class="docs"><h1>Pending DEPRECATION</h1>
</div><div class="codes"></div><div class="docs"><p>provide a constant set of components that
will be cleared each day.
Basically, we'll perform all of our processing
and allocations, then drop anything that's considered
ephemeral.  Typically, we'll have multiple changes
occuring over the same time instant, but spanning
multiple event or update-instants.  We only care
about the initial and the final value.</p>
</div><div class="codes"><pre class="brush: clojure">(def delta-components
  #{:position-delta :movement-delta :state-delta})</pre></div><div class="docs"><p>temporary hack to abstract out entity containers...</p>
</div><div class="codes"></div><div class="docs"><h1>Pending DEPRECATION</h1>

<p>defines a unit-entity selector.  This is a little
brittle, which is why I'm pushing it into a redefinable
function.  The stats stuff is dependent on the entity
records having these fields.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unit-entities [obj]
  (all-entities obj [:state :component :icon :color :position]))</pre></div><div class="docs"><h1>Description</h1>

<p>simstate is a consolidation of all the simulation state required for Marathon 
to do its thing.  Each of these bits used to be part of a hierarchical object 
model with parent-child relationships, where each child manager could get at 
the state for another child via its parent, the simulation Engine.  This worked
okay in the beginning, and fit with some naive object oriented programming 
notions, but ended up leading to coupling and some other phenomena. As a result
I've re-organized the code base to conform to a more functional-programming 
paradigm: specifically, data is maintained separate from functionality, rather 
than classic OOP where data is encapsulated and bundled with 
methods/properties.  The result is a simplification of the data model, as well
as functions that can produce and consume bits of data necessary for the 
simulation.  This simstate object really just gathers all the data in one 
place, so that functions that need to access multiple components of data
simultaneously CAN.  Since it's a record, and most of the elements are also 
records, we get the benefit of using clojure's associative map functions and 
sequence libraries to access and modify our state, rather than having to deal
with a special set of one-off functions.</p>
</div><div class="codes"></div><div class="docs"><p>Since simstate implements entity store, it can be used as the :state key of
a simcontext, and simcontext will forward all entity-store-related implementation
calls to it.  This gives us a fairly flexible way to manage our simulation context,
specifically the entity state: use the spork.entitysystem.store API to query
and update the simcontext directly.  marathon.ces.core is full of idioms that
do this very thing, although many namespaces will use the spork.entitysystem.store
directly.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defrecord simstate [store width height notifier]
  IEntityStore
  (add-entry [db id domain data] 
    (simstate. (add-entry store id domain data)
               width height notifier))
  (drop-entry [db id domain] 
    (simstate. (drop-entry store id domain) width height notifier)) 
  (get-entry      [db id domain] (get-entry store id domain))
  (entities       [db]     (entities store))
  (domains        [db]     (domains  store))
  (domains-of     [db id]  (domains-of     store id))
  (components-of  [db id]  (components-of  store id))
  (get-entity     [db id]  (get-entity     store id))
  (conj-entity    [db id components] 
    (simstate. (conj-entity store id components) width height notifier))
  INotification
  (notify! [obj e msg]
    (if (fn? notifier)
      (notifier e msg)
      (notify! notifier e msg)))
  (notify! [obj m]
     (if (fn? notifier) (notifier m)
         (notify! notifier m))))</pre></div><div class="docs"><h1>Currently Out of Use / Possible Migration / Documention</h1>
</div><div class="codes"></div><div class="docs"><p>A simple entity with 2D physics information, position and velocity. </p>

<p><strong>Entity Definitions</strong></p>
</div><div class="codes"><pre class="brush: clojure">(defentity physical-entity
  [id {:keys [position velocity]
       :or {position [0 0]
            velocity [0 0]}}]
  {:components [:position position
                :velocity velocity
                :physical true]})</pre></div><div class="docs"><p>An entity that can participate in messaging and behavior, keeps track of time.</p>

<p>update information tracking the last time the entity was examined.</p>
</div><div class="codes"><pre class="brush: clojure">(defentity interactive-entity
  [id {:keys [messages behavior statedata last-update t] 
       :or {messages nil
            behavior :default
            statedata fsm/spawning-data}}]
  {:components [:behavior    behavior
                :messages    messages
                :interactive true
                :statedata   statedata
                :spawntime   -1]})</pre></div><div class="docs"><p>Defines a specification for entities that correspond to force structure.</p>

<p>Note: nil initial values don't work well...</p>
</div><div class="codes"><pre class="brush: clojure">(defentity unit
  [id name type component policy state icon label position velocity color home
   &amp; {:keys [speed location behavior] :or {speed 8}}]
  {:specs [(physical-entity id {:position position
                                :velocity velocity})
           (interactive-entity id {:behavior (or behavior :default)})]
   :components
   [:name        name      ;unit entity's unique name. corresponds to a UIC 
    :type        type
    :src         type      ;unit entity's type, or capability it can supply.
    :component   component ;unit entity's membership in supply.
    :policy      policy    ;the policy the entity is currently following.
    :policystack []       ;a stack of any pending policy changes.
    :state       state
    :icon        icon
    :label       label
    :color       color
    :unit-entity true
    :speed       speed
    :home        home
    :deployable  false  ;unit's deployable status.
    :location    (or location home) ;physical location of the unit.
    :cycletime    0    ;the unit's current coordinate in lifecycle space.
    :followoncode 0 ;description of the categories this unit serve as a followon to.
    :positionpolicy :spawn
    :currentcycle nil ;the current cycle data structure for the unit.
    :cycles   []
    :oi-title &quot;no-description&quot; ;the description of the unit.
    :locationhistory [] ;list of all the locations visited.  ;:dwell-time-when-deployed nil                                       
    ]
   })</pre></div><div class="docs"><p>Defines a specification for entities that correspond to force structure demands.</p>
</div><div class="codes"><pre class="brush: clojure">(defentity demand
  [id name type priority startday duration overlap category source-first quantity title
   vignette operation demandgroup 
   &amp; {:keys [location behavior fills  source-first theater
             BOG StartState EndState MissionLength]}]
  {
   :components
   [:name name ;unique name associated with the demand entity.
    :src  type ;demand-type, or other identifier of the capability demanded.
    :priority priority ;numerical value representing the relative fill priority.
    :startday startday ;the day upon which the demand is activated and requiring fill.
    :duration duration ;the total time the demand is activated.
    :overlap overlap  ;the demand-specific overlap requirement, if any
    :category (or category :rotational) ;descriptor for deployed unit behavior over-rides.
    :source-first (or source-first :uniform)  ;descriptor for supply preference. 
    :quantity (or quantity 0) ;the total amount of entities required to fill the demand.
    :title  title  ;formerly OITitle.  Long-form description of the src capability.
    :vignette vignette ;Descriptor of the force list that generated this demand entity.
    :operation operation ;Fine-grained, unique description of the demand.
    :demandgroup demandgroup ;Ket that associates a demand with other linked demands.  
    :fills (or fills {}) ;an ordered collection of all the fills recieved over time.                   
    :units-assigned {} ;map of the units currently associated with the demand.
    :units-overlapping {};map of the units currently associated with this demand, 
                           ;that are not actively contributing toward filling the 
                                        ;demand, due to a relief-in-place state.
    :location   (or location name) ;;physical location of the demand.
    :theater     theater ;;newly added for SRM. Describes the geolocal theater of the demand
    :BOG           BOG  ;;newly added for SRM. Describes the geolocal theater of the demand
    :StartState    StartState ;;Defines a possible starting state for the demand, if any.
    :EndState      EndState ;;Defines the implication of leaving the demand on any associated entity.
    :MissionLength MissionLength ;;Defines the length of duration of a local assignment to the demand.
    ]})</pre></div><div class="docs"><h1>Actively In Use</h1>
</div><div class="codes"></div><div class="docs"><p>not sure how much of this needs to stick around...
Since entities are dispersed now, we may not need these guys
any longer.
It'd be nice to define some queries/views too..
Specifically, we can provide an associated type that knows how to
query an entity store; we can use said view against it and get
a resulting seq of entities.</p>
</div><div class="codes"></div><div class="docs"><p>defines a singleton container for supply information</p>

<p>need a changed component.</p>
</div><div class="codes"><pre class="brush: clojure">(defentity supplystore
  [id]
  {:components
   [:name :SupplyStore
    :srcs-in-scope {} ;Set of unique SRCs in scope.
    :deployable-buckets {} ;{category entity}, indicates entities that can fill demand.
;   :unitmap        ;{entity-name unitdata}, map of unique unit entities.
;   :unit-behaviors ;map of named unit behaviors.  may move this out...
;   :unit-updates ;set of eventful unit-days....might be able to handle this outside.
                ;this was listed as a tag structure earlier...not certain..
    :tags tag/empty-tags;set of supply tags...should move to a global tag-store.
    :has-ghosts ;boolean flag to determine if the supply can generate ghosts..might change.
    :follow-ons  {}]})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-supplystore [ces]  (gete ces :SupplyStore))</pre></div><div class="docs"><p>Defines a singleton container for demand information</p>
</div><div class="codes"><pre class="brush: clojure">(defentity demandstore
  [id]
  {:components
   [:name :DemandStore 
    ;:demandmap         {}
    :infeasible-demands {} 
    :unfilledq          nil
    :activations        {}
    :deactivations      {}  
    :activedemands      {}  ;possibly replace with active component
    :eligbledemands     {}  ;forgot what this is...
    :changed            {}  ;indicates demands that changed, we can handle this better.
    :demandtraffic      nil ;supress demand traffic, maybe old
    :tryfill            true ;no idea...
    :loginfeasibles     true ;logging info
    :tags               (tag/add-tag tag/empty-tags &quot;Sinks&quot;)
    :fillables          nil ;;forgot what this is for
    :verbose            nil ;logging information...
    :tlastdeactivation 0]})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-demandstore [ces] (gete ces :DemandStore))</pre></div><div class="docs"><p>Defines a singleton container for policy information,
   periods, and policy schedules.</p>
</div><div class="codes"><pre class="brush: clojure">(defentity policystore
  [id]
  {:components
   [:name :PolicyStore 
    :positions #{} ;set of all known positions.
    :locations #{}  ;set of all known locations, superset of positions.
    :periods  {&quot;Initialization&quot; p/+default-period+} ;Set of simulation periods...probably need to re-think this guy.
    :policies {} ;Kvp mapping of policy names to policy data
    :policytraffic       false   
    :activeperiod p/+default-period+ ;the current period 
    :periodchanges {}  ;the set of scheduled period changes....re-think this.
    :subscriptions {}  ;map of policy-&gt;client
    :composites    {}  ;map of composite policies
    ;schedules    
    ]})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-policystore (policystore :PolicyStore))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-policystore [ces] (gete ces :PolicyStore))</pre></div><div class="docs"><p>Defines a singleton container for fill information</p>

<p>Container to store all the data associated with matching supply to demand, 
namely substitution rules, scoping (both in and out of scope) for the current
run, and any other associated data.</p>
</div><div class="codes"><pre class="brush: clojure">(defentity fillstore
  [id]
  {:components
   [:name         :FillStore 
    :fillgraph    nil    
    :fillmap      nil
    :fillfunction nil
    :fills        {} 
    :rendergraphs false 
    :outofscope   {} 
    :allgraphs    
    :rawfillgraph  nil
    ]})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn make-fillstore [&amp; {:keys [fillgraph fillmap rawfillgraph]}]
  (merge (fillstore :FillStore)
         {:fillgraph fillgraph
          :fillmap fillmap
          :rawfillgraph rawfillgraph}))</pre></div><div class="docs"><p>Defines a entity with canonical simulation parameters for components.</p>
</div><div class="codes"><pre class="brush: clojure">(defentity parameters
  [id]
  {:components
   [:name :parameters 
    :SRCs-In-Scope     {} ;set of srcs that can be used/filled.
    :SRCs-Out-Of-Scope {} ;set of srcs that cannot be filled.
   ;imported parameters from timestep_engine, to be deprecated.   
   :pause       false  ;indicates if the simulation is currently paused, suspending simulation.
   :time-start  nil    ;Wall-clock Start time of the simulation.  
   :time-finish nil    ;Wall-clock Stop time of the simulation.
   :maximum-traffic true ;Flag to enable a debugging mode, with maximum event traffic.  
                   ;Slower and lots of I/O.
   :interactive  true ;Indicate the presence of a linked GUI form.  
                      ;Cedes control to the Form.  Maybe deprecated.
   :no-io false ;Forces simulation to try to suppress its I/O, particularly in output 
                ;metrics and event history.
   :moderate-io false ;only record the lightweight stuff, ala summaries, cyclerecords, deployments
               ;sandtrends are dumped out to csv.
   :no-supply-warning true ;Ignore lack of supply warnings when set.  
                     ;Necessary for requirements analysis.
   :no-demand-warning true ;Ignore lack of demand warnings when set.  
                     ;Necessary for supply-only analysis.
   :earlyscoping true ;Flag that tells the preprocessor to try to eliminate 
                       ;unusable data early on.
   :truncate-time true    ;used for requirements analysis.  Allows us to tell 
                          ;Marathon to stop the simulation AS SOON as the last demand 
                          ;has ended.  If there are no pending demand activations
                          ;we assume that we can stop.  This assumption holds for 
                          ;requirements analysis only....    
   :found-truncation false]})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-parameters [ces] (gete ces :parameters))</pre></div><div class="docs"><p><strong>Transient Data</strong>
We define entities with a transient component as being ephemeral or mutable...
For things like logging, or other activities, we'd like to retain
an  append-only event history.  It's easy to do this if we have
a component tagging the mutable structure, so that we may clear it between
frames.  For instance, we may have a system whose job is to traverse
transient components and finalize them.
So...for entities that have a transient and a finalize component,
we can process them in a controlled manner.  This makes it easy
to use different strategies for retaining things like log data,
or events, or other things.</p>
</div><div class="codes"></div><div class="docs"><p><strong>Location Definitions</strong>
Another unique entity that maintains data (primarily for lookup), that maps locations to
coordinates (in some coordinate system)</p>
</div><div class="codes"><pre class="brush: clojure">(defentity locations [id &amp; {:keys [location-map]
                            :or   {location-map {:reset [0 0]}}}]
  {:components [:name :locations
                :location-map location-map]})</pre></div><div class="docs"><p><strong>Location Operations</strong></p>
</div><div class="codes"><pre class="brush: clojure">(defn add-location [ces locname coords]
  (updatee ces :locations :location-map assoc locname coords))</pre></div><div class="docs"><p>generic location-based operations.</p>
</div><div class="codes"><pre class="brush: clojure">(defn find-loc [ces loc]
  (if-let [res (get (gete ces :locations :location-map) loc)]
    res
    (throw (Exception. (str &quot;Location not found: &quot; loc)))))</pre></div><div class="docs"><h1>Only Function Currently In Active Use For MARATHON</h1>

<p>Note: we do call on the entity definitions for the various stores.</p>
</div><div class="codes"></div><div class="docs"><p>REFACTOR: THe old width,height, etc. are no longer necessary.
We aren't really using simstate like we were before, even
notify is OBE.  TODO: Revert to using an empty store,
no need to wrap a specific simstate type....</p>
</div><div class="codes"></div><div class="docs"><p>Given a set of initial entities (currently units), creates and initializes the 
   default entitystore.  width and height determine the rendering canvas and the 
   size of things like the entity board.</p>

<p>The width/height is 1095, wonder if that's screwing up our sizing.
<strong>Entity Store Constructor</strong></p>
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;store
  [&amp; {:keys [width height notify init-store]
      :or {width 1095 height 730
           notify (fn [e msg] (println [:notification e msg]))
           init-store emptystore}}]
;  (let [emap    (reduce (fn [m e] (assoc m (:name e) e)) {} es)
;        trails  (-&gt;rec '() width height)]
    (-&gt; (-&gt;simstate init-store width height notify)
       ; (add-entities es)
        (add-entity  (parameters   :parameters))
        (add-entity  (supplystore  :SupplyStore))
        (add-entity  (demandstore  :DemandStore))
        (add-entity  (policystore  :PolicyStore))
        (add-entity  (locations    :locations))
        (add-entity  (fillstore    :FillStore))
;       (add-entity  (game-board     :board (keys emap) width height trails))        
;       (add-entity  (animated-board :animated-board))
;       (add-entity  (animated-map   :animated-map))
;       (initialize-nodes)
;       (initialize-map)
        ;)))</pre></div><div class="docs"><h1>PENDING DEPRECATION</h1>

<p>WE should decouple this from the original width/height convenience.  It's not
how we render things today.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ents [brd] (val (get-entry brd  :board :entities)))
(defn uics [brd] (map #(get-entity brd %) (ents brd)))</pre></div><div class="docs"><p>get a sequence of entities...this should be using lightweight containers...
basically select-all..</p>
</div><div class="codes"><pre class="brush: clojure">(defn eseq [brd] (map #(entity-at  brd %) (ents brd)))</pre></div><div class="docs"><p><strong>Entity Operations API</strong>
we may define a high-level interface for getters and setters...
to include notifications...</p>
</div><div class="codes"></div><div class="docs"><p>Alter the [x y] position of the entity.</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-entity-position [brd nm x y] (assoce brd nm :position [x y]))</pre></div><div class="docs"><p>Return the [x y] position of the entity.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-position        [brd nm]     (gete brd  nm :position))</pre></div><div class="docs"><p>Alter the shape associated with the entity.</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-entity-shape    [brd nm shp] (assoce brd  nm :shape shp))</pre></div><div class="docs"><p>Alter the entity's state.</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-entity-state    [brd e state]
  (-&gt; brd
      (assoce  e :state state)
      (notify! :state-change [e state])))</pre></div><div class="docs"><p>we should abstract this out to something a bit more useful.</p>
</div><div class="codes"><pre class="brush: clojure">(defn set-entity-color    [brd e clr]
  (-&gt;  brd
       (assoce  e :color clr)
       (notify!   :color-change [e clr])))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn get-trails          [brd] (gete brd :board :trails))</pre></div><div class="docs"><p>Movement is a primitive. We simply add the "current" velocity to the
entity's position.</p>
</div><div class="codes"><pre class="brush: clojure">(defn move-entity! [brd nm x y dx dy]
  (assoce brd nm :position
          [(+ x dx)
           (+ y dy)]))</pre></div><div class="docs"><p>this comes later...</p>
</div><div class="codes"><pre class="brush: clojure">(declare nodes!)</pre></div><div class="docs"><p>debug helper.</p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(defn node-info [lbl e x y x2 y2]
  (when @shared/debug
    (println [lbl e
              :from [x y]
              :to [x2 y2]
              :displacement [(- x2 x) (- y2 y)]
              :node (let [bnd (.getFullBounds ^org.piccolo2d.PNode (get (nodes!) e))]
                      [(.getX bnd) (.getY bnd)])
              ]))))</pre></div><div class="docs"><p>These are fundamental primitives for handling visual aspects of
the entity.</p>
</div><div class="codes"></div><div class="docs"><p>note, this combines movement (direction change) with displacement...
computes a displacement based on the entity's current position.</p>
</div><div class="codes"><pre class="brush: clojure">(defn move-to!
  ([ces e pos loc]  
   (let [[x  y ] pos 
         [x2 y2] (cond (vector? loc)   loc
                       (keyword? loc) (find-loc ces loc)
                       :else (throw (Exception. (str &quot;unmatched condition &quot; loc))))
         ;_      (node-info :move-to e x y x2 y2)
         ]
     (mergee ces e {:position     [x2 y2]
                    :displacement [(- x2 x) (- y2 y)]})))
  ([ces e loc] (move-to! ces e (gete ces e :position) loc)))</pre></div><div class="docs"><p>We may want to rephrase our movement so that everything is in terms of primitive
instructions, specifically, move-to.</p>
</div><div class="codes"><pre class="brush: clojure">(defn deploy-entity! [brd e state x y &amp; {:keys [destination location]}]
  (let [;_ (node-info :deploy-ent e x y x y)
        destination (or destination  :default) ;(board/random-region))
        ]
    (-&gt; brd
        (mergee  e {:state           :deploying
                    :location        destination
                    :velocity        [0  1]
                    :displacement    [0 -1] ;temporary debugging....                   
                    })        
        (notify!    {:state-change    [e state]
                     :location-change [e location destination]
                     :deployed       {:e e
                                      :component (gete brd e :component)
                                      :state state :x x  :y y}}))))</pre></div><div class="docs"><p>Interstingly, we "could" take notifications to just queue messages up, ephemerally,
and then distribute them onto the event bus in between...
Separates the line between pure and impure, if we want purity, we can simulate channels
(kind of an ass pain though).
If we allow impurity, we can maintain a consistent state, and allow systems to run
concurrently.  We may need to synch though...</p>
</div><div class="codes"></div><div class="docs"><p>can we combine impure action with pure storage? </p>
</div><div class="codes"></div><div class="docs"><p>when entities go back to reset (or prepare, depending on policy)</p>
</div><div class="codes"><pre class="brush: clojure">(defn reset-entity!  [brd {:keys [name state position component home location] :as ent}]
  (let [[x y] position]
    (-&gt; brd
        (mergee name {;;encoding multiple velocities indicates instantaneous change in
                      ;;velo.  Any components beyond the first indicate previous velocities.
                      :velocity  (case component
                                   :AC [1   0]
                                   [0.2 0])                      
                      :state          :dwelling
                      :location   home
                      })
        (move-to! name  position :reset) ;;abstracted movement.  Adds a displacement component
        (notify!  {:reset {:e name :state state :x x :y y}
                   :state-change [name state]                   
                   :location-change [name location home]
                   }))))</pre></div><div class="docs"><p>Defines a container for the animated graphical nodes and the rendering system for all 
   the pieces on the board.Defines a container for the animated graphical nodes and the rendering system for all 
   the pieces on the world map.Associates map node components with each entity, and registers the node components in the 
   root layer of the animated board entity in the entity store.Associates node components with each entity, and registers the node components in the 
   root layer of the animated board entity in the entity store.</p>

<p>Entity Board and stuff (currently deferred until quilsample code is generalized; trivial</p>
</div><div class="codes"><pre class="brush: clojure">(comment 
;;the game-board is not a physical entity, but we can store it in the ECS as a
;;unique entity and grab it pretty easily.  There may be some overhead, but i'm not too worried about it.
(defentity game-board [id entities width height trails]
  {:components [:entities entities
                :width width
                :height height
                :trails trails]})
;;__Entity Rendering__
(defentity animated-board
  [id &amp; {:keys [nodes]
         :or   {nodes board/empty-board}}]
  {:components [:nodes nodes]})
(defn get-animated-board [ces]
  (gete ces :animated-board :nodes))
;;This reuses the animated-board concept.
;;Except we'll likely need to scale the icons down
;;a bit...
(defentity animated-map
  [id &amp; {:keys [nodes]
         }]
  {:components [:nodes (or nodes
                           (board/empty-map))]})
(defn get-animated-map [ces] (gete ces :animated-map :nodes))
;;there's a problem atm...
;;we're not computing displacement every frame.
;;we have a more broadly-based rendering system.
;;anything that is visible is updated and rendered.
;;perhaps we can break it up into dynamic objects,
;;objects which have a displacement computed each frame,
;;and static objects, which have no displacement (we just re-render them).
(def ^:constant +zero-2d+ [0.0 0.0])
(defn render-nodes! [ces]
    (-&gt;&gt; [:name :velocity :position :node]
         (only-entities ces)         
         (reduce-kv (fn [acc id {:keys [name velocity position node]}]
                      (let [[^double dx ^double dy]       velocity
                            [x y]                         position
                            [^double xoff ^double yoff]  (or (gete acc name :displacement)
                                                             +zero-2d+)
                            endx (+  dx xoff)
                            endy (+  dy yoff) 
                            ]
                        (do (board/shift-node! node endx endy)                        
                            acc)))
                    ces)))
;;just define a system that listens for changes.
;;same with the board.
;;Convenience wrappers.
;;this lets us delegate to the board stored in the simstate.
;;when we add nodes, we also update the simstate by adding
;;a node to the entity's components (the actual mutable
;;piccolo2d node that's attached to the gameboard).  We also
;;enable the ces to be seen as a single layer (via the gameboard).
(extend-type quilsample.store.simstate 
  board/IBoard
  (add-node  [ab id icon x y]
    (let [brd (board/add-node (get-animated-board ab)
                        id icon x y)
          nd (get (.node-map brd) id)]
      (-&gt; ab
          (assoce id :node nd) ;add the node as a component
          (assoce :animated-board :nodes brd) ;update the new board (not &quot;really&quot; necessary))))
  (drop-node [b id]
    (let [brd (board/drop-node (get-animated-board b) id)
          nd (get (.node-map brd) id)]
      (-&gt; b
          (dissoce id :node nd) ;add the node as a component
          (assoce :animated-board :nodes brd) ;update the new board (not &quot;really&quot; necessary))))
  (get-layer [b] (board/get-layer (get-animated-board b)))
  (move-node [b nd x y] (do (board/move-node (get-animated-board b) nd x y)
                            b))
  picc/IPiccNode
  (as-node   [nd]       (picc/as-node (get-animated-board nd)))
  (add-child [nd child] (do (picc/add-child (get-animated-board nd) child)
                            nd)))
;;__Mutable Observers and Side-Effects__
;;This a little hacky at the moment; we should add support for multiple layers
;;or node targets.  We need to project these positions onto
;;map coordinates.  They're positions in policy space, not
;;physical locations.
(defn initialize-map
  ([ces] (initialize-map ces events/event-bus))
  ([ces bus]
   (let [the-map  (get-animated-map ces)
         us-locs  (vec (keys quilsample.maps/uslocs))
         new-map  (-&gt;&gt;  [:name :position :state :color :icon :speed :home]
                        (only-entities ces) ;;note we're using reduce.        
                        (reduce (fn [acc {:keys [position name icon color home]}]
                                  (let [home (or home
                                                 (rand-nth us-locs))                                                                                        
                                        token   (board/-&gt;token name icon (or color :white))]
                                    (-&gt; acc
                                        (board/add-token name token)
                                        (board/place-node name home))))
                                the-map)                      )
         ;;we setup a system to synchronize the map with changes to the store.
         ;;specifically, we want to listen for entity location changes
         ;;and color changes.  These events are translated into motion
         ;;on the map.  [todo - find a more expressive way to do this.]
         entity-changes
         (entevents/entity-channel :bus bus
           :interests [:location-change :color-change]
           :xform ;filter out location changes that result in zero movement.
           (filter (fn [{:keys [msg-type data] :as msg}]
                     (case msg-type
                       :location-change (let [[_ from to] data]
                                          (not= from to))
                       true))))
         ;;having a consistent name ensures we only ever consume a single thread for this.
         _  (sys/thread-pull :map-system entity-changes v
                             (let [{:keys [msg-type data] :as msg} v]                               
                               (case (get msg :msg-type)
                                 :location-change
                                 (let [[e from to] data]
                                   (try (board/send-to the-map e to  :arc? true :duration 20)
                                        (catch Exception e nil)))
                                 :color-change
                                 (let [[e x] data]
                                   (board/color-token the-map e x))                                     
                                 (throw (Exception. (str [:unhandled-msg-type msg 'map-handle]))))))
         ]
     (assoce ces :animated-map :nodes  new-map))))
(defn initialize-nodes
  [ces]
  (-&gt;&gt;  [:name :position :state :color :icon]
        (only-entities ces) ;;note we're using reduce.        
        (reduce (fn [acc {:keys [position name icon]}]
                  (let [[x y] position]
                    (board/add-node acc name icon x y)))  ces))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment 
;;note: this is somewhat coupled. and it's less than optimal for
;;performance atm.  Ideally, we'd use some variant of the
;;nodecache directly within piccolo, and decouple the
;;rendering from the notification of the trail change.
(defn set-entity-trail
  [brd e x y clr prev-clr]
  (let [brd (if (= prev-clr clr) brd ;no change in color
                ;(-&gt;
                 (set-entity-color brd e clr)
                    ;(notify! :color-change [e prev-clr clr]))
        ;)
    ]
    (when (and (pos? y)
               clr @shared/*trail*
               (&lt; (rand) 0.3))
      (let [trail-layer  (get-trails brd)]
        (canvas/push-shape  trail-layer (sketch/fade 0.1
                                              (-&gt;colored-ring clr x y)                                              ))))    
    brd)))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.data.protocols" name="marathon.data.protocols"><h1 class="project-name">marathon.data.protocols</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>This is a conglomeration of Marathon protocols, derived from what used to 
be VBA interface classes.  I'll probably be trimming these down significantly, 
since much of the functionality can be replaced with simpler functions on the 
core data structures....especially if the core data structures are just 
maps or records (which support a map API).</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.data.protocols
  (:require [spork.cljgraph [core :as graph]]
            [spork.util.metaprogramming :refer [keyvals-&gt;constants]]))</pre></div><div class="docs"><p>This is the policy interface.  We have both constant and composite 
(or time/event variant) policies. This interface is used to implement a common 
design pattern, the composite pattern. Basically, the old TimeStep_Policy 
elements are considered to be atomic implementations of this interface.</p>
</div><div class="codes"></div><div class="docs"><p>They provide the building blocks of more complex, or composite, policies. <br />
On their own, they never actually change, and are oblivious to time or events.</p>
</div><div class="codes"></div><div class="docs"><p>Conversely, composite policies implement the interface differently, and provide
some extra methods to deal with the possibility of time-driven, or event-driven 
policy changes. We care about this because there will be event-driven policy 
changes via a surge.</p>
</div><div class="codes"></div><div class="docs"><p>Composite policies allow us to easily implement a "policy schedule" without 
having it look any different from a normal policy.  In effect, units subscribe 
to a unique policy, and the policy implementation takes care of the rest.
   When an "internal" policy change or variation takes place, the composite 
   policy will be responsible for updating the unit.  It performs this update 
   via telling the unit to change policies from the active policy to the next 
   scheduled policy.  This is all done via atomic policy operations. It then 
   resets the unit's policy pointer to itself.</p>
</div><div class="codes"></div><div class="docs"><p>TOM Change 20 May 2011 -> Policy nodes are NOW POSITIONS, no longer Locations.
   'Change in nomenclature.
   'Has significant consquences, in that it separates spatial location from policy position.</p>
</div><div class="codes"></div><div class="docs"><p>TOM change 3 Jan 2011
Class for encapsulating implementations of policies ....
This is a datastructure designed to allow us to flexibly define Multiple policies.
Policy is = a state transition graph, the sequence of Positions a unit will cycle through
and parameters that guide said policy.
It is my contention that we can describe a vast number of policy types, including those currently
employed, by a parameterized function.
The crucial parameters are ....
   'Name
   'CycleLength 'duration of a standard cycle, absent interference
   'Minimum Dwell
   'Maximum Dwell
   'Maximum BOG
   'Lower Deployment Window
   'Upper Deployment Window
   'Overlap
Constants used for policy definition, among other things.  Imported from the 
original VBA implementation for the policystore. 
Might re-think this, for now it's a way of porting the existing implementation</p>
</div><div class="codes"><pre class="brush: clojure">(def policyconstants 
  {:Bogging &quot;Bogging&quot;
   :Dwelling &quot;Dwelling&quot;
   :BogDeployable &quot;BoggingDeployable&quot;
   :DwellDeployable &quot;DwellingDeployable&quot;
   :Deployable &quot;Deployable&quot;
   :Spawning   &quot;Spawning&quot;
   :Deploying  &quot;Deploying&quot;
   :Overlapping &quot;Overlapping&quot;
   :Waiting     &quot;Waiting&quot;
   :NotDeployable &quot;NotDeployable&quot;
   :ReturnToDeployable &quot;ReturnToDeployable&quot;
   :AC12 &quot;AC12&quot; 
   :AC13 &quot;AC13&quot; 
   :RC14 &quot;RC14&quot; 
   :RC15 &quot;RC15&quot; 
   :AC11 &quot;AC11&quot;
   :RC11 &quot;RC11&quot;
   :RC12 &quot;RC12&quot;
   :GhostPermanent12 &quot;GhostPermanent12&quot;
   :GhostPermanent13 &quot;GhostPermanent13&quot;
   :GhostTransient12 &quot;GhostTransient12&quot;
   :GhostTransient13 &quot;GhostTransient13&quot;   
   :reset &quot;Reset&quot;
   :train &quot;Train&quot;
   :ready &quot;Ready&quot;
   :available &quot;Available&quot;
   :deployed &quot;Deployed&quot;
   :demobilization &quot;DeMobilization&quot;
   :SubSymbol  &quot;{&gt;&quot;
   :EquivSymbol &quot;=&quot;
   ;;SRM constants...
   :PB_C3  &quot;PB_C3&quot;
   :PB_C4  &quot;PB_C4&quot;
   :PT_C4  &quot;PT_C4&quot;
   :PL_C4  &quot;PL_C4&quot;
   :R_C1   &quot;R_C1&quot;
   :R_C2   &quot;R_C2&quot;
   :MP_DA_C1   &quot;MP_DA_C1&quot;
   :MP_NDA_C3  &quot;MP_NDA_C3&quot;
   :MA_DA_C1   &quot;MA_DA_C1&quot;
   :MA_DA_C2   &quot;MA_DA_C2&quot;
   :MA_NDA_C3  &quot;MA_NDA_C3&quot;
   :MD_DA_C1   &quot;MD_DA_C1&quot;
   :MD_DA_C2   &quot;MD_DA_C2&quot;
   :MD_NDA_C3  &quot;MD_NDA_C3&quot;
   })</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(keyvals-&gt;constants policyconstants) ;make the constants first class symbols.</pre></div><div class="docs"><p>make the constants first class symbols.
inherited from substitution rules, may be vestigial.</p>
</div><div class="codes"><pre class="brush: clojure">(keyvals-&gt;constants {:Equivalence :Equivalence :Substitution :Substitution})</pre></div><div class="docs"><p>look into replacing this with a universal constant, or upperbound
for longs</p>
</div><div class="codes"><pre class="brush: clojure">(def ^:constant +inf+ 9999999)</pre></div><div class="docs"><p>RECONCILE BETWEEN THIS ONE AND ABOVE
need a protocol for policies...</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol IRotationPolicy 
  (atomic-name       [p])
  (bog-budget        [p])
  (get-active-policy [p])
  (get-policy        [p period])
  (policy-name       [p])
  (next-position     [p position])
  (overlap           [p])
  (get-position-graph   [p]) ;if we have this, we can build the rest... 
  (previous-position    [p position])
  (start-deployable     [p])
  (stop-deployable      [p])
  (start-state          [p])
  (transfer-time    [p start-position end-position])
  (cycle-length     [p])
  (end-state        [p])
  (get-cycle-time   [p position])
  (get-policy-type  [p])
  (get-position     [p cycletime])
  (get-state        [p position])
  (max-bog          [p])
  (max-dwell        [p])
  (max-mob          [p])
  (min-dwell        [p])
  (get-locations    [p]))</pre></div><div class="docs"><p>Functions for working with policies that can be changed after creation.</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol IAlterablePolicy
  (set-deployable       [p tstart tfinal] )
  (set-deployable-start [p cycletime]     )
  (set-deployable-stop  [p cycletime]     )
  (add-position         [p name state]    )
  (add-route            [p start destination transfer-time] )
  (set-position-graph   [p g])
  (merge-policy-stats   [p m]))</pre></div><div class="docs"><p>Functions for working with composite policies.</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol IPolicyContainer
  (add-policy       [p policy] 
                    [p period policy]))</pre></div><div class="docs"><p>This is a compatibility hack at the moment, I'll probably rip this
out.</p>
</div><div class="codes"><pre class="brush: clojure">(defprotocol IPeriodicPolicy
  (change-period [p period]))</pre></div><div class="docs"><p>changed to extends? for performance.</p>
</div><div class="codes"><pre class="brush: clojure">(defn on-period-change [p period]
  (if (extends?  IPeriodicPolicy (class p))
    (change-period p period)
    p))</pre></div><div class="docs"><p>Helper function to allow us to push maps into policies as positions.
Basically sets the state associated with a policy position.</p>
</div><div class="codes"><pre class="brush: clojure">(defn add-positions [p xs]
  (if (map? xs)
    (reduce-kv (fn [acc pos state]
                 (add-position acc pos (cond (set? state) state
                                             (coll? state) (set state)
                                             :else #{state}))) 
                 p xs)
      (reduce (fn [acc pos] (add-position acc pos {})))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn add-routes [p rs]
  (reduce (fn [acc [from to t]]
            (add-route acc from to t))
          p rs))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(definline between? [t l r]
  `(and (&gt;= ~t ~l) (&lt;= ~t ~r)))</pre></div><div class="docs"><p>Determining if we want to have this guy defined....
(defn state-at [p position]
  (if-let [res (get-state p position)]
    res
    (throw (Exception. (str [:position position :unknown-in-policy (:name p)])))))</p>
</div><div class="codes"><pre class="brush: clojure">(defn state-at [p position]
  (or (get-state p position) position))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def modifiers #{:deployable :not-deployable})
(defn modifier? [pos] (contains? modifiers pos))</pre></div><div class="docs"><p>Might want to cache this stuff....
Include a facility for defining deployable states..</p>
</div><div class="codes"><pre class="brush: clojure">(defn deployable-state? [s] 
  (when s (:deployable s)))</pre></div><div class="docs"><p>used to be isDeployable</p>
</div><div class="codes"><pre class="brush: clojure">(defn deployable-by?      [p cycletime]
  (between? cycletime (start-deployable p) (stop-deployable p)))</pre></div><div class="docs"><p>used to be deployable
A position is deployable in a policy if the node data associated 
with the position is deployable.  We just store deployability in 
each node.</p>
</div><div class="codes"><pre class="brush: clojure">(defn  deployable-at?       [p position]  
  (deployable-state? (state-at p position)))</pre></div><div class="docs"><p>used to be isDwell
this is inconsistent.  Need to alter...</p>
</div><div class="codes"><pre class="brush: clojure">(defn dwell-at? [p position]
  (let [s (state-at p position)]
    (or (= s Dwelling)
        (= s :dwelling)
        (:dwelling s))))</pre></div><div class="docs"><h1>Optimize</h1>

<p>this may be bogging us down....</p>
</div><div class="codes"><pre class="brush: clojure">(defmacro find-position [&amp; body]
  `(get-position ~@body))</pre></div><div class="docs"><p>memoization was not helping us here, at least not
this version.
(def find-position (memoize get-position))</p>
</div><div class="codes"></div><div class="docs"><p>Returns the deployable window for the policy [start stop]</p>
</div><div class="codes"><pre class="brush: clojure">(defn deployable-window [policy]
  [(start-deployable policy)  (stop-deployable policy)])</pre></div><div class="docs"><p>Note ---->
Deployability is no longer just a function of Position....it's also a function of
cycle time....this is based on an outdated assumption that a units availability would be associated with
its Position.  We could validate this assumption by creating more Positions....this is simple enough, although
it creates additional complexity.  On the other hand, when a unit changes Positions, we can check to see if
it will become available during the course of waiting at the next Position.  If so, we have the unit
behavior request an update for the unit at the specified avaiable time.
TOM Change 21 Mar 2011 -> I am going to adopt the convention that any Position with the substring "_Deployable"
is a valid deployment point.  We can use this to perform constant-time lookup to determine if a policy
allows a unit to deploy from a Position.
Consequently, deployability is driven ENTIRELY by the parameters for min deployable and max deployable.
When we assert, via the policy manager, a minimum deployable time and a maximum deployable time, we will
alter the structure of the Positiongraph to add additional nodes.
   Essentially, we add 2 new nodes -> StartDeployable and StopDeployable
We can add ANY Number of these nodes, by subverting existing nodes in the graph.  This is great, because it
allows us to potentially have highly variable, and dynamic policies.  Rather than a general window of deployable,
we could have multiple pockets of deployability.  Who knows.
To determine if a Position is deployable, we just do a DFS from the policystart to the currentPosition.
We then parse the resulting path (from the last Position), to determine the deployable state.  Simple.</p>
</div><div class="codes"></div><div class="docs"><p>Note -----> from insertModifier
'algorithm for transforming a graph into a graph with modified nodes existing after tstart
'This basically communicates meta-information about some temporally-dependent change in the policy.
'This allows us to schedule things like deployable windows, etc. formally in the structure of the graph.
'Makes it visual as well.  Plus, we can add multiple modifications to the policy.  This is pretty useful.
'Right now, it's primarily used to communicate the existence of the deployable window, but the cases can
'be drastically expanded.  The operative convention is that Anything delimited by a _ following the
'initial Position name is a modification.
'find the intersection of edges affected by the change.
'GetPosition at cycletime.
'This is the affected Position.
'create a new node subverting this Position...
   'utilize native graph function subert the node with a "Deployable".
   'new node automatically links to all subsequent nodes (should be 1 edge).
   'since we're conserving the cost, we update the edge costs for the two nodes...</p>
</div><div class="codes"></div><div class="docs"><p>more general, stick this into cljgraph...</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-node [g label f]
  (let [nd  (graph/get-node g label)
        res (f nd)
        ;_ (println [:updating label :from nd :to res])
        ]
    (graph/set-node g label res)))</pre></div><div class="docs"><p>also should be in cljgraph...should define path reducers too...</p>
</div><div class="codes"><pre class="brush: clojure">(defn update-nodes [g nodes f] 
  (reduce (fn [acc nd] (update-node acc nd f)) g nodes))</pre></div><div class="docs"><p>Adds or removes tg from s, depending on s's presence </p>
</div><div class="codes"><pre class="brush: clojure">(defn toggle-tag [s tg] 
  (if (set? s)      
    (if (contains? s tg) (disj s tg) (conj s tg))
    #{tg}))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn insert-modifier 
  ([policy cycletime {:keys [name weight] :or {name :modified weight 0}}]
     (let [x     (find-position policy    cycletime)
           nxt   (next-position policy    x)      
           pg    (get-position-graph policy)
           tprev (-&gt; (graph/depth-first-search pg (start-state policy) x {:weightf graph/arc-weight})
                     (get :distance)
                     (get x))
           offset  (- cycletime tprev)
           dnxt    (- (graph/arc-weight pg x nxt) offset)
           xdata   (graph/get-node pg x)
           nxtdata (graph/get-node pg nxt)
           newnode [x name]
           newstate (if (set? xdata)
                      (conj xdata name)
                      #{name xdata})
          ; _ (println [newnode newstate])
           ]                          
       (set-position-graph policy
            (-&gt; pg 
                (graph/disj-arc x nxt)
                (graph/conj-node name #{name})
                (graph/conj-node newnode  newstate)
                (graph/add-arcs [[x name offset]
                                 [name newnode weight]
                                 [newnode nxt dnxt]])))))
  ([policy cycletime] (insert-modifier policy cycletime {})))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn drop-ends [xs] (drop 1 (butlast xs)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn compute-cycle-length [p]
  (let [pg (get-position-graph p)]
    (reduce + 
            (let [[hd &amp; tl] (first (spork.cljgraph.core/cyclical-components pg))
                  full (into [(last tl) hd] tl)] 
              (map (fn [[from to]]  
                     (graph/arc-weight pg from to)) (partition 2 1 full))))))</pre></div><div class="docs"><p>Adds modifiers to each node in the position graph of a policy between :deployable and :non-deployable nodes, 
   indicating the position is an eligible deployable state.</p>
</div><div class="codes"><pre class="brush: clojure">(defn mark-deployable-region 
  [policy] 
  (let [pg (get-position-graph policy)]
    (if-let [path (graph/first-path (graph/depth-first-search pg :deployable :non-deployable))]    
      (-&gt;&gt; (update-nodes pg (drop 1 (butlast path)) (fn [nd]  
                                                       (conj (if (coll? nd) (set nd) #{nd}) :deployable)))
           (set-position-graph policy))
      (throw (Exception. (str &quot;No deployable range found between in &quot; policy))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defprotocol IUnitBehavior
  (behavior-name [b] &quot;Return the name of the behavior...duh.&quot;)
  (init-behavior [b state] &quot;Used for stateful initializaion, may tank this one.&quot;)
  (update [b deltat unit] &quot;Update unit with behavior b, given a time delta.&quot;)
  (change-state [b unit to-state deltat duration following-state] 
      &quot;Return the result of changing the unit's finite state machine to a 
       new state using behavior b.&quot;))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn policy? [obj]
  (extends? IRotationPolicy (class obj)))</pre></div><div class="docs"><h1>TODO# add inspection services to visualize the entity state.</h1>

<p>I'd like to add in some useful visuals to inspect the repl state in
a friendly manner.</p>
</div><div class="codes"><pre class="brush: clojure">(comment     
;;TODO Move this to spork.data.protocols at some point
(defprotocol IVisual
  (visualize [obj] &quot;renders obj in some visual format&quot;))
(extend-protocol IVisual 
   spork.util.table.column-table
   (visualize [obj] (spork.util.table/visualize obj))))</pre></div><div class="docs"><p>Legacy...</p>
</div><div class="codes"></div><div class="docs"><p>Nodes are input as a sequence of key value pairs. For our purposes, this will 
   be PositionName, State(bog/dwell/bogeployable/dwelldeployable/etc.)</p>

<p>This is a pretty huge protocol to use....we can probably dispense with 
most of it if we promise to use maps....
Assume properties are just map calls....</p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(defprotocol IRotationPolicy 
  (policy-name [p] &quot;Name of policy p.&quot;)
  (policy-cyclelength [p] &quot;Prescribed cycle length of policy p.&quot;)
  (policy-mindwell [p] 
     &quot;Minimum required Time spent dwelling prior to deploying.&quot;)
  (policy-maxdwell [p] 
     &quot;Maximum allowed Time spent dwelling, will return to CycleStart&quot;)
  (policy-maxbog [p] 
     &quot;Maximum contiguous amount of time a unit can spend in a bog state.&quot;) 
  (policy-MaxMOB [p] 
     &quot;Maximum contiguous amount of time a unit can spend in a mobilized state.&quot;)
  (policy-startdeployable [p] &quot;Earliest time an entity can deploy in the policy&quot;) 
  (policy-stopdeployable [p] &quot;Latest time an entity can deploy in the policy&quot;)
  (policy-PositionGraph [p] 
    &quot;DIRECTED graph, where edges are Position transitions, weights are 
     transition time, Node Data describes unit's state (bogging/dwelling, etc.)&quot;)
  (policy-startstate [p] &quot;Entry position for the start of a policy cycle&quot; ) 
  (policy-endstate [p] &quot;Penultimate node on a policy cycle.&quot; ) 
  (policy-overlap [p] 
    &quot;The amount of time a unit will spend in overlap when deployed.&quot;)
  (policy-subscribers [p] &quot;Set of entities that subscribe to this policy.  
                           Deprecated.&quot;)
  (get-active-policy [p] &quot;Returns the activepolicy of the current policy.  
                          Important for composite policies. 
                          Atomic policies don't get anything.&quot;)
  (atomic-name [p] 
   &quot;return the name of the active atomic policy if it's a composite policy.&quot;)
  (get-policy [p period] &quot;Provide a mapping of period to policy.&quot;)
  (on-period-change [p period] 
    &quot;handle transitioning of periods...probably move this.&quot;)
  (get-policy-type [p] &quot;Return an type indicator for the policy.&quot;)
  (subscribe-policy [p x] &quot;units subscribe to policies, so when we change, 
                           we can notify only the affected units.&quot;) 
  (add-position [p position state] &quot;Assoc a policy position/state&quot;)
  (add-route [p start dest weight] 
   &quot;Routes are edges in the graph. They represent some sequence that a unit 
    following this policy must pass through.  Description is used to add more 
    information about the nature of the transfer (is it definite or 
    conditional?) Generally, we should have one definite state transfer, and any 
    number of conditional/other transfers (arcs) leading from a node. Transfers 
    can even be probablistic, carrying information on the chance of an edge 
    being chosen.&quot;)
  (get-state [p position] 
     &quot;Get the state of the current Position (generally bogging,dwelling, etc., 
      but potentially anything). State information is stored at the Position's 
      node&quot;)
  (next-position [p position] 
   &quot;Get the next Position as a result of current Position and policy structure.
    If the Position has no arcs leading out (it's an island), then it is 
    considered an absorbing state and will return itself as the next Position.
    Rule of Thumb I instantiated is that if a Position does not exist in the
    Position nodes, then it must be coming from Deployed (demands are not 
    explicitly registered).&quot;)
  (previous-position [p position] 
     &quot;Get the previous position in the policy sequence.&quot;)
  (transfer-time [p start dest] 
     &quot;Returns the weight (assumably time) between two policy positions.&quot;)
  (get-position [p cycletime] 
      &quot;Given a cycletime, what is the resulting Position? Doing a simple linear 
       search, this is OK for small N. Our cycles shouldn't be that big ... will 
       have much less than 20, usually 6 Positions tops.&quot;)
  (get-cycletime [p position] 
     &quot;Given a position, returns the cycletime that intersects with the beginning 
      of the position.&quot;)
  (deployable? [p cycletime] 
      &quot;Returns true if the cycletime corresponds to a deployable state in the
       policy.&quot;)
  (dwell?  [p position] 
       &quot;Returns true if the policy position corresponds to a dwell state.&quot;)
  (deployable? [p position] 
     &quot;Returns true if a unit can deploy from the policy position.&quot;)
  (insert-modifier [p cycletime modifier] 
     &quot;Inserts a modifier node at the cycletime, which effectively creates a 
      modified pocket of policy space.  Modifiers were typically used to splice
      in deployable and non-deployable windows....may move this to a general 
      library.&quot;) 
  (set-deployable-start [p cycletime] 
     &quot;Insert a node that defines the start point in the lifecycle for 
      deployment.  By default, if there is no Deployable node in the policy, 
      then this policy will not deploy units.&quot;)
  (set-deployable-stop [p cycletime] 
   &quot;insert a node that defines the stop point in the lifecycle for deployment.&quot;)
  (set-deployable [p tstart tfinal]
    &quot;sets the deployable window.  I think this may be redundant. &quot;)
  (get-bogbudget [p] 
     &quot;The BOG Budget set by the policy.  In most policies, this will default to 
      MAXBog if the policy has 0 for a BOGBudget.  This allows us to separate 
      the concept of total time allowed to bog in an entire cycle, along with
      most time PER deployment&quot;))                 
(defn add-positions
  [p xs]
  (reduce (fn [acc [k v]] (add-position acc k v)) p (seq xs))) )</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.fill.filldata" name="marathon.fill.filldata"><h1 class="project-name">marathon.fill.filldata</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.fill.filldata
  (:use [spork.util.record]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defrecord+ fill [rule fillPath pathlength followon source])
(defn quality [f] (if (zero? (:pathlength f)) &quot;Primary&quot; &quot;Substitute&quot;))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.demand.demanddata" name="marathon.demand.demanddata"><h1 class="project-name">marathon.demand.demanddata</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>A container and associated functions necessary for managing demand entities.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.demand.demanddata
  (:use [spork.util.record]))</pre></div><div class="docs"><p>demanddata is the basic information required to represent demand entities.</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord+ demanddata 
  [name ;unique name associated with the demand entity.
   src ;demand-type, or other identifier of the capability demanded.
   priority ;numerical value representing the relative fill priority.
   startday ;the day upon which the demand is activated and requiring fill.
   duration ;the total time the demand is activated.
   overlap  ;the demand-specific overlap requirement, if any
   [category :rotational] ;descriptor for deployed unit behavior over-rides.
   [source-first :uniform]  ;descriptor for supply preference. 
   [quantity 0] ;the total amount of entities required to fill the demand.
   title    ;formerly OITitle.  Long-form description of the src capability.
   vignette  ;Descriptor of the force list that generated this demand entity.
   operation ;Fine-grained, unique description of the demand.
   demandgroup ;Ket that associates a demand with other linked demands.  
   [fills {}] ;an ordered collection of all the fills recieved over time.                   
   [units-assigned {}] ;map of the units currently associated with the demand.
   [units-overlapping {}]]);map of the units currently associated with this demand, </pre></div><div class="docs"><p>map of the units currently associated with this demand, 
that are not actively contributing toward filling the 
demand, due to a relief-in-place state.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-demand (make-demanddata))</pre></div><div class="docs"><p>'How many units do we still need here?
Public Function required() As Long
required = quantity - units-assigned.count
End Function</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn required [d] (- (:quantity d)
                      (-&gt; d :units-assigned count)))</pre></div><div class="docs"><p>'TOM Change 14 Mar 2011
'propose storing the quality of the fill using the fill path.  That way, we can dissect the fill path
'to determine anything else we want....use the fillgraph to get pathlength, if length meets a certain
'threshold, then it's a sub, etc.
Public Sub Assign(unit As TimeStep_UnitData, Optional quality As String)</p>
</div><div class="codes"></div><div class="docs"><p>If units-assigned.exists(unit.name) = False Then
   units-assigned.add unit.name, unit
Else
   Err.Raise 101, , "unit already assigned"
End If
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn assign [d u] (merge d {:units-assigned 
                             (assoc (:units-assigned d) (:name u) u)}))
(defn assign-many [d us] (reduce assign d us)) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn assigned? [d u]
  (contains? (:units-assigned d) (:name u)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn overlapping? [d u]
  (contains? (:units-overlapping d) (:name u)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn has-unit? [d u]
  (or (assigned? d u) (overlapping? d u)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn list-units [d] 
  (keys (:units-assigned d)))</pre></div><div class="docs"><p>'TOM Change 14 Mar 2011
Public Sub SendHome(unit As TimeStep_UnitData)</p>
</div><div class="codes"></div><div class="docs"><p>If units-assigned.exists(unit.name) = False And units-overlapping.exists(unit.name) = False Then
   Err.Raise 101, , "unit not assigned"
Else
   If units-assigned.exists(unit.name) Then units-assigned.remove unit.name
   If units-overlapping.exists(unit.name) Then units-overlapping.remove unit.name
End If</p>
</div><div class="codes"></div><div class="docs"><p>End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn send-home [d u]
  (if (has-unit? d u)
    (let [flds [:units-assigned :units-overlapping]
          ms (map #(hash-map % (dissoc (get d %) (:name u))) flds)]
       (apply merge d ms))
    d))</pre></div><div class="docs"><p>Public Sub SendOverlap(unit As TimeStep_UnitData)</p>

<p>If units-overlapping.exists(unit.name) = True Then
   Err.Raise 101, , "unit already overlapping"
Else
   units-assigned.remove unit.name
   units-overlapping.add unit.name, unit.name
End If</p>

<p>End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn send-overlap [d u]
  (if (has-unit? d u)    
    (let [assigned    (:units-assigned d)
          overlapping (:units-overlapping d)
          nm (:name u)]
      (-&gt; d
          (assoc :units-assigned   (dissoc assigned nm))
          (assoc :units-overlapping (assoc overlapping nm nm))))
    (throw (Exception. (str [&quot;Cannot find unit&quot; (:name u) d])))                            ))</pre></div><div class="docs"><p>Public Function unitCount() As Long
unitCount = units-overlapping.count + units-assigned.count
End Function</p>
</div><div class="codes"><pre class="brush: clojure">(defn unit-count [d] (reduce + ((juxt :units-assigned :units-overlapping) d)))</pre></div><div class="docs"><p>Public Sub fillWith(fill As TimeStep_Fill)
Assign fill.source, fill.quality
Fills.add fill.source.name, fill
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn fill-with [d fill]
  (assoc d :fills 
     (conj (:fills d) 
           (name (:fill-source fill)))))  </pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.supply.unitdata" name="marathon.supply.unitdata"><h1 class="project-name">marathon.supply.unitdata</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.supply.unitdata
  (:require [marathon.ces [core :as core]]
            [marathon.data [cycle :as cyc]
             ;[protocols :as p]
             ]
            [marathon.policy [policydata :as pol]])
  (:use [spork.util.record :only [defrecord+ inc-field dec-field get-vals]]))</pre></div><div class="docs"><h1>INCONSISTENCY</h1>

<p>unitdata is missing a deployment-index, which is expected for deployment records.</p>
</div><div class="codes"></div><div class="docs"><p>TODO# should we extend IRotationaPolicy to these guys? Convenience function...
record for unitdata state.</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord+ unitdata 
  [name ;unit entity's unique name. corresponds to a UIC 
   src ;unit entity's type, or capability it can supply.
   component ;unit entity's membership in supply.
   policy ;the policy the entity is currently following.
   policystack ;a stack of any pending policy changes.
   behavior ;the behavior the unit uses to interpret policy and messages.
   statedata ;generic state data for the unit's finite state machine.
   cycletime ;the unit's current coordinate in lifecycle space.
   followoncode ;description of the categories this unit serve as a followon to.
   locationname ;the current physical location of the unit.
   positionpolicy ;the current position of the unit in its policy space.
   currentcycle ;the current cycle data structure for the unit.
   cycles ;an ordered collection of the cycles that the unit has completed.
   spawntime ;the time in which the unit spawned.
   oi-title ;the description of the unit.
   locationhistory ;list of all the locations visited.
   dwell-time-when-deployed ;dwell time 
   ]
  ;marathon.data.protocols.IRotationPolicy)</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-unit
  (-&gt; (make-unitdata)
      (merge {:spawntime -1 :cycletime 0 })))    </pre></div><div class="docs"><p>pass a message to a unit, telling it to update itself.
units pass themselves as state, along with some msg, to their referenced 
behavior functions.</p>
</div><div class="codes"><pre class="brush: clojure">(defn unit-update [u msg]
  ((:behavior u) u msg))</pre></div><div class="docs"><p>Pending.  When we move to the component entity system, we'll pull this back
in.
allow units to be entities 
(extend unitdata IEntity (assoc default-entity :process-msg unit-update))</p>
</div><div class="codes"></div><div class="docs"><p>Public Sub InitCycles(t As Single)</p>
</div><div class="codes"></div><div class="docs"><p>Set CurrentCycle = CurrentCycle.NewCycle(0, policy.MaxBOG, policy.MaxDwell, policy.cyclelength, policy.MaxMOB)
With CurrentCycle
   .UICname = name
   .policyname = policy.name
   .tstart = t
   .src = src
   .Component = Component
End With</p>
</div><div class="codes"></div><div class="docs"><p>End Sub</p>
</div><div class="codes"></div><div class="docs"><p><strong>TODO</strong> Rename this to something cleaner.</p>
</div><div class="codes"><pre class="brush: clojure">(defn newcycle [t policy]
  (let [{:keys [MaxBOG MaxDwell cyclelength MaxMOB]} policy]    
    (cyc/make-cyclerecord t MaxBOG MaxDwell cyclelength MaxMOB)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn initCycles [u t]
  (let [policy (:policy u)
        c (merge (newcycle 0 policy) 
                 {:UICname (:name u)
                  :policyname (:name policy)
                  :tstart t
                  :src (:src u)
                  :component (:component u)})]
    (merge u {:currentcycle c})))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment 
;'Account for a name change in the current cycle
;'TOM Change 2 Sep 2011 -&gt; also update the cyclerecord state to account for changed expected bog/dwell/mob
;Public Sub ChangeCycle(t As Single)

;With CurrentCycle
;    .policyname = .policyname &amp; &quot;-&gt;&quot; &amp; policy.name
;    .Traversals.add t &amp; &quot;_Policy Change to &quot; &amp; policy.name
;End With
    
;End Sub )
)</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ChangeCycle [u t]
  (let [c (:currentycle u)
        p (:policy u)
        newname (str (:policyname c) &quot;-&gt;&quot; (:name p))
        traversal (conj (:traversals u) (str t &quot;_Policy Change to &quot; newname))]
    (merge u {:traversals traversal :currentcycle c})))</pre></div><div class="docs"><p>Public Sub addduration(dt As Single)
CurrentCycle.duration = CurrentCycle.duration + dt
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn add-duration [u t] 
  (merge u {:currentcycle (-&gt; (:currentcycle u) 
                            (inc-field :duration t))}))                                             </pre></div><div class="docs"><p>Public Sub AddBOG(bogtime As Single)
CurrentCycle.bog = CurrentCycle.bog + bogtime
CurrentCycle.bogbudget = CurrentCycle.bogbudget - bogtime
addduration bogtime
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn AddBOG [u t]  
  (let [cyclerecord (-&gt; (:currentcycle u) 
                (inc-field :bog t)  ;;patched
                (dec-field :bogbudget t))]   
    (add-duration (merge u {:currentcycle cyclerecord}) t)))</pre></div><div class="docs"><p>Public Sub AddDwell(dwelltime As Single, Optional available As Boolean)
If available Then CurrentCycle.availableTime = CurrentCycle.availableTime + dwelltime
CurrentCycle.dwell = CurrentCycle.dwell + dwelltime
addduration dwelltime
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn- addavailable [cyclerec t] 
  (inc-field :availableTime cyclerec t))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn AddDwell [u t &amp; [available]]
  (let [cyclerecord (-&gt; (:currentcycle u) 
                        (inc-field :dwell t))]                                                                    
    (add-duration 
      (merge u {:currentcycle 
                (if available (addavailable cyclerecord) cyclerecord)}))) t)</pre></div><div class="docs"><p>Public Sub addMOB(MOBtime As Single)
CurrentCycle.mob = CurrentCycle.mob + MOBtime
addduration MOBtime
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn addMOB [u t]
  (add-duration 
    (merge u {:currentcycle (inc-field :mob (:currentcycle u) t)})) t)</pre></div><div class="docs"><p>'Note, this will retain a good deal of data...we're keeping track of the unit's arforgen histories..
Public Sub RecordCycle(day As Single)
Cycles.add CurrentCycle
Set CurrentCycle = CurrentCycle.NewCycle(day, policy.MaxBOG, policy.MaxDwell, policy.cyclelength, policy.MaxMOB)
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn recordcycle [u t]
  (merge u {:cycles (conj (:cycles u) (:currentcycle u)) 
            :currentcycle (apply newcycle t 
                           (get-vals (:policy u) [:MaxBOG :MaxDwell 
                                                  :cyclelength :MaxMOB]))}))</pre></div><div class="docs"><p>'TOM change 2 Sep 2011
'mutate the current cycle object to reflect changes in expectations
Public Function modify(bogtime As Long, dwelltime As Long, policyduration As Long, Optional MOBtime As Single) As TimeStep_CycleRecord
Set modify = Me</p>
</div><div class="codes"></div><div class="docs"><p>With modify
   .BOGExpected = bogtime
   .BDRExpected = 1 / ((bogtime + MOBtime) / (policyduration - (bogtime + MOBtime)))
   .DurationExpected = policyduration
   .DwellExpected = dwelltime
   If .DwellExpected > 1095 And MOBtime = 0 Then Err.Raise 101, , "wierd "
   .MOBexpected = MOBtime
End With</p>
</div><div class="codes"></div><div class="docs"><p>End Function</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn-  modify-cyclerecord
  ([cyclerec bogtime dwelltime policyduration MOBtime] 
    (let [bogmob (+ bogtime MOBtime)]
      (merge cyclerec 
             {:bogexpected bogtime 
              :BDRExpected (/ 1 (/ bogmob (- policyduration bogmob)))
              :DurationExpected policyduration
              :DwellExpected dwelltime
              :MOBExpected MOBtime}))))</pre></div><div class="docs"><p>'TOM Change 2 Sep 2011
Public Sub ModifyCycle(plcy As IRotationPolicy)</p>
</div><div class="codes"></div><div class="docs"><p>With CurrentCycle
   'update the record to account for this....when we record the cycle as completed, we want to use expected
   'values from the new policy.
   .modify plcy.MaxBOG, plcy.MaxDwell, plcy.cyclelength, plcy.MaxMOB
End With</p>
</div><div class="codes"></div><div class="docs"><p>End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn modifycycle [u newpolicy]
  (let [vs (get-vals newpolicy [:maxBOG  :maxDwell :cyclelength :maxMOB])
        newrecord (apply modify-cyclerecord (:currentcycle u) vs)]
    (merge u {:currentcycle newrecord})))</pre></div><div class="docs"><p>Public Sub ChangeState(newstate As String, deltat As Single, Optional duration As Single)
Call behavior.ChangeState(Me, newstate, deltat, duration)
End Sub</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn changestate [u newstate dt duration]
  ((:behavior u) u newstate dt duration)) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn update [u dt]
  (unit-update u {:dt dt}))</pre></div><div class="docs"><p>Public Function CanDeploy() As Boolean</p>
</div><div class="codes"></div><div class="docs"><p>With policy
   CanDeploy = (followoncode &lt;> vbNullString) Or (cycletime >= .StartDeployable And cycletime &lt; .StopDeployable)
End With</p>
</div><div class="codes"></div><div class="docs"><p>End Function
Note -> this is obsolete.....need to use the version in sim.unit instead.</p>
</div><div class="codes"><pre class="brush: clojure">(defn can-deploy? [u &amp; [spawning policy]]
  (let [policy (or policy (:policy u))
        ct (:cycletime u)
        [start stop] [(:StartDeployable policy) (:StopDeployable policy)]] 
  (or (not= (:followoncode u) nil) 
      (and (&gt;= ct start) (&lt; ct stop)))))</pre></div><div class="docs"><p>Public Property Get bog() As Single
bog = CurrentCycle.bog
End Property</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-bog [u] (-&gt; u :currentcycle :bog))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn unit-bog-budget [u] (-&gt; u :currentcycle :bogbudget))</pre></div><div class="docs"><p>Public Property Get dwell() As Single
dwell = CurrentCycle.dwell
End Property</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-dwell [u] (-&gt; u :currentcycle :dwell))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn unit-stats [u]
  (let [c (:currentcycle u)]
    {:bog        (:bog   c)
     :dwell      (:dwell c)
     :cycle-time (:cycletime u)
     :duration   (:duration-expected c)}))</pre></div><div class="docs"><p>Public Property Get BDR() As Single
BDR = CurrentCycle.BDR
End Property</p>
</div><div class="codes"></div><div class="docs"><p>NOTE -> need to define cycle-bdr</p>
</div><div class="codes"><pre class="brush: clojure">(defn- cycle-bdr [c] 0.0)
(defn get-BDR [u] (cycle-bdr (:currentcycle u)))</pre></div><div class="docs"><p>Public Sub changePolicy(newpolicy As IRotationPolicy)
If Not (policy Is Nothing) Then policyStack.add newpolicy</p>
</div><div class="codes"></div><div class="docs"><p>If policyStack.count = 0 Then Err.Raise 101, , "no policy on stack!"
'TOM Change 21 July -> account for passage of time between updates!
If newpolicy.name &lt;> policy.name Then
'    If name = "32<em>BCT</em>AC" Then
'        Debug.Print "phenomenon"
'    End If</p>
</div><div class="codes"></div><div class="docs"><p>End If</p>
</div><div class="codes"></div><div class="docs"><p>End Sub</p>
</div><div class="codes"></div><div class="docs"><p><strong>TODO</strong> Move changepolicy to sim.unit
probably need to figure out a way to thread time for these guys, or 
establish parent/child relations.
newpolicy should be an IRotationalPolicy
Time is not threaded, shift this to the unit level simulation.</p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(defn changePolicy [u newpolicy]
  (if (not= (:name newpolicy) (-&gt; u :policy :name))
    (changestate u &quot;PolicyChange&quot; (- (get-time u) (last-update u))))))</pre></div><div class="docs"><p>Public Function getStats() As String
getStats = "Policy:" &amp; policy.AtomicName &amp; " Cycletime: " &amp; cycletime
End Function</p>
</div><div class="codes"></div><div class="docs"><p>'force the unit to broadcast a unitmoved event if it's the first time it moved.
'Note, we need to ensure that units are cleaned up at the end of day....using end of day
'logic, specifically, set moved = false for every unit that moved.</p>
</div><div class="codes"></div><div class="docs"><p>Public Sub ChangeLocation(newlocation As String)
If newlocation &lt;> LocationName Then
   If Not moved Then
       If hasParent Then
           moved = True
           parent.parent.trigger UnitMoved, name, newlocation, name &amp; " started moving from " &amp; _
                       LocationName &amp; " to " &amp; newlocation &amp; " on day " &amp; parent.getTime, , , Me
       End If
   Else
       parent.parent.trigger UnitMoved, name, newlocation, name &amp; " moved from " &amp; _
                       LocationName &amp; " to " &amp; newlocation &amp; " on day " &amp; parent.getTime, , , Me
   End If
   'update the location
   LocationName = newlocation
End If
End Sub</p>
</div><div class="codes"></div><div class="docs"><p><strong>TODO</strong> Move trigger move to sim.unit, this should not be 
encapsulated and requires a simulation context.
note need to define entity-trigger </p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(defn- trigger-move [u newlocation]
  (let [nm (:name u)
        t (get-time u)
        loc (:locationname u)
        msg (str nm &quot; moved from &quot; loc &quot; to &quot; newlocation &quot; on day &quot; t)]
      (entity-trigger u (make-packet :UnitMoved nm newlocation msg u)))))                      </pre></div><div class="docs"><p><strong>TODO</strong> Move changelocation  to sim.unit, this should not be 
encapsulated and requires a simulation context.
note need to define entity-trigger </p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(defn change-location [u newlocation]
  (if (or (= newlocation (:locationname u)) (not (:moved u)))
        (-&gt; (trigger-move u newlocation) 
             (merge {:moved true :locationname newlocation}))
        u))        )</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(core/stub &quot;Change Location&quot;
   (defn change-location [&amp; args]))      </pre></div><div class="docs"><p><strong>TODO</strong> Move changelocation  to sim.unit, this should not be 
encapsulated and requires a simulation context.
note need to define entity-trigger </p>
</div><div class="codes"></div><div class="docs"><p>Note -> not implemented.
Public Sub ChangePolicyPosition(newposition As String)
End Sub</p>
</div><div class="codes"><pre class="brush: clojure">(core/stub &quot;ChangePolicyPosition&quot;
   (defn change-policy-position [&amp; args]))</pre></div><div class="docs"><p>Private Function hasParent() As Boolean
hasParent = Not (parent Is Nothing)
End Function</p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.policy.policydata" name="marathon.policy.policydata"><h1 class="project-name">marathon.policy.policydata</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Rotational policy data definitions.  Both atomic and composite policies are 
represented here.
The general idea is that rotational policies correspond to state
transitions.  Positions in the policy have associated state data.
We can define complex policies by composing primitive policies
together using sequences and policies defined by period (or event
really...).  Policies conform to three basic protocols that 
define policy queries and alterations.  Also, policies have 
state transitions represented as a position graph, a directed 
graph with special properties.  </p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.policy.policydata
  (:use [spork.util.record :only [defrecord+]])
  (:require [spork.cljgraph [core :as graph]]
            [marathon.data  [protocols :as core]]))</pre></div><div class="docs"><p><strong>TODO</strong> Extend core/IRotationPolicy protocol to policy and
policycomposite..</p>
</div><div class="codes"></div><div class="docs"><p>a structure for unit entity policies.</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord+ policy [[name &quot;BlankPolicy&quot;]
                    [cyclelength core/+inf+]
                    [mindwell 0]
                    [maxdwell  core/+inf+]
                    [maxbog    core/+inf+]
                    [maxMOB    core/+inf+]
                    [recovery  90]
                    [startdeployable 0]
                    [stopdeployable core/+inf+]
                    [positiongraph  graph/empty-graph]
                    [startstate    :spawn]
                    [endstate      :spawn]
                    [overlap 45]]
  core/IRotationPolicy 
  (atomic-name         [p] name)
  (bog-budget          [p] maxbog)
  (get-active-policy   [p] p)
  (get-policy          [p period] p)
  (policy-name         [p] name)
  (next-position       [p position] (first (graph/sinks positiongraph position)))
  (overlap             [p] overlap) 
  (get-position-graph  [p] positiongraph)  
  (previous-position    [p position] (first (graph/sources positiongraph position)))
  (start-deployable     [p] startdeployable)
  (stop-deployable      [p] stopdeployable)
  (start-state          [p] startstate)
  (transfer-time    [p start-position end-position] (graph/arc-weight positiongraph start-position end-position))
  (cycle-length     [p] cyclelength)
  (end-state        [p] endstate)
  (get-cycle-time   [p position] (if (= position startstate) 0 
                                     (-&gt; (graph/depth-first-search positiongraph startstate position {:weightf graph/arc-weight})
                                         (get :distance)
                                         (get position))))                                          
  (get-policy-type  [p] :atomic)
  (get-position     [p cycletime] (loop [pos startstate
                                         t   0]
                                    (if-let [nxt (first (graph/sinks positiongraph pos))]
                                      (let [tnxt (+ t   (long (graph/arc-weight positiongraph pos nxt)))]
                                        (if (&gt;= tnxt cycletime) pos
                                            (if (= nxt startstate) ;we looped around without finding it..
                                              (throw (Exception. (str [&quot;Cycletime exceeds policy, looped! &quot; t name])))
                                              (recur nxt tnxt))))
                                      (throw (Exception. &quot;Cycletime exceeds policy!&quot;)))))                                    
  (get-state        [p position]   (graph/get-node positiongraph position))
  (max-bog          [p]            maxbog)
  (max-dwell        [p]            maxdwell)
  (max-mob          [p]            maxMOB)
  (min-dwell        [p]            mindwell)
  (get-locations    [p]           (graph/get-node-labels positiongraph))
  core/IAlterablePolicy
  (set-deployable       [p tstart tfinal] (-&gt; p 
                                              (core/insert-modifier tstart {:name :deployable})
                                              (core/insert-modifier tfinal {:name :non-deployable})
                                              (core/mark-deployable-region)))
  (set-deployable-start [p cycletime]  (core/insert-modifier p cycletime :name :deployable))
  (set-deployable-stop  [p cycletime]  (core/insert-modifier p cycletime :name :non-deployable))
  (set-position-graph   [p g]          (assoc p :positiongraph g)) 
  (add-position         [p name state]
      (let [stateset (or (graph/get-node positiongraph name) #{})]
        (-&gt;&gt; (if (set? state)
               (into stateset state)
               (conj stateset state))
             (graph/conj-node positiongraph name)
             (assoc p :positiongraph))))
  (add-route            [p start destination transfer-time] 
      (assoc p :positiongraph (graph/conj-arc positiongraph start destination transfer-time)))
  (merge-policy-stats   [p stats] (merge p stats)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-policy (make-policy))</pre></div><div class="docs"><p>policies defined by more than one atomic policy.
Debate turning policies away from a map....so we can support more
than one policy composition type based off of data structure used to 
contain the policies.</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord+ policymap [name
                       ^marathon.data.protocols.IRotationPolicy activepolicy 
                       activeperiod
                       [policies {}]]
  core/IRotationPolicy 
  (atomic-name         [p] (.atomic-name activepolicy))
  (bog-budget          [p] (.bog-budget activepolicy))
  (get-active-policy   [p] activepolicy)
  (get-policy          [p period] (get policies period))
  (policy-name         [p] name)
  (next-position       [p position] (.next-position activepolicy position))
  (overlap             [p] (.overlap activepolicy))
  (get-position-graph  [p] (.get-position-graph activepolicy))
  (previous-position   [p position] (.previous-position activepolicy position))
  (start-deployable    [p] (.start-deployable activepolicy))
  (stop-deployable     [p] (.stop-deployable activepolicy))
  (start-state         [p] (.start-state activepolicy))
  (transfer-time       [p start-position end-position] (.transfer-time activepolicy start-position end-position))
  (cycle-length        [p] (.cycle-length activepolicy))
  (end-state           [p] (.end-state activepolicy))
  (get-cycle-time      [p position] (.get-cycle-time activepolicy position))     
  (get-policy-type     [p] :composite)
  (get-position        [p cycletime] (.get-position activepolicy cycletime))                                    
  (get-state           [p position]  (.get-state activepolicy position))
  (max-bog             [p]            (.max-bog activepolicy))
  (max-dwell           [p]            (.max-dwell activepolicy))
  (max-mob             [p]            (.max-mob activepolicy))
  (min-dwell           [p]            (.min-dwell activepolicy))
  (get-locations       [p]            (.get-locations activepolicy))
  core/IPeriodicPolicy
  (change-period [p period]
                 (if-let [new-policy (get policies period)]
                   (merge p {:activeperiod period
                             :activepolicy new-policy})
                   (throw (Exception. (str [:period-undefined-for-policy p period])))))
  core/IPolicyContainer
  (add-policy          [p period policy]   (policymap. name (or activepolicy policy) (or activeperiod period) (assoc policies period policy)))
  (add-policy          [p keyval] (if (coll? keyval) 
                                    (let [[k v] keyval] (.add-policy p k v))
                                    (throw (Exception. &quot;Expected a [period policy] pair for arity 2 add-policy on a policymap&quot;)))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-policymap (make-policymap))</pre></div><div class="docs"><p>Defines a policy that scripts a sequence of policies, starting from
a root policy.  We might want to have a policy offset...depends on
how I'm using this in the code.  I think unit behavior was
interpreting policy, keeping track of its current state in the policy.</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord+ policyseq [name
                       ^marathon.data.protocols.IRotationPolicy rootpolicy   
                       [idx 0]
                       [policies []]]
  core/IRotationPolicy 
  (atomic-name         [p] (.atomic-name rootpolicy))
  (bog-budget          [p] (.bog-budget rootpolicy))
  (get-active-policy   [p] rootpolicy)
  (get-policy          [p period] (get policies period))
  (policy-name         [p] name)
  (next-position       [p position] (.next-position rootpolicy position))
  (overlap             [p] (.overlap rootpolicy))
  (get-position-graph  [p] (.get-position-graph rootpolicy))
  (previous-position   [p position] (.previous-position rootpolicy position))
  (start-deployable    [p] (.start-deployable rootpolicy))
  (stop-deployable     [p] (.stop-deployable rootpolicy))
  (start-state         [p] (.start-state rootpolicy))
  (transfer-time       [p start-position end-position] (.transfer-time rootpolicy start-position end-position))
  (cycle-length        [p] (.cycle-length rootpolicy))
  (end-state           [p] (.end-state rootpolicy))
  (get-cycle-time      [p position] (.get-cycle-time rootpolicy position))     
  (get-policy-type     [p] :sequential)
  (get-position        [p cycletime]  (.get-position rootpolicy cycletime))                                    
  (get-state           [p position]   (.get-state rootpolicy position))
  (max-bog             [p]            (.max-bog rootpolicy))
  (max-dwell           [p]            (.max-dwell rootpolicy))
  (max-mob             [p]            (.max-mob rootpolicy))
  (min-dwell           [p]            (.min-dwell rootpolicy))
  (get-locations       [p]            (.get-locations rootpolicy))
  core/IPolicyContainer
  (add-policy       [p period policy]   (.add-policy p policy))
  (add-policy       [p policy]  (assert (satisfies? core/IRotationPolicy policy) 
                                        &quot;expected a rotation policy for add-policy arity 2 on a policyseq&quot;)
                                (policyseq. name (or rootpolicy policy) idx  (conj policies policy))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-policyseq (make-policyseq))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.data.cycle" name="marathon.data.cycle"><h1 class="project-name">marathon.data.cycle</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>Provides a container for an invidual unit's cycle information.  Specifically, 
the policy followed, the unit in the cycle, the component of the unit, the 
accumulated state during the cycle (bog, mob, dwell, etc.), start and end 
of the cycle, transitions in the cycle, and more...</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.data.cycle
  (:use [spork.util.record :only [defrecord+ with-record]]
        [spork.util.general :as gen]))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defrecord+ cyclerecord 
  [uic-name    ;Associated uic
   src        ;The unit-type, or template that identifies the unit's capability.
   component  ;Identifier for the operating component (active,reserve,etc.)  
   policyname ;Policy the unit entity follows
   tstart     ;The start time of the unit's current cycle.
   tfinal     ;The expected end time of the unit's current cycle.
   [duration 0]   ;The time the entity has spent in cycle.   
   [available-time 0]  ;Time the entity spent in available pool
   [deployableTime 0] ;Time the entity spent in a deployable state.
   duration-expected  ;The expected cycle length.
   [bog 0]         ;The cumulative BOG experienced by the entity. (units of time, days)
   [bogbudget 0]   ;The remaining BOG a unit can expend in the current cycle.
   bog-expected ;The expected BOG days for the unit in the current cycle. 
   [dwell 0]       ;The cumulative Dwell days for the current cycle.
   dwell-expected ;The expected Dwell for the current cycle.
   mob-expected  ;mobilization time expected, if any, for the current cycle.
   [mob 0]          ;Accumulated mobilization days.
   [deployments 0]  ;count of deployments in the current cycle.
   [followons   0]  ;count of follow-on deployments for the current cycle.
   bog-to-dwell-expected  ;expected BOG/Dwell ratio for the current cycle.
   traversals]) ;record of state traversal, for the current cycle.</pre></div><div class="docs"><p>record of state traversal, for the current cycle.</p>
</div><div class="codes"></div><div class="docs"><p>Creates a new cycle, at time t, defined by the bogtime, dwelltime, etc. 
   characteristics, patterned off of cycle c, which provides the name of the 
   uic, the src, and the component.</p>

<p>Note -> this may be a little vestigial, or easily revamped; for instance, 
we can provide uic, src, and component and we're fine...</p>
</div><div class="codes"><pre class="brush: clojure">(defn ^cyclerecord cycle-NewCycle
  [cyclerec t bogtime dwelltime policyduration &amp; [MOBtime  ghost  bogbudget]]
    (with-record cyclerec
      :bog-expected  bogtime
      :bogbudget (if (zero? bogbudget) bogtime bogbudget)
      :bog-to-dwell-expected  (/ 1 (/ (+ MOBtime bogbudget)  
                                      (-  policyduration (+ bogbudget  MOBtime))))
      :duration-expected  policyduration
      :dwell-expected  dwelltime
      :mob-expected  MOBtime
      :tstart t
      :tfinal (+ t policyduration)))</pre></div><div class="docs"><p>Modifies oldcycle, assumably in the context of a policy change.  Returns the 
   result of the modification, as a new cycle.</p>
</div><div class="codes"><pre class="brush: clojure">(defn ^cyclerecord cycle-modify 
  [cyclerec bogtime dwelltime policyduration &amp; [MOBtime bogbudget]]
  (if (and (&gt; dwelltime 1095)  (zero? MOBtime) (not (= :inf dwelltime))
           (throw (Exception. &quot;Expected dwell time is abnormal...&quot;)))     
    (with-record cyclerec
      :bog-expected  bogtime
      :bog-to-dwell-expected (/ 1 (/ (+ bogtime MOBtime) 
                           ( - policyduration (+ bogtime  MOBtime))))
      :duration-expected policyduration
      :dwell-expected  dwelltime
      :mob-expected MOBtime
      :bogbudget bogbudget)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn ^cyclerecord cycle-add-traversal [cyclerec t startlocation endlocation]
  (let [trav  [t startlocation endlocation]       
        ts    (gen/get-else  cyclerec  :traversals [])] 
    (assoc cyclerec :traversals (conj ts trav))))</pre></div><div class="docs"><p>Computes the BOG:Dwell ratio for a cycle.</p>
</div><div class="codes"><pre class="brush: clojure">(defn bog-to-dwell
  [bog mob dwell available-time mob-expected bog-expected duration-expected 
   &amp; [conventional]]  
  (let [res 
        (cond (and  (&gt; bog  0) (&gt; dwell 0))
              (/ (+ bog mob)  dwell)
              (and (&gt; dwell 0) 
                   (&gt; available-time 0))
              (/ available-time dwell)
              :else 
              (/ (+ mob-expected  bog-expected) (- duration-expected 
                                                 (+ mob-expected bog-expected))))]
    (if conventional 
      (/ 1 res) 
      res)))</pre></div><div class="docs"><p>Computes the BOG:Dwell ratio from a cyclerecord.</p>
</div><div class="codes"><pre class="brush: clojure">(defn cycle-bog-to-dwell
  [cyclerec &amp; [conventional]]
  (let [{:keys [bog mob dwell available-time 
                mob-expected bog-expected duration-expected]} cyclerec]
    (bog-to-dwell bog mob dwell available-time 
         mob-expected bog-expected duration-expected conventional)))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.data.period" name="marathon.data.period"><h1 class="project-name">marathon.data.period</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>A module to capture functions that operate on periodic data.
Periods are defined as having a start and and end time.
We can test for intersection over a period.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.data.period)</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def inf-error 
  (Exception. &quot;Only numbers, or :inf and :inf-negative are valid keys&quot;))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn parse-inf [t] 
  (cond (keyword? t) 
    (case t 
      :inf  java.lang.Long/MAX_VALUE
      :inf-negative java.lang.Long/MIN_VALUE
      inf-error)
    (number? t) t
    :else inf-error))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;period [name tstart tfinal &amp; rest]
  {:name name :from-day tstart :to-day tfinal})</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def empty-period (-&gt;period nil nil nil))</pre></div><div class="docs"><p>Simple period constructor and modifier.  If p is provided, modifies the period name, else
returns a new period with the proper name.</p>
</div><div class="codes"><pre class="brush: clojure">(defn named-period [name &amp; [p]] (-&gt; (or p empty-period) (assoc :name name))) </pre></div><div class="docs"><p>General period constructor.  Defines a period [tstart...tfinal], where tstart &lt;= tfinal</p>
</div><div class="codes"><pre class="brush: clojure">(defn period-across [tstart tfinal]
  (assert (&lt;= (parse-inf tstart) (parse-inf tfinal)) 
          (str &quot;Periods must have final is &gt;= tstart &quot; [tstart tfinal]))
  (-&gt;period nil tstart tfinal))</pre></div><div class="docs"><p>Defines a period whose only valid intersection value is tstart, [tstart..tstart]
Used to define instantaneous phenomena...</p>
</div><div class="codes"><pre class="brush: clojure">(defn period-at [tstart] (period-across tstart tstart))</pre></div><div class="docs"><p>Defines a negatively unbounded period over [-inf...tfinal]</p>
</div><div class="codes"><pre class="brush: clojure">(defn period-to [tfinal] (period-across :inf-negative tfinal))</pre></div><div class="docs"><p>Defines a positively unbounded period over [tstart...inf]</p>
</div><div class="codes"><pre class="brush: clojure">(defn period-from [tstart] (period-across tstart :inf))</pre></div><div class="docs"><p>Defines a period that cannot ever intersect with any value.</p>
</div><div class="codes"><pre class="brush: clojure">(def period-undefined (period-across :inf :inf))</pre></div><div class="docs"><p>Defines a period that intersects every value of t [-inf...inf]</p>
</div><div class="codes"><pre class="brush: clojure">(def period-infinite (period-across :inf-negative :inf))
(defn period-&gt;list [p] (vals p))
(defn list-&gt;period [xs] (apply -&gt;period xs)) </pre></div><div class="docs"><p>Simple 1 dimensional intersection function.  Allows for infinite values in 
either direction, i.e. [tstart...inf], or [-inf...tfinal] are valid. <br />
Returns false if t is inf.</p>
</div><div class="codes"><pre class="brush: clojure">(defn intersect-1d [t tstart tfinal] 
  (cond (identical? t :inf) false 
        (and (identical? tstart :inf-negative) (identical? tfinal :inf)) true
        :else (and (&gt;= t tstart) (&lt;= t tfinal))))  </pre></div><div class="docs"><p>Determines if time t intersects the period p</p>
</div><div class="codes"><pre class="brush: clojure">(defn intersects-period? [t p] (intersect-1d t (:from-day p) (:to-day p)))</pre></div><div class="docs"><p>(Type    Name    FromDay ToDay)</p>
</div><div class="codes"><pre class="brush: clojure">(defn record-&gt;period [r]
  (-&gt;&gt; (period-across (parse-inf (:FromDay r)) (parse-inf (:ToDay r)))
        (named-period (:Name r))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def ^:constant +default-period+
  (-&gt;&gt; (period-across 0 0)
       (named-period :Initialization)))</pre></div><div class="docs"><p>----------OBSOLETE--------?</p>
</div><div class="codes"><pre class="brush: clojure">(defn make-temporal-period [&amp; [start-day end-day period-name &amp; rest]]
  (let [name (or period-name :Default)] (-&gt;period name start-day end-day)))</pre></div><div class="docs"><p>Public Function toString(p As GenericPeriod) As String
toString = p.name &amp; "'[" &amp; p.from-day &amp; ":" &amp; p.to-day &amp; "]'"
End Function</p>
</div><div class="codes"></div><div class="docs"><p>Public Function tableToPeriods(tbl As GenericTable) As Collection
Dim rec As GenericRecord</p>

<p>Set tableToPeriods = New Collection</p>

<p>While Not tbl.EOF
   Set rec = tbl.getGenericRecord
   tableToPeriods.add recordToPeriod(rec)
   tbl.moveNext
Wend</p>

<p>End Function</p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.processing.highwater" name="marathon.processing.highwater"><h1 class="project-name">marathon.processing.highwater</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>This namespace could probably be changed into a more general stream-processing
library.  It was built as a single-purpose script, namely to process a large 
time series, sampling by quarter, to produce a series of peaks in the data
and a much smaller set of data to examine.  There's definitely a general 
time-series set of reductions hiding in here somewhere...</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.processing.highwater
  (:use [spork.util.record 
           :only [defrecord+ with-record merge-from record-headers]]
        [spork.util.general :only [clumps]])
  (:require [spork.util [io :as io] 
                        [table :as tbl]]))</pre></div><div class="docs"><p>Note -> we're maintaining backward compatibility with the older version
of trend here.  We didn't always capture the AC/RC/NG/Ghost, etc. fill data.
Newer versions may have that information.  In order to process older datasets,
we want to keep these fields optional.</p>
</div><div class="codes"><pre class="brush: clojure">(defrecord+ trend [t 
                   Quarter 
                   SRC 
                   TotalRequired 
                   TotalFilled 
                   Overlapping
                   Deployed 
                   DemandName 
                   Vignette 
                   DemandGroup
                   OITitle
                   [ACFilled 0] 
                   [RCFilled 0] 
                   [NGFilled 0] 
                   [GhostFilled 0] 
                   [OtherFilled 0]])</pre></div><div class="docs"><p>Something for later...
(def field-parsers {:long  #(java.lang.Long/parseLong %)
                   :double #(java.lang.Double/parseDouble %)
                   :bool  #(java.lang.Boolean/parseBoolean %)
                   :string identity})</p>

<p>(defn record-parser [field-specs]
 (let [parsers (vec (map #(get field-parsers % tbl/parse-string-nonscientific) 
                         field-specs))
 (fn [^string x]
   (loop [acc []
          (tbl/split-by-tab x)</p>
</div><div class="codes"></div><div class="docs"><p>TODO -> turn this into a macro for reading records.
given a vec of strings, return a trend, fast...</p>
</div><div class="codes"><pre class="brush: clojure">(defn ^trend read-trend [xs]
    (-&gt;trend  
      (java.lang.Long/parseLong (nth xs 0)) ;t  
      (java.lang.Long/parseLong (nth xs 1)) ;Quarter
      (nth xs 2) ;SRC 
      (java.lang.Long/parseLong (nth xs 3)) ;TotalRequired 
      (java.lang.Long/parseLong (nth xs 4)) ;TotalFilled 
      (java.lang.Long/parseLong (nth xs 5)) ;Overlapping
      (java.lang.Long/parseLong (nth xs 6)) ;Deployed 
      (nth xs 7) ;DemandName 
      (nth xs 8) ;Vignette 
      (nth xs 9) ;DemandGroup
      (nth xs 10) ;OITitle
      (java.lang.Long/parseLong (nth xs 11)) ;[ACFilled 0] 
      (java.lang.Long/parseLong (nth xs 12)) ;[RCFilled 0] 
      (java.lang.Long/parseLong (nth xs 13)) ;[NGFilled 0] 
      (java.lang.Long/parseLong (nth xs 14)) ;[GhostFilled 0] 
      (java.lang.Long/parseLong (nth xs 15)))) ;[OtherFilled 0]]</pre></div><div class="docs"><p>[OtherFilled 0]]</p>
</div><div class="codes"></div><div class="docs"><p>an experiment.</p>
</div><div class="codes"><pre class="brush: clojure">(defn ^trend read-trend-arr [^String x]
  (let [xs (.split x &quot;\t&quot;)]
    (-&gt;trend  
      (java.lang.Long/parseLong (aget xs 0)) ;t  
      (java.lang.Long/parseLong (aget xs 1)) ;Quarter
      (aget xs 2) ;SRC 
      (java.lang.Long/parseLong (aget xs 3)) ;TotalRequired 
      (java.lang.Long/parseLong (aget xs 4)) ;TotalFilled 
      (java.lang.Long/parseLong (aget xs 5)) ;Overlapping
      (java.lang.Long/parseLong (aget xs 6)) ;Deployed 
      (aget xs 7) ;DemandName 
      (aget xs 8) ;Vignette 
      (aget xs 9) ;DemandGroup
      (aget xs 10) ;OITitle
      (java.lang.Long/parseLong (aget xs 11)) ;[ACFilled 0] 
      (java.lang.Long/parseLong (aget xs 12)) ;[RCFilled 0] 
      (java.lang.Long/parseLong (aget xs 13)) ;[NGFilled 0] 
      (java.lang.Long/parseLong (aget xs 14)) ;[GhostFilled 0] 
      (java.lang.Long/parseLong (aget xs 15))))) ;[OtherFilled 0]]</pre></div><div class="docs"><p>[OtherFilled 0]]</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def highwater-headers [:t :Quarter :SRC :TotalRequired :TotalFilled :Overlapping 
                        :Deployed :DemandName :Vignette :DemandGroup :OITitle 
                        :ACFilled :RCFilled :NGFilled :GhostFilled :OtherFilled])
(def headers   (record-headers trend))
(def fieldkeys (vec (map keyword headers)))</pre></div><div class="docs"><p>A Qtrend is a type alias for a tuple of Quarter, an Int, and a
   list of Trends. This associates a list of trends to a particular
   Quarter.</p>
</div><div class="codes"><pre class="brush: clojure">(defn Qtrend
  [q trs] 
  [q trs])</pre></div><div class="docs"><p>convert a list of stringified fields into a trend</p>
</div><div class="codes"><pre class="brush: clojure">(defn readTrend
  [coll &amp; {:keys [fieldnames] :or {fieldnames fieldkeys}}]
  ;;probably killing us in performance too...
;    (if (= fieldnames fieldkeys) ;default fields
  (read-trend (tbl/split-by-tab coll)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn tabLine     [coll] (clojure.string/join \tab  coll))</pre></div><div class="docs"><p>(defn trendString [tr]   (str (tabLine (vals tr)) \newline))
Modified to avoid call to str.</p>
</div><div class="codes"><pre class="brush: clojure">(defn trendString [tr]  (tabLine (vals tr)))</pre></div><div class="docs"><p>convert a nested list of trend fields into a list of trends.</p>
</div><div class="codes"><pre class="brush: clojure">(defn trendList
  [coll &amp; [fieldnames]]
  (if fieldnames 
    (map (fn [c] (readTrend c :fieldnames fieldnames)) coll) ;if fieldnames provided, use.
    (map readTrend coll))) ;else, use default fieldnames.</pre></div><div class="docs"><p>else, use default fieldnames.</p>
</div><div class="codes"></div><div class="docs"><p>convert a sample time into a quarter</p>
</div><div class="codes"><pre class="brush: clojure">(defn asQuarter
  [t] (inc (quot t 90)))</pre></div><div class="docs"><p>Extract the trend's quarter</p>
</div><div class="codes"><pre class="brush: clojure">(defn trendQuarter
  [tr] (asQuarter (:t tr)))</pre></div><div class="docs"><p>Group a list of Trends by quarters, returning a list of Quarterly Trends.</p>
</div><div class="codes"><pre class="brush: clojure">(defn groupByQuarter
  [trs]
  (-&gt;&gt; (clumps trendQuarter trs)
    (map (fn [[q trs]] (Qtrend q trs)))))</pre></div><div class="docs"><p>turn a list of trends into a Map of (src,t), v or a SampleMap
   where v is the sum of totalfilled for all trends of src at time t.
   Each quarter, we compute a set of samples keyed by the SRC and the
   sampletime of the trend, that maps to the total number of units filling
   demands for SRC on day t. There are instances where multiple samples for
   an SRC occur on the same day in the data, which we handle by summing.</p>
</div><div class="codes"><pre class="brush: clojure">(defn sampleQuarter
  [[q ts]]
  (let [sample (fn [acc {:keys [SRC t TotalFilled]}]
                 (if-let [v (get acc [SRC t])]
                   (assoc! acc [SRC t] (+ TotalFilled v))
                   (assoc! acc [SRC t] TotalFilled)))]
    (persistent! (reduce sample (transient {}) ts))))</pre></div><div class="docs"><p>For each SRC, we want to find a time t, where t has the highest number of uni
   filling demands, relative to every other t in the sample set.
   return a map of (SRC -> t) where t is the time the highest totalfilled
   sample for the SRC.</p>
</div><div class="codes"><pre class="brush: clojure">(defn maxSamples
  [samplemap]
  (let [maxf (fn [m [[s t] newval]]
               (if-let [[oldt oldval] (get m s)]
                 (if (or (&gt; newval oldval)
                         (and (= newval oldval) (&lt; t oldt)))
                   (assoc! m s [t newval])
                   m)
                 (assoc! m s [t newval])))]
    (persistent! (reduce maxf (transient {}) samplemap))))</pre></div><div class="docs"><p>highTrend is a filter function, that, given a corresponding map, will tell us
   if a Trend is indeed the highest trend in all the land!</p>
</div><div class="codes"><pre class="brush: clojure">(defn highTrend
  [srcmap {:keys [SRC t]}]
  (let [[tbest ] (get srcmap SRC)]
    (= tbest t)))</pre></div><div class="docs"><p>getHighTrends ties everything together for trends in a Quarter.
   The high trends are defined as all trends in the quarter, where the
   trend is identified as a highTrend, in the context of a heightmap.
   heightmap is defined as the maximum sampling, of the samplequarter of
   the quarterly trend.</p>
</div><div class="codes"><pre class="brush: clojure">(defn getHighTrends
  [[qtr trends :as qtrend]]
  (let [heightmap ((comp maxSamples sampleQuarter) qtrend)]
    (filter (partial highTrend heightmap) trends)))</pre></div><div class="docs"><p>We can represent our final computation as a lazy mapping of getHighTrends
   to a list of QTrends ... </p>
</div><div class="codes"><pre class="brush: clojure">(defn highWaterMarks
  [trends]
  (map getHighTrends (concat (groupByQuarter trends))))</pre></div><div class="docs"><p>Where xs is a tab delimited line sequence, and the first value of 
   xs is a row of headers, returns a lazy seq of trend records using the 
   headers in the first row.</p>
</div><div class="codes"><pre class="brush: clojure">(defn readTrends
  [xs]
  (let [fields (vec (map keyword (tbl/split-by-tab (first xs))))]
    (trendList (rest xs) fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn addHeaders [trends] (cons (str (tabLine headers) \newline) trends))</pre></div><div class="docs"><p>Given a lookup-map of {primarykeyval {fieldname expr}}, and a primary key, 
   returns a function that intersects fields from lookup-map and a record. <br />
   The resulting value should be identical to the record (field-wise), except 
   field values may be changed or computed by the intersection. </p>
</div><div class="codes"><pre class="brush: clojure">(defn intersect-fields
  [lookup-map primarykey]  
  (fn [record] 
    (merge-from record 
      (get lookup-map (get record primarykey)))))</pre></div><div class="docs"><p>this is a simple query....</p>
</div><div class="codes"><pre class="brush: clojure">(def testlookup 
  {&quot;SRC1&quot; {:SRC &quot;SRC1&quot;, :OITitle &quot;Little SRC&quot;, :STR 5}
   &quot;SRC2&quot; {:SRC &quot;SRC2&quot;, :OITitle &quot;Medium SRC&quot;, :STR 10}
   &quot;SRC3&quot; {:SRC &quot;SRC3&quot;, :OITitle &quot;Big SRC&quot;,    :STR 20}})</pre></div><div class="docs"><p>These operations will be replaced with more abstract SQL-like operations, 
once I get a library for it built....</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn src-lookup [srcmap]
  (fn [m] 
    (intersect-fields m srcmap :SRC)))</pre></div><div class="docs"><p>Adds a few computed fields to our entry.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compute-strengths
  [m]
  (let [? (fn [f] (get m f))
        strength (? :STR)]  
    {:ACStr (*  strength (? :ACFilled)) 
     :RCStr (* strength (? :NGFilled))
     :GhostStr (* strength (? :GhostFilled)) 
     :OtherStr (* strength (? :OtherFilled))
     :TotalStr (* strength (? :TotalFilled))
     :RequiredStr (* strength (? :TotalRequired))})) </pre></div><div class="docs"><p>Produces an entry processor that tacks on strength, OITitle, and computes 
   compo-specific strengths.</p>
</div><div class="codes"><pre class="brush: clojure">(defn append-src-data
  [srcmap]
  (comp compute-strengths (src-lookup srcmap))) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn file-&gt;trends [inpath]
  (with-open [rdr (clojure.java.io/reader inpath)]
    (vec (readTrends (line-seq rdr)))))</pre></div><div class="docs"><p>Given an lazy sequence of trend records, compiles the highwater trends from
   demandtrends.</p>
</div><div class="codes"><pre class="brush: clojure">(defn trends-&gt;highwater-records
  [rawtrends &amp; {:keys [entry-processor]}]
  (for [q (highWaterMarks rawtrends)
        trendrec (map (if entry-processor entry-processor identity) q)]
    trendrec))</pre></div><div class="docs"><p>Composition that produces an ITable from a lazy sequence of raw demand 
   trends, where the table is a fully computed set of highwater records.</p>
</div><div class="codes"><pre class="brush: clojure">(defn trends-&gt;highwater-table
  [rawtrends &amp; {:keys [entry-processor]}]
  (tbl/records-&gt;table
    (trends-&gt;highwater-records rawtrends :entry-processor entry-processor)))</pre></div><div class="docs"><p>Given a path to a demand trends file, computes highwater trends and returns
   an ITable data structure from util.table </p>
</div><div class="codes"><pre class="brush: clojure">(defn file-&gt;highwater-table
  [path &amp; {:keys [entry-processor]}]
  (trends-&gt;highwater-table (file-&gt;trends path) 
                           :entry-processor entry-processor))</pre></div><div class="docs"><p>this version is -120 seconds, take about 1 gb of ram.
Look at swapping out non-cached streams with lazy sequences.</p>
</div><div class="codes"></div><div class="docs"><p>Changed trendString implementation to use clojure.string libs
which use string builders.  Might switch the entire implementation 
use clojure.string/join, I still need to profile this dude.</p>
</div><div class="codes"></div><div class="docs"><p>Given an input file and an output file, compiles the highwater trends from
   demandtrends.  If lookup-map (a map of {somekey {field1 v1 field2 v2}} is 
   supplied, then the supplied field values will be merged with the entries 
   prior to writing.  We typically use this for passing in things like 
   OITitle and STR (strength) in a simple lookuptable, usually keyed by src.
   This pattern will probably be extracted into a higher order postprocess 
   function or macro....</p>
</div><div class="codes"><pre class="brush: clojure">(defn main
  [infile outfile &amp; {:keys [entry-processor]}]
    (with-open [lazyin  (clojure.java.io/reader infile)
                lazyout (clojure.java.io/writer (io/make-file! outfile))]
      (binding [*out* lazyout]
        (do (println (tabLine headers))
          (doseq [t (-&gt; (vec (readTrends (line-seq lazyin))) 
                        (trends-&gt;highwater-records 
                          :entry-processor entry-processor))]
                (println (trendString t))))))) ;modified to avoid stringcat.</pre></div><div class="docs"><p>modified to avoid stringcat.</p>
</div><div class="codes"></div><div class="docs"><p>Uses the table operations to handle i/o, rather than streaming everything.
   Wipes out outfile.</p>
</div><div class="codes"><pre class="brush: clojure">(defn altmain
  [infile outfile &amp; {:keys [entry-processor]}]
  (spit (clojure.java.io/writer (io/make-file! outfile))
        (tbl/table-&gt;tabdelimited
          (file-&gt;highwater-table infile :entry-processor entry-processor)))) </pre></div><div class="docs"><p>Sniff out paths to demand trends files from root.</p>

<p>This is a process, I'd like to move it to a higher level script....</p>
</div><div class="codes"><pre class="brush: clojure">(defn findDemandTrendPaths
  [root]
  (map io/fpath (io/find-files root #(= (io/fname %) &quot;DemandTrends.txt&quot;))))</pre></div><div class="docs"><p>Computes high water for for each p in path. dumps a corresponding highwater.
   in the same directory, overwriting.</p>
</div><div class="codes"><pre class="brush: clojure">(defn batch
  [paths &amp; {:keys [entry-processor]}]
  (doseq [source paths]
    (let [target (io/relative-path 
                   (io/as-directory (io/fdir source)) [&quot;highwater.txt&quot;])]
      (if (io/fexists? (clojure.java.io/file source))
        (do (println (str &quot;Computing HighWater : &quot; source&quot; -&gt; &quot; target))
            (main source target 
                  :entry-processor entry-processor))
        (println (str &quot;Source file: &quot; source&quot; does not exist!&quot;))))))</pre></div><div class="docs"><p>Computes high water for for each p in path. dumps a corresponding highwater.
   in the same directory, overwriting.</p>
</div><div class="codes"><pre class="brush: clojure">(defn alt-batch
  [paths &amp; {:keys [entry-processor]}]
  (doseq [source paths]
    (let [target (io/relative-path 
                   (io/as-directory (io/fdir source)) [&quot;highwater.txt&quot;])]
      (if (io/fexists? (clojure.java.io/file source))
        (let [_ (println (str &quot;Computing HighWater : &quot; source&quot; -&gt; &quot; target))]          
            (do (altmain source target 
                  :entry-processor entry-processor)))
        (println (str &quot;Source file: &quot; source&quot; does not exist!&quot;))))))</pre></div><div class="docs"><p>Compiles a batch of highwater trends, from demand trends, from all demand 
   trends files in folders or subfolders from root.</p>
</div><div class="codes"><pre class="brush: clojure">(defn batch-from
  [root &amp; {:keys [entry-processor]}]
  (batch (findDemandTrendPaths root) 
         :entry-processor entry-processor))</pre></div><div class="docs"><p>Compiles a batch of highwater trends, from demand trends, from all demand 
   trends files in folders or subfolders from root.</p>
</div><div class="codes"><pre class="brush: clojure">(defn alt-batch-from
  [root &amp; {:keys [entry-processor]}]
  (alt-batch (findDemandTrendPaths root) 
         :entry-processor entry-processor))</pre></div><div class="docs"><p>Generates a fake stream of entries</p>

<p>testing</p>
</div><div class="codes"><pre class="brush: clojure">(comment 
(defn fake-entries
  [src-count demand-count &amp; {:keys [tstart interval] 
                             :or {tstart 0
                                  interval 10}}]
  (let [fake-demand-name (memoize (fn [src d] (str &quot;Demand&quot; &quot;_&quot; src &quot;_&quot; d)))
        empty-entry      {:TotalRequired 1
                          :TotalFilled 1
                          :Overlapping 0
                          :Deployed 1                          
                          :Vignette    &quot;Sample&quot;
                          :DemandGroup &quot;SampleGroup&quot;
                          :ACFilled 1
                          :RCFilled 0
                          :NGFilled 0
                          :GhostFilled 0 
                          :OtherFilled 0}
        fake-entry       (fn [src d t] 
                           (map-&gt;trend 
                             (merge empty-entry 
                                    {:DemandName (fake-demand-name src d)
                                     :SRC     src
                                     :OITitle src
                                     :t t 
                                     :Quarter (inc (quot t 90))})))]
    (-&gt;&gt; (iterate #(+ % interval) tstart)
         (mapcat #(for [src (range src-count)
                        d   (range demand-count)]
                    (fake-entry src d %)))
         (concat))))
;;generate a fake table for testing and profiling purposes.
;;Note, it takes about 5 million entries for this guy.  ugh.
(defn fake-table [n]  
  (-&gt;&gt; (tbl/records-&gt;table (take n (fake-entries 2 10)))
       (tbl/order-fields-by highwater-headers)))
(def workdir &quot;C:\\Users\\tom\\Documents\\Marathon_NIPR\\&quot;)
(def batchdir 
  &quot;C:\\Users\\thomas.spoon\\Documents\\TAA 15-19\\Unconstrained Runs&quot;)
(def testfile (io/relative-path workdir [&quot;bcttrends.txt&quot;]))
(def bigfile  (io/relative-path workdir [&quot;dtrendsfull.txt&quot;]))
(def testout  (io/relative-path workdir [&quot;hw.txt&quot;]))
(def bigout   (io/relative-path workdir [&quot;highwater.txt&quot;])))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.processing.forgereader" name="marathon.processing.forgereader"><h1 class="project-name">marathon.processing.forgereader</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>A set of utilities for processing data; derived from an ad-hoc script.
FORGE data comes in a couple of important tables, specifically phases, 
tracks, and events.  The forgereader provides a library for processing these
tables, and producing </p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.processing.forgereader
  (:require [spork.util [table :as tbl]
                        [bridging :as br]]))</pre></div><div class="docs"><p>Rips text from string txt, parsing under the assumption that certain 
   alphanumeric codes for SRCs should be parsed as strings, not scientific
   notated numerals.</p>
</div><div class="codes"><pre class="brush: clojure">(defn SRCtext-&gt;table  
  [txt]
  (tbl/tabdelimited-&gt;table txt :parsemode :noscience))</pre></div><div class="docs"><p>NOTE remove this guy....used for testing.</p>
</div><div class="codes"><pre class="brush: clojure">(def testpath 
  (relative-path :docs
     [&quot;TAA 15-19&quot; &quot;Unconstrained Runs&quot; &quot;Derived Data&quot; &quot;Demand&quot;]))</pre></div><div class="docs"><p>Fetches canonical tables for phases, tracks, and event information from a 
   root directory, returning a map of parsed tables with corresponding entries.</p>
</div><div class="codes"><pre class="brush: clojure">(defn load-tables
  ([path]    
    (let [[p t e] (map #(SRCtext-&gt;table (slurp (relative-path
                                                 (as-directory path) (list %))))
                       [&quot;phases.txt&quot; &quot;tracks.txt&quot; &quot;events.txt&quot;])]
      {:phases p :tracks t :events e}))
  ([] (load-tables testpath)))</pre></div><div class="docs"><p>Converts a time phase table, or TP table, to a sequence of phases. Since
   TPs are reported in End Days, we stitch together the timings from each
   preceding phase. In the case of an initial time phase ending on 1, we
   prepend an implicit phase that starts at 0.</p>

<p>we primarily use two foreign keys when joining forge data.
TP and a generic index (a number) .
TP is the time phase, and shows up in the timephase table, and the</p>
</div><div class="codes"><pre class="brush: clojure">(defn tptable-&gt;phasemap
  [tptbl]
  (let [{:keys [phases timeperiods ends]}
        (reduce (fn [{:keys [phases timeperiods ends]} rec]
                  {:ends (conj ends (get rec &quot;TP End Day&quot;))
                   :phases (conj phases (get rec &quot;Sub-Phase&quot;))
                   :timeperiods (conj timeperiods (get rec &quot;TP&quot;))})
                {:ends [] :phases [] :timeperiods []}
                (tbl/record-seq tptbl))
        schedule (let [raw (partition 2 1 ends)
                       n (ffirst raw)]
                   (if (not= n 0)
                     (cons (list 0 n) raw)
                     raw) ) ]
    {:phases (zipmap phases schedule)
     :periods (zipmap timeperiods phases)}))</pre></div><div class="docs"><p>Cleans an event record of nil or blank entries.</p>

<p>the big change here is that for each track, we're building a phasemap ...
we need a function that consumes a sequence of change events ...
and maps the changes to a phase record.
If we want to compress a track, we basically drop time periods ...
It's an extension to drop-blankevents ...
Given an event-record, we've dropped blank timeperiods ...</p>

<p>Converts a timpphase key into a time represntation.</p>
</div><div class="codes"><pre class="brush: clojure">(defn drop-blankevents
  [event-record]
  (reduce (fn [acc k]
            (if (number? (get event-record k))
              acc
              (dissoc acc k))) event-record (keys event-record)))
(defn tpkey-&gt;time
  [tpkey] (Integer/parselnt (clojure.string/replace tpkey &quot;TP &quot; &quot;&quot; )))</pre></div><div class="docs"><p>Fetches the time interval associated with the time phase key.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-time
  [[tpkey _]] (tpkey-&gt;time tpkey &quot;TP &quot; &quot;&quot; ))</pre></div><div class="docs"><p>Compares the time intervals between two time phase keys.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compare-time
  [tp1 tp2] (compare (tpkey-&gt;time tp1) (tpkey-&gt;time tp2)))</pre></div><div class="docs"><p>Maps a time phase key into a [tstart tstop] time interval.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tp-&gt;timing
  [tpkey {:keys [periods phases]}]
  (get phases (get periods tpkey)))</pre></div><div class="docs"><p>Convert an event record into a schedule of events.</p>
</div><div class="codes"><pre class="brush: clojure">(defn eventrecord-&gt;schedule
  [rec]
  (into (sorted-map-by compare-time) (drop-blankevents rec)))</pre></div><div class="docs"><p>For a collection of events, determines where changes occur between contiguous
   entries' values.</p>
</div><div class="codes"><pre class="brush: clojure">(defn index-changes
  [events]
  (-&gt;&gt; (reduce
         (fn [[i vprev id phases] v]
           (if (not= v vprev) inew phase
             (let [new-id (inc id)
                   newphase {new-id {:samples [i] :data v}}]
               [(inc i) v new-id (merge phases newphase)])
             (let [phase (get phases id)
                   samples (get phase :samples [])]
               [(inc i) vprev id (assoc phases id
                              (assoc phase :samples (conj samples i)))])))
         [0 nil -1 (sorted-map)] events)
    last))</pre></div><div class="docs"><p>Compresses a schedule of events, eliminating redundant event values, where 
   the quantity associated with contiguous events is identical.  The resulting 
   compressed schedule is the minimal amount of information needed to cover the
   inflection points in the signal.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compress-schedule
  ([schedule lbl]
    (let [tps (vec (keys schedule))
          events (vec (vals schedule))
          groups (index-changes events)]
      (reduce (fn [acc v] (conj acc v)) []
              (for [[phase {:keys [samples data]}] groups]
                (let [to (nth tps (first samples))
                      tf (nth tps (last samples))]
                  [(str lbl phase \space \[ to &quot; - &quot; tf \])
                   [to tf]])))))
  ([schedule] (compress-schedule schedule &quot;Derived Phase &quot;)))</pre></div><div class="docs"><p>Compresses the nominal phase mapping based on the underlying schedule.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compress-phasemap
  [compressed-schedule phasemap]
  (let [phases (into {} (for [[phase [tpstart tpend]] compressed-schedule]
                          [phase [(first (tp-&gt;timing tpstart phasemap))
                                  (fnext (tp-&gt;timing tpend phasemap))]]))
        periods (-&gt;&gt; (mapcat (fn [[phase [tpstart tpend]]]
                               [[tpstart phase] [tpend phase]])
                             compressed-schedule)
                  (reduce (fn [acc [k v]] (assoc acc k v)) {}))]
    {:phases phases
     :periods periods}))</pre></div><div class="docs"><p>Produces a set of demand records for each period and phase according to the
   schedule.</p>
</div><div class="codes"><pre class="brush: clojure">(defn sample-demand
  [group schedule {:keys [phases periods] :as phasemap} timeperiod]
  (let [p (get periods timeperiod)
        op (str group \space p)
        [tstart tfinish] (get phases p)]
    {:phase p
     :start tstart
     :duration (- tfinish tstart)
     :vignette op
     :operation OJ?
     :group group}))</pre></div><div class="docs"><p>Turn one track record into N events. For each event, there is a start,
   duration, stop. Assuming we have a phasemap that maps trackrecord i ->
   timephase, we use phasemap to create a new record with start and duration.
   If compress is true, the data from the event record will define phasing,
   where phases consist of changes in the event data. Multiple time periods
   with identical data will be compressed into a single, derived phase.</p>
</div><div class="codes"><pre class="brush: clojure">(defn expand-track
  [eventrecord trackrecord phasemap &amp; {:keys [group compress]
                                       :or {group &quot;Anonymous Surge Event&quot;
                                            compress false}}]
  (let [schedule (eventrecord-&gt;schedule eventrecord)
        [ts phasemap] (if compress
                        (let [s (compress-schedule schedule)]
                              [(concat (map (comp first fnext) s))
                               (compress-phasemap s phasemap)])
                        [(keys schedule) phasemap])
        make-record (partial sample-demand group schedule phasemap)]
    (map #(merge trackrecord (make-record %) {:quantity (get schedule %)}) ts)))</pre></div><div class="docs"><p>define a mapping of forge fields to our desired format:</p>
</div><div class="codes"><pre class="brush: clojure">(def forgetemplate
  [[&quot;Type&quot; &quot;Type&quot; &quot;DemandRecord&quot;]
   [&quot;Enabled&quot; &quot;Enabled&quot; &quot;True&quot;]
   [&quot;Priority&quot; &quot;Priority&quot; 1]
   [:quantity &quot;Quantity&quot;]
   [&quot;DemandIndex&quot; &quot;DemandIndex&quot; 0]
   [:start &quot;StartDay&quot;]
   [ :duration &quot;Duration&quot;]
   [&quot;Overlap&quot; &quot;Overlap&quot; 45]
   [&quot;SRC&quot;]
   [&quot;SourceFirst&quot; &quot;SourceFirst&quot; &quot;Uniform&quot;]
   [:group &quot;DemandGroup&quot;]
   [:vignette &quot;Vignette&quot;]
   [:operation &quot;Operation&quot;]
   [&quot;ARFORGEN&quot; &quot;Category&quot; ]])</pre></div><div class="docs"><p>define a data bridge that uses our mapping.  </p>
</div><div class="codes"><pre class="brush: clojure">(br/defbridge forge-&gt;demand forgetemplate)</pre></div><div class="docs"><p>Given tbls, a map of tables with keys :phases :events :tracks, 
   a demand group, and an optional boolean indicating whether we should
   compress the tracks, produces a set of demandrecords in the format 
   described by the forge->demand databridge.</p>
</div><div class="codes"><pre class="brush: clojure">(defn tbls-&gt;demandrecords
  [tbls group &amp; [compress]]
  (let [phasemap (tptable-&gt;phasemap (:phases tbls))]
    (-&gt;&gt; (mapcat #(expand-track %1 %2 phasemap :group group :compress compress)
                 (tbl/record-seq (:events tbls)) 
                 (tbl/record-seq (:tracks tbls)))
      (map (partial bridge/translate-map (br/get-bridge :forge-&gt;demand))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(comment 
  (def tbls (load-tables))
  (def testtrack (first (tbl/record-seq (:tracks tbls))))
  (def testevent (first (tbl/record-seq (:events tbls))))
  (def testmap (tptable-&gt;phasemap (:periodtable tbls)))
;(defn res []
;  (loop [acc {}
;         remaining forgetemplate]
;    (if-let [[k vI v2] (first remaining)]
;      (recur (assoc acc k [vI v2]) (rest remaining))
;      acc)))
;expand all of our records ....
; (defn build-tracks [srctable tracktable]
;   (map-indexed)</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.processing.helmet.core" name="marathon.processing.helmet.core"><h1 class="project-name">marathon.processing.helmet.core</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>helmet is a tool the parses sample-queries relative to 
a set of records, validation rules, and sample-rules, 
and then samples from the records according to the sample-rules, 
validates the resultant set of sample records, and allows 
replications of the process.</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.processing.helmet.core
  (:require [spork.cljgui.components [swing :as gui]]
            [spork.util [general :as gen]
                        [table :as tbl]
                        [stats :as stats]
                        [record :as rec]
                        [sampling :as sample]]
            [spork.util.excel [core :as xl]]
            [marathon.processing.helmet [split :as split] 
                                        [collision :as collision]]))</pre></div><div class="docs"><h1>Overview</h1>
</div><div class="codes"></div><div class="docs"><p>Helmet is a re-write of a stochastic demand sampling.  The legacy version 
was an unnamed tool, built in excel, that used a worksheet interface, and 
a VBA backend.  The VBA implementation parsed data from a set of tables that
encoded sampling rules, primarily mappings of distributions and data 
transformations to subsets of a corpus of data records.  The sponsor extended
the requirements after the tool had been built, and the original developer 
was no longer around.  Unfortunately, the implementation precluded simple 
extension to handle the non-trivial cases that the requirements change 
introduced.  Additionally, there were previously unknown errors in the 
implementation that surfaced during early attempts to capitalize on the 
previous effort and extend it. <br />
After roughly 3 weeks of wasted effort, I made the decision to implement the 
sampling language in spork.util.sampling to support sampling rules of 
arbitrary complexity.  That language now serves as the basis for the 
stochastic demand rule engine.  To support legacy users, I wrapped the 
legacy interface (with some improvements) that existed in Excel.  The new 
application, dubbed Helmet, is a wrapper around the sampling rules and "cases"
encoded in the legacy Excel format.  One should note: the sampling is a 
general purpose clojure library.  Helmet is merely a wrapper and a specialized
Excel data-munging tool to accomodate legacy users.  Callers may use Helmet 
from the standard Marathon GUI, or may use the library programatically.  </p>
</div><div class="codes"></div><div class="docs"><h1>Differences from the Legacy Version</h1>
</div><div class="codes"></div><div class="docs"><p>Helmet capitalizes on the fact that Clojure has a really powerful reader.  As
such, much of the "data" in the casebook (an Excel workbook with some required
tables) is actually a native clojure data structure (like a map or a vector).
I was able to simplify much of the case definition, and provide the ability 
to compose sampling rules to eliminate much of the redundancy in the previous
spec.  Legacy users seemed to like the new format.  There is a detailed 
description of new data fields and rule expression semantics, available on 
request.  Later versions may ignore Excel entirely, preferring simple clojure
scripts and database connections for portability.  </p>
</div><div class="codes"></div><div class="docs"><h1>Typical Process</h1>

<p>When invoked as an application from the main Marathon GUI, the user is 
presented with a file selection dialogue asking for a casebook.  The 
path of the casebook is fed to the <strong>xlsx->futures</strong> function, with default
arguments.  Assuming the casebook is well-formed, a set of stochastically 
generated demand futures, as defined by the demand data, the sampling rules, 
and the case data from the casebook, will be generated in the same working 
folder.  These futures are standard tables of tab-delimited txt, and can be
easily read or modified.  Alternative formats are feasible, but currently not
in demand.  </p>
</div><div class="codes"></div><div class="docs"><p>If a user wishes to perform the same process from the clojure REPL, one can
do so via invoking (xlsx->futures ...) on an appropriate workbook path.  Check
the <strong>xlsx->futures</strong> docstring for more options for output configuration.</p>
</div><div class="codes"></div><div class="docs"><h1>Required Data</h1>
</div><div class="codes"></div><div class="docs"><h1>Cases</h1>
</div><div class="codes"></div><div class="docs"><p>The "Cases" table defines the name and global characteristics of active cases
to be sampled from.  Global characteristics include the number of futures to
generate, the random number seed to use, and constraints on duration and 
end-times.  Each enabled case in the "Cases" table must have a corresponding 
table (or worksheet) that defines the sampling rules for the case.  </p>
</div><div class="codes"></div><div class="docs"><h1>Case Sampling Rules</h1>

<p>Each case has a table of sampling rules that define a sampling context, ala 
<strong>spork.util.sampling</strong>.  The rows or records of the case table contribute 
a sampling rule to the sampling corpus, so all of the records for a case are
parsed into a composite sampling rule for the entire case.  When a case is 
sampled according to these rules, the result of each rule - a sequence of 
demand records -- are concatenated into a single "future".  Each case will 
have n futures, as defined by the information in the Cases table.  Each future
will ultimately reside in a unique tab-delimited file (when default processing
is used).  If a caller desires to, they can use the library functions directly
and keep case information in-memory as spork.util.table structures, rather 
than emitting files.  This may be useful for later experimental processes, or 
search processes such as <strong>marathon.processing.stoke</strong>.  </p>
</div><div class="codes"></div><div class="docs"><p>The sampling rules are encoded in a tabular format, where each rule has a name, 
a frequency, a distribution to transform the "start" field of sampled records 
by, a distribution to transform the "duration" field of sampled records by, 
and a pool of rules to draw from.  Both the start and distribution fields have
accompying values of "S1, S2, S3", and "D1, D2, D3" .  These are remnants of 
the legacy incoding, and imply the paramters to be sent to the distribution 
named in the associated "... Distribution" field.  This encoding only covers
the cases needed for Helmet, but is sufficient and conforms to the legacy 
design.</p>
</div><div class="codes"></div><div class="docs"><h1>Encoding Pools of Choices</h1>
</div><div class="codes"></div><div class="docs"><p>The pool of rules is either a clojure vector or a clojure map.  Clojure 
vectors, denoted by [...] imply a random choice with even probability amongst 
every rule in the sequence.  Users may enter multiple identical values for a 
vector pool, in which case the result is akin to an empirical distribution. <br />
Users may also prepend the vector sequence with the :every keyword, <br />
[:every ...]  to imply that, rather than a uniform choice, every rule in the 
pool is to be sampled and concatenated.  </p>
</div><div class="codes"></div><div class="docs"><p>Clojure maps, denoted by {rule1 n1, rule2 n2, ...} imply a weighted choice, 
with probability denoted by the numerical values associated with each rule. <br />
While a preferred convention, numerical values need not sum to 1.0 - they will
be normalized by default.  One may encode an empirical distribution by 
weighting the rules in the map with the number of observations.</p>
</div><div class="codes"></div><div class="docs"><h1>Validation Rules : Dependency Classes and Prioritization</h1>

<p>Validation covers two depenendent phenomena: prioritzation of demands, and 
the desire to resolve "collisions" between classes of prioritized demands. <br />
The "ValidationRules" table contains a dependency class, a priority, and a 
minimum time rule.  Dependency classes, when present, encode a prioritization 
between concurrent demands, if and only, the concurrent demands also have 
a dependency class.  Concurrent dependent demands, or collisions, are then 
resolved based on the rules in <strong>marathon.processing.helmet.collision</strong> .  In
general, demands are either merged or split, depending on priority, to resolve
collisions.  Demands with no associated dependency class are left untouched.  </p>
</div><div class="codes"></div><div class="docs"><h1>Demand Splitting</h1>

<p>One orthogonal requirement that emerged was the ability to split a group of 
demands according to context-specific rule-sets, where the "splitting" 
operation implied bifurcating demand records based on some notion of 
cumulative time relative to the group of demand records.  I decided to split
this into a final processing step, separate from the sampling rules.  Once 
samples are determing, if any splitting needs to be done - to identify "early"
demands in a logical group of demands [presumably for special policies] - 
then we split the demand records according to information in the DemandSplit 
table.  Where demand records map to a DemandSplit rule, the rule will detail
when a set of demands should be "split."  Splitting occurs relative to the 
earliest demand in the group of demand records sharing the split rule.  If 
the split-day, the day since the start of the earlist demand in the group, 
occurs during any demands, then the intersecting demands are bifurcated. <br />
Birfurcation creates two records, one defined up to the split, where the 
data is identical except for the duration.  Any records occuring after the 
split have - currently - "-Rotational" appened to their "SourceFirst" fields,
as dictated by the legacy methodology.</p>
</div><div class="codes"></div><div class="docs"><h1>Demand Records</h1>

<p>The "DemandRecords" table is effectively the sampling corpus for the entire 
set of sampling rules, across all cases.  Upon initialization, a sampling 
context is defined, where demand records are grouped into sampling rules by 
their "Group" field.  These rules are therefore available for use in composing
the rules found in the <strong>Case Sampling Rules</strong> and the pools.  The other field
of consequence is the "DemandSplit" field, which is used for the final 
processing step.</p>
</div><div class="codes"></div><div class="docs"><h1>Implementation</h1>
</div><div class="codes"></div><div class="docs"><p>Most of the following implementation concerns reading data from the casebook, 
and parsing tabular data into so-called "Cases" which describe the set of 
active cases to sample.  The casebook is read into a spork.util.table 
structure, acting as a lightweight database simulacrum of the casebook.    </p>
</div><div class="codes"></div><div class="docs"><p>utility-functions                        </p>
</div><div class="codes"><pre class="brush: clojure">(defn collapse-fields [fields r]
  (reduce (fn [acc [from-field to-field]]
            (-&gt; (assoc acc to-field (get acc from-field))
                (dissoc from-field))) r fields))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn integral-times [r]
  (let [s (get r :start)
        d (get r :duration)]
    (merge r {:start (quot s 1)
              :duration (quot d 1)})))</pre></div><div class="docs"><p>legacy definitions</p>
</div><div class="codes"></div><div class="docs"><p>these are the original fields from our legacy excel-based tables....</p>
</div><div class="codes"><pre class="brush: clojure">(def legacy-rule-fields 
  [&quot;Rule&quot; &quot;Frequency&quot; 
   &quot;StartDistribution&quot; &quot;S1&quot; &quot;S2&quot; &quot;S3&quot; 
   &quot;DurationDistribution&quot; &quot;D1&quot; &quot;D2&quot; &quot;D3&quot; &quot;Pool&quot;])</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def legacy-rule-keys (vec (map keyword legacy-rule-fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def start-fields    [&quot;StartDistribution&quot; &quot;S1&quot; &quot;S2&quot; &quot;S3&quot;])
(def start-keys (vec (map keyword start-fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def duration-fields [&quot;DurationDistribution&quot; &quot;D1&quot; &quot;D2&quot; &quot;D3&quot;])
(def duration-keys (vec (map keyword duration-fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def demand-fields [&quot;Type&quot; &quot;Enabled&quot; &quot;Priority&quot; &quot;Quantity&quot; 
                    &quot;DemandIndex&quot; &quot;StartDay&quot; &quot;Duration&quot; &quot;Overlap&quot; 
                    &quot;SRC&quot; &quot;SourceFirst&quot; &quot;DemandGroup&quot; &quot;Vignette&quot; 
                    &quot;Operation&quot; &quot;Category&quot; &quot;OITitle&quot;])
(def demand-keys (vec (map keyword demand-fields)))</pre></div><div class="docs"><p>We need this to bridge a problem with the legacy data set, namely that 
the arity of distributions was unknown in the data...there are always 
four arguments associated with a distribution, [name arg1 arg2 arg3], 
when the actual distribution may only need arg1, or it may need up to arg3...
This is a quick hack that encodes the arity for us.  Arities are drawn from 
util.stats </p>
</div><div class="codes"><pre class="brush: clojure">(def legacy-arity
  {:normal 2
   :gamma  2
   :beta   2
   :triangle  3
   :uniform   2
   :log-normal  2
   :exponential 1
   :log-logistic 2
   :fix 1})</pre></div><div class="docs"><p>Predicate to determine if the supplied field value v indicates building a 
   'distribution' that draws its data from a field, rather than stochastically.</p>
</div><div class="codes"><pre class="brush: clojure">(defn use-data?
  [v]
  (if (keyword? v) 
    (case v (:vignette :from-data :data) true
      nil)                    
    (case (clojure.string/lower-case v)
      (&quot;vignette&quot; &quot;from-data&quot; &quot;data&quot;) true 
      nil)))</pre></div><div class="docs"><p>Fetches an underlying statistical distribution according to the old encoding 
   from the original vba tool.</p>
</div><div class="codes"><pre class="brush: clojure">(defn legacy-distribution
  [dist-type dist-name args]
  (if (use-data? dist-name)
    nil
    (let [create-dist (stats/get-distribution dist-name)
          n   (or (get legacy-arity (keyword dist-name)) 
                  (throw (Exception.(str &quot;unknown distribution&quot; dist-name))))]
      (apply create-dist (take n args)))))</pre></div><div class="docs"><p>Fetches the arguments from a legacy record, depending on the distribution 
   type, either "start" or "duration",  from a record.  Returns a vector 
   compatible with the arguments for #'legacy-distribution.</p>
</div><div class="codes"><pre class="brush: clojure">(defn distribution-args
  [distribution-type rec]
  ((juxt (fn [_] distribution-type) first rest) (vals rec)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn- truthy-string? [s]
  (case (clojure.string/lower-case s)
    (&quot;true&quot; &quot;false&quot;) true 
    nil))</pre></div><div class="docs"><p>Parses values in legacy record into a normalized representation.  Symbols 
   become keywords, lists are assumed to be expressions that need to be 
   evaluated, vectors are recursively parsed (i.e. symbol->keyword).  Simplifies
   later processing, since we can use keywords synonymously with symbols.</p>
</div><div class="codes"><pre class="brush: clojure">(defn parse-legacy-field
  [v]  
  (cond (symbol? v) (keyword v)
        (list? v)   (eval v)
        (vector? v) (vec (map parse-legacy-field v))
        (map? v)    (let [ks (map parse-legacy-field (keys v))
                          vs (map parse-legacy-field (vals v))]
                      (zipmap ks vs))
        (string? v) (cond (= (first v) \&quot;) v
                          (truthy-string? v) (read-string 
                                               (clojure.string/lower-case v))
                          :else (parse-legacy-field (read-string v)))
        :else v)) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn check-fields [r fields]
  (assert (every? (set fields) 
                  (keys r)) 
          (str &quot;record does not conform to expected fields! &quot;
               {:record-fields (keys r)
                :expected-fields fields})))  </pre></div><div class="docs"><p>Converts a raw legacy record into a normalized record that can be processed 
   into a rule or other data structure.</p>
</div><div class="codes"><pre class="brush: clojure">(defn parse-legacy-record
  [r &amp; {:keys [expected-fields]}]
  (do (if expected-fields (check-fields r expected-fields))
    (into {} (for [[k v] r]
               [k (parse-legacy-field v)]))))</pre></div><div class="docs"><p>Returns a map that indicates the transformations to apply for start and 
   duration values, if any.  In some cases, start and duration will be 
   unmodified, i.e. derived from the source record, one or both fields may be
   missing from the resulting map.</p>
</div><div class="codes"><pre class="brush: clojure">(defn get-computed-fields
  [r]
  (let [start (apply legacy-distribution 
               (distribution-args &quot;start&quot; (rec/sub-record r start-keys)))     
        duration (apply legacy-distribution 
                   (distribution-args &quot;duration&quot; 
                        (rec/sub-record r duration-keys)))]
    (-&gt;&gt; (if start {:start start} {})
         ((fn [m] (if duration (assoc m :duration duration) m))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn include-all? [pool] (= :every (first pool)))
(def draws (atom 0))
(defn next-draw-index! []
  (let [v @draws]
    (do (swap! draws inc)
      v)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn -&gt;record-draw [nd]
  (sample/-&gt;transform 
    (fn [draws]  (let [idx (next-draw-index!)]
                   (map (fn [r] (assoc r :draw-index idx)) draws)))
    nd))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn apply-computed-fields [computed-fields original-fields]
    (let [newstart (if (contains? computed-fields :start)
                     (+ (get computed-fields :start) 
                        (get original-fields :start))
                     (get original-fields :start))]
      (merge original-fields (assoc computed-fields :start newstart))))</pre></div><div class="docs"><p>Modified to use new vocabulary.  We now allow forms of pools that
have [:no-replace [x1 x2 ....]] to use (->without-replacement ) 
instead of (->choice)</p>
</div><div class="codes"><pre class="brush: clojure">(defn no-replace? [pool]
  (case (first pool) 
    (:no-replace 'no-replace :without-replacement 'without-replacement) true
    nil))</pre></div><div class="docs"><p>Converts a raw legacy record into a sample-rule, as defined in util.sampling.
   We build a set of rules from the legacy rule records, forming them into a 
   sampling network, and then apply the ruleset to source data - usually demand 
   records.</p>
</div><div class="codes"><pre class="brush: clojure">(defn legacy-rule-record-&gt;sample-rule
  [rule-record]
  (let [parsed (parse-legacy-record rule-record 
                      :expected-fields legacy-rule-keys)
        distributions (get-computed-fields parsed)
        [name freq pool] (rec/get-fields parsed [:Rule :Frequency :Pool])]
    (-&gt;&gt; (cond (include-all? pool)
                  (sample/-&gt;transform flatten 
                        (sample/-&gt;replications 1 (subvec pool 1)))    ;;this looks suspect       
               (no-replace? pool)
                  (let [xs (second pool)]
                    (assert  (vector? xs) (str &quot;invalid pool sample :&quot; pool &quot;, expected a nested vector!&quot;))
                    (sample/-&gt;without-replacement xs))
               :else
                 (sample/-&gt;choice pool))
         ((fn [nd] (if (empty? distributions) nd 
                     (sample/-&gt;transform 
                       (fn [xs] 
                         (let [sampled-fields ((sample/merge-stochastic
                                                distributions) {})
                               f (partial apply-computed-fields sampled-fields)]
                               (map f xs))) nd))))
         ((fn [nd] (if (&gt; freq 1)                              
                     (sample/-&gt;replications freq [(-&gt;record-draw nd)])
                     (-&gt;record-draw nd))))
         (sample/-&gt;transform flatten)
         (assoc {} name))))</pre></div><div class="docs"><p>Given a table of demand-records, converts the table into a map of records 
   according to legacy processing rules.  Specifically, we add two fields to 
   the table if they don't exist [:start :duration], which are drawn from <br />
   StartDay and Duration.  records in the new table are are grouped by their 
   Group field, where each group key forms a map of entries.  These form the 
   context for executing rule-based sampling queries.</p>
</div><div class="codes"><pre class="brush: clojure">(defn read-legacy-population
  [table &amp; {:keys [group-field start-field duration-field] 
            :or {group-field :Group 
                 start-field :StartDay 
                 duration-field :Duration}}]
  (let [get-col (fn [fld] (first (vals (tbl/get-field fld table))))]
    (-&gt;&gt; table 
        (tbl/conj-fields {:start    (get-col start-field)
                          :duration (get-col duration-field)})
        (tbl/table-records)
        (group-by (comp keyword group-field)))))</pre></div><div class="docs"><p>This is a slight hack, until I get concatenation working in the dsl.
We just return a sequence of rule nodes, rather than a map of rule-name 
to rules.  </p>
</div><div class="codes"><pre class="brush: clojure">(defn read-legacy-rules [table]
  (let [recs (tbl/table-records table)]
    (assert (= (count (distinct (map :Rule recs)))
               (count recs)) (str &quot;Detected indentical rules, &quot; 
                                &quot;ensure that Rule field is distinct&quot; 
                                &quot;for each case&quot;))
       (reduce merge (map legacy-rule-record-&gt;sample-rule recs))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def case-fields [&quot;CaseName&quot; &quot;Enabled&quot; &quot;Futures&quot; &quot;MaxDuration&quot; 
                  &quot;RandomSeed&quot; &quot;Tfinal&quot; &quot;Replacement&quot;])</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def case-keys (vec (map keyword case-fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn parse-legacy-case [record] 
  (parse-legacy-record record :expected-fields case-keys))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn compound-key [xs]
  (-&gt;&gt; (interleave (map #(let [x (str %)] 
                           (if (= (first x) \:) 
                             (apply str (rest x)) 
                             x))   xs)
                   (repeat \-))
       (butlast)
       (apply str)
       (keyword)))</pre></div><div class="docs"><p>Wrapper for build-case.  Added to enforce O(1) memory constraints when 
   sampling from demand futures.  Rather than embedding the (potentially 
   high) future replications in the case rules using a replication node, 
   we treat the case rules as a sampler.  The sampler is responsible 
   for generating a uniquely identified case future, every time it is 
   sampled.  Also, the return is a map that describes a sampling operation
   rather than a pre-cooked set of samples.  In this case, the sampling 
   operation is evaluated as needed, to generate a set of samples - 
   identical in function to the old Helmet sampling rules.</p>

<p>Patched to fix a memory leak....Replacement for build-case. We now
encode the specified amount of futures in an intermediate sampler
specification map, rather than generating the entirety of the
samples for all futures at once.  This should scale much better
for larger cases, so long as we process the sampled futures lazily,
and without retaining the head.</p>
</div><div class="codes"><pre class="brush: clojure">(defn case-&gt;sampler
  [case-name case-rules future-count duration-max seed tfinal replacement]
  (let [idx           (atom 0)        
        seeder        (stats/make-random seed)
        next-idx!     (fn [] (let [i @idx]  (swap! idx inc) i))
        next-seed!    (fn [] (stats/draw seeder))]
    {case-name 
     {:case-name case-name
      :samples   future-count 
      :sampler
      (sample/-&gt;constrain 
              {:tfinal tfinal :duration-max duration-max  :seed seed}
       (stats/with-seed (next-seed!)  ;hack, we're re-seeding here for
                                      ;each rep, should have been
                                      ;covered in -&gt;constrain !
         (sample/-&gt;transform 
          (fn [case-futures] 
            (let [i (next-idx!)]
              (-&gt;&gt;  case-futures
                    (map #(let [vig (str (:Vignette %) &quot;_&quot; (:draw-index %))] ;tag
                               (merge % {:case-name  (tbl/field-&gt;string case-name)
                                         :case-future i
                                         :Vignette    vig
                                         :Operation   (str vig  &quot;_&quot; (:Operation %))}))))))
          (sample/-&gt;concatenate case-rules))))}}))</pre></div><div class="docs"><p>Given a sampling environment - typically the population from a helmet case 
   - and a sampler, returns a lazy sequence of stochastic futures.  Intended to 
   be used with doseq, or any other process that does not retain the head of the 
   sequence.</p>
</div><div class="codes"><pre class="brush: clojure">(defn sampler-&gt;stream 
  [env s]
  (when (&gt; (:samples s) 0)
    (lazy-seq 
     (cons (sample/sample-from env (:sampler s))
           (sampler-&gt;stream env (assoc s :samples (-&gt; s :samples dec)))))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn read-legacy-cases [table] (-&gt;&gt; (tbl/table-records table)
                                  (map parse-legacy-case)
                                  (filter :Enabled)))</pre></div><div class="docs"><p>Patched to use case->sampler, for lazy sampling of futures.</p>
</div><div class="codes"><pre class="brush: clojure">(defn compose-cases [case-records case-rules]
  (reduce (fn [acc case-record] 
            (let [{:keys [Futures Tfinal RandomSeed Enabled MaxDuration CaseName 
                          Replacement]} case-record]
              (conj acc 
                    (case-&gt;sampler CaseName (get case-rules CaseName) 
                                   Futures MaxDuration RandomSeed 
                                   Tfinal Replacement))))
          {} case-records))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn read-casebook [&amp; {:keys [wbpath ignore-dates?]}]
  (let [db (into {} (for [[k table] (xl/xlsx-&gt;tables 
                                      (or wbpath (gui/select-file))
                                      :ignore-dates? ignore-dates?)]
                      [k (tbl/keywordize-field-names table)]))
        case-records (read-legacy-cases (get db &quot;Cases&quot;))
        active-cases (map :CaseName case-records)
        population {:Population
                        (read-legacy-population (get db &quot;DemandRecords&quot;))}
        rules   (into {} (for [k  active-cases]
                           (let [rule-table (or (get db k)
                                                (get db (tbl/field-&gt;string k))        
                                                (throw (Exception. 
                                         (str &quot;Table &quot; k &quot; does not exist&quot;))))]
                             ;This is a hack at the moment.  We only return the
                             ;rule nodes of the the rule-table.
                             ;[case-name (read-legacy-rules rule-table)])))
                             [k (vals (read-legacy-rules rule-table))])))
        cases       {:Cases (compose-cases case-records rules)} 
        validation  {:ValidationRules (get db &quot;ValidationRules&quot;)}
        demandsplit {:DemandSplit (get db &quot;DemandSplit&quot;)}]
    (merge cases population validation demandsplit)))</pre></div><div class="docs"><p>Given a map of tables, process each case, building its associated rule set, 
   drawing from a sample population.  The results from each case are returned 
   via sampler->stream, where the entries in the stream are a seq of records 
   in a future.  Each record will have the case-name and the case-future added as 
   fields.  The table map, or the database, is expected to have at least the 
   following fields [:ValidationRules :DemandRecords :Cases], where each value
   is a table.  Each enabled case will be evaluated, returning a seq of 
   [[case-name case-future] lazy-records]</p>

<p>Patched.
Changed from original, patched to use lazy sequences and to eschew
intermediate maps (i.e. forcing results). This should return a 
map of lazy sequences of partitions of futures for each case. 
That's mouthful.  So, [[case-name case-future] lazy-records]
should be the outcome.  From here, we're ready to post process 
each set of lazy-records with collisions and splitting, etc.
We already have the case-name and case-future embedded in each 
record in the demand. </p>
</div><div class="codes"><pre class="brush: clojure">(defn compile-cases
  [db &amp; {:keys [field-merges] 
         :or   {field-merges {:start :StartDay 
                              :duration :Duration}}}]
  (let [case-key   (juxt :case-name :case-future)
        fix-fields (comp (partial collapse-fields field-merges) integral-times)]
    (concat
     (for [[case-name sampler]  (:Cases db)
           records-in-future  (sampler-&gt;stream (:Population db) sampler)] ;generate stream of futures 
       (-&gt;&gt; records-in-future
            (map      fix-fields)  ;window dressing
            (vector (case-key (first records-in-future))))))))</pre></div><div class="docs"><p>Given a seq of records, a map of split timings and a map of collision 
   classes, processes the sequence of records by handling collisions, then 
   applying the split logic. </p>
</div><div class="codes"><pre class="brush: clojure">(defn collide-and-split
  [splitmap classes xs &amp; {:keys [log?]}]
  (split/split-future splitmap  
    (collision/process-collisions classes xs :log? log?)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn table-&gt;lookup [db tbl-name lookup-field]
  (into {} (for [r (tbl/table-records (get db tbl-name))]
             [(get r lookup-field) r])))</pre></div><div class="docs"><p>Patched to support post-process-cases </p>
</div><div class="codes"><pre class="brush: clojure">(defn process-if [pred f xs] (if pred (f xs) xs))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn validate-splitmap [m]
  (assert (not= (keys m) (list nil))
          &quot;Splitting information appears to be invalid, ensure that you 
            have a DemandSplit field in the DemandRecords table, and a 
            DemandSplit field in the DemandSplit table.&quot;)
  m)</pre></div><div class="docs"><p>Changed the lookup field to use a column called DemandSplit, with 
corresponding column in the population of records.</p>
</div><div class="codes"></div><div class="docs"><p>Default post processing for each case.  We validate the case records by 
   handling collisions, and split the resulting data according to the 
   rules defined by DemandSplit.</p>

<p>Patched to avoid intermediate hash-map.</p>
</div><div class="codes"><pre class="brush: clojure">(defn post-process-cases
  [db futures &amp; {:keys [log? processes]}]
  (let [splitmap (validate-splitmap 
                   (table-&gt;lookup db :DemandSplit     :DemandSplit))
        classes  (table-&gt;lookup db   :ValidationRules :DependencyClass)]    
    (for [[case-key case-records] futures]
      [case-key
       (-&gt;&gt; case-records 
            (process-if (:collide processes)
                #(collision/process-collisions classes % :log? log?))
            (process-if (:split processes) 
                #(split/split-future splitmap %)))])))</pre></div><div class="docs"><p>Patched to included discrete processes..</p>
</div><div class="codes"><pre class="brush: clojure">(defn xlsx-&gt;futures [wbpath &amp; {:keys [ignore-dates? log? processes] 
                               :or {ignore-dates? true
                                    log? true
                                    processes #{:collide :split}}}]
  (let [db (read-casebook :wbpath wbpath :ignore-dates? ignore-dates?)]
    (post-process-cases db (compile-cases db) :log? log? :processes processes)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn futures-&gt;tables [futures &amp; 
                       {:keys [field-order] :or
                        {field-order 
                         (into demand-keys [:case-name :case-future])}}]
  (for [[case-name records] futures]
    [case-name  (-&gt;&gt; (tbl/records-&gt;table records)
                     (tbl/order-fields-by field-order)
                     (tbl/stringify-field-names))])) </pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.processing.helmet.collision" name="marathon.processing.helmet.collision"><h1 class="project-name">marathon.processing.helmet.collision</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs"><p>This is a small script for handling a set of business rules that define 
classes of collisions between data records.  In retrospect, a better solution
would be to define classes of collisions via some pattern construct, and then
add to the patterns as needed.  Anyway, this guy works for now..</p>
</div><div class="codes"><pre class="brush: clojure">(ns marathon.processing.helmet.collision)</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(def ^:dynamic *log-collisions* nil) </pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn start-time [record] (:StartDay record))
(defn end-time [record]   (+ (:StartDay record) (:Duration record)))
(defn duration [record]   (:Duration record))
(defn record-&gt;segment [r] [(start-time r) (end-time r)])</pre></div><div class="docs"><p>assumes record2 has bigger start time than record1</p>
</div><div class="codes"><pre class="brush: clojure">(defn near? [space record1 record2]
  (&lt; (- (:StartDay record2) (end-time record1)) space))</pre></div><div class="docs"><p>assumes record2 has bigger start time than record1
Need to check with Josh over what Overlap means.</p>
</div><div class="codes"><pre class="brush: clojure">(defn overlap? [record1 record2]   (&lt; (start-time record2) (end-time record1)))  </pre></div><div class="docs"><p>assumes record2 has bigger start time than record1</p>
</div><div class="codes"><pre class="brush: clojure">(defn contained? [record1 record2] (&lt; (end-time record2) (end-time record1)))
(defn priority-same? [record1 record2]
  (= (:Priority record1) (:Priority record2)))
(defn priority-greater? [record1 record2]
  (&lt; (:Priority record1) (:Priority record2)))</pre></div><div class="docs"><p>added from patch </p>
</div><div class="codes"><pre class="brush: clojure">(defn higher-priority [l r] (&lt; (:Priority l) (:Priority r)))
(defn adjacent? [l r] (= (end-time l) (start-time r)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn- log-fix [cause in result]
  (println (str &quot;Resolved collision &quot; cause \newline &quot; In: &quot; in 
                    \newline &quot; Out: &quot; result)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defmacro with-response [msg in &amp; body]
  `(let [res# ~@body]
     (do (if *log-collisions*      
           (log-fix ~msg ~in res#))
       res#)))</pre></div><div class="docs"><p>assumes left subsumes right.</p>
</div><div class="codes"><pre class="brush: clojure">(defn merge-records [l r]
  (with-response :simple-merge [l r]
    [(assoc l :Duration (- (max (end-time r) (end-time l)) (start-time l)))]))</pre></div><div class="docs"><p>assumes left contains right, returns 3 records.</p>
</div><div class="codes"><pre class="brush: clojure">(defn fix-contained [l r]
  (if (priority-greater? l r) 
    ; return l if it has higher priority and envelops r
    (with-response :left-envelops-right [l] [l])
    (with-response :right-partitions-left [l r]
      [(assoc l :Duration (- (start-time r) (start-time l)))
       r
       (merge l {:StartDay (end-time r)
                 :Duration (- (end-time l) (end-time r))})])))</pre></div><div class="docs"><p>fix two overlapping records, depending on their priority.</p>
</div><div class="codes"><pre class="brush: clojure">(defn fix-overlapped
  [l r]
  (let [[pl pr] (map :Priority [l r])]
        (if (&lt; pr pl) ; if the second record has higher priority
              ;truncate end of first record where the second record starts
          (with-response :right-truncates-left [l r]
            [(assoc l :Duration (- (start-time r) (start-time l))) r])
          ;else if the first record has higher priority, truncate to
          (with-response :left-truncates-right [l r]
            [l (merge r {:StartDay    (end-time l)
                         :Duration (- (end-time r) (end-time l))})]))))</pre></div><div class="docs"><p>New function to fix a third case of collisions.  Accounts for stretch cases.</p>
</div><div class="codes"><pre class="brush: clojure">(defn fix-stretch [l r]
  (when (not (adjacent? l r))
    (if (higher-priority r l)
      (with-response :left-stretches-to-right [l r]
        [(assoc l :Duration (- (start-time r) (start-time l))) r])
      (with-response :right-stretches-to-left  [l r]
        [l (assoc r :StartDay (end-time l))]))))</pre></div><div class="docs"><p>Patched due to a missing case, for records that need to be stretched, we were
failing to perform any operation. </p>
</div><div class="codes"></div><div class="docs"><p>fix-collision::record -> record -> [record]</p>
</div><div class="codes"><pre class="brush: clojure">(defn fix-collision [tmin l r]
  (if (not (near? tmin l r))
    (throw (Exception. &quot;Nothing to fix!&quot;))
    ; if two records are within minimum-space of each other
    ;if the two records have same priority
    (cond (priority-same? l r) (merge-records l r)
          (contained? l r)     (fix-contained l r)
          (overlap? l r)       (fix-overlapped l r)
          :else                (fix-stretch l r)))) ;new case</pre></div><div class="docs"><p>new case</p>
</div><div class="codes"></div><div class="docs"><p>should-fix?::record -> record -> boolean
fix::record -> record -> [record]
If fix returns nil, we assume that no fixes were
necessary, i.e. 1 and r were already clean.</p>
</div><div class="codes"><pre class="brush: clojure">(defn fix-records [should-fix? fix xs]
  (loop [remaining xs
         clean []]
    (cond (empty? remaining) clean
      (= (count remaining) 1) (into clean remaining)
      :else (let [l (first remaining)
                  r (second remaining)]
              (if (should-fix? l r)
                (if-let [fixed (fix l r)] ;check iff fix actually does something.
                  (recur (into fixed (drop 2 remaining)) clean) ;process fixed
                  (recur (rest remaining) (conj clean l)));if fixed is nil advance.
                (recur (rest remaining) (conj clean l))))))) ; advance.</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn work-groups [classes xs]
  (let [groups (group-by :DependencyClass xs)]
    (reduce (fn [acc [k v] ]
              (let [vs (get acc k {})]
                (assoc acc k (concat vs v)))) {}
            (map first (for [[k v] groups]
                         (if (contains? classes k)
                           {:collides v}
                           {:static   v}))))))
(defn fix-group [space xs]
  (fix-records (partial near? space)
               (partial fix-collision space) (sort-by start-time xs)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn prioritize-groups [classes xs]
  (-&gt;&gt; (for [[group-key recs] (group-by :DependencyClass xs)]
         (let [class-rec (get classes group-key)               
               p         (:Priority class-rec)
               space     (:MinTime class-rec)]
           (assert (and p space)
                   (str &quot;Could not find Priority or MinTime fields for &quot;
                        group-key))
           {:Priority p
            :space    space
            :records  (fix-group space (map #(assoc % :Priority p) recs))}))
    (sort-by :Priority)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn merge-groups
  ([left-group right-group]
    (if (every? (complement empty?) [left-group right-group])
      (let [space (min (:space left-group)
                       (:space right-group))
            ls (:records left-group)
            rs (:records right-group)]
        {:space space :records (fix-group space (concat ls rs))})
      (let [g (if (nil? left-group) left-group right-group)
            space (:space g)]
        {:space space :records (fix-group space (:records g))}))))</pre></div><div class="docs"><p>let process-collisions be a function::map -> record sequence -> record sequence
where, given a map of collision classes, and a record sequence, a new sequence
of records is returned that resolves any collisions existing in the input
record sequence, according the data derived from the collision-class map.</p>
</div><div class="codes"><pre class="brush: clojure">(defn process-collisions-sub
  [classes xs]
  (:records (reduce merge-groups (prioritize-groups classes xs))))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn fields-&gt;key [fields r]  (apply str (map #(get r %) fields)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn process-collisions
  [classes xs &amp; {:keys [src log? key-fields]
                 :or {src nil 
                      log? nil 
                      key-fields [:SRC :Title10_32]}}]
  (binding [*log-collisions* log?]
	  (let [f (if src
	            #(filter (fn [r] (= (:SRC r) src)) %)
	            identity)
	        {:keys [collides static]} (work-groups classes (f xs))]
	    (-&gt;&gt; collides
	      (group-by (partial fields-&gt;key key-fields))
	      (vals)        
	      (map (partial process-collisions-sub classes))       
	      (concat)
	      (flatten)        
	      (into static)))))</pre></div><div class="docs"><p>(defn read-recs [somefile]
 (read-string (slurp somefile)))</p>
</div><div class="codes"></div><div class="spacer docs">&nbsp;</div><div class="codes"></div><div class="docs"><div class="docs-header"><a class="anchor" href="#marathon.processing.helmet.split" name="marathon.processing.helmet.split"><h1 class="project-name">marathon.processing.helmet.split</h1><a class="toc-link" href="#toc">toc</a></a></div></div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(ns marathon.processing.helmet.split
  (:require [spork.util [sampling :as sample]]))</pre></div><div class="docs"><p>Document this badboy...
Patched..due to some complexities in splitting.</p>
</div><div class="codes"></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn add-group-times [splitmap xs &amp; {:keys [fields]
                                      :or  {fields [:DemandSplit :draw-index]}}]
  (let [gtimes (into {} (for [[[splitkey _] recs]
                            (group-by (apply juxt fields) xs)]
                          [splitkey (min (map :start recs))]))]
    (into {}
          (map (fn [[k rec]] [k (assoc rec :earliest-time (get gtimes k))])
               (seq splitmap)))))</pre></div><div class="docs"><p>Overriding the function from sample/split-record, since it's boffed.  This is 
   simple split function that bifurcates a record at t.  Assumes the record 
   intersects t, returns 2 records.</p>
</div><div class="codes"><pre class="brush: clojure">(defn split-record
  [t record &amp; {:keys [separation] :or {separation 0}}] 
  (let [[s d] [(get record :start) (get record :duration)]
        e (+ s d)
        d1 (- t s) 
        s2 t
        d2 (- e t)]
    [(assoc record :duration (- d1 separation))
     (merge record {:start t :duration d2})]))</pre></div><div class="docs"><p>Given a sequence of records, xs, scans the records up to the time  t defined 
   by [k :DayRule] in splitmap, applying a "split" that logically partitions
   the records into two groups: those that happen before t, and those that 
   happen after t.  Records that happen after t are additionally transformed 
   by an optional function f.  Note -> t is assumed to be a time relative to the
   records xs, such that xs will be split according to the earliest start in xs
   plus t.</p>

<p>Patched
helmet post processing....
we need to process each future using two scripts.
This is a little bit of a hack, but it's fairly general...</p>
</div><div class="codes"><pre class="brush: clojure">(defn split-by-time
  ([f t xs]
    (if (&gt; (:start (first xs)) t)
        (map f xs)
        (loop [status    :scanning
               remaining xs
               acc       []]
        (if (empty? remaining) 
          acc
          (let [x (first remaining)]         
            (cond 
              (and (= status :scanning) 
                   (sample/segment-intersects? (sample/record-&gt;segment x) t))
              (let [[l r] (split-record t x)]
                (recur nil (cons r (rest remaining)) (conj acc l)))
              (= status :scanning)
                (recur :scanning (rest remaining) (conj acc x))
              :else (recur status (rest remaining) (conj acc (f x)))))))))
    ([t xs] (split-by-time identity t xs)))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn title32? [r] (= (int (:Title10_32 r)) 32))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn add-start-dur [r] 
  (merge r {:start (get r :StartDay)
            :duration (get r :Duration)}))</pre></div><div class="docs">
</div><div class="codes"><pre class="brush: clojure">(defn drop-start-dur [r]
  (-&gt; (merge r {:StartDay (get r :start) 
                :Duration (get r :duration)})
      (dissoc :start)
      (dissoc :duration)))</pre></div><div class="docs"><p>Patched to account for unique draws and demandgroups.</p>
</div><div class="codes"></div><div class="docs"><p>Given a map of {demandgroup1 {:DayRule x :SourceFirst y},
                   demandgroup2 {:DayRule x :SourceFirst y}}
   Applies the rules defined by the demand group to the records in xs.</p>
</div><div class="codes"><pre class="brush: clojure">(defn split-future
  [splitmap xs &amp; {:keys [exclude?] 
                  :or   {exclude? title32?}}]
  (-&gt;&gt; (for [[[splitkey _] split-recs] 
             (group-by (juxt :DemandSplit :draw-index) (map add-start-dur xs))]
        (if-let [{:keys [SourceFirst DayRule]} (get splitmap splitkey)]
          (let  [tmin (reduce min (map :start split-recs))
                 recs-by-src (map #(sort-by :start %)
                                 (vals (group-by :SRC split-recs)))]
            (map (fn [recs]                   
                   (let  [{:keys [in out]} 
                          (group-by #(if (exclude? %) :out :in) recs)]
                     (into out 
                           (when in 
                         (split-by-time 
                           #(merge % {:SourceFirst SourceFirst
                                      :Operation  (str (:Operation %) 
                                                       \_ &quot;Rotational&quot;)}) 
                           (+ tmin DayRule) in)))))   recs-by-src))
           split-recs))
    (flatten)
    (map drop-start-dur)))</pre></div><div class="docs"><p>probably move this guy out at some point...</p>
</div><div class="codes"></div><div class="docs"><p>Perform a sensitivity analysis for a single future.
If we're doing a sensitivity analysis, one way to look at it 
is to vary something, and measure the sensitivity of the result.
It's a simple experiment.  At the barest level, we're just doing 
repeated evaluations of functions relative to input variation,
albeit the variation is controlled.</p>
</div><div class="codes"></div><div class="docs"><p>We can do a very quick sensitivity check by compiling stochastic
demand for a future, NOT processing its demand split, and then 
creating N futures where the demand split is varied.  We may 
include this in a later run...</p>
</div><div class="codes"><pre class="brush: clojure">(defn future-&gt;multiple-splits [xs splitmap splitnums &amp; {:keys [exclude?] 
                                                        :or   {exclude? title32?}}]
  (assert (every? pos? splitnums) &quot;Inputs for splitnums must all be positive numbers&quot;)
  (let [new-split (fn [n]  (persistent! (reduce-kv 
                                        (fn [acc k v] (assoc! acc k (assoc v :DayRule n))) (transient {}) splitmap)))]
    (-&gt;&gt; (map new-split splitnums)
         (map-indexed (fn [idx sm] (-&gt;&gt; (split-future sm xs :exclude? exclude?)
                                        (map #(assoc % :SplitCase (nth splitnums idx)))))))))</pre></div><div class="spacer docs">&nbsp;</div><div class="codes"></div></body><div class="footer">Generated by <a href="https://github.com/fogus/marginalia">Marginalia</a>.&nbsp;&nbsp;Syntax highlighting provided by Alex Gorbatchev's <a href="http://alexgorbatchev.com/SyntaxHighlighter/">SyntaxHighlighter</a>marginalia.html$floating_toc_html@c827db</div><script type="text/javascript">SyntaxHighlighter.defaults['gutter'] = false;
SyntaxHighlighter.all();

// hackity hack
$(window).load(function() {
    var ft = $("#floating-toc");
    var ul = ft.find('ul');
    var lis = ft.find('li');
    var liHeight = $(lis.first()).height();

    ul.css('margin', '0px');
    ft.css('height', liHeight + 'px');

    showNs = function(ns) {
        var index = 0;

        for(i in nsPositions.nss) {
            if(ns == nsPositions.nss[i]) index = i;
        }

        if(index != lastNsIndex) {
            lastNsIndex = index;
            ul.animate({marginTop: (-1 * liHeight * index) + 'px'},
               300);
        }

    }

    var calcNsPositions = function() {
        var hheight = $('.docs-header').first().height();
        var nss = [];
        var anchors = [];
        var positions = [];
        $.each(lis, function(i, el) {
            var ns = $(el).attr('id').split('_')[1];
            nss.push(ns);
            var a = $("a[name='"+ns+"']");
            anchors.push(a);
            positions.push(a.offset().top - hheight);
            // console.log(a.offset().top)
        });

        return {nss: nss, positions: positions};
    }

    var nsPositions = calcNsPositions();
    // console.log(nsPositions)
    var lastNsIndex = -1;
    var $window = $(window);

    var currentSection = function(nsp) {
        var ps = nsp.positions;
        var scroll = $window.scrollTop();
        var nsIndex = -1;

        for(var i = 0, length = ps.length; i < length; i++) {
            if(ps[i] >= scroll) {
                nsIndex = i-1;
                break;
            }
        }

        if(nsIndex == -1) {
             if(scroll >= ps[0]) {
                 nsIndex = ps.length - 1;
             } else {
                 nsIndex = 0;
             }
        }

        return nsp.nss[nsIndex];
    }

    $(window).scroll(function(e) {
        showNs(currentSection(nsPositions));
    });
});
</script></html>